---
layout: post
title:  1.3 Computer System Architecture
date:   2025-06-13 14:25:51 +0900
categories: ComputerScience OS
---

<!--more-->
컴퓨터 시스템은 프로세서의 수와 배치 구조에 따라 다양한 아키텍처로 구분된다. 본 글에서는 단일 프로세서 시스템부터 멀티프로세서, 클러스터 시스템까지 주요 구조를 체계적으로 살펴본다.

## 📂 목차
- [1.3.1 Single-Processor Systems](#131-single-processor-systems)
    - [Single Core](#single-core)
    - [Special-purpose Processor](#special-purpose-processor)
- [1.3.2 Multiprocessor Systems](#132-multiprocessor-systems)
    - [Symmetric MultiProcessing, SMP](#symmetric-multiprocessing-smp)
    - [Multi-Core System](#multi-core-system)
    - [확장성의 한계와 NUMA](#확장성의-한계와-numa)
    - [Blade Server](#blade-server)
- [1.3.3 Cluster System](#133-cluster-systems)
    - [High Availability Service](#high-availability-service)
    - [Cluster Structures](#cluster-structures)
    - [Parallel Cluster & HPC](#parallel-cluster--hpc)
    - [WAN Clustering & Shared Disk](#wan-clustering--shared-disk)

---

## 📚 본문

일반적인 컴퓨터 시스템은 사용되는 범용 **[프로세서](#processor)**의 수에 따라 대략적으로 분류 가능하다.

### 1.3.1 Single-Processor Systems

컴퓨터 시스템은 **사용되는 프로세서 수와 구조**에 따라 다음과 같이 구분된다.

#### Single Core

- 하나의 **[CPU](#cpu)** + **하나의 [Core](#core)**를 가지는 시스템이다.
- CPU는 **[General-purpose Instruction Set](#general-purpose-instruction-set)** 및 **[사용자 프로세스](#사용자-프로세스)**를 실행 가능하다.

#### Special-purpose Processor

- 디스크, 키보드, 그래픽 컨트롤러등에 **전용 마이크로프로세서**가 탑재된 걸 **특수 목적 프로세서**라고 한다.
- **[Special-purpose Instruction Set](#special-purpose-instruction-set)**만을 실행하고, 일반적인 프로세스를 실행하지 않는다.
- 운영체제가 이들을 직접 제어하거나 상태를 모니터링 한다.

> 예시
> 디스크 컨트롤러 마이크로프로세서: 메인 CPU로 부터 요청을 받아서 자체 **[Disk Queue](#disk-queue) 및 [Scheduling Algorithm](#scheduling-algorithm)**을 실행
> 키보드 내부 마이크로 프로세서: **키 입력을 감지하고 코드로 변환**하여 CPU로 전송하는 마이크로 프로세서가 내장

다른 시스템이나 상황에서는 이러한 특수 목적 프로세서가 하드웨어에 저수준 컴포넌트로 내장되어 있다. 운영체제는 이들과 직접 통신은 못하고 프로세서가 독립적으로 작업을 수행하게 된다.

**특수 목적 마이크로 프로세서가 여러개 있다고 시스템이 멀티 프로세서 시스템이 되는 것은 아니다.**

### 1.3.2 Multiprocessor Systems

단일 처리는 느릴 수 있고 CPU가 연산 처리하는데 있어 다수의 Device의 요청을 받게 되면 지연될 수 있다.

이러한 시스템은 컴퓨터 하나에 두 개 이상의 Processor를 가지는 형태로 구성하여 **[Throughput(처리량)](#throughput)**과 속도를 늘릴 수 있다. 프로세서들은 **[Computer Bus](#computer-bus)**를 공유하며 **[Clock Signal](#clock-signal)**, 메모리, 주변 장치를 공유한다. 하지만 **N개의 프로세서를 사용한다고 해서 성능이 N배 빨라지는 것은 아니다.**

이는 각 구성 요소들이 제대로 작동하도록 유지하는 데 드는 오버헤드가 발생하기 때문이며, 공유 자원에 대한 **[Contention(경합)](#contention)** 도 추가로 발생하기 때문에 기대에 못미치는 성능 향상을 얻을 수 있다.

멀티프로세서 시스템에서도 두 가지로 크게 나눌 수 있다.

#### Symmetric MultiProcessing, SMP

각 CPU 프로세서가 동등한 입장에서 운영체제의 기능과 사용자 프로세스를 모두 처리할 수 있는 시스템을 **Symmetric MultiProcessing System** 이라고 한다.

![symmetric-multiprocessing-architecture]({{site.baseurl}}/assets/img/symmetric-multiprocessing-architecture.png)

각 CPU는 자신만의 **[Register Set](#register-set)**과 **Local Cache**를 가지고 있지만, 모든 프로세서는 **System Bus**를 통해 물리적 메모리를 공유한다.

장점으로는:
- N개의 CPU가 있다면 N개의 프로세스가 동시에 실행이 가능하다.
- 전체 시스템의 성능이 크게 저하되지 않는다.

단점으로는 어떤 CPU 는 **Idle** 인 반면, 다른 CPU 는 **Overrloaded** 상태가 되는 비효율이 발생할 수 있다.

이런 비효율성은 프로세서 간에 특정 데이터 구조나 자원을 공유함으로써 이를 완화할 수 있다. 시스템은 **프로세스나 자원을 동적으로 여러 프로세서 사이에서 공유할 수 있어서 프로세서 간 작업량의 편차를 줄이는데 도움**이 많이 된다.

하지만 공유에 있어서 **자원의 제어권을 명백히 구분해야하기 때문에 매우 신중하게 설계**되어야 한다.

#### Multi-Core System

멀티프로세서 시스템에서 **하나의 칩에 여러 연산 코어가 존재하는 멀티 코어 시스템**도 포함된다.

![a-dual-core-design-with-two-cores-on-the-same-chip]({{site.baseurl}}/assets/img/a-dual-core-design-with-two-cores-on-the-same-chip.png)

-  **[칩 내부의 코어 간 통신(on-chip communication)](#on-chip-communication)** 이 **칩 간 통신(between-chip communication)**보다 훨씬 빠르기 때문에 단일 코어를 여러 칩에 나눠 배치하는 구조보다 더 효율적
- 전력을 훨씬 더 적게 소비
- 각 코어는 **Register Set** + **[L1 Cache](#l1-cache)** 보유, 각 프로세스는 **[L2 Cache](#l2-cache)**를 통해 칩끼리 메모리 공유

운영체제 입장에서는 N개의 일반적인 CPU 처럼 보이게 된다.

따라서 운영체제 설계자와 어플리케이션 프로그래머에게 이러한 처리 코어들을 효율적으로 활용해야 할 부담을 가지게 되는데 이는 추후에 다룬다.

**연산 처리 계층적 구조 정리**
- Processor (물리적 칩)
    - Core (실제 연산 단위)
        - Register Set (가장 빠르고 가장 작은 기억장소)
        - L1 Cache (코어별 고속 캐시)
        - L2 Cache (대부분 코어 간 공유되는 캐시)

#### 확장성의 한계와 NUMA

멀티 프로세서 시스템에 CPU를 추가하면 계산 성능은 증가하지만, 무한히 확장되지는 않는다. 또한 **CPU를 너무 많이 추가하면 시스템 버스에 대한 경쟁이 병목되어서 성능이 오히려 저하**가 된다.

이를 해결하기 위해
- 각 CPU에 **[전용 로컬 메모리](#전용-로컬-메모리)**를 제공
- CPU 간에는 **[System Interconnect](#system-interconnect)** 로 연결 -> **모든 CPU가 하나의 물리적 주소 공간 보유**

![NUMA-multiprocessing-architecture]({{site.baseurl}}/assets/img/NUMA-multiprocessing-architecture.png)

#### Blade Server

여러 개의 **[Processor Board](#processor-board)**, **[I/O Board](#io-board)**, **[Network Board](#network-board)** 등이 하나의 **[Chassis](#chassis)** 안에 포함된 시스템이다.

각 블레이드 **Processor Board**가 독립적으로 부팅되고, 자체 운영체제를 실행하는 구조이며, 여러 개의 독립적인 멀티프로세서 시스템으로 구성된다.

**멀티프로세서 시스템**이 한 시스템 내의 **CPU 확장을 다룬다**면, **클러스터 시스템**은 **여러 독립적인 시스템(= Node)을 확장**하여 하나의 논리적 시스템처럼 작동하게 한다.

### 1.3.3 Cluster Systems

**여러 독립적인 노드(멀티코어 컴퓨터 시스템)**를 네트워크로 느슨하게 연결하여 구성한 시스템이며, 공유 저장소를 사용하여 각 노드끼리 **[LAN](#lan) / [InfiniBand](#infiniband) 등**으로 상호 통신을 한다.

#### High Availability Service

Cluster System 은 기본적으로 **[High Availability](#high-availability)** 를 제공한다. High Availability 는 일부 노드가 장애가 발생하여도 서비스는 계속 지속될 때 얻을 수 있다.

고가용성은 다음 두 개념을 만족하는 개념이다:
- **Graceful Degradation**: 일부 하드웨어가 고장나도 남은 자원으로 서비스 유지
- **Fault Tolerance**: 단일 구성 요소(노드)가 고장나도 시스템이 끊김 없이 계속 동작

이렇게 봤을 때 **Clustering System** 은 다음 두 가지로 분류될 수 있다.

#### Cluster Structures

- **Asymmetric**: 한 노드는 **[Hot-stanby Mode](#hot-stanby-mode)**, 나머지 노드가 작업을 수행
- **Symmetric**: 여러 호스트가 동시에 다수의 실행 가능한 어플리케이션을 실행하며 상호 모니터링 수행

#### Parallel Cluster & HPC

클러스터를 병렬 처리 환경으로 사용하여 연산 성능을 극대화 가능
- 여러 노드가 동일한 저장소에 접근 가능
- 프로그램을 여러 작업 단위로 나눠 여러 노드에서 병렬 실행
- 모든 노드의 계산 결과를 통합하여 최종 결과물 생성

#### WAN Clustering & Shared Disk

- [WAN](#wan-wide-area-network) 환경에서도 클러스터 가능
- **Parallel Cluster**는 여러 노드가 동일한 저장소(공유 디스크)에 동시에 접근하지만 일반 OS는 동시 접근 미지원
- 이때 동시에 데이터를 접근해야하는 경우는 락 관리 및 접근 제어가 필요하게 된다 -> **[Distributed Lock Manager(DLM)](#distributed-lock-manager-dlm)** 소프트웨어 사용

---

## ✒️ 용어

###### CPU

명령어들을 수행하는 하드웨어이다.

###### Core

**명령어를 실행**하고 데이터를 저장하기 위한 **Register 집합을 포함하는 구성요소이며 CPU의 가장 기본적 연산 단위**이다.

###### Processor

하나 이상의 코어를 포함할 수 있는 연산 장치로, 일반적으로는 **하나의 물리적인 CPU 칩**을 말한다.

###### Multicore

다수의 Core들을 동일 CPU 에 배치한 형태이다.

###### Multiprocessor

다수의 프로세서를 포함하는 형태이다.

###### SMP (Symmetric Multiprocessing)

각 CPU가 동등한 권한으로 OS와 사용자 작업을 수행하는 구조로, 물리 메모리를 공유함

###### L1 Cache

각 코어에 직접 연결된 매우 작은 용량의 고속 캐시 메모리

###### L2 Cache

같은 칩 내부의 여러 코어가 공유하는 중간 속도의 캐시 메모리

###### NUMA (Non-Uniform Memory Access)

각 CPU에 전용 메모리를 두고, 전체적으로는 공유 주소 공간을 유지하는 구조

###### On-Chip Communication

동일한 칩 내부에서 발생하는 통신으로, 매우 빠르고 전력 효율이 높음

###### Blade Server

여러 개의 독립적인 시스템 보드(CPU, I/O, 네트워크 등)를 하나의 섀시에 탑재한 서버 형태

###### Processor Board

CPU와 메모리 등이 탑재된 **블레이드 서버의 핵심 연산 유닛**. 각 블레이드 서버는 **각각의 독립적인 Processor Board를 가지고 있어 자체적으로 연산과 처리가 가능**하다.

###### I/O Board

입출력 장치와의 연결을 담당하는 보드. 디스크, 키보드, 마우스, USB 등 다양한 장치와의 인터페이스를 제공한다. **입출력 흐름을 제어하고 데이터 전송을 중재하는 역할**을 한다.

###### Network Board

네트워크 통신을 위한 전용 보드이며, 이더넷, 파이버 채널 등 다양한 네트워크 형태를 지원한다.

- 서버 간 통신이나 외부와의 연결을 담당
- 서버의 데이터 흐름과 트래픽 처리에 중요한 역할을 함
- 고속 전송을 위해 전용 네트워크 컨트롤러가 탑재

###### General-purpose Instruction Set

운영체제와 사용자 애플리케이션에서 사용하는 일반적인 계산, 논리, 제어, 데이터 이동 등의 명령들을 포함한 CPU의 명령어 집합이다.

- **ADD, MOV, JMP, LOAD, STORE, AND, OR** 등이 있음
- 범용 CPU는 이 명령어들을 기반으로 모든 종류의 소프트웨어를 실행할 수 있음
- 이는 특정 작업만 수행하는 **전용 명령어 집합(special-purpose instruction set)** 과 대비됨

###### Special-purpose Instruction Set

**특정 하드웨어 장치를 제어하기 위한 제한된 기능의 명령어 집합**으로, 범용 명령어와 달리 **일반적인 계산이나 논리 연산은 수행하지 않는다**.

- 주로 디스크 컨트롤러, 키보드, 그래픽 카드 등에 내장된 **마이크로프로세서에서 사용됨**
- 일반 사용자 프로그램은 직접 사용할 수 없으며, 운영체제가 **장치 드라이버를 통해 간접적으로 제어**함

> 예: **START_IO, RESET_DEVICE, SCAN_KEY** 등의 간단한 명령 포함

###### Disk Queue

디스크 큐(Disk Queue)는 **디스크 I/O 요청들이 저장되는 대기열(queue)**로, 운영체제가 처리해야 할 디스크 접근 요청들을 일정한 순서에 따라 관리하기 위해 사용된다.

- 디스크에 대한 읽기/쓰기 요청이 발생하면, 해당 요청은 큐에 추가된다.
- 디스크는 한 번에 하나의 요청만 처리할 수 있기 때문에, 요청들을 순차적으로 관리해야 한다.
- 운영체제는 **특정 디스크 스케줄링 알고리즘을 통해 큐에 있는 요청들의 처리 순서를 결정**한다.
- 요청의 처리 순서에 따라 디스크의 처리 시간, 평균 대기 시간, 응답 시간 등이 달라질 수 있다.
- 디스크 큐는 특히 **하드디스크(HDD)**에서 성능에 큰 영향을 미친다 (**헤드 이동 시간 존재**).
- SSD에서는 물리적 움직임이 없지만, 여전히 I/O 요청 관리를 위해 디스크 큐 개념은 유지된다.

디스크 큐는 **운영체제가 디스크 접근 요청을 최적화하고, 전체 시스템의 I/O 성능을 향상시키는 핵심 메커니즘**이다.

###### Scheduling Algorithm

스케줄링 알고리즘은 어떤 객체을 우선적으로 핸들링할지 결정하는 방법이다. 여기 운영체제에서의 스케줄링 알고리즘은 다음 기능을 수행한다:
- 다중 프로그래밍 시스템에서 동시에 실행 대기 중인 여러 프로세스 중 하나를 선택해야 한다.
- 선택 기준과 방식에 따라 시스템의 공정성, 응답 시간, 처리량, 자원 활용률 등이 달라진다.
- CPU 스케줄링 외에도 디스크 스케줄링, 네트워크 패킷 스케줄링 등 다양한 분야에 활용된다.

###### Throughput

단위 시간 당 시스템이 처리한 작업의 양이며, 작업의 기준은 프로세스 수, 페이지 수, 전송된 비트 수 등등 다양하다.

###### Contention

여러 프로세스나 장치가 동시에 하나의 자원을 사용하려고 할 때 발생하는 충돌 현상을 경합이라고 한다.

> 두 개의 프로세스가 동시에 프린터를 사용하려 하면 한쪽은 기다려야 한다.
> 이러한 경합이 많아지면 전체 시스템 성능이 저하될 수 있다.

###### 사용자 프로세스

일반 사용자가 실행하는 응용 프로그램이나 작업을 의미하며, 운영체제가 생성하고 관리하는 프로세스 중 하나이다.

> 예: 웹 브라우저, 텍스트 편집기, 게임 등

###### 전용 로컬 메모리

NUMA 구조에서 각 CPU가 독립적으로 접근 가능한 메모리 공간을 의미하며, 해당 CPU가 직접 연결되어 빠르게 접근할 수 있는 메모리이다.

> 다른 CPU가 접근할 경우 지연(latency)이 발생할 수 있음

###### Clock Signal

컴퓨터의 모든 부품이 **동기화된 속도로 작동하도록 주기적으로 발생하는 신호**로, CPU를 비롯한 각 하드웨어 장치가 일정한 타이밍에 동작하게 만든다.

> 예: 3.0GHz의 Clock Signal는 1초에 30억 번 신호가 발생함을 의미함

###### System Interconnect

여러 CPU의 전용 로컬 메모리를 서로 연결하는 고속 데이터 통신 경로이다.  
연결은 **고속 버스, 크로스바, HyperTransport, Intel QPI** 등 다양하다.

이때 Interconnect 를 통한 **원격 메모리 접근은 지연(latency)**이 크므로 운영체제가 CPU 스케줄링 시 최대한 로컬 메모리를 사용하도록 조정해야 한다.

###### Chassis

서버나 컴퓨터 시스템에서 **여러 개의 보드(Processor, I/O, Network 등)** 를 물리적으로 탑재하고 고정하는 **외형적 하드웨어 프레임** 또는 케이스를 의미한다.

###### LAN

LAN(Local Area Network)은 **좁은 지역 내(예: 집, 학교, 회사 등)**에서 컴퓨터나 장치들을 연결하는 네트워크이며 짧은 거리에서 빠른 속도로 데이터 전송이 가능하다.

보통 **이더넷(Ethernet)**방식으로 구성되고, 하나의 공유된 자원(프린터, 파일 서버 등)을 여러 장치가 사용할 수 있도록 해준다. **라우터, 스위치, 허브 등의 네트워크 장비가 사용**된다.

__봐도 모르면 네트워크를 공부하고 오자__

###### Register Set

**CPU 코어(칩) 내부에 내장**된 고속의 작은 저장장치 집합으로, 연산에 직접 사용되는 **데이터를 일시적으로 저장**한다. 명령어 실행 중에 자주 접근해야 하는 **데이터(피연산자, 주소, 결과 등)**를 빠르게 처리할 수 있도록 하고 **RAM보다 훨씬 빠르지만 용량은 매우 작다**.

CPU마다 여러 종류의 레지스터를 가짐(이는 위에서 이미 다뤘다):
- **General-purposed Registers**: 연산 대상 데이터를 임시로 저장
- **Special-purposed Registers**: 프로그램 카운터(PC), 명령어 레지스터(IR), 스택 포인터(SP) 등
- ⭐️**Flag Register**: 연산 결과 상태(오버플로우, 0인지 등)를 저장

Register Set은 CPU 칩에 직접 포함되어 있어 처리 속도를 극대화하는 데 핵심적인 역할을 한다.

###### InfiniBand

고속 데이터 전송을 위한 서버 간 통신 인터페이스(고속 네트워크 아키텍처).
주로 슈퍼컴퓨터나 데이터센터에서 사용되며, 낮은 지연 시간과 **높은 대역폭(수십~수백 Gbps)**을 제공한다. **메모리 간 직접 접근(RDMA)**을 지원해 CPU 부담을 줄이고 효율을 높인다. **이더넷보다 빠르고 안정적이지만, 비용과 설정 난이도가 상대적으로 높다**.

###### High Availability

시스템을 가능한 한 멈추지 않도록 설계하는 개념이며, 서버나 네트워크 장애 발생 시에도 서비스가 계속 작동하도록 중복 구성을 통해 대비한다.

> 예: 이중화된 서버, 자동 장애 전환(failover), 클러스터링 등.
목표는 서비스 다운타임 최소화와 신뢰성 극대화
> 주로 금융, 병원, 통신 등 서비스 중단이 치명적인 분야에서 중요하게 사용됨

###### Hot-standby Mode

예비 시스템이 항상 작동 준비 상태로 대기하는 방식이다.

주 시스템(Main System, Main Node)이 장애를 일으키면, **즉시 예비 시스템(Standby System)**으로 자동 전환(failover)되어 서비스가 중단되지 않도록 한다.

Hot-standby는 주 시스템과 데이터를 실시간으로 동기화하거나 거의 실시간에 가깝게 유지한다.

- 예비 시스템이 항상 켜져 있고, 자원을 소비함
- 전환 속도가 매우 빠름 → 서비스 중단 시간 거의 없음
- 비용이 높지만 **High Availability**가 요구되는 환경에 적합함

> 예: 금융 서버, 통신 장비, 항공 관제 시스템 등.

###### WAN (Wide Area Network)

**광범위한 지역(도시, 국가, 대륙 간)**을 연결하는 네트워크이다. 인터넷도 WAN의 일종이며, LAN이나 MAN을 서로 연결해주는 구조이고 속도는 LAN보다 느릴 수 있지만, 넓은 거리의 통신이 가능하게 한다.

**통신 사업자의 인프라(광케이블, 위성 등)를 사용**하며, 라우팅, 보안, 대역폭 제어가 중요함.

###### Distributed Lock Manager (DLM)

분산 시스템에서 자원 접근 충돌을 방지하기 위한 잠금 관리 시스템이다.

여러 노드(서버)가 동시에 공유 자원(파일, 데이터베이스 등)에 접근할 때 **상호 배타성(Mutual Exclusion)**을 보장한다. DLM은 자원의 **소유권(lock ownership)**을 추적하고, 잠금 요청 간 충돌을 조정하여 데이터 일관성을 유지한다.

---

## 🔗 출처
- 도서: [Operating System Concepts 10th Edition]()
