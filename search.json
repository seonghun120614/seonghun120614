[
  
    {
      "title": "[멋사 백엔드 19기] TIL 45일차 Rest API",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/web/2025/10/29/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-45%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-29",
      "content": "📂 목차  Rest API          REST의 주요 원칙      Rest Controller                  HttpMessageConverter                    ResponseEntity                  ResponseEntity Builder          ResponseEntity BodyBuilder          ResponseEntity 응답 생성                    ServletUriComponentsBuilder                  CREATE REST          READ REST          UPDATE REST          DELETE REST                    Spring HATEOAS      📚 본문Rest API웹 서비스의 한 형태로 Representational State Transfer (REST) 아키텍처 스타일을 따르도록 구성하는 API 를 써야 한다.REST의 주요 원칙  자원(Resource) 기반 설계          RESTful 서비스에서 모든 콘텐츠는 자원(Resource) 으로 표현된다.      각 자원은 URI(Uniform Resource Identifier) 로 식별된다.      예시: /api/users/1 → id가 1인 사용자 자원        무상태(Stateless)          각 요청(Request)은 서버와 독립적으로 처리된다.      서버는 클라이언트의 상태를 저장하지 않으며, 모든 요청은 필요한 정보를 스스로 포함해야 한다.      이를 통해 서버 설계가 단순해지고, 확장성(Scalability) 이 높아진다.        표준 HTTP 메서드 활용          자원에 대한 CRUD 동작을 HTTP 메서드로 명확히 표현한다.                  GET: 조회(Read)          POST: 생성(Create), 멱등성 성질 X          PUT: 수정(Update)          PATCH: 부분 수정          DELETE: 삭제(Delete)                    이를 통해 API가 직관적이고 일관성 있게 설계된다.        멱등성은 동일 요청을 보내면 서버의 상태를 동일하게 유지하냐이다.  다양한 표현(Representation)          자원은 JSON, XML 등 다양한 형태로 표현될 수 있다.      클라이언트의 Accept 헤더에 따라 서버는 가장 적절한 데이터 형식으로 응답한다.        연결성(Connectivity) &amp; HATEOAS          자원들은 하이퍼링크(Hyperlink) 를 통해 서로 연결될 수 있다.      HATEOAS(Hypermedia As The Engine Of Application State) 를 통해 클라이언트는 API 응답 내 링크를 따라가며추가적인 자원에 접근할 수 있다.      Rest Controller@Controller + @ResponseBody 어노테이션의 결합이며, viewname 을 반환하는 부분이 데이터(JSON/XML) 를 직접 응답으로 보내는 컨트롤러를 의미한다.@RestController@RequestMapping(\"/users\")public class UserController {    @GetMapping(\"/{id}\")    public User getUser(@PathVariable Long id) {        return new User(id, \"홍길동\", \"hong@example.com\");    }}이전에 Controller 어노테이션은 viewname 을 반환하고, model 에 데이터를 넣어주는 역할을 하지만, 여기서는 Model 이 안쓰이기 때문에 전달하지 않고 데이터를 그대로 HandlerAdapter 에 전달한다.HttpMessageConverter데이터를 전달할 때 위처럼 객체를 전달함을 볼 수 있는데, 우선 반환값으로는 다음을 전달할 수 있다.  String  DTO  ResponseEntity&lt;?&gt;@RestController 는 객체를 반환하면 뷰를 렌더링하지 않고,HttpMessageConverter 가 그 객체를 JSON 또는 XML 형식으로 변환하여 HTTP 응답 본문(Response Body) 에 직접 기록한다.즉, HandlerAdapter 가 컨트롤러 메서드를 실행한 뒤 반환값을 전달하면, HttpMessageConverter 가 해당 객체 타입과 Accept 헤더를 참고하여 적절한 변환기(MappingJackson2HttpMessageConverter)를 선택하고 직렬화(JSON 변환)를 수행 후 반환시키게 된다.변환기 구현체  MappingJackson2HttpMessageConverter: JSON 변환  Jaxb2RootElementHttpMessageConverter: XML 변환  StringHttpMessageConverter: 문자열 처리ResponseEntityHTTP 응답을 객체의 형태로 추상화한 클래스이다. Spring MVC 에서 @RestController 나 @Controller(@ResponseBody 어노테이션을 함수에 붙여야 함) 에서 사용가능하며, HTTP 스펙 까지 세밀하게 제어가 가능하다.넣을 수 있는 정보는 다음과 같다:      Body    Headers          Content-Type      Location      Authorization        Status Code          200      201      404      …      메서드들을 파헤쳐 본다.public ResponseEntity(@Nullable T body, @Nullable MultiValueMap&lt;String, String&gt; headers, int rawStatus) {    this(body, headers, HttpStatusCode.valueOf(rawStatus));}/**    * Create a {@code ResponseEntity} with a body, headers, and a status code.    * @param body the entity body    * @param headers the entity headers    * @param statusCode the status code    */public ResponseEntity(@Nullable T body, @Nullable MultiValueMap&lt;String, String&gt; headers, HttpStatusCode statusCode) {    super(body, headers);    Assert.notNull(statusCode, \"HttpStatusCode must not be null\");    this.status = statusCode;}위가 완전체의 생성자이다. body, headers, statusCode 순으로 넣을 수 있으며, headers 에는 MultiValueMap 이 들어가는 것을 볼 수 있다. ResponseEntity 는 위 생성자 외에도 이를 builder 패턴으로 만드는 것도 허용한다. 따라서 정적 Builder 메서드들을 보자.ResponseEntity Builder우선 가장 기본적으로 ResponseEntity.status() 로 먼저 틀을 잡는다.public static BodyBuilder status(HttpStatusCode status) {    Assert.notNull(status, \"HttpStatusCode must not be null\");    return new DefaultBuilder(status);}내부적으로는 위와 같이 되어 있으며, status 가 null 이라면 당연히 예외가 발생하도록 설계되어 있다. 마지막으로는 DefaultBuilder를 생성하면서 리턴하고 있다. DefaultBuilder 는 private static 의 nested class 로 구성하여서 우리가 굳이 볼 필요는 없지만, ResponseEntity.BodyBuilder 인터페이스를 구현하는 것을 볼 수 있다. 이를 잠깐 살펴보자.ResponseEntity BodyBuilder필드  HttpStatusCode  HttpHeaders생성자  int statusCode  HttpStatusCode statusCode관련 메서드메서드는 전부 Builder 패턴이기에 method chaining 이 가능하다.header(String name, String... values)        // 단일/복수 헤더 추가headers(HttpHeaders headers)                // HttpHeaders 전체 복사headers(Consumer&lt;HttpHeaders&gt; consumer)     // 람다로 헤더 커스터마이징allow(HttpMethod... methods)        // Allow 헤더 설정contentLength(long length)          // Content-LengthcontentType(MediaType type)         // Content-TypeeTag(String tag)                    // ETaglastModified(ZonedDateTime/Instant/long) // Last-Modifiedlocation(URI location)              // Location 헤더cacheControl(CacheControl cache)    // Cache-ControlvaryBy(String... headers)           // Vary 헤더최종 생성 ResponseEntity 로 반환하는 메서드는 다음과 같다:&lt;T&gt; ResponseEntity&lt;T&gt; body(T body)  // 실제 body 포함하여 생성&lt;T&gt; ResponseEntity&lt;T&gt; build()       // body 없이 ResponseEntity 생성위를 토대로 ResponseEntity 는 HTTP 상태코드와 함께 ResponseEntity 를 쉽게 생성할 수 있게 된다.ResponseEntity 응답 생성Status 200  ok(): 상태 코드 200 OK 로 BodyBuilder 생성  ok(T body): 상태 코드 200 OK 와 body 를 포함한 ResponseEntity 생성  of(Optional&lt;T&gt; body): Optional 값이 있으면 200 OK + body, 비어있으면 404 Not Found  ofNullable(T body): null 이면 404 Not Found, null 이 아니면 200 OK + bodyStatus 201 created반드시 생성된 자원의 위치를 헤더로 알려줘야 한다.  created(URI location): 201 Created 상태 + Location 헤더 설정 주로 POST 에서 새 리소스 생성 시 사용URI location = ServletUriComponentsBuilder    .fromCurrentRequest()    .path(\"/{id}\")    .buildAndExpand(id)    .toUri();return ResponseEntity.created(location)                    .body(memo);기타 상태 코드 빌더  accepted() → 202 Accepted  noContent() → 204 No Content  badRequest() → 400 Bad Request  notFound() → 404 Not Found  unprocessableEntity() → 422 Unprocessable Entity  internalServerError() → 500 Internal Server Error이제 위를 이용하여 CRUD 전부를 만들어보자.ServletUriComponentsBuilderHTTP 요청을 기반으로 URI 를 편리하게 생성할 때 사용할 수 있는 유틸리티 클래스이며, 주로 REST API 에서 새 리소스 생성(CREATED) 후에 Location 헤더 설정에 많이 쓰이게 된다.요청 설정  fromCurrentRequest(): 현재 요청 URI 를 기준으로 Builder 생성  fromCurrentContextPath(): 컨텍스트 루트 기준  fromServletMapping(): 서블릿 매핑 기준Path 변수/쿼리 추가  path(\"/subpath\"): URI 뒤에 경로 추가  queryParm(\"page\", 1): 쿼리 파라미터 추가URI 객체 생성  buildAndExpand(Object... uriVariables): {id} 같은 Path 변수 치환  toUri(): java.net.URI 객체 반환CREATE REST201 상태 코드를 가지며, ResponseEntity.created() 함수로 간단히 세팅할 수 있다. 상태코드만 세팅 되기 때문에 body 와 header 는 자유롭게 넣어주어야 한다.@PostMapping(consumes = \"text/plain\",             produces = \"application/json\")@Transactionalpublic ResponseEntity&lt;Memo&gt; createMemo(@RequestBody String content) {    if (content.isBlank())        return ResponseEntity.status(HttpStatus.BAD_REQUEST).build();    long idx = memos.size();    var memo = memos.put(idx, new Memo(idx, content));    URI location = ServletUriComponentsBuilder.fromCurrentRequest()            .path(\"/{id}\")            .buildAndExpand(\"id\", idx)            .toUri();    return ResponseEntity.created(location)            .body(memo);}여기서 PostMapping 에는 들어올 content-type 을 지정해주어야 String 으로 알맞게 mapping 이 될 수 있겠다. 만약 application/json 으로 받으려면 DTO 를 따로 정의해주고 Body 에는 구조적 데이터 형태를 지키면서 요청을 보내야 한다.  location 을 넣음으로써 self-descriptive 성질을 충족한다고 볼 수 있다.create 에는 RESTful 을 위해 이렇게 자기 설명을 해주는 헤더가 필요하고,이를 통해 새로 생성된 리소스의 URI 가 어디있는지 알려주어야 한다.READ RESTMutiple READ@GetMapping(produces = \"application/json\")@Transactional(readOnly = true)public ResponseEntity&lt;List&lt;Memo&gt;&gt; getMemos() {    List&lt;Memo&gt; lst = Arrays.asList(memos.values().toArray(new Memo[0]));    return ResponseEntity.ok()            .header(\"Content-Type\", \"application/json\")            .header(\"X-Total-Count\", String.valueOf(lst.size()))            .body(lst);}Single READ@GetMapping(path = \"/{id}\",            produces = \"application/json\")@Transactional(readOnly = true)public ResponseEntity&lt;Memo&gt; getMemos(@PathVariable Long id) {    if (id == null || !memos.containsKey(id))        return ResponseEntity.status(HttpStatus.NOT_FOUND)                                .header(\"Content-Type\", \"application/json\")                                .build();    return ResponseEntity.ok().header(\"Content-Type\", \"application/json\")                            .body(memos.get(id));}UPDATE REST업데이트는 좀 복잡하다. create + read 의 구현을 좀 가져와서 사용하면 되겠다.@PutMapping(path = \"/{id}\",            consumes = \"text/plain\",            produces = \"application/json\")@Transactionalpublic ResponseEntity&lt;Memo&gt; updateMemo(@PathVariable Long id,                                        @RequestBody String content) {    if (id == null || content.isBlank() || !memos.containsKey(id))        return ResponseEntity.status(HttpStatus.BAD_REQUEST)                             .header(\"Content-Type\", \"application/json\")                             .build();    var memo = new Memo(id, content);    memos.put(id, memo);    URI location = ServletUriComponentsBuilder.fromCurrentRequest()                                              .path(\"/{id}\")                                              .buildAndExpand(\"id\", id)                                              .toUri();    return ResponseEntity.ok()                         .header(\"Content-Type\", \"application/json\")                         .header(\"Location\", location.toString())                         .body(memo);}DELETE REST@DeleteMapping(path = \"/{id}\")@Transactionalpublic ResponseEntity&lt;?&gt; deleteMemo(@PathVariable Long id) {    if (id == null || !memos.containsKey(id))        return ResponseEntity.status(HttpStatus.NOT_FOUND)                                .header(\"Content-Type\", \"application/json\")                                .build();    memos.remove(id);    return ResponseEntity.noContent().build(); // 204 Status}이렇게 하면 REST 의 제약조건들을 대부분 만족하지만 HATEOAS 가 없게 된다.Spring HATEOAS스프링에서는 REST 를 지키기 위해 Spring HATEOAS 를 제공한다. 이는 REST 원칙을 엄격하게 지키기 위함이며, 단순한 DTO 나 객체 반환만으로는 링크 정보 제공이 불가하기 때문에 Spring HATEOAS 에서 제공해주는 EntityModel 으로 한 번 더 감싸서 반환시켜주는게 원칙이다.implementation 'org.springframework.boot:spring-boot-starter-hateoas'위를 추가하면 다음이 자동으로 추가된다:  spring-hateoas  spring-web  spring-context  Jackson 모듈데이터class Memo {    private Long id;    private String content;    private LocalDateTime createdAt;    private LocalDateTime updatedAt;    public Memo(Long id, String content, LocalDateTime createdAt, LocalDateTime updatedAt) {        this.id = id;        this.content = content;        this.createdAt = createdAt;        this.updatedAt = updatedAt;    }    // getters and setters    public Long getId() { return id; }    public String getContent() { return content; }    public void setContent(String content) { this.content = content; }    public LocalDateTime getCreatedAt() { return createdAt; }    public LocalDateTime getUpdatedAt() { return updatedAt; }    public void setUpdatedAt(LocalDateTime updatedAt) { this.updatedAt = updatedAt; }}class MemoRequest {    private String content;    public String getContent() { return content; }    public void setContent(String content) { this.content = content; }}위를 토대로 작성해보자.CREATE@PostMapping@Transactionalpublic ResponseEntity&lt;EntityModel&lt;Memo&gt;&gt; createMemo(@RequestBody MemoRequest request) {    // 새 메모 생성    long id = memos.size();    Memo memo = new Memo(id, request.getContent(), LocalDateTime.now(), LocalDateTime.now());    memos.put(id, memo);    // HATEOAS 링크 생성    EntityModel&lt;Memo&gt; resource = EntityModel.of(memo);    resource.add(WebMvcLinkBuilder.linkTo(            WebMvcLinkBuilder.methodOn(MemoController.class).getMemo(id)    ).withSelfRel());    resource.add(WebMvcLinkBuilder.linkTo(            WebMvcLinkBuilder.methodOn(MemoController.class).updateMemo(id, null)    ).withRel(\"update\"));    resource.add(WebMvcLinkBuilder.linkTo(            WebMvcLinkBuilder.methodOn(MemoController.class).deleteMemo(id)    ).withRel(\"delete\"));    // HTTP 201 Created와 Location 헤더 반환    URI location = WebMvcLinkBuilder.linkTo(            WebMvcLinkBuilder.methodOn(MemoController.class).getMemo(id)    ).toUri();    return ResponseEntity.created(location).body(resource);}READ 단건@GetMapping(\"/{id}\")public ResponseEntity&lt;EntityModel&lt;User&gt;&gt; getUser(@PathVariable Long id) {    User user = userService.findById(id);    if (user == null) return ResponseEntity.notFound().build();    EntityModel&lt;User&gt; resource = EntityModel.of(user);    resource.add(WebMvcLinkBuilder.linkTo(        WebMvcLinkBuilder.methodOn(UserController.class).getUser(id)    ).withSelfRel());    resource.add(WebMvcLinkBuilder.linkTo(        WebMvcLinkBuilder.methodOn(UserController.class).updateUser(id, null)    ).withRel(\"update\"));    return ResponseEntity.ok(resource);}READ 다건@GetMappingpublic ResponseEntity&lt;List&lt;EntityModel&lt;Memo&gt;&gt;&gt; getAllMemos(        @RequestParam(defaultValue = \"0\") int page,        @RequestParam(defaultValue = \"10\") int size) {    List&lt;Memo&gt; allMemos = new ArrayList&lt;&gt;(memos.values());    int start = page * size;    int end = Math.min(start + size, allMemos.size());    List&lt;Memo&gt; pagedMemos = allMemos.subList(start, end);    List&lt;EntityModel&lt;Memo&gt;&gt; resources = new ArrayList&lt;&gt;();    for (Memo memo : pagedMemos) {        EntityModel&lt;Memo&gt; resource = EntityModel.of(memo);        resource.add(WebMvcLinkBuilder.linkTo(                WebMvcLinkBuilder.methodOn(MemoController.class).getMemo(memo.getId())        ).withSelfRel());        resources.add(resource);    }    return ResponseEntity.ok()            .header(\"X-Total-Count\", String.valueOf(allMemos.size()))            .body(resources);}UPDATE@PutMapping(\"/{id}\")public ResponseEntity&lt;EntityModel&lt;Memo&gt;&gt; updateMemo(        @PathVariable Long id,        @RequestBody MemoRequest request) {    Memo memo = memos.get(id);    if (memo == null) return ResponseEntity.notFound().build();    memo.setContent(request.getContent());    memo.setUpdatedAt(LocalDateTime.now());    EntityModel&lt;Memo&gt; resource = EntityModel.of(memo);    resource.add(WebMvcLinkBuilder.linkTo(            WebMvcLinkBuilder.methodOn(MemoController.class).getMemo(id)    ).withSelfRel());    resource.add(WebMvcLinkBuilder.linkTo(            WebMvcLinkBuilder.methodOn(MemoController.class).deleteMemo(id)    ).withRel(\"delete\"));    return ResponseEntity.ok(resource);}DELETE@DeleteMapping(\"/{id}\")public ResponseEntity&lt;Void&gt; deleteMemo(@PathVariable Long id) {    Memo removed = memos.remove(id);    if (removed == null) return ResponseEntity.notFound().build();    return ResponseEntity.noContent().build();}코드가 너무 많아서 AI 도움을 받아서 정확한 부분은 아직 검증은 못했다.하지만 다음 메서드를 통해 보일러플레이트 코드를 조금 줄일 수 있을 것이다.private EntityModel&lt;Memo&gt; wrapping(Memo memo) {    EntityModel&lt;Memo&gt; resource = EntityModel.of(memo);    var memoCtrl = WebMvcLinkBuilder.methodOn(MemoController.class);    resource.add(WebMvcLinkBuilder.linkTo(memoCtrl.getMemo(memo.id())).withSelfRel());    resource.add(WebMvcLinkBuilder.linkTo(memoCtrl.updateMemo(memo.id(), null)).withSelfRel());    resource.add(WebMvcLinkBuilder.linkTo(memoCtrl.deleteMemo(memo.id())).withSelfRel());    resource.add(WebMvcLinkBuilder.linkTo(memoCtrl.getMemos()).withSelfRel());    return resource;}HTTP 헤더헤더에는 다양한 값을 넣을 수 있는데:  Cache-Control: 클라이언트 / 중간 프록시가 캐싱할 수 있는지, 얼마나 오래 캐시할지 지정  ETag: 리소스의 고유 식별자(보통 해시값), 변경 시 새 값으로 갱신  Last-Modified: 리소스 최종 수정 시각  Expires: 캐시 만료 기간Cache 관련 헤더HTTP는 리소스를 효율적으로 전송하기 위해 캐싱(Caching) 메커니즘을 제공한다. 이를 제어하는 핵심 수단은 HTTP 헤더(Header) 이며, 서버와 클라이언트가 리소스의 유효성, 만료 시점, 재검증 정책 등을 협의할 수 있다.Cache-Control캐시 정책을 가장 세밀하게 제어할 수 있는 핵심 헤더로써, HTTP/1.1 이후의 모든 캐싱 로직은 이 헤더를 기준으로 동작한다.  Cache-Control: , =, ...디렉티브라는게 있는데, 디렉티브에는 다음 내용들이 들어갈 수 있다.캐싱 가능 여부  no-store: 요청/응답 모두 캐시에 저장하지 않음  no-cache: 저장은 가능하지만, 재사용 전 서버 검증이 필요함 (ETag / Last-Modified)  public: 모든 캐시(공유 캐시 포함) 에서 저장 및 재사용 가능  private: 사용자 전용 캐시(브라우저 등) 에서만 저장 가능유효 기간  max-age=초: 캐시된 리소스의 유효시간(초 단위)  s-maxage=초: 공유 캐시(프록시, CDN 등)에서의 유효 시간  max-stale=초: 만료된 캐시라도 지정된 시간 안이면 사용 허용  min-fresh=초: 앞으로 최소 초 이내에 새로고침해야 사용 가능재검증 정책  must-revalidate: 만료 후 반드시 원서버에 검증 후 사용  proxy-revalidate: 중간 프록시 캐시만 재검증 강제기타  immutable: 리소스가 절대 바뀌지 않음을 명시(브라우저 재검증 생략 가능)  stale-while-revalidate=초: 만료 후에도 지정 시간 동안 캐시 사용하며 백그라운드 갱신      stale-if-error=초: 서버 오류 발생 시, 지정 시간 내 캐시 사용 허용    Last-Modified: 서버 -&gt; 클라이언트 로의 리소스 최종 수정 시각 제공  If-Modified-Since: 클라이언트 -&gt; 서버 로의 이전 응답의 수정 시각을 보냄(서버가 비교 후 반환)ETag &amp; If-None-Match리소스의 고유 식별자(Entity Tag) 를 기반으로 더 정밀하게 캐시 재검증을 수행한다.  ETag: 서버 -&gt; 클라이언트, 리소스 버전 식별자(보통 해시값)  If-None-Match: 클라이언트 -&gt; 서버, 이전에 받은 ETag 를 전달, 일치 시 304 응답          만약 다르면 새 콘텐츠와 함께 200 OK + 새로운 ETag 반환      Vary캐시 구분 기준을 지정하는 헤더이며, 같은 URL 이라도 요청 헤더 값에 따라 다른 응답을 캐시해야 할 때 사용한다.  Vary: Accept-Encoding, User-Agent하지만 캐시는 터미널 자체에서는 없고 캐시 스토리지 기능이 있는 유저에게만 캐싱이 가능하다.  웹 브라우저  CDN(Cloudflare, Akamai, etc.): 서버 응답 헤더를 기준으로 전 세계 캐시 서버에 저장  Reverse Proxy(nginx, Varnish): 서버 앞단에서 HTTP 캐시를 수행  API Gateway / Load Balancer: 응답 헤더 기반으로 캐싱 가능 (AWS API, Gateway, Nginx reverse cache)  HTTP 클라이언트 (Postman 등): 자체 캐시가 없거나 비활성화됨(직접 구현해야 함)다음 장에서 이를 더 자세히 다루자."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 44일차 JUnit",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/27/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-44%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-27",
      "content": "📂 목차  TDD          Red-Green-Refactor      단위 테스트                  Test Coverage                    통합 테스트      시스템 테스트        SpringBootTest          SpringBoot Web Test      JUnit 5      주요 어노테이션                  @RepeatedTest          @ParameterizedTest          @TestFactory                    라이프사이클 관련      Assertions        Mockito          @Mock      @InjectMocks      @Spy      @Captor      📚 본문TDD테스트를 먼저 작성하고 테스트를 통과하는 코드를 구현하는 개발 방법론이다.  코드 품질 향상  버그 조기 발견  설계 단순화 및 유지보수 용이  코딩 목표의 명확성Red-Green-Refactor테스팅의 상태는 다음과 같이 흘러가게 된다.  Red: 실패하는 테스트 작성          아직 기능이 구현되지 않았으므로 테스트 실패        Green: 최소한의 코드 작성으로 테스트 통과          기능 구현        Refactor: 코드 리팩토링          테스트가 통과하므로 안전하게 구조 개선 가능      단위 테스트프로그램의 가장 작은 단위(주로 메서드) 를 독립적으로 테스트, 즉 Bottom-Up 방법이며, 다음 특징이 있다.  독립적이어야 함  빠르게 실행 가능  작은 단위에 집중하여 가장 비용이 적음따라서 보통 개발 단계에서 채택할 수 있는 테스트이다.Test Coverage최소 수준 부터 100% 의 테스트 범위 까지 매 수준마다 단위 테스트를 실시해야 한다.가장 최소 수준의 Coverage 는 메서드/클래스 단위일 것이다.통합 테스트여러 모듈/컴포넌트가 함께 동작하는지를 테스트 한다.  모듈 혹은 클래스 간 상호작용 확인  실제 서비스 환경과 유사하게 검증해야 한다시스템 테스트전체 시스템을 테스트하며, 어플리케이션 전체가 coverage 가 된다. 이때는 실제 사용 시나리오를 기반으로 하여 테스트를 하기 때문에 시나리오 명세서를 통해 하나하나 테스트가 진행되는 듯하다.  이 외에도 다양한 테스트들이 있기 때문에 찾아보기를 바란다.SpringBootTest스프링 프레임워크를 사용하면, 스프링 자체의 어플리케이션 컨텍스트가 생성되게 되는데, 이는 어플리케이션 전반에서 사용되게 된다.이를 테스트 환경에서도 작성하기 위해 또 테스트 코드와 실제 개발 코드를 분리시키기 위해 Spring Initializer 에서 생성된 프로젝트에는 src/test 도 있었다. 여기서는 java 쪽 폴더와 데칼코마니처럼 클래스들을 생성하여 테스트 코드를 작성할 수 있도록 해놨다.하지만 이렇게 테스트할 때 우리는 컨텍스트를 들고와야 한다. 테스트 쪽에서는 스프링 어플리케이션을 실행하는 코드가 어디에도 없지만, 어노테이션 하나만으로 우리가 java 폴더에 개발한 해당 Spring Bean 들을 다 들고 온다.@SpringBootTestclass UserServiceIntegrationTest {    @Autowired    UserService userService;    @Autowired    UserRepository userRepository;    @Test    void createUserTest() {        User user = userService.createUser(\"hong\", \"hong@email.com\");        assertNotNull(userRepository.findById(user.getId()));    }}특징  모든 Spring Bean 을 로드 -&gt; 의존성 주입이 가능  실제 DB, JPA Repository, Service 등등 을 포함한 통합 테스트도 가능  일반적인 단위 테스트(@Test) 보다 느릴 수 있음  단순히 단위 테스트만 하고 싶다면 굳이 사용할 필요는 없고, Bean 의 범위를 줄여주는 @WebMvcTest, @DataJpaTest 등으로 범위를 좁힌다.따라서 @SpringBootTest 는 클래스 수준의 어노테이션으로 작성되며, webEnvironment 속성을 지원한다. 이 webEnvironment 는 다음 4가지 옵션이 있다:  MOCK &lt;- 기본값  RANDOM_PORT  DEFINED_PORT  NONEMOCK 기능은 예를 들어 웹 환경이 어플리케이션의 클래스 경로에 있는 경우에만 내장 서버를 시작하는 대신 mock 웹 환경을 활용하게 된다. 하지만 웹 기능이 없다면 일반 ApplicationContext 를 로딩하게 된다.이 외에도 다른 옵션에는 RANDOM_PORT 는 웹 어플리케이션 컨텍스트를 로딩하고 내장서버를 시작하여 사용 가능한 임의의 포트에 노출된 실제 웹 환경을 제공, DEFINED_PORT 는 프로퍼티에 정의된 포트를 사용하게 된다.보통은 NONE 을 더 많이 사용했을텐데, 이 값이 바로 모의 웹 환경 이나 웹 환경이 전혀 없는 ApplicationContext 가 생성되는 것이고 내장 서버도 시작되지 않는다.SpringBoot Web Test위에서 SpringBootTest.WebEnvironment.MOCK 을 사용하여 모의 웹 환경을 토대로 실행할 수 있게 됨을 보았다. 보통 이는 다음과 같은 클래스 수준 어노테이션과 같이 쓴다.  @AutoConfigureMockMVC: Spring MVC 웹 계층을 Mock 환경에서 테스트할 때 사용          이걸 붙이면 실제 서버를 띄우지 않고 DispatcherServlet, 컨트롤러, 필터, 인터셉터 등 MVC 구성을 테스트 할 수 있음      리엑티브는 지원하지 않으며, Spring MVC 에서만 사용        @AutoConfigureWebTestClient:          Spring WebFlux 환경에서 비동기 웹 계층을 테스트      실제 서버 또는 WebFlux 컨텍스트를 띄워서 WebTestClient 로 요청/응답 검증을 한다고 한다(자세한건 모른다).      MVC 기반에서는 사용하지 않으며, Spring WebFlux 에서만 사용      즉 두 어노테이션의 사용은 각자 리액티브냐, MVC 냐에 달려있다. 아래는 예시이다.Spring MVC Test@SpringBootTest@AutoConfigureMockMvcclass UserControllerTest {    @Autowired    private MockMvc mockMvc;    @Test    void getUserTest() throws Exception {        mockMvc.perform(get(\"/users/1\"))               .andExpect(status().isOk())               .andExpect(jsonPath(\"$.name\").value(\"hong\"));    }}Spring WebFlux Test@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)@AutoConfigureWebTestClientclass UserControllerWebFluxTest {    @Autowired    private WebTestClient webTestClient;    @Test    void getUserTest() {        assert webTestClient.get().uri(\"/users/1\")                            .exchange()                            .expectStatus().isOk()                            .expectBody()                            .jsonPath(\"$.name\").isEqualTo(\"hong\");    }    @Test    void test(@Autowired WebTestClient client) {        assert client.get() // GET 요청 보내겠다.                     .uri(\"/aircraft\") // 해당 URI 로 엔드포인트 설정                     .exchange() // request / response 의 교환이 일어났다면,                     .expectStatus().isOk() // HTTP 200 의 응답을 확인 후 Response Body 반환                     .expectBody(Iterable.class) // 바디에 Iterable 이 포함됐는지 확인                     .returnResult() // Iterable 에 해당하는 response 회수                     .getResponseBody() // response 의 응답 바디 반환                     .iterator() // iterator 로 형 변환                     .hasNext(); // 값이 하나라도 있다면 true    }}Flux 까지는 보지 않고, 우선 JUnit 5 을 사용하는 것을 익히자.JUnit 5테스트 코드를 작성하기 위한 패키지이다. 검증하는 코드는 주피터 엔진이 포함된 JUnit 5를 통해 테스트 코드를 작성할 수 있으며, 다음 기능들을 제공한다:  이전 버전에 비해 개선된 코틀린 코드 테스트  @BeforeAll, @AfterAll 사용하여 인스턴스화/설정 을 한꺼번에 가능  JUnit 4 코드도 테스트에 지원JUnit 은 3가지 모듈로 구성되는데 JUnit Platform, JUnit Jupiter, JUnit Vintage 로 JUnit 5 는 Jupiter + Platform 이 되겠다(Vintage 는 JUnit 3, 4 테스트 호환 모듈이라고 보면 된다).주요 어노테이션기본적으로 @SpringBootTest 를 통해 해당 클래스를 실행할때 테스트 클래스 임을 설정하고, 컨텍스트를 불러올 수 있다. 내부의 메서드들은 전부 @Test 를 사용하여 메서드 수준의 테스트를 작성할 수 있다. 여기서는 그 외의 다양한 어노테이션을 본다.@RepeatedTest동일한 기능을 데이터만 바꿔가면서 실행하고 싶을 수 있다.class RepeatedTestExample {    @RepeatedTest(5)    @DisplayName(\"반복 테스트 기본 예시\")    void repeatFiveTimes() {        System.out.println(\"테스트 실행 중...\");        assertTrue(Math.random() &gt;= 0); // 단순 검증    }}@ParameterizedTest위와 반복 실행은 똑같지만, 다양한 테스트 케이스를 넣도록 할 수 있다.@ValueSource 로 테스트 케이스들 넣기@ParameterizedTest@ValueSource(ints = {1, 2, 3})void testPositiveNumbers(int number) {    assertTrue(number &gt; 0);}  지원 타입: ints, longs, doubles, strings, classes, 모르면 내부 보자@EnumSource 로 테스트 케이스들 넣기enum Color { RED, GREEN, BLUE }@ParameterizedTest@EnumSource(Color.class)void testEnum(Color color) {    assertNotNull(color);}@CsvSource 로 테스트 케이스들 넣기@ParameterizedTest@CsvSource({    \"apple, 1\",    \"banana, 2\",    \"orange, 3\"})void testFruit(String name, int quantity) {    assertNotNull(name);    assertTrue(quantity &gt; 0);}@CsvFileSource 로 테스트 케이스들 넣기@ParameterizedTest@CsvSource({    \"apple, 1\",    \"banana, 2\",    \"orange, 3\"})void testFruit(String name, int quantity) {    assertNotNull(name);    assertTrue(quantity &gt; 0);}@MethodSource 로 테스트 케이스들 넣기static Stream&lt;Arguments&gt; provideNumbers() {    return Stream.of(        Arguments.of(1, 2, 3),        Arguments.of(2, 3, 5)    );}@ParameterizedTest@MethodSource(\"provideNumbers\")void testAddition(int a, int b, int expected) {    assertEquals(expected, a + b);}  장점: 동적, 복잡한 객체 제공 가능@ArgumentsSource 로 테스트 케이스들 넣기class MyArgumentsProvider implements ArgumentsProvider {    @Override    public Stream&lt;? extends Arguments&gt; provideArguments(ExtensionContext context) {        return Stream.of(Arguments.of(1,2), Arguments.of(3,4));    }}@ParameterizedTest@ArgumentsSource(MyArgumentsProvider.class)void testCustomProvider(int a, int b) {    assertTrue(a &lt; b);}  장점: 매우 유연, 외부 API 연동 가능장점을 이용하기 위해서 ArgumentsSource, MethodSource 를 사용하여 넣어주자. 나머지는 다양하게 넣는거 뿐이다.@TestFactory실행 시점에 테스트 케이스를 동적으로 생성하는 메서드에 붙이는 어노테이션이며, 여러 개의 테스트 데이터들을 넣어 결과로 Collection 혹은 Stream 의 형태로 반환되게 된다. 예시를 보자.class DynamicTestExample {    @TestFactory    Stream&lt;DynamicTest&gt; dynamicTestsFromStream() {        return Stream.of(1, 2, 3)                .map(n -&gt; dynamicTest(\"test for \" + n,                        () -&gt; assertTrue(n &gt; 0)));    }    @TestFactory    Stream&lt;DynamicTest&gt; dynamicStringTests() {        String[] words = {\"apple\", \"banana\", \"cherry\"};        return Stream.of(words)                .map(word -&gt; dynamicTest(\"Length &gt; 0 for \" + word,                        () -&gt; assertTrue(word.length() &gt; 0)));    }    @TestFactory    Stream&lt;DynamicTest&gt; dynamicTestsFromRandom() {        return Stream.generate(() -&gt; (int)(Math.random()*100))                    .limit(5)                    .map(n -&gt; dynamicTest(\"test for \" + n,                                            () -&gt; assertTrue(n &gt;= 0)));    }}dynamicTest(\"이름\", Executable) 을 통해 테스트 이름과 로직을 지정하며, 이를 통해 테스트 이름을 런타임에 동적으로 지정할 수 있게 되며, 랜덤과 함께 사용한다면 더 강력한 테스트 범위까지 확장시킬 수 있고 데이터가 동적이게 된다.라이프사이클 관련모든 것은 함수 수준이다.  @BeforeEach: non-static 으로 각 테스트 전에 실행  @AfterEach: non-static 으로 각 테스트 후에 실행  @BeforeAll: static 메서드로 클래스 전체 테스트 전 한 번 실행  @AfterAll: static 메서드로 클래스 전체 테스트 후 한 번 실행조건부 실행  @EnabledOnOs, @DisabledOnOs: 특정 OS 에서만 활성화 / 비활성화  @EnabledOnJre, @DisabledOnJre: 특정 JRE 에서만 실행  @EnabledIf, @DisabledIf: 커스텀 조건SpEL 에 따라 실행/비활성화예외 및 시간 지정  @Timeout: @Timeout(500, unit = TimeUnit.MILLISECONDS)  assertThrows테스트 그룹화  @Tag(\"fast\"): 테스트 그룹을 지정하며, 특정 지정 태그만 실행이 가능하도록 할 수 있다.AssertionsAssertions 클래스는 다양한 검증을 수행할 수 있는 기능을 제공하는 클래스이다.assertEquals(expected, actual);assertNotEquals(expected, actual);assertTrue(condition);assertFalse(condition);assertNull(object);assertNotNull(object);assertThrows(Exception.class, () -&gt; {...});assertAll(() -&gt; {...}, () -&gt; {...}); // 여러 검증 동시에assertArrayEquals(expected, actual);assertIterableEquals(expected, actual);assertLinesMatch(expectedLines, actualLines); // 문자열 라인 단위 비교여기서 주의할 점은 expected 가 우리가 기대할 값이 들어가야 하지 실제 값이 들어가면 안된다. 둘은 자리가 정해져 있다. 이런 메서드들을 @Test 의 단위에 맞게 넣어주어 사용하면 된다.MockitoSpring 테스트에서 자주 쓰이는 가짜 객체 기능을 제공하는 패키지이다. 테스트를 할 대상 객체가 의존하는 다른 외부 객체를 필요로 할 때 우리는 테스트를 섣불리 못하게 되지만, Mockito 를 활용하면 가짜 객체를 부여하여 테스트를 독립적으로 할 수 있다.@Mock가짜 객체를 생성하는 어노테이션이며, 필드에 붙여주게 된다. 클래스에 @ExtendWith(MockitoExtension.class) 어노테이션을 붙여주면 Mockito 를 사용할 수 있게 된다.Mock 은 말 그대로 가짜이기 때문에 특징으로는 다음과 같다:  Mock 객체는 실제 구현체를 호출하지 않고 테스트에서 지정한 동작만 수행  Mock 객체는 when(...).thenReturn(...) 또는 doReturn(...).when(...) 같은 구문을 사용하여 호출 시 반환값과 동작을 정의 가능  Mock 객체의 메서드 호출 여부, 호출 횟수 등을 verify(...) 메서드로 검증 가능@InjectMocksMock 객체를 주입할 대상 클래스를 지정해야 한다. 즉 위의 @Mock 만 사용해서는 안되며, 이를 어디에 주입시켜줄지를 지정해줘야 하는데 이를 @InjectMocks 로 한다. 그래서 보통 클래스에 하나만 이 어노테이션을 사용하는게 일반적이며, 여기에 @Mock, @Spy 가 자동 주입이 되게 된다.예시@ExtendWith(MockitoExtension.class)class UserServiceTest {    @Mock    private UserRepository userRepository; // Mock 객체 생성    @InjectMocks    private UserService userService; // Mock 주입    @Test    void createUserTest() {        User mockUser = new User(\"hong\");        when(userRepository.save(any(User.class))).thenReturn(mockUser);        User user = userService.createUser(\"hong\");        assertEquals(\"hong\", user.getName());        verify(userRepository).save(any(User.class)); // 호출 여부 검증    }}@Spy실제 객체를 사용하면서 일부 메서드만 Mock 처리를 한다. 가짜로 처리하고 싶은 메서드는 when(...).thenReturn(...) 으로 가짜 동작을 덮어씌울 수 있다.@Spyprivate UserService userService = new UserService();@Testvoid testSpy() {    when(userService.getUserName()).thenReturn(\"mocked name\");    // getUserName 은 Mock 동작, 다른 메서드는 실제로 실행됨    assertEquals(\"mocked name\", userService.getUserName());}  Stub: 호출되면 정해진 값을 돌려주는 가짜 객체@CaptorArgumentCaptor 를 생성하는 어노테이션이다. 테스트에서 메서드 호출 시 전달된 인자(argument) 를 캡처(capture)하여 검증하고 싶을 때 사용한다.  메서드가 호출될 때 전달된 실제 인자 값을 꺼내서 확인할 수 있음  verify() 와 함께 사용  여러 인자를 순서대로 검증할 수 있음@Mockprivate UserRepository userRepository;@InjectMocksprivate UserService userService;@Captorprivate ArgumentCaptor&lt;User&gt; userCaptor; // 인자 캡쳐용@Testvoid createUser_capturesArgument() {    userService.createUser(\"hong\");    verify(userRepository).save(userCaptor.capture()); // save()에 전달된 User 객체 캡처    User capturedUser = userCaptor.getValue();    assertEquals(\"hong\", capturedUser.getName()); // 전달된 객체의 값 검증}"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 43일차 Spring Data Jpa",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/27/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-43%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-27",
      "content": "📂 목차  Spring Data JPA란?  Spring Data JPA의 동작 구조  Repository 계층의 이해          CrudRepository      JpaRepository        쿼리 메서드(Query Method)          쿼리 메서드 자동 쿼리 생성 기능 사용      @Query 애너테이션으로 직접 JPQL 쿼리 작성                  Path Expression          네이티브 쿼리 사용                    특정 컬럼 조회                  Interface Projection          DTO Projection                      JPQL 과 Criteria  Spring Data JPA 실무 활용          Specification (동적 쿼리)      📚 본문Spring Data JPA란?Spring Data JPA 는 JPA(Java Persistence API) 를 기반으로 한 스프링 프레임워크의 데이터 접근 추상화 도구입니다. 복잡한 데이터베이스 접근 코드를 줄이고, 인터페이스 기반의 선언적 방식으로 CRUD 및 쿼리 기능을 쉽게 구현할 수 있도록 도와줍니다. 이를 통해 개발자는 비즈니스 로직에 집중할 수 있습니다.Spring Data JPA의 동작 구조Spring Data JPA 는 EntityManager 를 사용해 데이터베이스와 통신한다. Repository 인터페이스를 정의하면 스프링이 런타임에 Proxy 객체를 생성하여 실제 구현체를 제공하고 이 Proxy 는 메서드 호출 시 적절한 JPA 쿼리를 실행한다.  EntityManager: JPA의 핵심 인터페이스로, 엔티티의 생명주기 관리 및 쿼리 실행 담당  Repository: 개발자가 정의하는 인터페이스  Proxy: 스프링이 자동 생성하는 구현체로, 메서드 호출을 실제 DB 쿼리로 변환Repository 계층의 이해Spring Data JPA 는 여러 Repository 인터페이스를 제공하는데 Crud 는 우선 Spring Data 에서 공통적으로 제공하는 기능이며 이를 확장하는 Spring Data JPA 의 JpaRepository 가 있다.JpaRepositoryJpaRepository 어노테이션은 CrudRepository 를 확장하며 페이징 기능과 정렬 기능을 기본적으로 제공하게 된다.Repository └─ CrudRepository&lt;T, ID&gt;     └─ ListCrudRepository&lt;T, ID&gt; └─ PagingAndSortingRepository&lt;T, ID&gt;     └─ ListPagingAndSortingRepository&lt;T, ID&gt;QueryByExampleExecutor&lt;T&gt; + ListPagingAndSortingRepository&lt;T, ID&gt; + ListCrudRepository&lt;T, ID&gt;  └─ JpaRepository&lt;T, ID&gt;필요한 기능을 쓸 때는 해당 인터페이스 내부의 메서드들을 보면서 사용하는 것이 좋다. 또한 JpaRepository 는 기본적으로 Iterator 보단 List 를 반환하도록 짜여져 있기 때문에 성능적으로 안좋을 수 있다. 이럴때는 JpaRepository 를 사용하기 보다는 직접 BaseRepository 를 만들어서 사용하는 것이 좋다.쿼리 메서드(Query Method)쿼리 메서드 자동 쿼리 생성 기능 사용Spring Data JPA는 메서드 이름으로 쿼리를 자동 생성한다. 메서드 이름을 작성할 때는 다음과 같은 규칙으로 작성한다. 이전에도 다뤘기에 간단히 정리하고 넘어간다.Prefix  find…By: 조회 (가장 많이 사용됨)  read…By: 조회 (find와 동일 기능)  get…By: 조회 (find와 동일 기능)  query…By: 조회 (find와 동일 기능)  count…By: 조건에 맞는 개수 조회  exists…By: 조건 존재 여부 확인  delete…By: 조건에 맞는 데이터 삭제  remove…By: delete와 동일 기능Property Expressions  Is, Equals: = — findByName(String name)  IsNot, Not: != — findByStatusNot(String status)  LessThan: &lt; — findByAgeLessThan(int age)  LessThanEqual: &lt;= — findByAgeLessThanEqual(int age)  GreaterThan: &gt; — findByAgeGreaterThan(int age)  GreaterThanEqual: &gt;= — findByAgeGreaterThanEqual(int age)  Between: BETWEEN — findByCreatedAtBetween(Date start, Date end)  Like: LIKE (패턴 매칭) — findByNameLike(String name)  NotLike: NOT LIKE — findByNameNotLike(String name)  StartingWith: LIKE 'abc%' — findByNameStartingWith(String prefix)  EndingWith: LIKE '%abc’ — findByNameEndingWith(String suffix)  Containing: LIKE '%abc%' — findByNameContaining(String keyword)  In: IN (...) — findByIdIn(List&lt;Long&gt; ids)  NotIn: NOT IN (...) — findByIdNotIn(List&lt;Long&gt; ids)  True, False: boolean 조건 — findByActiveTrue()  IsNull: IS NULL — findByDeletedAtIsNull()  IsNotNull: IS NOT NULL — findByDeletedAtIsNotNull()  Before: &lt; (날짜 전) — findByCreatedAtBefore(LocalDate date)  After: &gt; (날짜 후) — findByCreatedAtAfter(LocalDate date)  And, Or 을 붙여 속성 표현식 여러개 사용 가능Limit(Top / First)조회 개수를 제한할 때 사용하며, 접두사 쪽에 prefix 와 by 사이에 사용한다.  Top{n}, First{n}: 상위 n 개 조회Distinct마찬가지로 접두사 쪽에 prefix 와 by 사이에 사용findDistinctByEmail(String email);findDistinctTop3ByOrderByScoreDesc();IgnoreCase속성 표현식 마지막에 추가findByUsernameIgnoreCase(String username);findByEmailContainingIgnoreCase(String keyword);반환 타입  Entity: 단일 엔티티 반환 (결과 없으면 null)  Optional: 단일 결과를 Optional로 반환  Collection: 여러 개 결과 반환  Page: 페이징 처리된 결과 반환  Slice: 다음 페이지 존재 여부만 있는 슬라이스 반환  Stream: Java Stream으로 반환  long, int: count, delete 등 숫자 결과 반환  boolean: 존재 여부 반환  Future, CompletableFuture: 비동기 반환@Query 애너테이션으로 직접 JPQL 쿼리 작성JPQL(Java Persistence Query Language) 은 객체 지향 쿼리 언어로, 엔티티 객체를 대상으로 쿼리 작성을 한다.String jpql = \"SELECT u FROM User u WHERE u.age &gt; :age\";List&lt;User&gt; users = em.createQuery(jpql, User.class)                     .setParameter(\"age\", 18)                     .getResultList();이를 내부적으로 Spring Data JPA 가 자동으로 생성시켜주어 다음과 같이 작성만 하면 파라미터와 매핑을 시킬 수 있게 된다.// 1번째, 2번째 파라미터를 ?1, ?2로 지정@Query(\"SELECT u FROM User u WHERE u.age &gt; ?1 AND u.status = ?2\")List&lt;User&gt; findByAgeAndStatus(int age, String status);// 날짜 범위 조회@Query(\"SELECT o FROM Order o WHERE o.createdAt BETWEEN ?1 AND ?2\")List&lt;Order&gt; findOrdersBetweenDates(LocalDate start, LocalDate end);// :email 이 메서드 파라미터 email과 매핑@Query(\"SELECT u FROM User u WHERE u.email = :email\")User findByEmailNamed(@Param(\"email\") String email);@Query(\"SELECT u FROM User u WHERE u.age &gt;= :minAge AND u.age &lt;= :maxAge\")List&lt;User&gt; findByAgeRange(@Param(\"minAge\") int minAge, @Param(\"maxAge\") int maxAge);// 페이징 및 정렬 기능@Query(\"SELECT u FROM User u WHERE u.status = :status ORDER BY u.createdAt DESC\")Page&lt;User&gt; findByStatusWithPaging(@Param(\"status\") String status, Pageable pageable);Path ExpressionJPQL 에서는 엔티티의 필드를 속성 경로로 표현할 수 있는데,자식 엔티티 접근@Entitypublic class Parent {    @Id private Long id;    @OneToMany(mappedBy = \"parent\") private List&lt;Child&gt; children;}@Entitypublic class Child {    @Id private Long id;    private String name;    @ManyToOne private Parent parent;}위와 같이 있다고 쳤을때, ParentRepository 에서는 다음과 같은 쿼리를 작성할 수 있다.SELECT c FROM Parent p JOIN p.children c WHERE c.name = 'Tom';이는 아래와 같음SELECT c.*FROM parent pJOIN child c ON c.parent_id = p.idWHERE c.name = 'Tom'따라서 테이블 이름이 아니라 엔티티 필드 이름을 그대로 써서 Java 객체 지향 프로그래밍을 그대로 적용시킬 수 있다. 익숙해지면 다음과 같은 코드도 작성 가능하다.다단계 경로 탐색SELECT o FROM Order o WHERE o.customer.address.city = 'Seoul'이는 Native SQL 을 쓰면 여러 테이블 조인이 필요하지만 JPQL 을 쓰면 JPA 가 알아서 필요한 JOIN 을 생성시켜주기 때문에 신경을 쓰지 않아도 된다.  MySQL 조인 절 생략 어구LEFT (OUTER) JOINRIGHT (OUTER) JOIN(INNER) JOIN네이티브 쿼리 사용위와 똑같지만 nativeQuery = true 로 해주어야 한다.@Query(value = \"SELECT * FROM users WHERE status = ?1\", nativeQuery = true)List&lt;User&gt; findByStatusNative(String status);이때 네이티브 쿼리를 쓸 때 단점이 있다.  데이터베이스 의존성 증가: 특정 DB에 종속적이 되어 이식성 저하  JPA 최적화 미활용: 영속성 컨텍스트의 1차 캐시, 변경 감지 등 미활용  따라서 요약하면 왠만하면 쿼리 메서드를 사용, 그 다음 복잡한 것은 JPQL 사용, 그래도 안되면 SQL 사용특정 컬럼 조회단일 컬럼은 그냥 타입 리스트로 반환하면 된다.List&lt;String&gt; findNameByAgeGreaterThan(int age);하지만 여러 컬럼이 있을때 이땐 Object[] 로 반환할 수 있는데,@Query(value = \"SELECT name, email FROM user WHERE name LIKE %:name%\", nativeQuery = true)List&lt;Object[]&gt; findUsersByNameNative(@Param(\"name\") String name);이를 써도 되기는 하지만, 타입 안전성이 떨어지고, 가독성이 낮으며, 영속성 컨텍스트에서 관리가 안된다(마지막 문제는 나머지도 다 똑같다). 타입 안전성을 위해 다음을 보자.Interface Projection조회하고 싶은 컬럼 이름과 getter 메서드 이름을 맞춘 인터페이스를 정의하여 반환타입으로 인터페이스를 사용 가능하다.public interface UserNameOnly { String getName(); }public interface UserEmailOnly { String getEmail(); }public interface UserNameAndEmail extends UserNameOnly, UserEmailOnly { }// Repository query methodList&lt;UserNameAndEmail&gt; findByAgeGreaterThan(int age);인터페이스로 정의했을 때의 단점은  set 을 할 수 없어 영속성 컨텍스트에 반영 X  레퍼런스 형 반환 제한레퍼런스 형을 반환할 수 없기에 다음 DTO 를 쓴다.DTO Projection엔티티 대신 필요한 데이터만 DTO 로 프로젝션하여 조회할 수 있다.public record UserDTO(    String name,    String email) { }@Query(\"SELECT new com.example.UserDTO(u.name, u.email) FROM User u WHERE u.age &gt; :age\")List&lt;UserDTO&gt; findByAge(@Param(\"age\") int age);DTO로 정의했을 때의 단점은  set 을 할 수는 있지만, JPA 가 추적하지 않기 때문에 영속성 컨텍스트에 반영 X  JPQL 에 들어가는 new (패키지명).(클래스명) 때문에 DTO 라는 것은 보통 패키지를 잘 이동하지 않는 쪽에다가 두는게 좋다. 즉, 모든 곳에서 쓰일 수 있는 common 패키지에 두는 것JPQL 과 CriteriaCriteria API 는 타입 세이프한 동적 쿼리 생성에 유용하다.CriteriaBuilder cb = em.getCriteriaBuilder();CriteriaQuery&lt;User&gt; cq = cb.createQuery(User.class);Root&lt;User&gt; user = cq.from(User.class);cq.select(user).where(cb.greaterThan(user.get(\"age\"), 18));List&lt;User&gt; result = em.createQuery(cq).getResultList();하지만 이는 너무 장황하다. 써야할 코드도 많으며, 가독성이 안좋고, 필드명을 문자열로 작성해야 해서 컴파일 시점에 체크가 불가하다. 따라서 Querydsl 을 사용하는데 나중에 보자.Spring Data JPA 실무 활용Specification (동적 쿼리)조건에 따라 동적으로 쿼리 생성 가능하다.public class UserSpecification implements Specification&lt;User&gt; {    private String username;    public UserSpecification(String username) { this.username = username; }    @Override    public Predicate toPredicate(Root&lt;User&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) {        if (username == null) return cb.conjunction();        return cb.equal(root.get(\"username\"), username);    }}Querydsl 과의 비교Querydsl 은 타입 안전성과 복잡한 쿼리 작성에 강점이 있으며, Spring Data JPA 와 함께 사용 가능하다. Spring Data JPA 는 빠른 개발과 간결한 코드에 유리하기 때문에 이 두 장점을 합쳐서 혼합하여 사용하는게 좋다.QUser user = QUser.user;JPAQuery&lt;User&gt; query = new JPAQuery&lt;&gt;(em);List&lt;User&gt; users = query    .from(user)    .where(user.status.eq(\"ACTIVE\")           .and(user.age.gt(20)))    .orderBy(user.createdAt.desc())    .fetch();  Querydsl 세팅은 검색해서 해보자."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 42일차 JPA 심화",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/24/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-42%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-24",
      "content": "📂 목차  JPA 심화          ORM      JPA 주요 Class      JPA 활용                  @Entity          EntityTransaction          Entity 동일성 vs 동등성          @Column          @Enumerated          @Temporal          @Lob          @PrePersist 와 @PostPersist                    JPA 엔티티 매핑                  @OneToOne          OneToOne 에서의 FetchType.LAZY 로딩의 문제점          toString(), JSON 의 재귀적 호출 가능성          @ManyToOne, @OneToMany          EAGER, LAZY 그리고 N+1 문제          @ManyToMany                    📚 본문JPA 심화JPA 는 객체지향적인 데이터 접근이라는 모토를 가지고 만들어진 관계형 데이터베이스 패러다임을 객체지향적으로 바꿔서 접근하는 기술이자 라이브러리이다.JDBC 와는 다르게 작동하고, 이후에 실무에서도 자주 사용하니 매우 자세히 들여다 볼 것이다.ORM객체 지향적으로 보기 위해 데이터 접근 로직을 SQL 에서 분리시키고 비즈니스 로직에만 집중할 수 있도록 지원하기 위해 ORM(Object-Relational Mapping) 이라는 개념을 통해 객체와 테이블을 자동으로 매핑한다.이러한 개념이 필요한 이유는 다음과 같다. SQL을 직접 작성할 때는 다음과 같은 반복 작업이 필연적으로 발생한다.문제점  자바 상의 객체를 테이블의 row 와 매핑시키기 위한 데이터 변환이 필요  SQL 문자열을 직접 작성 및 유지보수 하는 것은 굉장히 보일러 플레이트 코드  DBMS 에 의존하게 되는 쿼리 처리  스키마 변경 시 모든 SQL 코드를 수정해야 하고, 이는 곧 JAVA 내부 코드를 수정해야 하는 것과 동일  나무 위키 참조이러한 이유 때문에 1차적인 수정 이후에도 n차 수정이 필요하게 되는 상황이 발생하며, 매번 유사 코드를 일일히 입력하는 것은 굉장히 노동 집약적인 일이다. JPA 는 이름에 걸맞게 Persistence 라는 논리화된 저장공간을 제공함으로써 개발자에게 위 문제들을 해결 할 편리한 기능들을 제공한다.JPA 주요 Class+----------------------------------+|          javax.persistence       |+----------------------------------+        ┌──────────────────────────────┐        │         Persistence          │  ← JPA 진입점 (static 클래스)        └──────────────────────────────┘                      │                      ▼        ┌──────────────────────────────┐        │   EntityManagerFactory       │  ← EM 생성 팩토리 (Thread-safe)        └──────────────────────────────┘                      │                      ▼        ┌──────────────────────────────┐        │       EntityManager          │  ← 영속성 컨텍스트 단위 관리 객체        └──────────────────────────────┘          │      ▲               ▲          │      │               │          │      │               │          ▼      │               ▼┌────────────────────┐   ┌────────────────────┐│  EntityTransaction │   │       Query        │└────────────────────┘   └────────────────────┘   │                              │   ▼                              ▼begin(), commit(), rollback()   getResultList(), getSingleResult()  Persistence 정적 클래스: EntityManagerFactory 를 생성하는 진입점          createEntityManagerFactory(String persistenceUnitName): 내부적으로 META-INF/persistence.xml 을 읽어 설정 정보를 로드하는 역할을 한다.        EntityManagerFactory 인터페이스: EntityManager 인스턴스를 생성하는 팩토리(Thread-safety)          createEntityManger()      close()      싱글톤으로 사용해야 한다.        EntityManager 인터페이스: 엔티티의 생명주기와 영속성 컨텍스트를 관리하는 핵심 인터페이스          persist(), find(), merge(), remove()      트랜잭션 제어: EntityManager getTransaction()      JPQL 실행: createQuery()      SQL 실행: createNativeQuery()      쓰레드 안전하지 않기 때문에 한 번 트랜잭션이 실행될 때 동안만 생성되고 사라진다.      영속성 컨텍스트 관리를 담당한다.      AutoClosable 을 확장하여 제공하기 때문에 자원을 닫아주는 것이 필요        EntityTransaction 인터페이스: 트랜잭션을 수동으로 제어할 수 있는 인터페이스          begin(), commit(), rollback(), isActive()        Query 인터페이스: JPQL 또는 네이티브 SQL 을 실행하는 객체          setParameter(String name, Object value)      setResultList(), getSingleResult()      JPA 활용순수 JPA 를 쓰기 위해 다음을 추가한다.implementation 'org.hibernate:hibernate-core:6.4.4.Final'implementation 'jakarta.persistence:jakarta.persistence-api:3.1.0'JPA 표준 인터페이스는 jakarta 로, 구현체는 hibernate-core 로 들고온다. DB 드라이버는 각자 맞게 들고오자(필자는 mysql).Hibernate 설정 파일src/main/resources/META-INF/persistence.xml 를 통해 생성할 EntityManagerPersistence 를 설정해줘야 한다(위 Persistence 정적 클래스 참고).&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;persistence xmlns=\"http://java.sun.com/xml/ns/persistence\"             xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"             xsi:schemaLocation=\"http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd\"             version=\"2.0\"&gt;    &lt;persistence-unit name=\"examplePU\" transaction-type=\"RESOURCE_LOCAL\"&gt;        &lt;provider&gt;org.hibernate.jpa.HibernatePersistenceProvider&lt;/provider&gt;        &lt;class&gt;com.example.Member&lt;/class&gt;        &lt;properties&gt;            &lt;!-- JDBC 설정 --&gt;            &lt;property name=\"jakarta.persistence.jdbc.driver\" value=\"com.mysql.cj.jdbc.Driver\"/&gt;            &lt;property name=\"jakarta.persistence.jdbc.url\" value=\"jdbc:mysql://localhost:3306/exampledb\"/&gt;            &lt;property name=\"jakarta.persistence.jdbc.user\" value=\"{이름}\"/&gt;            &lt;property name=\"jakarta.persistence.jdbc.password\" value=\"{비밀번호}\"/&gt;            &lt;!-- hibernate 설정 --&gt;            &lt;property name=\"hibernate.hbm2ddl.auto\" value=\"update\"/&gt;            &lt;property name=\"hibernate.dialect\" value=\"org.hibernate.dialect.MySQLDialect\"/&gt;            &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt;            &lt;property name=\"hibernate.format_sql\" value=\"true\"/&gt;        &lt;/properties&gt;    &lt;/persistence-unit&gt;&lt;/persistence&gt;persistence 태그 안에 persistence-unit 이 와야 하며 각 persistence-unit 은 persistence 설정 파일 하나를 의미하는 듯하다. 여기 안에 해당 persistence-unit 이 관리 할 class 태그들을 넣어준다.  transaction-type 옵션: JTA 대신 트랜잭션을 자바 애플리케이션에서 관리한다는 것을 의미provider 태그: JPA 프로바이더로 Hibernate Core 의 org.hibernate.jpa.HibernatePersistenceProvider 를 사용properties 로 jdbc 와 hibernate 구현체에게 인자를 전달할 수 있다.  dialect: 다양한 파생된 SQL 들중 어떤 것을 쓸지 정하는 태그  hbm2ddl.auto          create: DB 를 데이터 정의어를 코드 기준으로 새로 생성      update: 이미 생성되어져 있는 DB 와 코드가 서로 다르다면 코드 기준으로 업데이트      create-update: 어플리케이션 실행 시 코드 기준으로 테이블을 생성하고, 종료 시점에 모두 삭제      validate: Java 코드와 DB 스키마가 일치하는지 검증만 수행하고, 수정은 하지 않는 설정      none: DDL 자동 생성 기능을 사용하지 않음        show_sql: JPA(Hibernate) 가 실행하는 SQL 쿼리를 콘솔에 출력하도록 설정. SQL이 실제로 어떤 식으로 수행되는지 확인할 때 유용함, 보통 개발 단계에서 사용  format_sql: 위 sql 을 보여줄 때, indent 시켜 보여줄지 아닐지 정하는거@Entity위 Persistence 가 관리할 클래스로 com.example.Member 를 정의했다. 위 경로대로 클래스 파일을 생성하자.import jakarta.persistence.Entity;import jakarta.persistence.Id;@Entitypublic class Member {\t@Id\tprivate Long id;}@Entity 는 JPA 가 관리할 데이터라는 것을 명시해주고, 데이터를 관리하려면 데이터의 구분 기준을 @Id 로 정의해줘야 한다. 따라서 기본적으로 위 구성을 따라야 한다./*** (Optional) The entity name. Defaults to the unqualified* name of the entity class. This name is used to refer to the* entity in queries. The name must not be a reserved literal* in the Jakarta Persistence query language.*/String name() default \"\";주석에 따르면, 해당 이름은 나중에 쿼리에 쓰일 이름이며, 이는 딱히 지정하지 않아도 내부적으로 Member 라는 것으로 query langugage 에 쓰일 예정이다. 이제 이 엔티티를 관리하는 Persistence Context 를 생성하기 위해 Entity Manager 를 생성하고, Entity Manager 를 생성하기 위해 Entity Manager Factory 를 생성해야 한다.public class Application {\tpublic static void main(String[] args) {\t\tEntityManagerFactory emf = Persistence.createEntityManagerFactory(\"examplePU\");\t\tEntityManager em = emf.createEntityManager();\t}}실행하면 다음 테이블이 생성됨을 볼 수 있다.JPA 는 내부적으로 비어있는 생성자를 통해 먼저 객체를 생성하고 그 이후에 값을 세팅해주게 된다. 따라서 빈 생성자는 필수이다. 또 여기서 @Id 를 꼭 넣어야 하는 이유는 객체를 구분할 명분이 필요해서 이다. 이를 좀 더 자세히 보자.엔티티 구분 기준  A persistence context is a set of entity instances in which for any given persistent entity identity (defined by an entity type and primary key) there is at most one entity instance공식 문서에 따르면, entity type 과 primary key 를 기준으로 정의되는 존재성이 바로 엔티티이다. 이때 테이블은 id 를 키로 하고, id 를 통해 객체를 구분하게 된다.테이블 명 바꾸기생성되는 Member 테이블은 클래스 명을 따라가게 되며 명시적으로 자동 생성되는 테이블 명을 지정시켜주려면 다음 어노테이션을 입력한다.import jakarta.persistence.Entity;import jakarta.persistence.Id;import jakarta.persistence.Table;@Entity@Table(name = \"members\")public class Member {\t@Id\tprivate Long id;}실행 시 다음과 같이 생성되어 있음을 볼 수 있다.이제 이 엔티티가 어떻게 생성되고 삭제되기 까지의 생명주기를 보자.Entity 상태 다이어그램  New: 객체 생성 상태  Managed: 영속화 상태  Removed: 삭제예정 상태  Detached: 비영속화 상태엔티티는 위와 같은 생명주기를 가진다. 기본적으로 영속화 된 이후에서야 다른 Removed, Detached 로 갈 수 있다.New 상태public class Application {\tpublic static void main(String[] args) {\t\tEntityManagerFactory emf = Persistence.createEntityManagerFactory(\"examplePU\");\t\tEntityManager em = emf.createEntityManager();\t\t// New 상태\t\tMember member = new Member();\t}}New 상태public class Application {\tpublic static void main(String[] args) {\t\tEntityManagerFactory emf = Persistence.createEntityManagerFactory(\"examplePU\");\t\tEntityManager em = emf.createEntityManager();\t\t// New 상태\t\tMember member = new Member();\t}}Managed 상태public class Application {\tpublic static void main(String[] args) {\t\tEntityManagerFactory emf = Persistence.createEntityManagerFactory(\"examplePU\");\t\tEntityManager em = emf.createEntityManager();\t\tMember member = new Member();\t\t// 영속화 상태\t\tem.persist(member);\t}}Detached 상태public class Application {\tpublic static void main(String[] args) {\t\tEntityManagerFactory emf = Persistence.createEntityManagerFactory(\"examplePU\");\t\tEntityManager em = emf.createEntityManager();\t\tMember member = new Member();\t\tem.persist(member);\t\t\t\tem.detach(member);\t}}Removed 상태public class Application {\tpublic static void main(String[] args) {\t\tEntityManagerFactory emf = Persistence.createEntityManagerFactory(\"examplePU\");\t\tEntityManager em = emf.createEntityManager();\t\tMember member = new Member();\t\tem.persist(member);\t\t\t\tem.remove(member);\t}}위 코드들을 실행시키면 아직 persistence context 에만 올라갈 뿐, Id 를 생성시켜주지 않아서 푸쉬까지는 못한다(커밋하면 org.hibernate.id.IdentifierGenerationException 에러 뜬다..). 따라서 DB 자체에 자동으로 ID 를 생성시켜주는 AUTO_INCREMENT 를 사용하도록 어노테이션을 붙여주어 아이디를 생성시켜주고 커밋을 해줘야 한다.GeneratedValue자동으로 생성해주는 @GeneratedValue 어노테이션을 통해 영속 컨텍스트에 진입하는 객체에 대해 Id 값이 null 이면 아이디를 자동 생성시켜주어서 영속성 컨텍스트에 들여오도록 할 수 있다. 애초에 Id 가 null 이면 영속성 컨텍스트에 들어올 수 없다.@Entity@Table(name = \"members\")public class Member {\t@Id\t@GeneratedValue(strategy = GenerationType.IDENTITY)\tprivate Long id;\tprivate String name;\tpublic Member() { }\tpublic Member(String name) {\t\tthis.name = name;\t}}위와 같이 입력해준다. 안에 들어갈 자동 생성 전략은 다음 옵션들이 있다.  GenerationType.IDENTITY: 엔티티 기본 키를 DB의 identity 컬럼을 사용하여 PersistenceProvider 가 할당해야 함을 명시  GenerationType.SEQUENCE: 엔티티 기본 키를 DB의 SEQUENCE 형을 사용하여 PersistenceProvider 가 할당해야 함을 명시  GenerationType.UUID: 엔티티 기본 키를 RFC 4122 표준의 UUID 를 생성하여 PersistenceProvider 가 할당해야 함을 명시  GenerationType.TABLE: 엔티티 기본 키를 PersistenceProvider 가 기본 DB 테이블을 사용하여 할당, 실제 DB 안에 별도의 시퀀스 테이블을 만들어서 키 값을 저장하고 조회하기 때문에 DB 종류에 상관 없이 시퀀스 역할 테이블을 만들어서 키 값을 저장  GenerationType.AUTO: 위 4개 옵션 중 알아서 할당아이디를 생성시켜줬다면 다음을 실행시켜서 푸시할 수 있다.EntityManager em = EMF.createEntityManager();Member member = new Member();em.getTransaction().begin();em.persist(member);em.getTransaction().commit();EntityTransaction위에서 getTransaction() 이라는 메서드가 EntityTransaction() 을 반환한다고 이 포스팅 앞부분에서 얘기했다. 이 클래스는 오직 transaction-type 설정 값이 RESOURCE_LOCAL 일때 사용된다.주요 메서드  begin() – 트랜잭션 시작          이미 활성화 상태면 IllegalStateException 발생        commit() – 트랜잭션 커밋, DB 반영          비활성 상태면 IllegalStateException      실패 시 RollbackException        rollback() – 트랜잭션 롤백          비활성 상태면 IllegalStateException      예기치 않은 오류 발생 시 PersistenceException        setRollbackOnly() – 트랜잭션을 롤백만 가능하도록 표시          비활성 상태면 IllegalStateException        getRollbackOnly() – 롤백 표시 여부 확인  isActive() – 트랜잭션 진행 여부 확인하나의 커밋 단위, 스냅샷 단위를 구분지을 수 있는 트랜잭션 개념을 제공한다. 따라서 위 코드를 좀 더 보기 좋고, 메모리를 고려한 다음과 같이 수정한다.EntityManager em = EMF.createEntityManager();Member member = new Member(\"홍길동\");em.getTransaction().begin();try {    em.persist(member);    em.getTransaction().commit();} catch (Exception e) {    if (em.getTransaction().isActive())        em.getTransaction().rollback();    throw e;} finally {    em.close();}이제 DB에 record 가 추가되어 있음을 볼 수 있다.Entity 동일성 vs 동등성동일성은 메모리 상에서 같은 객체 인스턴스인지를 비교한다.동일성Member member1 = new Member(\"홍길동\");Member member2 = member1;동등성을 보자. 동등성은 엔티티의 내부적인 필드 값들에 대해 같음에 대한 논리적인 비교를 통하여 같은 엔티티인지 비교를 한다. equals() 가 동등성의 예시이다.이때 JPA 에서의 영속화 컨텍스트 내는 @Id 기준 동등성 비교를 하며, 컬렉션에서는 hashCode() + equals() 기준 동등성 비교를 한다. 따라서 Id 만 잘생성시켜줬다면 알아서 영속화 컨텍스트에 들어가는 엔티티가 같은지 판별해준다. 하지만 이는 다음과 같은 상황을 유발한다.@Entitypublic class Member {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String name;    public Member() {}    public Member(String name) { this.name = name; }    // ID 기준으로만 즉, persistence context 내에서만 구분    // equals/hashCode 미구현}// Main.classem.getTransaction().begin();// New 객체 생성 후 persistMember m1 = new Member(\"홍길동\");em.persist(m1);em.getTransaction().commit();// m1은 이제 Managed 상태로 ID가 부여됨System.out.println(\"m1 ID: \" + m1.getId()); // e.g. 1L// Detached 상태에서 객체 수정em.detach(m1);Member m2 = new Member(\"홍길동\"); // 새로운 객체, ID 없음m2.setId(m1.getId());           // 같은 ID를 강제로 세팅// 컬렉션에 넣기Set&lt;Member&gt; members = new HashSet&lt;&gt;();members.add(m1);members.add(m2); // equals/hashCode가 없으면 중복 판단 실패 → 두 객체 모두 추가System.out.println(\"Set 크기: \" + members.size()); // 출력: 2 (중복 있음)// 비정상적위와 같은 오류 때문에 equals, hashCode 의 구현이 Id 를 기준으로 하도록 구현해야 한다.// equals 메서드: id 기반 비교@Overridepublic boolean equals(Object o) {    if (this == o) return true;  // 1. 같은 참조면 true    if (o == null || getClass() != o.getClass()) return false;  // 2. null 또는 다른 클래스면 false    Member member = (Member) o;    return id != null &amp;&amp; id.equals(member.id);  // 3. id가 있고 같으면 true}// hashCode 메서드: id 기반@Overridepublic int hashCode() {    return id != null ? id.hashCode() : 0;  // id가 없으면 0 반환}하지만 이 또한 다음 상황에 대처를 못한다.Set&lt;Member&gt; members = new HashSet&lt;&gt;();members.add(member1);em.persist(member1);  // id 할당// HashSet에서 hashCode 변경으로 member1을 찾을 수 없음따라서 JPA 에 들어가기전 무조건 value 가 있는 값에 대한 equals() 와 hashCode() 를 구현하는 것을 실무에서는 사용하며, 이를 candidate key(후보 키) 로 선정될 수 있는 값을 고르게 된다(실무에서는 비즈니스 키라고 하는 듯하다). 따라서 equals() + hashCode() 를 id 기준으로 규칙에 맞게 설정해줘야 한다.@Overridepublic boolean equals(Object o) {    if (this == o) return true;    if (o == null || getClass() != o.getClass()) return false;    Member member = (Member) o;    return phoneNumber != null &amp;&amp; phoneNumber.equals(member.phoneNumber);}@Overridepublic int hashCode() {    return phoneNumber != null ? phoneNumber.hashCode() : 0;}위에서는 phoneNumber 을 비즈니스 키로 보고 동등성 구현을 한다. 이것만 설정해주면 되는게 아니라 entity 내부에서 phoneNumber 을 비즈니스 키로 한다고 기준을 삼았다면, 엔티티 생명주기 전 구간에서 항상 not null 임을 보장해주어야 한다.기준으로 삼은 키는 다음 규칙을 통해 동등성 구현을 해주어야 한다.엔티티 동등성 구현 규칙  식별자(id) 기반 비교: 데이터베이스 레코드를 대표하는 id로 비교  일관성 유지: equals()가 true면 hashCode()도 같은 값 반환  null 처리: 비영속 엔티티는 id 가 null 일 수 있으므로 null 처리 필수          그래서 비즈니스 키로 우회        복합 키: 키가 여러 필드로 구성되면 모든 필드로 비교@ColumnJPA(Entity 클래스의 필드) 와 데이터베이스의 컬럼(column) 을 매핑할 때 사용하는 애너테이션이다.속성  name: 컬럼의 이름, 기본값은 해당 변수명으로 필드명이 DDL 로 선언되게 된다. 아래와 같이 camel 표기법을 snake 로 바꿔줄 수 있다.@Column(name = \"phone_number\")private String phoneNumber;  unique: @UniqueConstraint 애너테이션의 또 다른 사용으로 유일 제약 조건이 단일 컬럼에만 적용될 때 쓰면 된다. 기본값은 false 이다.  nullable: 데이터베이스의 컬럼이 NULL 을 허용하는지 여부, 기본 값은 true 라서 null 이 들어갈 수 있도록 되어 있다.  insertable: PersistenceProvider 가 생성하는 SQL INSERT 문에 이 컬럼이 포함될지의 여부이다. 만약 false 라면 insert 가 가능하지 않은 필드며, 기본 값은 true 이다.  updatable: PersistenceProvider 가 생성하는 SQL UPDATE 문에 ~ 이하 생략  columnDefinition: DDL 문을 생성할 때, 칼럼의 타입을 그대로 사용하도록 강제하는 옵션이다.          예: @Column(columnDefinition = \"VARCHAR(32) DEFAULT 'A'\") → 생성되는 DDL에 VARCHAR(32) DEFAULT 'A'가 그대로 들어감      NOT NULL 도 넣어도 되지만, nullable 에 쓰는게 가독성이 더 좋을 듯하다.        table: 거의 사용되지 않음, 특정 엔티티가 여러 테이블에 매핑이 될 때, 해당 컬럼이 어느 테이블에 속하는지 지정하기 위해 존재함. 보통 SecondaryTable 이나 SecondaryTables 와 같은 어노테이션과 함께 엔티티가 여러 테이블에서 사용될 때 사용하는데, 다음 예제를 보면 이해가 될 것이다.@Entity@Table(name = \"members\")@SecondaryTable(name = \"member_details\")public class Member {    @Id    private Long id;    @Column(name = \"username\")    private String username; // 기본 테이블 members    @Column(table = \"member_details\", name = \"address\")    private String address;  // 보조 테이블 member_details    @Column(table = \"member_details\", name = \"phone_number\")    private String phoneNumber; // 보조 테이블 member_details}address, phoneNumber 는  member_details 라는 보조 테이블에 저장되고, JPA 가 내부적으로 두 테이블을 ID 기준으로 조인해서 관리하게 된다.  하지만 이는 left join 을 사용하기 때문에 성능상 안좋다. 따라서 자주 사용하지 않는 세부 정보를 분리시켜야 할 때만 사용하는 것이 좋다.  length: DDL 테이블을 생성할 때, VARCHAR 형태의 컬럼을 만들기 위해 사용된다. length = 100 이라면 VARCHAR(100) 에 매핑된다.  precision: 숫자(DECIMAL, NUMERIC 등) 타입의 전체 자릿수(정수부 + 소수부)를 지정하는 옵션이다, scale 과 같이 써야 한다. 만약 scale 을 안쓰면 DB 마다 이를 달리 해석하여 타입을 정하게 된다.  scale: 소수점 이하의 자릿수를 지정하는 옵션, precision 과 같이 써야 한다. 만약 scale 만 있게 되면 오류가 발생 할 수도 있고 아닐 수도 있다. 그냥 같이 쓰자.@EnumeratedEnum 타입 매핑을 할 수 있다.public @interface Enumerated {    /** (Optional) The type used in mapping an enum type. */    EnumType value() default ORDINAL;}  EnumType.ORDINAL: DB 에 Enum 순서(0, 1, 2, …) 로 저장하도록 한다.  EnumType.STRING: DB 에 Enum 이름(String) 으로 저장하도록 한다.public enum MemberStatus {    ACTIVE,    INACTIVE,    SUSPENDED}ORDINAL 규칙을 사용하여 저장할 것이라면, 순서가 바뀌면 모든 데이터가 서로 매핑(순서)이 이상하게 되기 때문에 STRING 을 하는게 좋다. 이때 STRING 으로 하면 자동으로 VARCHAR 타입이 됨을 알고 있자.@TemporalJava 의 Date/Calendar 타입에는 날짜 + 시간 정보가 모두 들어있는데, DB 에는 DATE, TIME, TIMESTAMP 등의 여러 타입으로 나뉘어 저장해야할 수도 있다. 이들에게 매핑시키기 위해 Temporal 어노테이션을 제공하며, 필드에 적용시킬 수 있다.  TemporalType.Date: 날짜만 저장 (DATE yyyy-MM-dd)  TemporalType.TIME: 시간만 저장 (TIME HH:mm:ss)  TemporalType.TIMESTAMP: 날짜 + 시간 모두 저장 (yyyy-MM-dd HH:mm:ss)  Temporal 은 자동 생성이 아니다. 그냥 매핑만 하는것이다. 생성은 따로 해줘야 한다..@Lob문자열 CLOB, 바이너리 BLOB 와 같은 데이터를 정의하고 싶을때 필드에 붙이는 어노테이션이다. 굉장히 큰 데이터를 저장하기 위한 어노테이션이기 때문에 기본적으로 조회할 때 Lazy 로딩을 써야 한다.@Lob@Basic(fetch = FetchType.LAZY)private byte[] imageData;  @Basic 은 fetch, optional 속성만 가지고, 어렵지 않기에 쓰게 될 경우에는 코드 내부를 즉석으로 파헤쳐서 쓰는게 좋다, 기본 값은 각각 FetchType.EAGER, true 이다.@PrePersist 와 @PostPersist@PrePersist 는 우선 메서드에 적용하는 JPA 표준 어노테이션이며, 이 어노테이션이 붙은 메서드는 JPA 엔티티 내부에서 선언되고, JPA 엔티티를 영속화 후 커밋하기 직전에 호출하게 된다. @PostPersist 는 당연하게도 SQL 실행 후의 실행이다(INSERT 문 실행 직전/직후).@Entitypublic class Member {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    @Column(nullable = false, updatable = false)    private LocalDateTime createdAt;    @PrePersist    protected void onCreate() {        System.out.println(\"PrePersist 호출!\");        createdAt = LocalDateTime.now();    }    @PostPersist    protected void afterInsert() {        System.out.println(\"PostPersist 호출!\");    }}  유사하게 @PreUpdate, @PostUpdate, @PreRemove, @PostRemove 도 있다. @PostLoad 는 엔티티 SELECT 직후에 수행된다.JPA 엔티티 매핑테이블에는 JOIN 과 같은 연산을 통해 테이블에 분산된 필드들을 합쳐서 조회할 수 있는 기능을 제공한다. 이를 JPA 에서도 할 수 있다. 여기서는 소유주(Foreign Key 를 가지는 엔티티)가 누구냐가 중요하며, 이를 기준으로 쓰는 애너테이션이 달라진다.@OneToOne단방향 관계를 정의하고 싶을때 사용한다.@Entitypublic class Member {    @Id    private Long id;    @OneToOne    @JoinColumn(name = \"locker_id\") // FK 컬럼 지정    private Locker locker;}@JoinColumn 은 외래 키 컬럼을 정의하는 어노테이션이며, 실제 locker_id 라는 필드명의 열이 생성되며, 이 말은 Member 이 해당 관계의 소유주라는 것이다. @JoinColumn 은 이러한 @~To~ 의 어노테이션과 함께 써야하는 어노테이션이다.@JoinColumn 이 붙여진 필드는 타입을 통해서 저장할 엔티티를 식별하고, 해당 엔티티의 식별자(@Id) 정보를 가져와 @JoinColumn 안의 name 속성을 통해서 열을 정의하게 된다. JoinColumn 어노테이션은 name 속성외에 다양한 속성들을 넣을 수 있다:JoinColumn 속성  referencedColumnName: 참조할 컬럼 지정, 기본적으로 @Id 가 붙은 필드 지정  nullable: FK 컬럼이 NULL 을 허용할지의 여부이다, 기본 값은 true 이다.  insertable / updatable: 설명 생략, 기본 값은 둘 다 true 이다.  unique: FK 컬럼의 유일 여부(OneToOne 에서는 이 속성이 반드시 true 여야 한다.), 기본값은 false 이다.  UNIQUE 제약은 NULL 끼리의 중복은 허용하게 된다.OneToOne 속성      mappedBy: 양방향 연관관계를 설정할 때 핵심적으로 사용하는 속성인데, 연관관계의 주인이 아닌 쪽에서 사용한다. 즉, FK 를 안가지고 있는 쪽에서 사용하며 속성 값으로는 주인이 가진 필드 이름(변수 명)을 지정하게 된다.    fetch: 연관 엔티티의 로딩 방식을 지정한다. FetchType.EAGER 가 기본 값이다.          FetchType.EAGER: 해당 엔티티를 가져올 때, 연관 엔티티도 기본적으로 다 가져옴      FetchType.LAZY: 기본적으로 프록시 객체를 생성하여 미리 채워놨다가, 로직에서 필요한 일이 생길때 그제서야 SQL 문을 던져 해당 프록시 객체를 대체하여 채우게 된다(메모리 최적화).        cascade: 연관 엔티티에 대한 작업을 전파할지 안할지이다. 이는 이전에 배웠던 JS 에서의 클릭 이벤트를 하위 자식에게도 전파할지 아니면 상위 부모에게도 전파할지 아닐지의 개념과 같다.          CascadeType.PERSIST: 해당 엔티티를 Persistence Context 에 올릴 때 연관 엔티티도 자동으로 Persistence Context 에 올림      CascadeType.MERGE: 해당 엔티티를 병합할 때(비영속-&gt; 영속) 연관 엔티티도 병합      CascadeType.REMOVE: 해당 엔티티를 삭제할 때 연관 엔티티도 자동 삭제      CascadeType.REFRESH: 엔티티를 DB 에서 다시 읽어들일 때, 연관 엔티티도 다시 읽어들임      CascadeType.DETACH: 영속 -&gt; 비영속 이하 설명 동일      CascadeType.ALL: 위 옵션들 다 때려 넣은 속성            orphanRemoval: 컬렉션이나 단일 엔티티를 소유하는 관계(owner) 쪽에서 사용해야 의미가 있으며, 해당 소유자가 삭제되면 그 하위 관련 엔티티도 자동 삭제가 된다. 기본값은 false 이다.    optional: null 값 허용 여부 기본은 true위처럼 애너테이션을 필드에 넣었다면 연관된 다른 객체에서는 굳이 아무것도 안해줘도 된다. 하지만 서로간의 데이터를 서로 가지게 하고 싶게 하려면 다음과 같이 구성해야 한다(양방향 소유).@Entitypublic class Member {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String name;    @OneToOne(mappedBy = \"member\") // Locker가 FK 소유하기에 mappedBy 는 소유주 쪽의 변수명을 String 리터럴로 선언    private Locker locker;}@Entitypublic class Locker {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String code;    @OneToOne    @JoinColumn(name = \"member_id\", unique = true) // FK 소유, UNIQUE 제약 조건 명시    private Member member;}DDL 은 다음과 같이 된다.CREATE TABLE member (    id BIGINT PRIMARY KEY,    name VARCHAR(255));CREATE TABLE locker (    id BIGINT PRIMARY KEY,    code VARCHAR(255),    member_id BIGINT UNIQUE,  -- 1:1 관계이므로 UNIQUE 제약    CONSTRAINT fk_locker_member FOREIGN KEY (member_id)        REFERENCES member(id));OneToOne 에서의 FetchType.LAZY 로딩의 문제점성능 최적화를 위해 이때 FetchType.LAZY 로딩을 쓰고 싶을 수 있는데, Locker 는 FK 를 가지고 있기 때문에 owner 이며, Member 는 FK 가 없는 mappedBy 로 종속되고 있는 필드이다. 이때 Member 쪽의 필드에서 FetchType.LAZY 를 적용했다고 쳤을 때, Member 를 조회할 때는 JPA 가 프록시 객체를 만들어서 실제 객체는 필요할 때만 가져오게 될 것이다.근데 여기서 프록시 객체가 정상 동작을 하려면 FK 값이나 식별자를 미리 알아야 한다. 근데 DB 스키마에는 member 테이블에 FK 가 있지 않고 locker 테이블에 FK 를 소유하도록 소유자를 정했기 때문에 프록시 객체가 잘 동작하지 않게 되어서 결국에는 JPA 가 프록시 객체를 생성 못하고 해당 필드를 채우기 위해 바로 조회하도록 하게 만들게 된다. 이는 Fetch.EAGER 로 동작하게 되는 것과 같은 원리다.따라서 다음을 통해 해겷한다:  FK 를 주인 쪽에 뚜기 -&gt; 정상 LAZY  ManyToOne + UNIQUE 제약 패턴 사용 -&gt; LAZY 정상 동작 가능toString(), JSON 의 재귀적 호출 가능성OneToOne 에서나 어느 다른 관계에서나 서로 엔티티 내부에 서로의 변수를 가지도록 한다고 해보자. 그렇다면, toString() 으로 출력할 때, JSON 으로 직렬화 할때에서 서로 계속 호출하게 되어서 무한 루프가 발생한다.이를 방지하기 위해 OneToOne 에서나 OneToMany 에서는 다음 해결책을 쓴다:  문자열 출력 문제는 toString() 두 엔티티 중 한 쪽에서 내부적으로 해당 필드 제외  직렬화 문제는 @JsonIgnore 사용  DTO 로 변환시켜 따로 필드를 선언 후 관리@ManyToOne, @OneToMany@Entitypublic class Member {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String name;    // Member → Order (1:N)    @OneToMany(mappedBy = \"member\", cascade = CascadeType.ALL, orphanRemoval = true)    private List&lt;Order&gt; orders = new ArrayList&lt;&gt;();    // 편의 메서드    public void addOrder(Order order) {        orders.add(order);        order.setMember(this);    }    public void removeOrder(Order order) {        orders.remove(order);        order.setMember(null);    }}@Entitypublic class Order {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String orderNumber;    // Order → Member (N:1)    @ManyToOne(fetch = FetchType.LAZY)    @JoinColumn(name = \"member_id\")    private Member member;    public void setMember(Member member) {        this.member = member;    }}ManyToOne 과 OneToMany 는 항상 서로 붙어 다니는 것을 기억하자. ()To() 중에 첫번재로 오는 단어의 기준은 항상 해당 엔티티에서 나아가는 대응되는 것으로 생각한다. 따라서 Order 의 다수가 Member 1명으로 가기 때문에 Order 에서는 ManyToOne 을 쓴 것을 볼 수 있다.나머지는 다 똑같다. JoinColumn 은 소유하는 엔티티 쪽에 선언하고, FK 필드를 생성하게 Member 하나만 가지게 되는 쪽에 당연히 들어가는게 맞다(Member 쪽에 JoinColumn 을 넣었다면 Order 가 여러 개 이기 때문에 이는 한 필드에 여러 엔티티가 들어가게 됨을 의미한다… 모순이며 중간 테이블이 생성되게 될 수도 있다 bad pattern). 또한 mappedBy 는 당연히 FK 에 의해 종속되는 곳 쪽의 엔티티에서 가져야 한다.EAGER, LAZY 그리고 N+1 문제이전에 봤듯이 EAGER 는 사용 안하는 편이 좋음을 볼 수 있다. 굳이 사용하지도 않는 필드에 대해 다 가지고 와서는 메모리를 다 잡도록 하기 때문에 기본적으로 실무에서는 LAZY 를 전부 다 쓴다. 또한 EAGER 는 내부적으로 SQL 문이 다음과 같이 매번 바뀐다:  부모 엔티티를 조회하고 그 안의 연관 엔티티들도 조회하려고 할 때,          N+1 SELECT 문제가 발생할 수 있음 (예: Team 조회 후 Team 내부의 Member 를 순회하면서 각 Member 를 별도로 조회)        컬렉션 필드가 EAGER일 경우, 내부적으로 SQL이 한 번에 조인되거나 별도 SELECT 로 조회될 수 있음          FK 컬럼이 nullable = true인 경우, LEFT JOIN 이 사용되어 연관 엔티티가 없어도 부모 엔티티는 조회됨 → 카르테시안 곱으로 불필요한 데이터 로딩, 성능 상 안좋음      FK 컬럼이 nullable = false인 경우, INNER JOIN 으로 최적화되어 불필요한 행이 줄어듦 이는 성능 상 좋음        절대 사용하지 말자.따라서 LAZY 를 사용하면 되겠지만, LAZY 에서 하나를 들고 오고(Team 을 들고오고 내부적으로 List&lt;Member&gt; 에 프록시 객체들을 넣어놓음) 다시 그 내부 연관 엔티티들을 순회할 때는 당연히 N+1 번 수행하게 된다. 따라서 위 문제들을 전부 해결하지는 못하고 N+1 의 문제만을 여전히 남겨둔다.  이 문제는 비즈니스 로직에서 내부적으로 연관 엔티티를 전부 순회해야하는 로직이 필요할 때 발생하기에 이런 로직이 없다면 그냥 LAZY 만 써도 된다. 아래의 fetch join 은 선택적으로 써야한다.이를 해결할 수 있는게 바로 fetch join 이다. fetch join 은 sql 문에 직접 있는 기능이며, 이는 inner join 으로 효율적으로 들고오며, eager 에서의 N 번의 select 없이 해당 연관 엔티티들도 전부 영속성 컨텍스트에 올라가게 되며, 내부의 연관 엔티티까지 조회할때 추가적인 SQL 문 없이 컨텍스트에서 사용할 수 있게 된다.@ManyToMany다 대 다의 관계는 보통 실무에서는 중간 테이블을 통해 구현된다. 따라서 다 대 다 어노테이션이 있다면 물리적으로 중간에 테이블이 따로 있다고 보면 된다.  중간에 테이블을 따로 두는 이유는 관계형 데이터베이스는 다대다라는 관계를 지원하지 않는다. 컬렉션 필드를 저장할 수 없을 뿐더러 FK 한 개로는 1:N 관계만이 가능하기에, 중간 테이블을 둬서 관리하게 된다.@Entitypublic class Student {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String name;    @ManyToMany    @JoinTable(        name = \"student_course\",  // 중간 테이블 이름        joinColumns = @JoinColumn(name = \"student_id\"),   // 현재 엔티티 FK        inverseJoinColumns = @JoinColumn(name = \"course_id\") // 상대 엔티티 FK    )    private List&lt;Course&gt; courses = new ArrayList&lt;&gt;();}@Entitypublic class Course {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String title;}Student 가 Courses 를 소유하는 예시이다. 두 쪽 다 접근할 수 있게 하려면 다음 코드로 짠다.@Entitypublic class Student {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String name;    @ManyToMany    @JoinTable(        name = \"student_course\",        joinColumns = @JoinColumn(name = \"student_id\"),        inverseJoinColumns = @JoinColumn(name = \"course_id\")    )    private List&lt;Course&gt; courses = new ArrayList&lt;&gt;();}@Entitypublic class Course {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String title;    @ManyToMany(mappedBy = \"courses\")    private List&lt;Student&gt; students = new ArrayList&lt;&gt;();}JoinTable 에 대해서만 정리하자:  다대다(ManyToMany) 관계에서 중간 테이블(join table)을 정의할 때 사용  중간 테이블 이름, 외래 키 컬럼 등을 지정 가능  단방향/양방향 관계 모두 사용 가능            속성      설명      기본값                  name      중간 테이블의 이름 지정      엔티티 이름 기반 자동 생성              joinColumns      현재 엔티티(FK 소유 엔티티)와 연결되는 컬럼 지정      자동 생성              inverseJoinColumns      상대 엔티티와 연결되는 컬럼 지정      자동 생성              catalog      테이블이 속하는 DB 카탈로그 이름      ””              schema      테이블이 속하는 DB 스키마 이름      ””              uniqueConstraints      중간 테이블의 UNIQUE 제약 조건 지정      없음              indexes      중간 테이블에 생성할 인덱스 지정      없음      Lombok EqualsAndHashCode위에서 엔티티의 동등성을 구현하는 예제를 보았다. 이를 계속 구현해서 쓰기는 반복되는 보일러플레이트 코드가 있을 수 있어 롬복에서는 EqualsAndHashCode 를 통해 쉽게 equals, hashCode 를 생성할 수 있다.모든 필드 기준으로 동등성 검증import lombok.EqualsAndHashCode;import lombok.Data;@Data@EqualsAndHashCodepublic class User {    private Long id;    private String name;    private String email;}특정 필드만 사용@EqualsAndHashCode(onlyExplicitlyIncluded = true)@Datapublic class User {    @EqualsAndHashCode.Include    private Long id;    private String name;    private String email;}특정 필드만 제와@EqualsAndHashCode.Excludeprivate String tempField; // equals/hashCode에 포함되지 않음EqualsAndHashCode 속성  String[] of: equals(), hashCode() 에 어떤 필드만 비교/사용할지 명시  String[] exclude: 어떤 필드들을 제외할지 지정  boolean callSuper: 슈퍼 클래스의 equals/hashCode 도 포함  CacheStrategy cacheStrategy: hashCode() 를 처음 한 번만 계산하고, 그 이후에는 그 결과를 캐싱해서 그대로 가져올 수 있음, 단 해당 객체의 필드가 불변이어야 하며, 불변이 아니라면 캐싱된 값이 잘못된 해시 값으로 남음용어JTA  자바 표준 트랜잭션 관리 API  여러 리소스(DB, 메시지 큐 등)에 걸친 분산 트랜잭션 관리 가능      ACID 트랜잭션 보장    JTA vs RESOURCE_LOCAL            구분      JTA      RESOURCE_LOCAL                  트랜잭션 관리      컨테이너(EJB, Spring) / 애플리케이션 서버      애플리케이션 내에서 직접              지원 범위      여러 DB, JMS 등 분산 트랜잭션      단일 DB 트랜잭션              선언      transaction-type=\"JTA\"      transaction-type=\"RESOURCE_LOCAL\"              커밋/롤백      컨테이너가 관리      개발자가 직접 EntityTransaction 사용        JPA에서 활용          persistence.xml에서 transaction-type=\"JTA\" 설정      컨테이너가 트랜잭션 관리 → EntityTransaction 사용 불필요      Spring에서는 @Transactional 어노테이션으로 간편하게 트랜잭션 관리 가능        핵심 요약          JTA는 분산 트랜잭션 관리용 표준 API      단일 DB만 사용할 경우는 RESOURCE_LOCAL 사용      엔터프라이즈 환경에서 여러 리소스를 하나의 트랜잭션으로 묶고 싶을 때 사용      PersistenceProvider  JPA 구현체를 나타내는 인터페이스  JPA 표준 인터페이스(EntityManager, EntityManagerFactory 등)를 실제 구현체(Hibernate, EclipseLink 등)와 연결      Persistence.createEntityManagerFactory() 호출 시 내부적으로 사용    역할          EntityManagerFactory 생성      EntityManager 생성 시 내부 로직 제공      트랜잭션 처리, 영속성 컨텍스트 관리, SQL 생성 등 JPA 기능을 구현        대표 구현체 예시          Hibernate: org.hibernate.jpa.HibernatePersistenceProvider      EclipseLink: org.eclipse.persistence.jpa.PersistenceProvider        JPA 설정 예시 (persistence.xml)&lt;persistence-unit name=\"examplePU\" transaction-type=\"RESOURCE_LOCAL\"&gt;    &lt;provider&gt;org.hibernate.jpa.HibernatePersistenceProvider&lt;/provider&gt;    &lt;class&gt;com.example.Member&lt;/class&gt;    &lt;properties&gt;        &lt;!-- JDBC 및 Hibernate 설정 --&gt;    &lt;/properties&gt;&lt;/persistence-unit&gt;"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 41일차 JPA 기본",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/10/23/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-41%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-23",
      "content": "📂 목차  JPA          ORM      JPA 장점      JDBC 와 JPA 차이      JPA 클래스 다이어그램                  EntityManagerFactory 인터페이스          EntityManager                    @Entity                  Entity Lifecycle          Entity 동등성          Entity 구현                    Persistence Context                  비영속 엔티티 처리          1차 캐시                    Transaction                  JPA Entity Manager Factory 관리                    📚 본문JPA이전에 배웠던 JDBC 는 테이블을 기준으로 했다면, JPA 는 객체를 기준으로 DB 의 상태를 업데이트를 한다. 자바에석 객체와 관계형 데이터베이스를 매핑(ORM) 하기 위한 표준 인터페이스를 JPA 라고 한다. 따라서 SQL 을 따로 직접 쓰지 않고 객체만을 수정하는 것으로 DB를 다룰 수 있다.plugins {    id 'java'}group = 'org.example'version = '1.0-SNAPSHOT'repositories {    mavenCentral()}dependencies {    implementation 'org.hibernate:hibernate-core:6.4.4.Final'    implementation 'com.mysql:mysql-connector-j:8.3.0'    implementation 'jakarta.persistence:jakarta.persistence-api:3.1.0'    implementation 'org.slf4j:slf4j-simple:2.0.13'    compileOnly group: 'org.projectlombok', name: 'lombok', version: '1.18.32'}test {    useJUnitPlatform()}이런 구현체의 기술은 hibernate 사가 만들었고 이를 바탕으로 인터페이스 표준화 되었다.ORM여기서 ORM은 객체 지향 프로그래밍 언어와 관계형 데이터베이스 간의 데이터를 변환하는 프로그래밍 기술이며, 매개변수를 일일히 binding 시킬 필요 없이 객체만 저장하면 hibernate 가 알아서 ORM 기술을 통해 SQL 문을 생성해준다.JPA 장점  SQL 작성량 감소  유지보수 용이  DB 에 독립적인 코드  객체 지향적인 코드 작성 가능JDBC 와 JPA 차이            구분      JDBC      JPA                  코드 작성      SQL 직접 작성      객체 중심, SQL 자동 생성              데이터 변환      ResultSet 수동 매핑      자동 매핑              생산성      낮음 (반복 코드 많음)      높음 (보일러플레이트 제거)              유지보수      SQL 수정 시 여러 곳 변경      엔티티 변경으로 자동 반영              DB 독립성      낮음 (DB별 SQL 차이)      높음 (Dialect로 자동 처리)              학습 곡선      낮음      높음      JPA 클래스 다이어그램간단히 보자.Hibernate Core 는 실제 구현체이다. 우리는 Interface 만 보고 사용하는데, 인터페이스들 내부를 보자.EntityManagerFactory 인터페이스JPA 의 핵심 구성요소 중 하나이다. DB 와의 연결을 관리하고 EntityManager 를 생성하는 역할을 한다.EntityManagerFactory emf = Persistence.createEntityManagerFactory(\"unitName\");EntityManager em = emf.createEntityManager();따라서 EntityManager 는 factory 에서 최초로 생성되게 된다. EntityManagerFActory 는 당므 역할을 가진다.  생성 책임: EntityManager 객체를 생성  DB 설정 관리: persistence.xml 또는 yml 의 설정 정보를 읽어 DB 연결 구성  비용이 큼: 생성 시 많은 초기화 작업이 일어나므로, 어플리케이션 당 하나만 생성하는 것이 일반적EntityManagerEntityManagerFactory 에서 만들어지는 EntityManager 라는 것은 DB 와의 모든 상호작용을 처리하는 인터페이스이며, Persistence Context 라는 저장소에 엔티티를 저장하고 관리하는 것을 수행한다.  엔티티 저장: persist()  조회: find()  수정: 영속 상태의 엔티티를 변경하면, 트랜잭션 커밋을 통해 자동 반영(Dirty Checking)  삭제: remove()우리가 자주 다루는 객체이며, DB 와 가장 교류가 많이 일어나는 객체이다. 여기서 관리되는 객체를 IoC 컨테이너에서 관리하는 Bean 것처럼 별칭을 붙이는데 Entity 라고 한다.  EntityManager 는 스레드 안전하지 않다. 따라서 각 트랜잭션마다 따로 EntityManagerFactory 를 통해 EntityManager 를 생성하는 것이 좋다.@EntityJPA 를 쓰기 전에 다음 의존성을 추가해준다.// JPA API (표준 인터페이스)implementation 'jakarta.persistence:jakarta.persistence-api:3.1.0'// Hibernate (JPA 구현체)implementation 'org.hibernate:hibernate-core:6.4.4.Final'모르면 위는 검색하면 된다. 엔티티를 정의하기 위해 @Entity 애너테이션을 비즈니스 도메인 쪽에 쓸 수 있다.@Entity  // JPA에게 이 클래스가 테이블과 매핑된다고 알림@Table(name = \"users\")  // (선택) 테이블 이름 지정public class User {    @Id  // 기본 키(PK) 지정    @GeneratedValue(strategy = GenerationType.IDENTITY)  // 자동 증가    private Long id;    @Column(nullable = false, length = 50)  // 컬럼 속성 정의    private String name;    @Column(unique = true, nullable = false)    private String email;    // 기본 생성자 (필수)    protected User() {}    public User(String name, String email) {        this.name = name;        this.email = email;    }    // Getter/Setter}여기서 @Entity 가 해당 클래스가 Entity 로써, JPA 에게 알리는 역할을 한다. 기본적으로 이런 Table 과의 ORM 은 1:1 로 매핑이 되어야 하며, 반드시 식별자가 필요하여서 @Id 로 기본키를 지정하여야 한다.규칙  1:1 로 테이블과 매핑  @Id 식별자 필요  기본 생성자 필요  final 금지(필드던 클래스던)또 위와 같이 설정하면 끝이 아니라, persistence.xml 을 통해 EntityManagerFactory 의 설정을 통해 관리할 엔티티를 추가해줘야 한다.&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;persistence xmlns=\"http://java.sun.com/xml/ns/persistence\"             xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"             xsi:schemaLocation=\"http://java.sun.com/xml/ns/persistence                                 http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd\"             version=\"2.0\"&gt;    &lt;persistence-unit name=\"UserPU\" transaction-type=\"RESOURCE_LOCAL\"&gt;        &lt;provider&gt;org.hibernate.jpa.HibernatePersistenceProvider&lt;/provider&gt;        &lt;class&gt;com.example.jpa.User&lt;/class&gt;        &lt;properties&gt;            &lt;!-- 데이터베이스 연결 설정 --&gt;            &lt;property name=\"jakarta.persistence.jdbc.driver\"                      value=\"com.mysql.cj.jdbc.Driver\"/&gt;            &lt;property name=\"jakarta.persistence.jdbc.url\"                      value=\"jdbc:mysql://localhost:3306/exampledb\"/&gt;            &lt;property name=\"jakarta.persistence.jdbc.user\"                      value=\"user\"/&gt;            &lt;property name=\"jakarta.persistence.jdbc.password\"                      value=\"user1234\"/&gt;            &lt;!-- Hibernate 설정 --&gt;            &lt;property name=\"hibernate.dialect\"                      value=\"org.hibernate.dialect.MySQLDialect\"/&gt;            &lt;property name=\"hibernate.hbm2ddl.auto\"                      value=\"update\"/&gt;            &lt;property name=\"hibernate.show_sql\"                      value=\"true\"/&gt;            &lt;property name=\"hibernate.format_sql\"                      value=\"true\"/&gt;        &lt;/properties&gt;    &lt;/persistence-unit&gt;&lt;/persistence&gt;여기서 persistence-unit 태그가 보일텐데, 이 태그가 하나의 영속성 컨텍스트의 단위를 정의하는 태그이다. name 이 persistence-unit 을 식별하는 이름이며, 나머지 옵션들은 다음과 같다.  transaction-type=\"RESOURCE_LOCAL\": 트랜잭션 타입  provider: JPA 구현체를 지정하는 부분이며 hibernate 사에서 만든 구현체를 넣어주면 된다.  class: 이 persistence-unit 에서 관리할 엔티티 클래스를 명시한다(나머지는 그냥 복붙을 하면 되지만, 이는 개발자가 넣어줘야 한다).  properties: 이는 자바의 프로퍼티 설정하는 것과 똑같다. 생략한다.          hibernate.dialect: SQL 문법 에서 파생된 문법들에 맞춰 자동으로 지정하는 프로퍼티      hibernate.hbm2ddl.auto: 엔티티 기반으로 DDL 스크립트를 자동 처리하는 동작을 지정하는 프로퍼티 시작, create, update, create-drop, validate, none 이 있음      hibernate.show_sql: hibernate 가 실행하는 SQL 을 콘솔에 출력할지 여부      hibernate.format_sql: 로그로 출력되는 SQL 을 보기 좋게 포매팅        create: 기존 테이블 삭제 후 재생성create-drop: 종료 시 테이블 삭제update: 변경사항만 반영validate: 스키마 검증만 수행none: 아무 작업도 하지 않음이제 Entity 를 관리하기 위한 준비를 마쳤으면 엔티티가 어떻게 생성되고 끝나는지도 보자.Entity Lifecycle엔티티는 기본적으로 4가지 상태를 가진다.            상태(State)      설명      주요 특징      전이 메서드 및 조건      DB 반영 시점      비고                  New (비영속, Transient)      엔티티가 생성되었지만 영속성 컨텍스트에 등록되지 않은 상태      - JPA가 관리하지 않음- 식별자(ID) 미할당- DB와 무관      em.persist(entity) → Persistent(영속)      없음      new 키워드로 생성된 엔티티              Managed (영속, Persistent)      영속성 컨텍스트에 의해 관리되는 상태      - 1차 캐시에 저장됨- 변경 감지(Dirty Checking) 가능- 트랜잭션 커밋 시 DB 반영      - persist()로 등록- find() 또는 JPQL 조회 시- merge() 결과로 반환될 때      flush() 또는 트랜잭션 commit 시점      em.detach(), em.clear(), em.close()로 분리 가능              Detached (준영속, Detached)      한때 영속이었으나 현재 컨텍스트와 분리된 상태      - 변경 감지 안 됨- DB 반영 불가- 동일 ID 새 조회 가능      - em.detach(entity)- em.clear() (전체 제거)- em.close() (종료)- 트랜잭션 종료 후      없음      다시 영속화하려면 em.merge(entity) 필요              Removed (삭제 예약, Removed)      엔티티가 삭제 예약된 상태      - DB에서 삭제될 예정- 아직 컨텍스트에는 존재 (삭제 플래그)      em.remove(entity)      flush() 또는 commit() 시점에 DELETE 실행      em.persist()로 다시 영속화 가능 (삭제 취소 효과)              Deleted (DB 삭제됨)      실제로 DB에서 삭제 완료된 상태      - 트랜잭션 커밋 후 DELETE 반영 완료      트랜잭션 커밋 완료 시      이미 DB에서 제거됨      이후 재사용 불가      Entity 동등성JPA 에서 엔티티 동일성을 이해하기 위해 크게 두 가지를 구분해야 한다.  객체 동일성(Object Identity): 자바의 두 객체가 메모리 상 같은 인스턴스인지 여부  논리적 동일성(Entity Identity): 엔티티 PK 를 통해 같은지 판별이를 통해 다음을 보자.Entity 구현import jakarta.persistence.*;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;@Entity@Table(name = \"jpa_user\")@NoArgsConstructor@Getter@Setterpublic class User {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    private String name;    private String email;    public User(String name, String email) {        this.name = name;        this.email = email;    }}@GenearatedValue를 볼 수 있는데, 해당 필드가 DB 테이블의 자동 생성 기능을 이용하고 있고, 그 기능이 어떤 타입인지를 써주면 id 가 null 이더라도 Persist Context 에 들어갔을때 아이디를 자동 생성해준다.  GeneratedType.IDENTITY: MySQL 의 AUTO_INCREMENT 와 매핑  GeneratedType.SEQUENCE: Oracle 이나 PostgreSQL 의 SEQUENCE 자료구조와 매핑  GeneratedType.TABLE  GeneratedType.AUTO: JPA 구현체가 자동으로 생성Persistence Context영속성 컨텍스트라고 하며, 영속성 컨텍스트는 1차 캐시라 봐도 무방하다. 내부적으로 엔티티를 관리할 때 중요한 것은 Entity 의 구별법인데, 여기서 영속성 컨텍스트는 논리적 동일성을 따르고, 따라서 같음을 구현하고 싶을때는 equals() 와 hashCode() 를 PK 기반으로 구현  엔티티 동일성  JPA 에서 엔티티 동일성을 이해할 시 크게 두 가지를 구분      객체 동일성(Object Identity): 자바 == 연산자를 이용해 두 객체가 메모리 상 같은 인스턴스인지 여부    논리적 동일성(Entity Identity): 엔티티 PK 를 통해 같은지 판별  Detached 엔티티와의 동등성을 검증할 때는 PK 가 같아도 서로 다른 자바 객체일 수 있다.User detachedUser = new User();detachedUser.setId(1L);User managedUser = em.find(User.class, 1L);System.out.println(detachedUser == managedUser); // falseSystem.out.println(detachedUser.equals(managedUser)); // true, equals를 PK 기반으로 구현했다면  영속성 컨텍스트 내: 같은 PK → 같은 객체  영속성 컨텍스트 밖: PK 가 같아도 다른 객체 (equals() 는 PK 기반이면 true)  equals / hashCode: PK 기반으로 구현하는 것이 일반적(Lombok 을 씀)동등성 구현 원칙  식별자(id) 기반 비교: 데이터베이스 행을 대표하는 id 로 비교  일관성 유지: equals() 가 true 면 hashCode() 도 같은 값 반환  null 처리: 비영속 엔티티는 id 가 null 일 수 있으므로 null 처리 필수  복합 키: id 가 여러 필드로 구성되면 모든 필드로 비교// equals 메서드: id 기반 비교@Override public boolean equals(Object o) {\tif (this == o) return true; // 1. 같은 참조면 true \tif (o == null || getClass() != o.getClass()) return false; // 2. null 또는 다른 클래스면 false\tUser user = (User) o; \treturn id != null &amp;&amp; id.equals(user.id); // 3. id가 있고 같으면 true } // hashCode 메서드: id 기반@Override public int hashCode() { \treturn id != null ? id.hashCode() : 0; // id가 없으면 0 반환 }비영속 엔티티 처리User user1 = new User(\"Alice\", \"alice@example.com\");  // id = null  User user2 = new User(\"Alice\", \"alice@example.com\");  // id = null    System.out.println(user1.equals(user2));  // false (id가 둘 다 null)Set&lt;User&gt; users = new HashSet&lt;&gt;();users.add(user1);em.persist(user1);  // id 할당됨 (예: id = 1)  // 문제: HashSet에서 hashCode 변경으로 user1을 찾을 수 없음이를 해결하기 위해 엔티티를 컬렉션에 추가하기 전에 영속화하거나, 비즈니스 키 사용 비즈니스 키는 우선 유일해야 하며 not null 이어야 함. 따라서 다음과 같이 구현:@Column(unique = true, nullable = false)private String email; // 비즈니스 키이는 DB 레벨에서의 검증이지 실제 비영속 엔티티를 선언할때 이게 된다는 아니다. 이러고 다음을 구현한다:@Override public boolean equals(Object o) {\tif (this == o) return true; \tif (o == null || getClass() != o.getClass()) return false; \tUser user = (User) o; \treturn email != null &amp;&amp; email.equals(user.email); // email로 비교 }@Overridepublic int hashCode() { \treturn email != null ? email.hashCode() : 0; }이렇게 하더라도 단점이 존재(비즈니스 키 변경시 문제 발생)따라서 실무에서는  논리적 동등성 사용  컬렉션 사용 전 영속화  불변 비즈니스 키 존재 시: email, username 등 불변 필드로 구현 가능@Column(unique = true, nullable = false, updatable = false)// 불변 필드, Setter 은 없애도록, JPA 가 UPDATE 문에서 컬럼 제외, 비즈니스 키로써 적합private String email;  Lombok 사용: @EqualsAndHashCode(onlyExplicitlyIncluded = true) + @EqualsAndHashCode.Include 사용, 롬복은 자동으로 equals(), hashCode() 를 제공함, 하지만 가변 필드를 사용하면 equals / hashCode 변경 가능성이 존재하여 위 코드 예시의 @Column 과 합쳐서 사용하여서 equals() 와 hashCode() 에서 해당 @EqualsAndHashCode.Include가 있는 필드만을 동등성 검증에 포함시켜줌import lombok.EqualsAndHashCode;import jakarta.persistence.*;@Entity@EqualsAndHashCode(onlyExplicitlyIncluded = true)public class User {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    @EqualsAndHashCode.Include    @Column(unique = true, nullable = false, updatable = false)    private String email;    private String name;    public User(String email, String name) {        this.email = email;        this.name = name;    }}1차 캐시영속성 컨텍스트는 1차 캐시가 있음으로써 DB 와의 트래픽을 줄일 수 있다. 처음 엔티티 매니저에게 요청을 하면 엔티티 매니저는 요청을 토대로 Persistence Context 의 1차 캐시에 해당 객체가 있는지를 본다. 만약 찾고자 하는게 없다면 다음 과정을 거친다:read 과정  1차 캐시에 있으면 해당 객체를 반환하고 없다면 다음 과정을 거친다.  Entity Manager 는 빈 객체를 통해서 DB 에게 다시 요청한다(즉 SELECT 쿼리문을 던질 것이다)  Entity Manager 는 해당 객체를 받고 데이터를 Persistence Context 에게 알리며  Persistence Context 는 이를 다시 1차 캐시에 저장한다(없었기 때문)  그러고 result 를 반환한다.따라서 영속성 컨텍스트는 알아서 PK 를 기준으로 하여 객체의 메모리 관리를 진행하게 된다. DB 접근 횟수를 줄이기 때문에 성능 최적화 기능도 한다.Transaction마지막으로 트랜잭션 클래스를 보자. 트랜잭션은 DB 작업의 논리적 단위라고 하며, 여러 작업을 하나로 묶어서 모두 성공하거나 실패하거나 두 상태 중 하나로만 되도록 하는 단위이며 특징으로는 ACID 를 가진다.JPA 에서의 트랜잭션은 DB 의 트랜잭션이랑 의미 차이는 많이 없지만 JPA 에서는 트랜잭션 단위로 영속성 컨텍스트를 관리하게 되고 1차 캐시에 있는 변경 사항을 DB에 반영하고 싶을 때 commit() 을 하며 rollback() 으로 persistence context 에서 진행중인 작업을 이전의 commit 상태로 바꿀 수 있다.EntityManager em = emf.createEntityManager();EntityTransaction tx = em.getTransaction();try {    tx.begin();  // 트랜잭션 시작    User user = new User(\"Alice\", \"alice@example.com\");    em.persist(user); // 1차 캐시에 저장, DB에는 아직 반영 X    user.setName(\"Alice Updated\"); // Dirty Checking으로 변경 추적    tx.commit(); // DB에 INSERT + UPDATE 실행} catch (Exception e) {    tx.rollback(); // 실패 시 DB 반영 취소} finally {    em.close();}위 코드를 사용하여 EntityTransaction 을 가져올 수 있고, 실패시 롤백 까지의 구현을 try-catch 로 할 수 있다.JPA Entity Manager Factory 관리이렇게 보면 엔티티 매니저는 트랜잭션의 시작과 끝에서만 생존하여 메모리에 상주되어야 하므로 함수 내부에서 선언되고 삭제되어야 한다. 이때 이를 만드는 EntityManagerFactory 를 통해서 만들게 되는데, 이를 Singleton 으로 두며, 어플리케이션이 종료될때 factory 자원을 회수할 수 있도록 만드는 코드가 다음과 같다.public class JPAUtil {\tprivate static final EntityManagerFactory emfInstance =\t\t\tPersistence.createEntityManagerFactory(\"lionPU\");\t// Java 어플리케이션이 종료될 때 자동으로 close()메소드가 호출되도록 합니다.\tstatic {\t\tRuntime.getRuntime().addShutdownHook(new Thread(() -&gt; {\t\t\tif (emfInstance != null) {\t\t\t\tSystem.out.println(\"---- emf close ---\");\t\t\t\temfInstance.close();\t\t\t}\t\t}));\t}\tprivate JPAUtil() {}\tpublic static EntityManagerFactory getEntityManagerFactory() {\t\treturn emfInstance;\t}}EntityManagerFactory 는 스레드 안전하기 때문에 저렇게 선언한다고 한들 만들어지는 EntityManager 끼리의 충돌은 없다. static 블록은 클래스가 JVM 에 로드될 때 딱 한 번 실행되는 코드이다. 여기서 어플리케이션 하나에 하나가 생성되는 Runtime 객체를 들고와 addShutdownHook 를 걸고 있는 것을 볼 수 있다.hook 라는 것은 특정 트리거가 실행될 때 실행되는 함수를 말하며 이벤트라고 봐도 무방하다. 따라서 shutdown 되면 해당 Thread 를 실행하는 것을 정의하고 있다(emf의 자원 회수). 중요한 것은 이렇게 static 으로 자원을 회수하도록 코드화 하는 것이다. 다른 클래스에서 해당 자원을 회수하기 위해 회수하는 코드를 추가한다면 SRP 가 훼손될 수 있다.위 방식 말고도 또 다른 방식으로는 Spring 의 이벤트 리스너를 사용하는 것이다(스프링을 가용할 환경이 된다면 쓰도록 한다).@Componentpublic class EMFCleanup {    private final EntityManagerFactory emf;    public EMFCleanup(EntityManagerFactory emf) {        this.emf = emf;    }    @EventListener    public void onApplicationEvent(ContextClosedEvent event) {        if (emf.isOpen()) {            System.out.println(\"---- emf close (Spring) ----\");            emf.close();        }    }}활용은 이 정도만 하면 된다. 나머지 고급 개념들은 다음 포스트에서 다룬다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 40일차 미니프로젝트와 Flux에 대해",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/21/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-40%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-21",
      "content": "📂 목차  Spring Flux          Flux 를 통해 Client 가 쿼리를 보내는 구조                  Backpressure                    Flux 를 통해 Client 가 쿼리를 보내는 구조        Spring JDBC 의 DB Default 기능을 쓰도록 만들기📚 본문Flux플럭스는 Spring WebFlux 에서 제공하는 Reactive Stream 타입 중 하나이다.  Flux&lt;T&gt;: 0-N 개의 데이터를 비동기 스트림으로 처리  Mono&lt;T&gt;: 0-1 개의 데이터를 비동기 처리 (Flux 의 특수 형태)플럭스는 non-blocking 방식의 비동기 처리이기 때문에 요청에 대한 효율적인 처리를 가능하다. 또한 이 때문에 MSA 에서 서비스 간의 통신과 데이터 스트림 처리에 유리하게 된다.Flux Subscribe플럭스는 기본적으로 lazy 하게 동작한다. 해당 데이터를 요청하기 전까지는 아무런 일도 일어나지 않으며 구독 시점에서 데이터 처리가 시작되게 된다.Flux&lt;Integer&gt; numbers = Flux.range(1, 5);numbers.subscribe(System.out::println); // 1~5 출력// 콜백numbers.subscribe(    value -&gt; System.out.println(\"onNext: \" + value),    error -&gt; System.err.println(\"onError: \" + error),    () -&gt; System.out.println(\"onComplete\"));Operators  변환: map, filterMap, concatMap  필터링: filter, take, skip  결합: merge(Flux 합치기), zip(각 Flux1, Flux2 의 요소를 묶어 Tuple 생성), combineLatest  오류 처리: onErrorReturn, onErrorResume, retryPublisher  Cold Publisher: 구독할 때마다 데이터를 새로 생성하는 전략(Flux.range())Flux&lt;Integer&gt; coldFlux = Flux.range(1, 3);coldFlux.subscribe(System.out::println); // 구독할 때마다 1,2,3  Hot Publisher: 발생하는 이벤트를 여러 구독자가 공유하는 전략(Flux.interval() 에 자주 사용)// 1초마다 Long 값을 방출하는 Flux 를 생성, 기본적으로 ColdPublisherFlux&lt;Long&gt; hotFlux = Flux.interval(Duration.ofSeconds(1))                         // Cold Flux 를 Hot Flux 로 변환함,                         // 여러 구독자가 같은 값을 동시에 공유하도록 만듦                         // 즉 구독자가 새로 생겨도 데이터 스트림은 이미 진행중일 수 있음                         .publish()                         // 최소 한 명의 구독자가 나타나면 자동으로 Flux 가 실행되도록 설정함                         .autoConnect();Cold 는 시간 개념이 없고 Hot 은 시간 개념이 있다고 생각하면 된다.Backpressure역압력이라고 하며, 소비자가 처리할 수 있는 속도보다 생산자가 데이터를 더 빨리 보내면 어떻게 처리할지 결정하는 전략을 말한다.Flux 를 통해 Client 가 쿼리를 보내는 구조WebFlux 를 쓰면 일반적으로 클라이언트에서 HTTP 요청을 Controller, Service, Repository 의 흐름으로 처리를 하게 될텐데, 이를 비동기/논블로킹으로 처리하게 된다.만약 클라이언트 요청을 Flux 로 받고 싶다면, Controller 에서 Flux 를 직접 반환하는 경우가 많다. 예시를 보면@Componentpublic class UserClient {    private final WebClient webClient;    public UserClient(WebClient.Builder webClientBuilder) {        this.webClient = webClientBuilder.baseUrl(\"http://user-service\").build();    }    public Flux&lt;UserDto&gt; getUsers() {        return webClient.get() // HTTP GET 요청 준비                        .uri(\"/users\") // 요청할 URI 지정                        .retrieve() // 서버로부터 응답을 가져오기 위한 응답 처리 준비                        .bodyToFlux(UserDto.class); // 서버 응답 Body 를 Flux&lt;UserDto&gt; 로 변환 - Mono 로 하면 안에 List 가 들어감 이를 Flux 로 저장하면 0-N 개의 데이터 처리 가능    }}외부 MSA 서비스 호출용 Client 이며, 내부에서 WebClient 를 이용해 비동기 호출을 할 때 Flux/Mono 를 반환한다. 핵심은 Flux 를 직접 사용하는 로직은 Service 또는 Client 에서 구현하고, Controller 는 단순히 반환만 담당한다.  Client 클래스: MSA API 호출 담당  Service 클래스: 비즈니스 로직 수행Spring JDBC 의 DB Default 기능을 쓰도록 만들기JDBC 를 실제로 쓸때, 흔히 DB 의 기본값이 자동으로 들어갈테니 해당 값을 넣지 않고 save 를 하면 될 줄 알았지만 아니였다.DB 의 기본값 defualt 와 엔티티의 null 은 별개이며, 값을 아직 모른다, 아직 세팅되지 않았다는 null 의 의미는 SQL INSERT 시에 NULL 로 명시적으로 넣게 되어 버린다. 즉 값이 없으니 DEFAULT 를 써야지가 아니라 NULL 을 넣으려고 했구나 라고 인식하게 되며, 이럴 때는 null 도 없도록 아예 필드명을 쓰지 말아야 한다.만약 이를 하고 싶다면 Spring Data JDBC 에서 Auditing 을 활성화하면 되며, 이는 엔티티가 생성 및 수정이 될 때 자동으로 메타데이터 필드들을 관리해준다.@Configuration@EnableJdbcAuditingpublic class JdbcConfig {}이렇게 하면 다음 어노테이션을 사용할 수 있게 된다.@CreatedDateprivate LocalDateTime createdAt;@LastModifiedDateprivate LocalDateTime updatedAt;@CreatedByprivate String createdBy;  insert 시점: @CreatedDate, @CreatedBy 값 자동 세팅  update 시점: @LastModifiedDate 값 자동 세팅즉, Audit 필드를 자동으로 채워주는 기능이지 DB 의 default 값을 직접 트리거 하는 기능은 아니지만, 이를 통해 필드를 자동으로 채워지게 할 수 있다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 39일차 Spring Data JDBC",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/19/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-39%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-19",
      "content": "📂 목차    📚 본문Connection conn = null;PreparedStatement pstmt = null;ResultSet rs = null;try {    conn = dataSource.getConnection();    pstmt = conn.prepareStatement(\"SELECT * FROM users WHERE id = ?\");    pstmt.setLong(1, userId);    rs = pstmt.executeQuery();        if (rs.next()) {        return new User(            rs.getLong(\"id\"),            rs.getString(\"name\"),            rs.getString(\"email\")        );    }} catch (SQLException e) {    throw new RuntimeException(e);} finally {    if (rs != null) try { rs.close(); } catch (SQLException e) {}    if (pstmt != null) try { pstmt.close(); } catch (SQLException e) {}    if (conn != null) try { conn.close(); } catch (SQLException e) {}}이전의 순수 JDBC 의 DB 에게 SQL 문을 던지는 과정이다. 이렇게 장황하고 보일러 플레이트 식 코드는 매우 유지보수가 까다롭고 힘들다. 이를 Spring 과 합치면 매우 간단한 코드가 된다.단점  반복되는 보일러 플레이트 코드  복잡한 예외처리: Checked Exception 인 SQLException 을 매번 처리  리소스 누수 위험: finally 블록에서 수동으로 close() 해야함  가독성 저하: 다른 보일러플레이트 코드 때문에 실제 비즈니스 핵심 로직이 보이지가 않음Spring JDBC스프링이 제공하는 JDBC 템플릿 기반 추상화 계층이며, 예외, 자원 해제, 트랜잭션(위 코드) 등을 자동으로 처리해준다. 개발자는 SQL 과 매핑 로직만 이해하면 된다.JdbcTemplateTemplate Method 패턴으로, “변하는 것과 변하지 않는 것을 분리하라” 를 따라서 다음으로 구분된다.변하지 않는 것(Template)  Connection 획득/반환  Statement 생성/실행  예외 변환  리소스 정리변하는 것(Callback)  SQL 쿼리  파라미터 바인딩  결과 매핑 로직// JdbcTemplate의 내부 구조 (단순화)public class JdbcTemplate {        private DataSource dataSource;        public &lt;T&gt; T query(String sql, RowMapper&lt;T&gt; rowMapper, Object... args) {        Connection conn = null;        PreparedStatement pstmt = null;        ResultSet rs = null;                try {            // 1. 변하지 않는 부분: 리소스 획득            conn = dataSource.getConnection();            pstmt = conn.prepareStatement(sql);                        // 2. 변하지 않는 부분: 파라미터 바인딩            for (int i = 0; i &lt; args.length; i++) {                pstmt.setObject(i + 1, args[i]);            }                        // 3. 변하지 않는 부분: 쿼리 실행            rs = pstmt.executeQuery();                        // 4. 변하는 부분: 결과 매핑 (Callback!)            if (rs.next()) {                return rowMapper.mapRow(rs, 1);            }                    } catch (SQLException e) {            // 5. 변하지 않는 부분: 예외 변환            throw translateException(e);        } finally {            // 6. 변하지 않는 부분: 리소스 정리            closeResultSet(rs);            closeStatement(pstmt);            closeConnection(conn);        }    }}단일 Query 연산JDBC 는 queryForObject 을 사용하여 딱 하나의 row 를 가져올 수 있다.방법 1: RowMapper 직접 구현public User findById(Long id) {    String sql = \"SELECT * FROM users WHERE id = ?\";        return jdbcTemplate.queryForObject(sql,         (rs, rowNum) -&gt; new User(            rs.getLong(\"id\"),            rs.getString(\"name\"),            rs.getString(\"email\"),            rs.getInt(\"age\")        ),         id    );}jdbcTemplate 는 필드에 선언되고 의존성 주입을 받아 사용한다. 이때 jdbcTemplate 의 queryForObject 메서드를 통해 sql과 RowMapper 그리고 그 이후부터는 파라미터 바인딩을 위한 필요한 변수들을 나열해준다.RowMapper 는 BiFunction 이고, 함수형 인터페이스가 들어가며, ResultSet 과 몇 번째 row 인지를 알려주게 된다. 이를 통해 P.S. 가 완성되고, 거기에 binding 하게 된다.방법 2: BeanPropertyRowMapper (자동 매핑)가장 간단하며, 가져올 클래스 명을 직접 넣어주기만 하면 된다.public User findByIdAuto(Long id) {    String sql = \"SELECT * FROM users WHERE id = ?\";    return jdbcTemplate.queryForObject(sql,         new BeanPropertyRowMapper&lt;&gt;(User.class),         id    );}다수 Query 연산여러 개의 rows 를 들고오는 쿼리를 날릴 때는 query, queryForList 를 사용한다. 명칭을 제외한 나머지 문법이나 사용법은 위와 동일하니 그냥 넘어간다.public List&lt;User&gt; findByAgeGreaterThan(int age) {    String sql = \"SELECT * FROM users WHERE age &gt; ?\";    return jdbcTemplate.query(sql, userRowMapper, age);}// queryForList 는 List 로 받을 수 있는 메서드이며 클래스 명을 명시해줘야 한다.public List&lt;String&gt; findAllEmails() {    String sql = \"SELECT email FROM users\";    return jdbcTemplate.queryForList(sql, String.class);}수정 연산(insert, delete, update 등등)간단한 INSERT-INTO-VALUES 나 DELETE-FROM-WHERE 혹은 UPDATE-SET-WHERE 등의 단순한 것들은 생략하겠다.자동 생성된 키를 사용해야 할 때메서드 내의 인자 배열이 조금 달라지는데, 첫번재 인자로 (connection) -&gt; ... 의 함수형 인터페이스가 들어가며 반환 값으로 Statement 를 내뱉는다. 이때 해당 반환값을 설정할 때, connection.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS) 를 선언하여 ps 에서 가져올 수 있도록 한다(executeUpdate() 후에 getGeneratedKeys() 로 얻을 수 있음). 그 다음으로 미리 선언해놓은 KeyHolder(키 보유자) 를 선언하여 생성된 키를 보관할 수 있도록 바구니를 3번째 인자에 건내주면 된다.// 자동 생성된 키 반환public long insertAndGetId(User user) {    String sql = \"INSERT INTO users (name, email, age) VALUES (?, ?, ?)\";        KeyHolder keyHolder = new GeneratedKeyHolder();        jdbcTemplate.update(connection -&gt; {        PreparedStatement ps = connection.prepareStatement(sql,             Statement.RETURN_GENERATED_KEYS);        ps.setString(1, user.getName());        ps.setString(2, user.getEmail());        ps.setInt(3, user.getAge());        return ps;    }, keyHolder);        return keyHolder.getKey().longValue();}가져올 때는 위와 같이 가져오면 된다.배치 삽입BatchPreparedStatementSetter 라는 것을 사용하여 인터페이스를 통해 메서드를 정의시켜주면 된다. 이때 setValues() 는 i 번째에 해당하는 유저 값을 ps 에 넘겨주기만 하면 된다.// 배치 삽입 (대량 데이터)public int[] batchInsert(List&lt;User&gt; users) {    String sql = \"INSERT INTO users (name, email, age) VALUES (?, ?, ?)\";        return jdbcTemplate.batchUpdate(sql, new BatchPreparedStatementSetter() {        @Override        public void setValues(PreparedStatement ps, int i) throws SQLException {            User user = users.get(i);            ps.setString(1, user.getName());            ps.setString(2, user.getEmail());            ps.setInt(3, user.getAge());        }                @Override        public int getBatchSize() {            return users.size();        }    });}  jdbcTemplate.batchUpdate(sql, users, 1000, Mapper) 로 써도 된다.NamedParameterJdbcTemplate순서 기반 파라미터의 문제점:  파라미터 순서 실수 가능  가독성 저하  유지보수 어려움이를 위해 이름 기반의 파라미터 바인딩을 하는 템플릿 등장@Repositorypublic class UserRepository {        private final NamedParameterJdbcTemplate namedJdbcTemplate;        public UserRepository(JdbcTemplate jdbcTemplate) {        this.namedJdbcTemplate = new NamedParameterJdbcTemplate(            jdbcTemplate.getDataSource()        );    }        // Map 사용    public User findById(Long id) {        String sql = \"SELECT * FROM users WHERE id = :id\";                Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();        params.put(\"id\", id);                return namedJdbcTemplate.queryForObject(sql, params, userRowMapper);    }        // SqlParameterSource 사용 (더 타입 안전)    public int insert(User user) {        String sql = \"\"\"            INSERT INTO users (name, email, age)             VALUES (:name, :email, :age)        \"\"\";                SqlParameterSource params = new MapSqlParameterSource()            .addValue(\"name\", user.getName())            .addValue(\"email\", user.getEmail())            .addValue(\"age\", user.getAge());                return namedJdbcTemplate.update(sql, params);    }        // BeanPropertySqlParameterSource (객체 자동 매핑)    public int insertAuto(User user) {        String sql = \"\"\"            INSERT INTO users (name, email, age)             VALUES (:name, :email, :age)        \"\"\";                SqlParameterSource params = new BeanPropertySqlParameterSource(user);        return namedJdbcTemplate.update(sql, params);    }}대충 보면 알겠지만, :(parameter명) 을 기준으로 parameter binding 이 일어나게 되고, SqlParameterSource 라는 인터페이스에 적당한 구현체를 선언하여 쿼리 혹은 수정 실행 메서드에 인자로 같이 넣고 있음을 볼 수 있다. 넣을 수 있는 것들은 다음과 같다.  Map&lt;String, Object&gt;  MapSqlParameterSource: method chaining 가능  BeanPropertySqlParameterSource: 자동 매핑을 시켜줌// IN 절 처리 (여러 값)public List&lt;User&gt; findByIds(List&lt;Long&gt; ids) {    String sql = \"SELECT * FROM users WHERE id IN (:ids)\";        Map&lt;String, Object&gt; params = Map.of(\"ids\", ids);    return namedJdbcTemplate.query(sql, params, userRowMapper);}DataAccessException 계층DataAccessException (unchecked)├── DataIntegrityViolationException│   ├── DuplicateKeyException│   └── ConstraintViolationException├── DataRetrievalFailureException│   └── EmptyResultDataAccessException├── DeadlockLoserDataAccessException└── TransientDataAccessResourceExceptionUnchecked 인 이유는 SQLException 의 대부분은 복구가 불가능하며, 비즈니스 로직에서의 예외 처리 강제는 부적절하기 때문이다. 따라서 이를 null 이나 Optional 로 적절히 흘려보내어 처리하게 된다.SimpleJdbcInsert데이터베이스의 메타데이터를 활용하여 똑똑한 삽입이 가능하다.@Repositorypublic class UserRepository {        private final SimpleJdbcInsert simpleJdbcInsert;        public UserRepository(DataSource dataSource) {        this.simpleJdbcInsert = new SimpleJdbcInsert(dataSource)            .withTableName(\"users\")            .usingGeneratedKeyColumns(\"id\");    }        public long insert(User user) {        Map&lt;String, Object&gt; parameters = new HashMap&lt;&gt;();        parameters.put(\"name\", user.getName());        parameters.put(\"email\", user.getEmail());        parameters.put(\"age\", user.getAge());                // INSERT 문을 자동 생성!        Number newId = simpleJdbcInsert.executeAndReturnKey(parameters);        return newId.longValue();    }        // BeanPropertySqlParameterSource 사용    public long insertAuto(User user) {        SqlParameterSource params = new BeanPropertySqlParameterSource(user);        return simpleJdbcInsert.executeAndReturnKey(params).longValue();    }}Spring Data JDBC &amp; R2DBCSpring Data JDBC 는 어떠한 구현체도 없이 그저 함수명 만으로 함수 내부의 로직을 알아서 전부 짜주는 경지까지 이르지만, 복잡한 쿼리나 최적화가 필요한 쿼리만 일부 짜야 한다.우선 그러려면 Spring Data JDBC 에서 제공해주는 Repository 라는 인터페이스를 먼저 알아야 한다.Spring Data JDBC 공식 문서Repository 인터페이스Spring 데이터 저장소 추상화의 중심은 인터페이스이다. 매개변수화 타입으로 관리할 도메인 클래스 T 와 도메인 클래스의 식별자 유형(PK 유형) ID 를 인수로 받고, Repository 는 이 작업할 유형을 캡처하고 이 인터페이스를 확장하는 인터페이스를 찾는 데 도움이 되는 마커 인터페이스 역할을 하게 된다.  Spring Data 에서는 도메인 유형, 즉 T 를 엔티티 로 간주하며, 데이터의 단위로 간주한다. 따라서 전체에서 엔티티라는 용어가 도메인 유형 또는 집계 라는 용어와 혼용되어서 사용될 수 있다.CrudRepository 인터페이스public interface CrudRepository&lt;T, ID&gt; extends Repository&lt;T, ID&gt; {  &lt;S extends T&gt; S save(S entity);  Optional&lt;T&gt; findById(ID primaryKey);  Iterable&lt;T&gt; findAll();  long count();  void delete(T entity);  boolean existsById(ID primaryKey);  // … more functionality omitted.}모를 땐 코드 내부를 뜯어보면 되니 그냥 외우지 말자. CrudRepository 는 다음과 같은 인터페이스들을 제공한다. 각각은 함수명처럼 직관적이게 동작하며, 이 인터페이스에 선언된 메서드는 일반적으로 CRUD 연산을 할 수 있도록 지원하게 된다.  나중에 메서드 명에 따라 다른 동작을 수행하도록 할 수 있는데, 이는 쿼리 메서드 정의에서 보며, 이 다음 포스팅에서 JpaRepository 또한 이와 같은 것을 제공하며 MongoRepository 도 마찬가지이다.PagingAndSortingRepository 인터페이스우리가 어떤 사이트의 검색을 통해 다양한 것을 검색할 때, 검색 대상의 특성에 따라 내림차순 오름차순 정리를 할 수 있는 것을 볼 수 있는데, 이것이 PagingAndSortingRepository 의 기능이다.public interface PagingAndSortingRepository&lt;T, ID&gt;  {  Iterable&lt;T&gt; findAll(Sort sort);  Page&lt;T&gt; findAll(Pageable pageable);}여기는 Crud 가 없기에 같이 extends 를 해주어서 사용해야한다. 즉, 두 인터페이스를 같이 사용하면 된다.  List 반환 보다는 Iterable 반환Pageable페이징 기능을 구현할 때 핵심이 되는 인터페이스인데 페이지 단위를 들고올 때 Pageable 을 구현한 객체를 통해 Page 를 가져오게 된다.public interface Pageable {    int getPageNumber();  // 현재 페이지 번호 (0부터 시작)    int getPageSize();    // 한 페이지당 보여줄 데이터 개수    long getOffset();     // 몇 번째 데이터부터 시작할지 (pageNumber * pageSize)    Sort getSort();       // 정렬 기준 (Sort 객체)    Pageable next();      // 다음 페이지로 이동    Pageable previousOrFirst(); // 이전 페이지 또는 첫 페이지로 이동    Pageable first();     // 첫 페이지로 이동    boolean hasPrevious(); // 이전 페이지가 있는지 여부}주요 메서드는 위와 같은데, 이를 다 구현하기는 빡쎄고, PageRequest.of 를 통해 Pageable 을 간단히 얻을 수 있다.Pageable pageable = PageRequest.of(0, 10); // 0번 페이지, 페이지당 10개Pageable pageable = PageRequest.of(1, 5, Sort.by(\"name\").ascending());이때 Spring MVC 와 함께 쓴다면 다음과 같이 간단히 된다.@GetMapping(\"/users\")public Page&lt;User&gt; getUsers(Pageable pageable) {    return userRepository.findAll(pageable);}// GET /users?page=0&amp;size=5&amp;sort=name,descPagePage&lt;User&gt; page = userRepository.findAll(pageable);List&lt;User&gt; users = page.getContent();     // 현재 페이지 데이터int pageNumber = page.getNumber();        // 현재 페이지 번호int totalPages = page.getTotalPages();    // 전체 페이지 수long totalElements = page.getTotalElements(); // 전체 데이터 개수boolean hasNext = page.hasNext();         // 다음 페이지 존재 여부Page 는 totalElements 를 계산하기 때문에 조금 무겁다. 대신 Slice 를 사용하면 이를 계산하지 않아도 된다.Slice전체 데이터 개수(total count)를 계산하지 않고, 다음 페이지가 있는지만 알려주는 방식이다.Page 동작SELECT * FROM users ORDER BY id LIMIT 10 OFFSET 0;SELECT COUNT(*) FROM users;Slice 동작SELECT * FROM users ORDER BY id LIMIT 11 OFFSET 0;나머지는 다 같고 그냥 반환값만 Slice 로 해주면 된다.public interface UserRepository extends PagingAndSortingRepository&lt;User, Long&gt; {    Slice&lt;User&gt; findByAgeGreaterThan(int age, Pageable pageable);}⭐️ New Entity Detection기본적으로 Spring Data 의 엔티티가 새로운지 안새로운지의 판단해야 한다. 예를 들어 save() 메서드는 C 기능과 U 기능을 함께 하는 메서드이다(만약 새로운 엔티티라면 Create 기능으로, 새로운 엔티티가 아니라면 Update 기능으로 실행됨).규칙은 위부터 아래로 우선순위를 가진다.규칙  @Id 애너테이션(프로퍼티)          INSERT: null 혹은 원시 타입에서 default value 인 경우 = 신규      UPDATE: 그 외        @Version 애너테이션(프로퍼티) 이 있다면 다음 기준으로 신규 여부 판단          INSERT: null 또는 원시형 = 신규      UPDATE: 값이 존재하고 0이 아님        org.springframework.data.domain.Persistable 인터페이스 구현 시          Spring Data 는 엔티티 내부의 isNew() 메서드를 호출하여 신규 여부를 판단한다.        TIP. AccessType.PROPERTY 를 사용하면 Persistable 속성이 감지되어 유지됩니다. 이를 방지하려면 @Transient 를 사용@NoRepositoryBean 를 정의하여 자주 사용하는 메서드들 정의@NoRepositoryBeaninterface MyBaseRepository&lt;T, ID&gt; extends Repository&lt;T, ID&gt; {    // 모든 Repository 가 공통으로 사용할 메서드    default void printEntityInfo(T entity) {        System.out.println(\"Entity info: \" + entity.toString());    }    // 공통적인 find 메서드 규약 정의    Optional&lt;T&gt; findByName(String name);}interface UserRepository extends MyBaseRepository&lt;User, Long&gt; { … }NoRepositoryBean 은 Bean 으로 등록되지 않도록 하는 애너테이션이다. 이를 통해 MyBaseRepository 는 Bean 으로 등록되지 않고, 이를 상속한 하위 인터페이스들만 실제 Bean 으로 등록되어 사용된다.이를 사용하는 유용한 이유는 공통 로직이나 규약을 묶어두는 베이스 리포지토리를 정의할 때, Spring Data 가 이를 실수로 실제 구현 대상으로 감지하지 않게 만들 수 있기 때문이다.저장소 활성화 구성 정의하기ComponentScan 처럼 EnableJpaRepositories 나 EnableJdbcRepositories 를 통해 Jdbc 레포지토리의 범위를 지정할 수 있다.@Configuration@EnableJpaRepositories(\"com.acme.repositories\")class ApplicationConfiguration {  @Bean  EntityManagerFactory entityManagerFactory() {    // …  }}@Configuration@EnableJdbcRepositories(\"${app.scan.packages}\")public class ApplicationConfiguration {  // …}필터 사용은 ComponentScan 과 동일하다.⭐️ Query MethodRepository Proxy 는 메서드 이름으로 스토리지 별 쿼리를 생성하는 방법 2가지를 제공하게 된다.  메서드 이름으로부터 직접 쿼리를 유도함  수동으로 정의된 @Query 를 사용함이렇게 정의된 사용 가능한 인터페이스 메서드들은 실제 데이터 스토어에 따라 내부적인 쿼리 구조가 달라지지만, 이 쿼리 구조들 중에 반드시 어떤 쿼리가 실행될지를 결정하는 전략이 존재해야만 한다. 이를 Query Lookup Strategies 라고 한다.Query Lookup Strategies레포지토리 프록시가 쿼리를 해결하기 위해 사용할 수 있는 전략은 다음과 같다.  XML 설정에서는 query-lookup-strategy 속성을 통해 네임스페이스 수준에서 전략을 지정  Java 설정에서는 @EnableJdbcRepositories 애너테이션의 queryLookupStrategy 속성을 사용 가능우리는 두번째를 주로 이용하게 된다.  일부 전략은 특정 데이터 스토어에서는 지원되지 않을 수 있음전략 종류  CREATE          메서드 이름으로부터 스토어별 쿼리를 생성하려고 시도한다.      일반적인 접근 방식은 메서드 이름에서 잘 알려진 prefix 를 제거하고 나머지 이름을 파싱하여 쿼리를 구성      prefix 라고 함은 find, get, update 등등 지정된 단어로 시작하는 것        USE_DECLARED_QUERY          이미 선언된 쿼리를 찾으려고 시도하며, 선언된 쿼리를 찾지 못하면 예외를 발생시킴      쿼리는 어노테이션(@Query)이나 다른 방법으로 미리 정의될 수 있음      특정 스토리지에서 사용 가능한 옵션은 해당 스토리지 문서를 참고      리포지토리 인프라가 부트스트랩 시점에 메서드에 대한 선언된 쿼리를 찾지 못하면 실패        CREATE_IF_NOT_FOUND(기본값)          CREATE 와 USE_DECLARED_QUERY 를 결합한 전략이며      먼저 선언된 쿼리를 찾고, 없으면 메서드 이름 기반 커스텀 쿼리를 생성하게 된다.      명시적으로 설정하지 않으면 기본 전략으로 사용된다.      메서드 이름으로 빠르게 쿼리를 정의할 수 있으며, 필요에 따라 선언된 쿼리를 추가해 세밀하게 조정 가능하다.      Query Creation쿼리를 이제 생성하는 규칙을 보자. 크게 쿼리는 다음과 같이 나뉘게 된다.  주어(subject): 첫 번째 부분(find…By, exists…By)은 쿼리의 주어를 정의하고          주어를 나타내는 도입 절(introducing clause) 은 추가 expressions 을 포함할 수 있다.      introducing clause: 이 절의 모든 텍스트는 descriptive 으로 간주되며 Distinct, Top, First 등을 사용하면 쿼리에 distinct 플래그를 설정하거나 결과 개수를 제한할 수 있게 된다.        술어(predicate): 두 번째 부분은 쿼리의 조건을 정의한다.          부록(appendix): 마지막 부분에는 정렬(sorting)과 대소문자(letter-casing) 수정자를 포함한 쿼리 메서드 주어(subject) 키워드와 쿼리 메서드 술어(predicate) 키워드의 콜라보이다.  하지만 첫 번째 By 는 실제 predicate 의 시작을 나타내는 delimiter 역할을 하게 되고, 기본적으로 엔티티 속성에 조건을 정의하고 And, Or 로 연결 할 수 있다. 이런 부록이 연결자를 통해 계속 연결될 수 있다.      실제 메서드 파싱 결과는 쿼리를 생성하는 영속성 저장소(persistence store) 에 따라 달라진다. 하지만 일반적으로 다음 사항들은 유지된다.      expression 은 주로 property 접근과 operator 의 결합으로 이루어지며, 속성 표현식은 And 와 Or 로 결합 가능하다.        Between, LessThan, GreaterThan, Like 등의 연산자를 속성 표현식(부록)에 적용할 수 있으며 지원되는 연산자는 저장소마다 다를 수 있다.        메서드 파서는 개별 속성에 대해 IgnoreCase 플래그를 설정할 수 있다.  Reserved Method Names레포지토리의 메서드는 일반적으로 속성 이름으로 바인딩 되지만, 기본 레포지토리에서 상속 받은 특정 메서드 이름과 관련해서는 몇 가지 예외가 있다. 예를 들어 findById 와 같은 Id 는 실제 @Id 가 풑어있는 속성을 대상으로 하게 된다(findByPk 해도 된다).class User {  @Id Long pk;      // 식별자 속성  Long id;          // 식별자 아님  // …}interface UserRepository extends Repository&lt;User, Long&gt; {  Optional&lt;User&gt; findById(Long id);       Optional&lt;User&gt; findByPk(Long pk);       Optional&lt;User&gt; findUserById(Long id); }Property Expressions속성 표현식은 관리되는 엔티티의 직접적인 속성만을 참조할 수 있다. 이전 예시처럼 쿼리를 생성할 때 파싱된 속성이 도메인 클래스의 속성임을 미리 확인한다. 하지만 엔티티 내의 속성에서 속성의 또 속성을 가지고 오면 어떨까?List&lt;Person&gt; findByAddressZipCode(ZipCode zipCode);예를 들어 Person 이 Address 를 가지고 있고, 그 Address 가 ZipCode 를 가지고 있다고 가정하자. 이 경우 메서드는 x.address.zipCode 라는 속성 탐색(Property Traversal)을 생성한다.생성된 Spring Data JPA 의 속성 탐색의 속성 해석 알고리즘은 다음과 같은 방식으로 작동하게 된다.      AddressZipCode 전체를 하나의 속성 이름(첫 글자 소문자)으로 간주하여 도메인 클래스에서 찾는다.    해당 속성이 없으면, 알고리즘은 오른쪽부터 camel-case 단위로 분할하여 다시 시도한다.          AddressZip, Code 로 분할        분할이 실패하면 왼쪽으로 이동하면서 다시 시도한다.          Address, ZipCode 로 분할      이는 한가지 잘못된 속성을 선택할 위험이 있는 알고리즘인데, 만약 Person 클래스에서 addressZip 이라는 속성이 별도로 존재한다고 해보자. 그러면 알고리즘은 첫번째 분할에서 이미 AddressZip 을 매칭시켜버리고, 그 타입은 code 속성이 없기 때문에 실패하게 된다.이때 메서드 이름에 언더스코어(_) 를 사용하여 명시적으로 탐색 지점을 구분할 수 있으며 다음과 같이 작성하면 된다.List&lt;Person&gt; findByAddress_ZipCode(ZipCode zipCode);_ 에 대한 규칙은 다음과 같다.  _ 로 시작하는 필드명: 밑줄 그대로 유지되며, 중첩 경로를 구분하려면 __ 를 사용해야 한다.  대문자로만 구성된 필드명: 모두 대문자인 필드명은 그대로 사용할 수 있고, 중첩 경로를 표현해야 한다면, _ 로 구분해야 한다.  두 번째 글자가 대문자인 필드명: qCode 처럼 첫 글자는 소문자이고 두 번째 글자가 대문자인 경우, 해석 시 두 글자를 대문자로 시작하는 형태(QCode) 로 사용해야 한다. 즉, String qCode 는 속성 표현식에서 QCode 로 표현해야 한다는 것이다.  경로 모호성: Code q 와 String qCode 둘을 엔티티가 가지고 있고 Code 는 또 String code 를 가지고 있다고 해보자. 이때는 속성 해석 알고리즘은 직접 속성을 우선적으로 하기 때문에 qCode 필드를 먼저 매칭시키게 된다.Repository Methods Returning Collections or Iterables여러 개의 결과를 반환하는 쿼리 메서드는 일반적인 Java 컬렉션 타입인 Iterable, List, Set 을 사용할 수 있다. 이 외에도 Spring Data 에서 제공하는 Streamable(Iterable 을 확장한 커스텀 타입) 이나 Vavr 라이브러리 컬렉션 타입도 반환타입으로 사용할 수 있다(주로 Iterable 을 사용한다).StreamableIterable 이나 일반적인 컬렉션 타입의 대체 타입으로 사용할 수 있다. 이 타입은 Iterable 에는 없는 비병렬(non-parallel) Steam 접근 메서드를 제공하며, filter, map 등의 스트림 연산을 직접 수행할 수 있고, 다른 Streamable 객체들로 바꿀 수 있는 기능도 제공한다.interface PersonRepository extends Repository&lt;Person, Long&gt; {  Streamable&lt;Person&gt; findByFirstnameContaining(String firstname);  Streamable&lt;Person&gt; findByLastnameContaining(String lastname);}Streamable&lt;Person&gt; result = repository.findByFirstnameContaining(\"av\")  .and(repository.findByLastnameContaining(\"ea\"));사용자 정의 Streamable 래퍼 타입 반환컬렉션을 감싸는 전용 래퍼 타입을 제공하는 것은 여러 개의 결과를 반환하는 쿼리 결과에 대한 전용 API 를 제공하기 위한 흔한 패턴이다. 보통 이런 래퍼 타입은 레포지토리 메서드가 컬렉션 타입을 반환한 뒤, 그 결과를 수동으로 감싸서(wrapper instance) 생성하는 방식으로 사용한다.하지만 Spring Data 에서는 다음 조건을 만족한다면 이러한 래퍼 타입 자체를 쿼리 메서드의 반환 타입으로 직접 사용할 수 있다.  그 타입이 Streamable 인터페이스를 구현해야 함  Streamable 을 인자로 받는 생성자 또는 정적 팩터리 메서드(of, valueOf) 중 하나를 제공해야 한다.class Product {                                           MonetaryAmount getPrice() { … }}@RequiredArgsConstructor(staticName = \"of\")class Products implements Streamable&lt;Product&gt; {           private final Streamable&lt;Product&gt; streamable;  public MonetaryAmount getTotal() {                        return streamable.stream()      .map(Product::getPrice)      .reduce(Money.of(0), MonetaryAmount::add);  }  @Override  public Iterator&lt;Product&gt; iterator() {                     return streamable.iterator();  }}interface ProductRepository extends Repository&lt;Product, Long&gt; {  Products findAllByDescriptionContaining(String text); }  @RequiredArgsConstructor(staticName = “of”): final 필드나 @NonNull 이 붙은 필드만을 대상으로 자동으로 생성자를 만들어줌. 이때 of 라는 정적 팩터리 메서드를 생성자 대신 제공해준다. 즉 다음과 같다:```java@RequiredArgsConstructor(staticName = “of”)class Example {    private final String name;}// =========== 아래로 변환 ============public class Example {    private final String name;private Example(String name) {    this.name = name;}public static Example of(String name) {    return new Example(name);} } ```Streaming Query ResultsStream 또한 사용할 수 있는데:@Query(\"select u from User u\")Stream&lt;User&gt; findAllByCustomQueryAndStream();Stream&lt;User&gt; readAllByFirstnameNotNull();@Query(\"select u from User u\")Stream&lt;User&gt; streamAllPaged(Pageable pageable);Stream 은 내부적으로 데이터 저장소 전용 리소스를 감쌀 수 있으므로 사용이 끝난 후에는 반드시 닫아야 한다.Asynchronous Query ResultsSpring 의 비동기 메서드 실행 기능을 사용하면 레포지토리 쿼리를 비동기적으로 실행할 수 있다.즉, 메서드가 호출되자마자 즉시 반환되며, 실제 쿼리는 String 의 TaskExecutor 에 제출된 별도의 작업에서 실행된다고 한다.  비동기 쿼리는 리액티브 쿼리랑은 다르다.@AsyncFuture&lt;User&gt; findByFirstname(String firstname);@AsyncCompletableFuture&lt;User&gt; findOneByFirstname(String firstname);java.util.concurrent.Future 를 반환타입으로 하며, CompletableFuture 도 반환값으로 사용할 수 있다.Paging, Iterating Large Results, Sorting &amp; Limiting쿼리에서 파라미터를 처리하려면, 이전 예제들에서 봤듯이 파라미터로 정의하면 된다. 이외에도 Spring Data 는 Pageable, Sort, Limit 와 같은 특정 타입을 인식하여 쿼리에도 동적으로 페이징, 정렬, 결과 제한 등을 적용시킬 수 있다.Page&lt;User&gt; findByLastname(String lastname, Pageable pageable);Slice&lt;User&gt; findByLastname(String lastname, Pageable pageable);List&lt;User&gt; findByLastname(String lastname, Sort sort);List&lt;User&gt; findByLastname(String lastname, Sort sort, Limit limit);List&lt;User&gt; findByLastname(String lastname, Pageable pageable);Sort, Pageable Limit 를 사용하는 API 들은 null 값이 아닌 인자를 반드시 전달받아야 함을 알고 있자."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 38일차 Spring MVC 심화",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/17/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-38%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-17",
      "content": "📂 목차  Cookie          Cookie 의 구성요소      Spring 에서 Cookie 다루기                  setHttpOnly          setSecure          setSameSite                      Session          Session 동작 원리                  Session 생성                    Session 구조      Session 활용 예시        Exception Handling          ExceptionHandler 규칙      📚 본문Cookie웹 브라우저와 서버 사이에서 정보를 작고 단순한 문자열 형태로 저장하고 주고 받는 방법이며, 서버가 브라우저에 데이터를 잠깐 기억해달라고 요청하면 브라우저는 이를 로컬에 저장하고 같은 도메인으로 요청할 때마다 서버에 다시 전달하게 된다.용도  로그인 상태 유지(Session ID 저장)  사용자 선호 설정 저장(언어, 테마)  트래킹 및 분석(방문 기록, 장바구니 정보)서버측에서는 응답으로 보낼때 쿠키를 저장해달라고 요청할 수 있고, 그때 HTTP 에는 Set-Cookie 헤더가 포함되게 된다. 이후에 브라우저가 요청을 서버에 한다면 자동으로 이 쿠키들이 전송되게 된다.서버 -&gt; 브라우저 Set-Cookie 헤더Set-Cookie: userId=park123; Path=/; Max-Age=3600; HttpOnly; Secure브라우저 -&gt; 서버 CookieCookie: userId=park123  HTTP 상태를 보존하는 가장 낮은 레벨의 메커니즘이 바로 Cookie 이다.Cookie 의 구성요소  Name: 이름  Value: 값  Domain: 쿠키가 적용될 도메인  Path: 쿠키가 적용될 경로  Max-Age: 쿠키 유효기간(-1 이면 창을 껏다 키면 사라지는 옵션)  Secure: HTTPS 에서만 전송  HttpOnly: JS 에서 접근 불가, XSS 방어용  SameSite: CSRF 공격 방지(Strict, Lax, None)Spring 에서 Cookie 다루기@CookieValue 어노테이션을 통해 읽어오기@GetMapping(\"/viewCookie\")public String viewCookie(@CookieValue(value = \"userId\", required = false) String userId,                         Model model) {    model.addAttribute(\"userId\", userId);    return \"cookie_view\";}  브라우저에 쿠키가 저장되어 있고 userId 라는 이름의 쿠키가 있다면 들고옴 없으면 null쿠키 생성 및 저장@PostMapping(\"/addCookie\")public String addCookie(CookieRequest cookieRequest, /* @ModelAttribute 생략 가능 */                        HttpServletResponse response) {    Cookie cookie = new Cookie(cookieRequest.cookieName(), cookieRequest.cookieValue());    cookie.setPath(\"/\");    cookie.setMaxAge(-1);    response.addCookie(cookie);    return \"redirect:/viewCookie\";}  @ModelAttribute 는 하나의 object 만이 요청으로 오게 되면 생략이 가능하다.쿠키 삭제@GetMapping(\"/delCookie\")public String deleteCookie(HttpServletResponse response) {    Cookie cookie = new Cookie(\"userId\", null);    cookie.setMaxAge(0); // 만료    cookie.setPath(\"/\");    response.addCookie(cookie);    return \"cookie_deleted\";}  브라우저에서 쿠키를 제거하려면 같은 이름, 같은 Path, MaxAge=0 으로 다시 보내야 함setHttpOnly자바스크립트에서 쿠키에 접근하는 것을 차단한다. 즉, document.cookie 로 접근할 수 없게 된다.  XSS 공격 방지용  SessionID 가 드러나지 않도록setSecureHTTPS 연결에서만 쿠키를 전송하도록 제한을하며, HTTP 요청에서는 이 쿠키가 전송되지 않는다.  네트워크 상에서 쿠키가 노출되는 것을 방지하고  HTTP 의 암호화 부재로, 누군가 트래픽 감청 시 세션ID 가 노출되면 안된다setSameSiteCSRF 공격 방지를 위해 쿠키가 어떤 요청 상황에서 전송될 수 있는지를 제한하는 옵션이다. 기본값은 Lax 이다.  CSRF 는 요청을 보낸 페이지의 도메인 과 요청을 받는 서버의 도메인이 다를 수 있는데 이럴때 크로스 사이트 요청이라고 한다. 기본적으로 다른 사이트의 요청은 쿠키를 전송하지 않는다.Session웹에서 HTTP 는 stateless 프로토콜이다. 즉, 요청 -&gt; 응답 사이에 서버는 사용자를 기억하지 못하는데, 대부분의 웹 어플리케이션은 사용자 상태 유지가 필요하다.여기서 등장하는 것이 session 이며, 세션은 서버가 클라이언트 별로 유지하는 일시적 데이터 저장 공간이라고 볼 수 있다.Session 동작 원리  사용자가 브라우저로 요청을 보냄  서버는 세션 객체를 생성하고, 고유한 Session ID 를 발급 받음  세션 ID 는 주로 쿠키(JSESSIONID) 를 통해 클라이언트에 전달됨  클라이언트는 이후 요청마다 세션 ID 를 서버에 보내고, 서버는 이를 사용하여 세션 저장소를 조회하게 된다.Session 생성Spring MVC 에서 Session 은 HttpSession 인터페이스를 통해 제공되지만, 실제로는 Servlet 컨테이너(Tomcat, Jetty 등)에서 관리한다. 즉, Spring 이 직접 세션 객체를 만드는 것이 아니라 요청 시 Servlet 컨테이너가 세션을 정하고 Spring 은 그걸 활용한다.따라서 DispatcherServlet 에서 받아진 HttpServletRequest 안에 Session 이 들어있게 된다.  request.getSession() 호출          요청 쿠키에 JSESSIONID 를 확인      없으면 새로운 세션 객체 새성      고유한 세션 ID 를 생성(UUID 또는 랜덤 문자열)      서버 메모리(기본은 HashMap 등)에 세션 저장      클라이언트에게 Set-Cookie: JSESSIONID=랜덤값 전송        이후 요청에서 세션 사용          브라우저가 JSESSIONID 쿠키를 보내면 컨테이너가 세션 객체를 조회해서 반환      Spring Controller 에서 바로 session.getAttribute(\"user\") 등으로 접근 가능      Session 구조  HttpSession: 인터페이스  StandardSession (Tomcat 구현)          id: 세션 식별자      creationTime: 세션 생성 시간      lastAccessedTime: 마지막 접근 시간      attributes: 세션에 저장된 key-value Map        Servlet 이 생성함을 알고 있자Session 활용 예시@GetMapping(\"/login\")public String login(HttpSession session) {    // 로그인 성공 후 사용자 정보를 세션에 저장    session.setAttribute(\"user\", \"park\");    session.setAttribute(\"role\", \"admin\");    return \"home\";}  이때 String, Object 로 들어가는데, Object 는 Serializable 해야 한다.SessionAttribute@ModelAttribute 처럼 여기서도 @SessionAttribute 의 name 옵션은 생략 가능하다.@GetMapping(\"/dashboard\")public String dashboard(@SessionAttribute(name=\"user\", required=false) String user) {    if (user == null) return \"redirect:/login\";    return \"dashboard\";}SessionAttributes이 어노테이션은 살짝 헷갈릴 수 있는데, 새롭게 접속하는 클라이언트는 쓸려는 key 가 Session 에 없기 때문에 @ModelAttribute 로 key 가 생성되면 @SessionAttributes 덕분에 이 값이 세션에도 저장되게 된다. 즉, HTTP Session 이 생성될 때마다 자동으로 저장하도록 지정한다.@SessionAttributes(\"visitCount\")public class SessionController {\t// HTTP Request 에서 모델에 값이 없을 때만 호출되는 애너테이션이다.    // 하지만, 위에서 SessionAttributes 로 HTTP Session 범위로 만들었기 때문에 해당 key 는 세션이 끝날때까지 계속 유지\t@ModelAttribute(\"visitCount\")\tpublic Integer initVisitCount() {\t\tSystem.out.println(\"initVisitCount\");\t\treturn 0;\t}    ...}  만약 클라이언트가 같은 컨트롤러의 다른 요청을 다시 보내게 되면 세션에 이미 key 가 존재해서, 이 값을 자동으로 Model 에 적용하고, 이 어노테이션은 Controller 단위로 적용되므로 다른 컨틀롤러에서는 해당 key-value 를 못쓴다. 다만, 다른 컨트롤러에서 동일 key 를 수동으로 꺼내서 쓰는건 가능하다. 세션은 공유 영역이기 때문Exception Handling보통 자바에서 에러를 만나게 되면 내부적으로 try-catch 를 사용하여 처리를 하게 된다. 하지만 이를 컨트롤러에서 메서드 하나하나 마다 생성시킨다고 한다면 유지보수가 어려워진다.이때 사용할 수 있는게 @ExceptionHandler 이다. 컨트롤러 단위에서 예외 처리를 해주고 예외를 한 곳에서 처리할 수 있다. 만약 하나의 컨트롤러에 대해서 Exception Handling 을 하고 싶다면 그 컨트롤러 내부에 @ExceptionHandler 가 붙은 메서드를 정의하면 된다.@Controllerpublic class UserController {    @GetMapping(\"/user\")    public String getUser(@RequestParam(required = false) String name) {        if (name == null) throw new IllegalArgumentException(\"이름이 없습니다!\");        return \"user\";    }    @ExceptionHandler(IllegalArgumentException.class)    public String handleIllegalArgument(IllegalArgumentException e, Model model) {        model.addAttribute(\"error\", e.getMessage());        return \"error\"; // error.html 로 포워딩    }}모든 컨트롤러 즉, 전역적인 예외 처리를 하고 싶다면 클래스를 따로 만들어 @ControllerAdvice 를 클래스에 붙여주면 된다.@ControllerAdvicepublic class GlobalExceptionHandler {    @ExceptionHandler(IllegalArgumentException.class)    public String handleIllegalArgument(IllegalArgumentException e, Model model) {        model.addAttribute(\"error\", e.getMessage());        return \"error\";    }    @ExceptionHandler(Exception.class)    public String handleGeneral(Exception e, Model model) {        model.addAttribute(\"error\", \"서버 오류가 발생했습니다.\");        return \"error\";    }}ControllerAdvice 는 다음 옵션을 제공한다.  basePackages: 특정 패키지 하위의 컨트롤러들에만 예외 처리를 적용할 때 사용@ControllerAdvice(basePackages = \"com.example.user\")public class UserExceptionHandler { ... }  basePackageClasses: 클래스 기준으로 패키지를 지정할 수 있다. 해당 클래스가 속한 패키지가 자동 인식된다. 아래와 같이 쓰면 UserController 가 속한 패키지의 모든 컨트롤러에 적용됨@ControllerAdvice(basePackageClasses = UserController.class)public class UserExceptionHandler { ... }  assignableTypes: 특정 클래스나 타입(컨트롤러 클래스 또는 인터페이스)에만 예외 처리를 적용, basePackageClasses 랑 다른 점은 속한 클래스의 적용 유무이다.@ControllerAdvice(assignableTypes = {AdminController.class, UserController.class})public class SpecificControllerAdvice { ... }  annotations: 특정 애너테이션이 붙은 컨트롤러들에만 적용@ControllerAdvice(annotations = RestController.class)public class RestApiExceptionHandler { ... }  RestControllerAdvice 는 REST API 용 전역 처리ExceptionHandler 규칙모든 편리한 것에는 규칙이 있음을 잊지 말고 여기서도 규칙을 지키도록 어떤 규칙이 있는지 보자.보통 @ExceptionHandler 메서드가 자동으로 주입 받을 수 있는 인자는 컨트롤러의 일반 핸들러 메서드와 동일한 규칙으로 인자를 해결한다. 즉 HandlerMethodArgumentResolver 들이 지원하는 모든 타입이 사용 가능하다.  예외 타입  HTTP 관련 표준 타입          HttpServletRequest      HttpServletResponse      HttpSession      ServletRequest / ServletResponse      WebRequest        Spring MVC 의 웹레벨 도우미          HttpEntity      Locale      Principal      InputStream / Reader 등등        모델 관련 타입(보통 key-value 를 나타내는거-Map 면 다 된다)          Model      ModelMap      ModelAndView      Map&lt;String, Object&gt;        요청 바인딩 관련          @RequestParam      @RequestHeader      @RequestBody      @PathVariable      @ModelAttribute      @CookieValue      @SessionValue      …      위 타입들은 자동으로 주입 받는다. 따라서 보통 첫 인자로 Exception 하위 클래스를 인자를 정의해주면 내부에서 이를 사용할 수 있다. 그리고 보통 Error 처리를 할 때, Status 코드와 에러 메시지를 열거형으로 선언하고 이를 사용해주는게 깔끔할 것 같다.@ControllerAdvicepublic class GlobalExceptionHandler {    @ExceptionHandler(ResourceNotFoundException.class)    public ModelAndView handleNotFound(ResourceNotFoundException e) {        ModelAndView mav = new ModelAndView(\"error/404\");        mav.addObject(\"message\", e.getMessage());        return mav;    }    @ExceptionHandler(ValidationException.class)    public String handleValidation(ValidationException e, Model model) {        model.addAttribute(\"errors\", e.getErrors());        return \"error/validation\";    }    @ExceptionHandler(DataAccessException.class)    public String handleDatabaseError(DataAccessException e,                                     Model model) {        logger.error(\"Database error\", e);        model.addAttribute(\"error\", \"Database error occurred\");        return \"error/500\";    }    @ExceptionHandler(Exception.class)    public String handleGeneral(Exception e, Model model) {        logger.error(\"Unexpected error\", e);        model.addAttribute(\"error\", \"An unexpected error occurred\");        return \"error/general\";    }}// Custom Exceptionpublic class ResourceNotFoundException extends RuntimeException {    public ResourceNotFoundException(String message) {        super(message);    }}"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 37일차 Spring MVC 기초",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/16/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-37%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-16",
      "content": "📂 목차  Spring MVC          Controller 설계                  @RequestMapping          @PathVariable          @RequestParam          @RequestBody          ⭐️ @RequestHeader          고급 옵션                    Model &amp; View      Thymeleaf                  ⭐️ Spring 의 Model, BindingResult 바인딩 처리 및 Thymeleaf 의 BindingResult 호출          ⭐️ @ModelAttribute 와 Thymeleaf 사이의 생략 관계 정리                    Forwarding 과정      Redirecting 과정      Forward vs Redirect 비교 요약      📚 본문Spring MVCModel-View-Controller 패턴을 기반으로 하는 웹 애플리케이션 프레임워크  Model: 비즈니스 데이터 + 로직  View: 사용자에게 보여지는 화면 (HTML, JSON 등)  Controller: 요청을 받고 Model과 View 를 연결Spring 은 MVC 2.0 버전 패턴으로 위와 같이 적용하고 있다. DispatcherServlet 은 모든 HTTP 요청의 진입점이며, 톰캣과 디스패쳐가 연결되어 있다. 처리 과정을 자세히 살펴보자.  브라우저에서 요청, DispatcherServlet 이 받음  HandlerMapping가 어떤 Controller 가 이 요청을 처리할지 찾음  HandlerAdapter가 알맞은 Controller 메서드를 호출함  Controller 는 메서드 호출 받았을 때, Model 데이터를 만들고 View 이름을 반환하게 된다.          모델을 어떤 view 에 적용시켜줄지를 알려주어야 하니 view 이름을 반환하는 것이다.        ViewResolver 가 View 객체를 생성한다.  View 는 생성된 Model 을 읽어들여서 데이터를 적용한다  View 가 사용자에게 결과를 전달한다.Browser Request      ↓DispatcherServlet      ↓HandlerMapping → 어떤 Controller인지 결정      ↓HandlerAdapter → Controller 호출      ↓Controller → Model 생성 / View 이름 반환      ↓ViewResolver → View 객체 생성      ↓View → 사용자에게 HTML / JSON 응답개발자가 관여할 것은 보라색 뿐이다. 이제 이를 설계해보자.Controller 설계@RestController@RequestMapping(\"/users\")public class UserController {    @GetMapping(\"/{id}\")    public UserDto getUser(@PathVariable Long id) {        return userService.getUserById(id);    }    @PostMapping(\"/\")    public UserDto createUser(@RequestBody UserDto userDto) {        return userService.createUser(userDto);    }}하나하나 뜯어본다.@Controller 는 Spring MVC에서 웹 요청을 처리하는 클래스임을 나타내는 애너테이션이다. 즉, 이 클래스 안의 메서드들이 HTTP 요청과 응답을 담당하게 된다.역할  클래스 레벨에 붙음 → 이 클래스가 Controller 임을 Spring 에 알림  Spring Bean 으로 등록 → IoC 컨테이너에서 관리  ⭐️ 중요: @RestController = @Controller + @ResponseBody 의 결합이며 반환값을 JSON, HTTP Body 로 바로 전달하고 싶을 때 쓴다.@RequestMappingController 에 들어가는 함수들은 전부 제 기능을 하기 위해 @RequestMapping 이 주로 붙는다.@RequestMapping(value = \"/users\", method = RequestMethod.GET)public List&lt;User&gt; getAllUsers() { ... }이때 위 애너테이션은 다음과도 같다.@GetMapping(\"/users\")public List&lt;User&gt; getAllUsers() { ... }더 쉽게 제공하는 편이다. 이런게 4개 더 있다.            매핑 어노테이션      설명      예시                  @GetMapping      GET 요청 처리      @GetMapping(\"/users\")              @PostMapping      POST 요청 처리      @PostMapping(\"/users\")              @PutMapping      PUT 요청 처리      @PutMapping(\"/users/{id}\")              @DeleteMapping      DELETE 요청 처리      @DeleteMapping(\"/users/{id}\")              @PatchMapping      PATCH 요청 처리      @PatchMapping(\"/users/{id}\")      @RestController@RequestMapping(\"/users\")public class UserController {    @GetMapping(\"/{id}\")    public String getUser(@PathVariable Long id) {        return \"사용자 조회: \" + id;    }    @PostMapping(\"/\")    public String createUser(@RequestBody String userName) {        return \"사용자 생성: \" + userName;    }    @PutMapping(\"/put/{id}\")    public String updateUser(@PathVariable Long id, @RequestBody String newName) {        return \"사용자 수정: \" + id + \" -&gt; \" + newName;    }    @DeleteMapping(\"/delete/{id}\")    public String deleteUser(@PathVariable Long id) {        return \"사용자 삭제: \" + id;    }    @PatchMapping(\"/patch/{id}\")    public String patchUser(@PathVariable Long id, @RequestBody String newEmail) {        return \"사용자 이메일 수정: \" + id + \" -&gt; \" + newEmail;    }}위와 같이 사용 가능하다. 여기서 잘 보면 @RequestMapping 어노테이션을 클래스 레벨에 두어 내부 메서드 레벨의 @RequestMapping 들에 대해서 prefix 를 적용하는 것처럼 된다.이제 파라미터에 대한 매핑을 보자.파라미터 매핑| 어노테이션        | 설명                                  ||——————|————————————|| @PathVariable   | URL 경로의 변수 값을 매핑          || @RequestParam   | 쿼리 파라미터 값을 매핑             || @RequestBody    | 요청 Body(JSON 등)를 객체로 매핑   || @RequestHeader  | HTTP Header 값 매핑             || @CookieValue    | 쿠키 값 매핑                     || @ModelAttribute | 폼 데이터를 객체에 바인딩           |하나하나 다 중요한 것들이니 자세히 본다.@PathVariableUrl 에 있는 값을 그대로 받을 수도 있다. 이는 사용자 검색을 더 편리하게 할 수 있고, 스크래핑 정보도 제공하기 편리하게 할 수 있다.@GetMapping(\"/users/{id}\")public String getUser(@PathVariable Long id) {    return \"사용자 조회: \" + id;}@RequestParamurl 전체의 query 부분으로 key-value 를 보낼때 이를 받게 할 수도 있다.// GET /users/search?name=홍길동&amp;age=20@GetMapping(\"/search\")public String searchUser(        @RequestParam String name,        @RequestParam int age) {    return \"검색 사용자: \" + name + \", 나이: \" + age;}@GetMapping(\"/search\")public String searchUser(        @RequestParam(name = \"name\", required = false, defaultValue = \"익명\") String name,        @RequestParam(name = \"age\", required = false, defaultValue = \"0\") int age) {    return \"검색 사용자: \" + name + \", 나이: \" + age;}// GET /users/filter?roles=ADMIN&amp;roles=USER&amp;roles=GUEST@GetMapping(\"/filter\")public String filterUsers(@RequestParam List&lt;String&gt; roles) {    return \"필터 역할: \" + roles;}PostMapping 을 통해서 form 으로 password, username 등도 받을 수 있다.  여러 개를 받을 때는 &amp;로 연결하고 key 를 중복해서 선언해주면 된다.@RequestBody보통 API 만들 용도로 쓰인다 왜냐면 body 자체가 구조화된 데이터 형태로 들어와야 자바 객체로 변환하기 편하며, 클라이언트가 보낸 JSON 등의 데이터를 객체로 직접 받을 때 사용하면 된다.@PostMapping(\"/\")public String createUser(@RequestBody UserDto userDto) {    return \"사용자 생성: \" + userDto.getName() + \", 나이: \" + userDto.getAge();}  @RequestBody: HTTP 요청의 Body 부분(JSON, XML, 텍스트 등)을 자바 객체로 바로 변환해주는 역할(보통 JSON 등으로 매핑)⭐️ @RequestHeader/* GET /users/header Authorization: Bearer abc123 User-Agent: Chrome*/@GetMapping(\"/header\")public String getHeader(        @RequestHeader(\"Authorization\") String authHeader,        @RequestHeader(value = \"User-Agent\", required = false) String userAgent) {    return \"인증 헤더: \" + authHeader + \", 브라우저: \" + userAgent;}보통 인증 토큰이 있는지 없는지 판별할 때 쓸 수 있겠다.  토큰 인증  API 키 검증고급 옵션RequestMapping 에서 붙일 수 있는 옵션이며, 단순히 요청 뿐 아니라 형식, 파라미터, 헤더에 따라 매핑을 더 세밀히 제어할 수 있도록 한다.            옵션      설명                  consumes      요청 Content-Type 제한 (application/json)              produces      응답 Content-Type 지정 (application/json)              params      특정 요청 파라미터 존재 여부로 매핑              headers      특정 HTTP 헤더 존재 여부로 매핑      사용 예시consumes 는 요청 Content-Type 을 제한하는데, 쉽게 말해서 JSON 요청만 처리하게 제한하도록 할 수 있고 다른 다양한 것들이 있다.consumes@PostMapping(value = \"/users\", consumes = \"application/json\")public String createUser(@RequestBody UserDto userDto) {    return \"JSON으로 사용자 생성: \" + userDto.getName();}produces 는 응답의 Content-Type 을 지정한다. 위랑 다르다. 만약 다음과 같이 입력되었다면 JSON 형태로만 응답하도록 지정하는 것과 같다.produces@GetMapping(value = \"/users/{id}\", produces = \"application/json\")public UserDto getUser(@PathVariable Long id) {    return new UserDto(id, \"홍길동\", 25);}params 는 특정 쿼리 파라미터 조건이 있을 때만 매핑을 하게 된다. 예를 들어 admin 이라는 parameter key 에 value 로 true 가 아니라면 해당 함수는 매핑이 안되게 된다. 따라서 두 메서드는 다른 메서드로 동작되고 중복 선언으로 오류가 안뜬다.params// 예: /users/search?admin=true 일 때만 매핑됨@GetMapping(value = \"/users/search\", params = \"admin=true\")public String searchAdminUsers() {    return \"관리자 계정 검색\";}// 예: /users/search?role=user 일 때만 매핑됨@GetMapping(value = \"/users/search\", params = \"role=user\")public String searchNormalUsers() {    return \"일반 사용자 검색\";}headers 는 요청이 오는 HTTP 헤더에 조건이 있을때만 매핑을 하게 된다. 브라우저 별로 사용하는 API 가 달라서 그에 호환되는 처리를 할 수도 있다.headers@GetMapping(value = \"/users/version\", headers = \"X-API-VERSION=1\")public String getUserV1() {    return \"API Version 1 호출됨\";}@GetMapping(value = \"/users/version\", headers = \"X-API-VERSION=2\")public String getUserV2() {    return \"API Version 2 호출됨\";}이제 Model 과 View 를 보자.Model &amp; View모델은 단순히 데이터를 담는 통(Bean) 이며, 요청과 응답 사이에서 데이터를 전달하는 핵심 매개체이다. Spring MVC 에서는 다음 3가지 형태로 Model 을 다룬다.  org.springframework.ui.Model: 단순 key-value 저장소  ModelMap: Model 과 유사하나 LinkedHashMap 기반  ModelAndView: Model + ViewName 을 한번에 관리  사용자의 요청이 들어오면 DispatcherServlet 이 해당 Controller 메서드를 호출한다.  Controller 메서드는 비즈니스 로직을 수행하고, 그 결과를 Model 에 담는다.  DispatcherServlet 은 Model 에 담긴 데이터를 View 에 전달한다.  View(예: Thymeleaf, JSP) 는 ${key} 또는 *{key} 문법으로 데이터를 참조한다.String 예시@Controller@RequestMapping(\"/example\")public class ExampleController {    @GetMapping(\"/model\")    public String modelExample(Model model) {        // Model에 데이터 담기        model.addAttribute(\"message\", \"Hello, Model!\");        model.addAttribute(\"number\", 42);        // view 이름 반환 (hello.html)        return \"hello\";    }}ModelMap 예시@Controller@RequestMapping(\"/example\")public class ExampleController {    @GetMapping(\"/modelmap\")    public String modelMapExample(ModelMap modelMap) {        // ModelMap에 데이터 담기        modelMap.put(\"message\", \"Hello, ModelMap!\");        modelMap.put(\"number\", 123);        // view 이름 반환 (hello.html)        return \"hello\";    }}ModelAndView 예시@Controller@RequestMapping(\"/example\")public class ExampleController {    @GetMapping(\"/modelandview\")    public ModelAndView modelAndViewExample() {        ModelAndView mav = new ModelAndView();        // view 이름 지정        mav.setViewName(\"hello\");        // 데이터 추가        mav.addObject(\"message\", \"Hello, ModelAndView!\");        mav.addObject(\"number\", 999);        return mav;    }}  redirect 방식은 ModelAndView(\"redirect:(path)\") 처럼 ModelAndView 에서도 사용 가능하다.ThymeleafJava spring 에서 자주 사용하는 HTML 렌터링 서버사이드 템플릿 엔진이다.기본 구조는 다음과 같고, resorces/templates/ 폴더에 html 을 저장하게 된다.&lt;!DOCTYPE html&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt;    &lt;title&gt;Thymeleaf 예제&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1 th:text=\"${message}\"&gt;Hello&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;꼭 html 에 태그로 xmlns:th=\"http://www.thymeleaf.org\" 를 넣어주어야 한다. th 는 자유다. Thymeleaf 는 View 계층에 포함되는 애이며, 여기에 들어가는 데이터들이 전부 Model 에서 가져오게 되겠다.텍스트 표현  th:text=\"${var}: 변수 값 출력  th:utext=\"${var}: HTML 태그를 포함한 문자열 출력 (escape 안함)  th:inline=\"text\": 텍스트 인라인 표현 가능 ${var} 사용속성 바인딩  th:href=\"@{/home}\": 링크 URL 바인딩  th:src=\"@{/images/logo.png}\": 이미지 src 바인딩  th:class=\"@{condition ? 'active' : ''} 조건부 클래스 적용조건문  th:if: 조건이 true 면 해당 태그 렌더링  th:unless: 조건이 false 면 해당 태그 렌더링  &lt;p th:text=\"${user.age &gt;= 18 ? '성인' : '미성년'}\"&gt;&lt;/p&gt; 처럼 쓸 수도 있다.반복문  th:each=\"(for 내부 변수) : ${var}\": 컬렉션 반복URL 링크 처리  th:href=@{경로}: 컨텍스트 경로 자동 적용이 된다. ${} 와 같이 경로 안에 파라미터 포함 가능  실습 코드에서는 다음과 같이 되어 있는데, &lt;a th:href=\"@{/users/{id}(id=${user.id})}\"&gt;View Profile&lt;/a&gt; {} 는 단순 변수이며 $ 나 * 등이 없다. 이때는 () 를 통해 id 에 직접 넣을 수 있도록 할 수 있다.변수 표현식  ${var}: 일반 변수  *{field}: form 객체의 field (th:object 안에서)&lt;!-- Form 처리 --&gt;&lt;form th:action=\"@{/users}\" th:object=\"${userForm}\" method=\"post\"&gt;    &lt;input type=\"text\" th:field=\"*{username}\" /&gt;    &lt;input type=\"email\" th:field=\"*{email}\" /&gt;    &lt;button type=\"submit\"&gt;Submit&lt;/button&gt;&lt;/form&gt;  #{msg.key}: 메시지 국제화(i18n)          messages.properties 에 greeting=안녕하세요, {0}님의 key-value 가 있다고 쳐보자.  Thymeleaf 를 쓰는 HTML 에서는 다음과 같이 쓸 수 있다.  &lt;p th:text=\"#{greeting(${user.name})}\"&gt;기본 인사&lt;/p&gt;        ~{template}: fragment/template 참조 아래를 통해 더 자세히 살펴보자.th:replace&lt;!-- header.html --&gt;&lt;!-- fragment 등록 --&gt;&lt;div th:fragment=\"header\"&gt;    &lt;h1&gt;사이트 헤더&lt;/h1&gt;&lt;/div&gt;&lt;!-- main.html --&gt;&lt;!-- fragment 사용 --&gt;&lt;div th:replace=\"header :: header\"&gt;&lt;/div&gt;템플릿의 위치는 application.yml 이나 프로퍼티에 spring.thymeleaf.prefix=classpath:/templates/, spring.thymeleaf.suffix=.html 처럼 기본적으로 넣어져있고, 이를 따로 지정하여 넣어줄 수 있다. 이때 그 하위의 html 에 대한 Thymeleaf 문법으로 작성된 문서들이 다 불러와지고, fragment 도 그때 등록된다. 추가로 더 알아볼 것은 ClassLoaderTemplateResolver 을 통해서도 이런 template 위치를 코드 내에서도 지정 가능하다(나중에 알아보자).위 코드르 보면 :: 를 통해 자바의 정적 참조 문법과 비슷하며, th:replace 를 통해 (파일 경로) :: (fragment 명) 을 써서 지정 가능하다.실습&lt;!-- fragments/header.html --&gt;&lt;header th:fragment=\"header\"&gt;    &lt;nav class=\"navbar\"&gt;        &lt;a th:href=\"@{/}\"&gt;Home&lt;/a&gt;        &lt;a th:href=\"@{/about}\"&gt;About&lt;/a&gt;        &lt;a th:href=\"@{/contact}\"&gt;Contact&lt;/a&gt;    &lt;/nav&gt;&lt;/header&gt;&lt;!-- fragments/footer.html --&gt;&lt;footer th:fragment=\"footer\"&gt;    &lt;p&gt;&amp;copy; 2024 My Application&lt;/p&gt;&lt;/footer&gt;&lt;!-- main.html --&gt;&lt;!DOCTYPE html&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt;    &lt;title&gt;My App&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div th:replace=\"~{fragments/header :: header}\"&gt;&lt;/div&gt;    &lt;main&gt;        &lt;h1&gt;Main Content&lt;/h1&gt;        &lt;!-- Page specific content --&gt;    &lt;/main&gt;    &lt;div th:replace=\"~{fragments/footer :: footer}\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;  fragment 의 단점은 경로 지정을 정확히 해주어야만 한다.폼 처리  th:action: form 제출 URL  th:method: form method  th:field: input, select, textarea value 바인딩기타 유용 속성  th:value  th:checked  th:selected  th:disabled  th:style  th:onclick  가장 중요한 것은 th:(HTML 의 속성 명) 의 형태를 띠며, 값 내부에 java 코드를 일부 집어넣을 수 있다는 것이다. 굳이 외우지 말자.⭐️ Spring 의 Model, BindingResult 바인딩 처리 및 Thymeleaf 의 BindingResult 호출교육을 들은 후 아예 프로젝트를 새로 만들어 사용하고 있을때 User 의 회원가입 요청을 받아 Post 로 요청을 주는 것을 하고 있었는데, 입력 검증으로 validate 를 하고 있을때, BindingResult 에서는 잘 뜨던 오류 메시지들이, 유독 thymeleaf 템플릿에서는 렌더링이 안되어서 검증 실패 오류 메시지가 안넘어가는 것을 알아내던 도중 다음 사실을 알았다.다음은 문제의 코드이다.view&lt;form method=\"post\" th:action=\"@{/user/register}\" th:object=\"${userRegisterDto}\"&gt;\t&lt;label for=\"username\"&gt;Username&lt;/label&gt;&lt;br/&gt;\t&lt;input type=\"text\" id=\"username\" th:field=\"*{username}\" required&gt;&lt;br/&gt;\t&lt;span th:if=\"${#fields.hasErrors('username')}\" th:errors=\"*{username}\" style=\"color:red;\"&gt;&lt;/span&gt;&lt;br/&gt;\t&lt;label for=\"email\"&gt;Email&lt;/label&gt;&lt;br/&gt;\t&lt;input type=\"text\" id=\"email\" th:field=\"*{email}\" required&gt;&lt;br/&gt;\t&lt;span th:if=\"${#fields.hasErrors('email')}\" th:errors=\"*{email}\" style=\"color:red;\"&gt;&lt;/span&gt;&lt;br/&gt;    ...controller@GetMapping(\"/register\")public String registerForm(Model model) {    model.addAttribute(\"userRegisterDto\", new UserRegisterDTO(null, null, null));    return \"user/registerForm\";}@PostMapping(\"/register\")public String register(@Valid UserRegisterDTO userRegisterDto, BindingResult result, Model model) {    if (result.hasErrors()) {        model.addAttribute(\"userRegisterDto\", userRegisterDto);        return \"user/registerForm\";    }    ...위의 상황을 먼저 정리해보자.Spring 이 Model 과 BindingResult 로의 바인딩 과정  Spring 은 자동으로 Model 에 Attribute 를 바인딩 할 때, 다음 기본명명규칙을 사용한다.          클래스 명을 기준으로 한다.      Ex) UserRegisterDTO userRegisterDto -&gt; userRegisterDTO 를 키로하여 바인딩        Spring 은 BindingResult 의 에러 정보를 자동으로 저장할 때, 다음 규칙을 사용한다.          클래스 명을 키로 하고 에러 정보를 저장한다      Ex) @Valid UserRegisterDTO userRegisterDto가 있다면 userRegisterDTO 를 키로 하고 에러 정보를 저장      Thymeleaf 의 Error 정보를 들고 오는 과정  Thymeleaf 는 th:object 의 값을 키로 하여 BindingResult 에게 해당 키에 대한 정보를 들고오게 된다.          th:object 명을 키로 하고 에러 정보를 들고온다      Ex) th:object=\"userRegisterDto\" 라면, BindingResult 의 userRegisterDto 의 에러 정보를 들고 오게 됨      문제 상황 정리는 끝났다. 여기서 잘못된 점은 바로 모델에게 내가 직접 주입하여서 빈을 넣었기 때문이다. 즉 스프링은 정의된 약속대로 흘러가야 하는데 내가 이를 명명 규칙을 무시하고 모델에 addAttribute 를 토대로 넣어버린다면 어디에선가 오류가 생긴다는 것이다.따라서 Thymeleaf 는 userRegisterDto 를 들고와야 하는데, BindingResult 가 알고 있는 것은 Class 명명 규칙을 따르기 때문에 userRegisterDTO 에 저장된 에러 정보를 못들고 오고 빈 text 만을 렌더링 하게 되는 것이다. 이는 오류로 뜨지도 않고 알 방법도 없다.따라서 다음으로 바꿔야 한다.  thymeleaf 의 th:object 를 수정하고, Model 에 들어가는 key 값도 같게 수정  @ModelAttribute 채택이제 ModelAttribute 를 상세히 보자.⭐️ @ModelAttribute 와 Thymeleaf 사이의 생략 관계 정리@ModelAttribute 가 우선 뭔지 봐야 한다. RetentionPolicy 로는 함수, 인자에 사용하고, 메서드 매개변수 또는 메서드 반환 값을 이름이 지정된 모델 속성과 바인딩하여 웹 뷰에 노출하는 애너테이션이다.즉, 다시 말해서, (name 옵션 값) : (메서드 매개변수 값), (name 옵션 값) : (메서드 반환 값) 으로 모델에 바인딩하여 웹 뷰에 노출한다는 것이다.이때 만약 name 옵션을 생략하면 어떻게 될까? 기본적으로 위에서 봤다시피 클래스 이름에서 첫 글자를 소문자로 바꾼 것을 기본 모델 이름으로 사용하며, 메서드에서도 마찬가지로 반환 타입 클래스 이름에서 첫 글자를 소문자로 바꾼 것을 사용하게 된다.따라서 우리는 항상 클래스 명을 따라가야 함을 잊지 말아야 한다.@ModelAttribute 를 사용한 Thymeleaf 의 th:object 생략object 없이 그냥 key-value 만을 넘겨주었을 때, th:object 없이 *{} 를 그대로 사용할 수 있게 된다.&lt;form method=\"post\" th:action=\"@{/user/register}\"&gt;\t&lt;label for=\"username\"&gt;Username&lt;/label&gt;&lt;br/&gt;\t&lt;input type=\"text\" id=\"username\" th:field=\"*{username}\" required&gt;&lt;br/&gt;\t&lt;span th:if=\"${#fields.hasErrors('username')}\" th:errors=\"*{username}\" style=\"color:red;\"&gt;&lt;/span&gt;&lt;br/&gt;\t&lt;label for=\"email\"&gt;Email&lt;/label&gt;&lt;br/&gt;\t&lt;input type=\"text\" id=\"email\" th:field=\"*{email}\" required&gt;&lt;br/&gt;\t&lt;span th:if=\"${#fields.hasErrors('email')}\" th:errors=\"*{email}\" style=\"color:red;\"&gt;&lt;/span&gt;&lt;br/&gt;\t&lt;label for=\"password\"&gt;Password&lt;/label&gt;&lt;br/&gt;\t&lt;input type=\"password\" id=\"password\" th:field=\"*{password}\" required&gt;&lt;br/&gt;\t&lt;span th:if=\"${#fields.hasErrors('password')}\" th:errors=\"*{password}\" style=\"color:red;\"&gt;&lt;/span&gt;&lt;br/&gt;\t&lt;button type=\"submit\"&gt;Submit&lt;/button&gt;&lt;/form&gt;@ModelAttribute 의 생략을 이용한 Thymeleaf 의 th:object 자동 바인딩이걸 말하기 전에 HandlerMethodArgumentResolver 을 먼저 보아야 한다. 스프링이 내부적으로 어떻게 argument 를 해결하는지를 보자.스프링 MVC 는 컨트롤러 메서드 매개변수를 처리할 때 HandlerMethodArgumentResolver 를 사용하게 된다. 이 놈은 HandlerAdapter 가 결정된 컨트롤러 메서드를 호출하려고 준비한 후에 실행되는 애이고, 다음 역할을 한다:  컨트롤러 메서드의 매개변수를 해석하고  필요한 객체를 생성 및 바인딩이제 HandlerAdapter 는 HandlerMethodArgumentResolver 가 만들어준 값으로 메서드를 호출하게 된다.  매개변수가 스프링이 관리할 수 있는 POJO 라면, @ModelAttribute 가 자동 적용된다.이때 스프링이 바인딩을 다음과 같이 하게 된다.  스프링이 새 객체를 생성하게 된다(빈 생성자를 토대로 함).  ⭐️ HTTP 요청 파라미터가 있다면 setter 나 field 를 통해 객체에 값을 채운다.          Ex) UserRegisterDTO 에 username, email 등이 있다고 치면, 쿼리 스트링에 ?username=park&amp;email=a@b.com 으로 있으면 자동으로 채워줌        객체를 모델에 기본 이름(class 이름의 첫 글자를 소문자로 바꾼 명칭) 으로 자동 추가한다.  뷰에서 th:object=\"${기본 이름}\" 으로 사용할 수 있게 된다  TIP. 따라서 GET 요청일 때는 보통 비어 있는 DTO 를 생성하여서 form backing object 로 사용하게 된다.TIP. POST 요청 시에는 HTTP 파라미터가 채워진 DTO 가 전달되게 될 것이다.이제 언제 이런 자동 바인딩이 일어나는 지를 살펴보자.자동 바인딩이 일어나는 규칙  POJO 객체          @ModelAttribute 가 자동 적용됨      GET/POST 상관 없이 HTTP 파라미터를 객체 필드에 바인딩      자동 모델 이름으로 클래스명 첫 글자 소문자로 함(이게 싫으면 @ModelAttribute 쓰기)        특별한 타입 (Model, HttpServletRequest, BindingResult, Principal 등)          POJO 객체 바인딩과는 별도로 스프링이 직접 제공하며,      모델에 자동으로 추가가 안된다.        BindingResult          항상 바로 앞의 @Valid 또는 @ModelAttribute 객체와 쌍으로 사용하도록 되어 있고, 다른 POJO 객체와 순서가 섞이면 오류가 발생하게 된다.        BindingResult 는 항상 POJO 객체와 1:1 로 쌍을 이루면서 등장한다. 따라서 POJO 가 2개면 BindingResult 인자도 2개 들어가야 한다.이것들만 지키면 항상 자동 바인딩은 일어난다.Forwarding 과정이제 Forwarding 이 어떻게 동작하는지 완벽히 이해가 가능하다.  HTTP POST 요청을 통해 WAS 를 거쳐 HttpServletRequest 와 HttpServletResponse 를 생성하게 된다.          HttpServletRequest 와 HttpServletResponse 객체는 요청-응답 생명주기를 대표하는 객체            DispatcherServlet 가 이를 받고 받은 HttpRequest 에서의 path 를 HandlerMapping 에 주게 된다.    받은 path 에 알맞은 mapping 함수를 Controller 에서 골라지게 된다.          정확히는 HandlerMapping 목록을 순회하며, 이 URL 요청을 처리할 수 있는 Controller 의 메서드를 탐색한다.      찾은 결과를 HandlerExecutionChain 객체로 래핑 후 반환한다.      여기에 실제 Controller 메서드와 Interceptor 체인이 포함되게 된다.        DispatcherServlet 은 HandlerAdapter 를 통해 받았던 데이터(header, body 등등)를 Controller 에 넘겨 주게 된다.          Controller 마다 호출 방식이 다르기 때문에 DispatcherServlet 은 HandlerAdapter 를 사용해 호출 과정을 추상화한다.      Spring 은 기본적으로 RequestMappingHandlerAdapter 를 사용하고, ArgumentResolver 와 ReturnValueHandler 체계를 통하여 매개변수를 분석(@RequestParam, @ModelAttribute, @RequestBody 등)하고, 반환값을 해석 하게 된다(String, ModelAndView, ResponseBody 등)            이제 Controller 는 내부적으로 비즈니스 로직을 실행시켜 알맞은 결과값을 반환 후    Model 을 통해 넘겨줄 데이터들을 정해준 후에 뷰 이름을 HandlerAdapter 에게 반환하게 된다.          여기서 Controller 가 리턴한 값을 받아 ModelAndView 객체로 통합하게 된다.      만약 반환 타입이 String 이면 viewName 으로 해석하고,      별도로 Model 에 저장된 데이터를 함께 담는다.      이때 4번 단계에서 ModelAndView, ResponseBody 등으로 리턴하면 수행 단계가 조금 달라지긴 한다. 그 자체를 그대로 사용하게 된다.        ModelAndView 로 이미 Controller 에서 HandlerAdapter 에게 반환되었다면 6번 과정은 생략하고 다음 단계로 이동한다.  그러고 DispatcherServlet 이 HandlerAdapter 로 부터 받은 viewName 을 가지고, ViewResolver 에게 어떤 view 를 쓸 지를 정하게 되고,          DispatcherServlet 은 viewName 을 ViewResolver 에게 넘긴다(ModelAndView 를 받았다면 이 과정은 없다).      ViewResolver 는 논리 뷰 이름(logical view name) 을 물리적 리소스 경로로 변환하여 View 객체(ThymeleafView, JstlView 등)으로 변환한다 (ThymeleafViewResolver, InternalResourceViewResolver 등이 ViewResolver 의 대표적 구현체이다)      최종적으로 View 가 생성된다.        그 다음 DispatcherServlet 은 받았던 HttpServletResponse 와 함께 View 로 forwarding 을 해주고,          DispatcherServlet 은 선택된 View 객체의 render() 메서드를 호출하고, 이때 HttpServletRequest, HttpServletResponse 이 전달된다.        View 에서는 ViewResolver 를 통해 알맞은 View 가 생성되고, View 는 Model 을 참조하여서 결과들을 가져오고 완전한 문서를 만들게 된다          View 는 Model 의 데이터를 참조하고, 렌더링 결과는 HttpServletResponse 의 body 로 직접 작성되게 된다.      렌더링이 끝나면 DispatcherServlet 이 response.flushBuffer() 후 요청-응답 객체는 소멸된다.      Redirecting 과정이제 Redirecting 이 어떻게 동작하는지 완벽히 이해가 가능하다.Controller 의 return 값이 \"redirect:\" 접두어를 포함한 String 일 때      사용자가 POST 요청을 보낸다. WAS(Tomcat 등)가 이를 받아 HttpServletRequest, HttpServletResponse 객체를 생성하고 DispatcherServlet 에게 요청을 전달한다.    DispatcherServlet 은 요청의 URI 정보를 확인하여 HandlerMapping 에게 어떤 Controller 가 처리해야 하는지 조회를 맡긴다.          HandlerMapping 은 요청 정보를 기반으로 적절한 @RequestMapping 메서드를 찾아 HandlerExecutionChain 으로 감싸 반환한다.      이 객체에는 Controller 메서드와 Interceptor 체인이 포함된다.        DispatcherServlet 은 HandlerAdapter 를 통해 해당 Controller 메서드를 실행한다.          이때 HandlerAdapter 는 ArgumentResolver, ReturnValueHandler 를 통해 요청 데이터를 파라미터에 바인딩하고, 반환 타입(String, ModelAndView, ResponseBody) 을 분석한다.        Controller 가 비즈니스 로직을 처리한 후, return \"redirect:/users/welcome\"; 처럼 \"redirect:\" 로 시작하는 문자열을 반환한다.          이 접두어는 Spring MVC 내부에서 RedirectView 로 자동 변환되도록 트리거한다.        ⭐️ DispatcherServlet 은 반환된 뷰 이름을 확인하고, \"redirect:\" 접두어가 포함되어 있음을 감지하면 RedirectView 를 생성한다.          ⭐️ 이때는 ViewResolver 를 거치지 않는다.      ⭐️ 대신 RedirectView 의 render() 가 호출되어 HttpServletResponse 에 302 Found 상태 코드와 Location 헤더를 설정한다.        응답이 클라이언트(브라우저)로 전송된다.          응답 헤더 예시:        HTTP/1.1 302 FoundLocation: /users/welcome                    브라우저는 이를 보고 /users/welcome 으로 새로운 GET 요청을 자동으로 보낸다.            새로운 GET 요청이 발생하면 WAS 는 다시 HttpServletRequest, HttpServletResponse 를 새로 생성하고, 다시 1~4번의 Forwarding 과정과 동일한 DispatcherServlet 처리 흐름을 거친다.    이때, 이전 요청의 Model 데이터는 유지되지 않는다.          대신 RedirectAttributes.addFlashAttribute() 로 추가된 데이터는 일시적 세션(FlashMap) 에 저장되어 새 요청 시점에 한 번만 사용된다.      이후 요청이 완료되면 FlashMap 데이터는 자동 소멸된다.        새로운 Controller 메서드(/users/welcome) 가 호출되고, 뷰 렌더링이 완료되면 최종 HTML 응답이 브라우저에 전달된다.  즉, Redirect 는 “요청이 두 번 일어난다”.첫 번째 요청은 서버의 302 응답으로 끝나고,두 번째 요청이 실제 결과 페이지를 렌더링한다.따라서 Forward 와 달리 URL 이 바뀌며, Model 데이터는 유지되지 않는다.Forward vs Redirect 비교 요약            구분      Forward      Redirect                  요청 횟수      1회      2회 (POST → GET)              URL 변경      ❌ 그대로 유지      ✅ 변경됨              데이터 전달      Model 로 전달      FlashAttribute 로 1회 전달              처리 방식      서버 내부 이동      클라이언트 재요청              주 용도      단순 뷰 렌더링      PRG(Post-Redirect-Get) 패턴, URL 노출 변경 등        Forward 는 “서버 내부 이동”Redirect 는 “클라이언트 재요청”— 이 한 줄만 정확히 기억하면, Spring MVC 흐름은 완전히 잡은 것이다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 36일차 Spring Boot Logging",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/15/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-36%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-15",
      "content": "📂 목차  목적          로깅 정보 종류      로깅 소스        Spring Boot Logging          Logger 사용해보기      Spring Boot 로깅 설정                  properties, yml 을 통한 설정          xml 을 통한 고급설정                    Logback                  logback-spring.xml 로딩 과정          ⭐️ Logback 클래스 구조                    Logger 가져오기      MDC 를 통한 멀티 스레드 환경, 사용자/요청 단위의 로그 추적하기                  Thead 간 MDC 주의점          MDC 구조                    SLF4J Parameterized Logging      📚 본문우선 로깅은 프로그램이 실행되는 동안 발생하는 이벤트, 상태, 오류, 경고, 정보 등을 기록하는 행위이다.목적  문제 해결(Debugging): 오류가 발생했을 때 원인을 추적할 수 있음  운영/모니터링: 서비스가 정상적으로 돌아가는지 확인  분석/통계: 사용자 행동, 성능, 트래픽 등을 분석  감사(Audit): 누가 언제 어떤 작업을 했는지 기록로깅 정보 종류  DEBUG: 개발 중 세부적인 상태 정보  INFO: 일반적인 실행 정보  WARN: 경고, 문제가 될 수 있는 상황  ERROR: 오류 발생, 예외 상황  FATAL: 치명적인 오류, 프로그램 종료 필요로깅 소스  파일: 로그 파일에 기록  콘솔: 터미널 또는 IDE 콘솔에 출력  원격 서버 / DB: 중앙 서버로 수집 후 분석  로그 관리 시스템: ELK(Elasticsearch, Logstash, Kibana), GrafanaSpring Boot Loggingspring boot 는 log 구현체에 직접 접근하기 보다 SLF4J 의 Facade 패턴을 사용하여 추상화된 계층을 이용하게 된다. SLF4J 는 Simple Logging Facade for Java 의 약자로 자바용 로깅 추상화 라이브러리이다. 핵심 아이디어는 로깅 라이브러리 자체(Log4j, Logback, java.util.logging 등) 에 의존하지 않고 통일된 인터페이스를 통하여 로그를 남길 수 있도록 해준다.Application Code       ↓SLF4J API (Facade 패턴)       ↓Logback (Default) / Log4j2 / JUL       ↓Output (Console, File, etc.)위 의존 관계를 보면 알다시피 실제 로그 처리 구현체와 코드를 분리시켜 어떤 로그 라이브러리를 써도 SLF4J 가 알아서 처리해준다.  Logback: Spring Boot 기본 로깅 구현체, 성능이 빠르고, 설정이 비교적 직관적이다, XML, Groovy 로 설정 가능  Log4j2: Apache 사에서 개발하였고, 고성능, 비동기 기반의 로깅 프레임워크이다. Logback 의 장점을 흡수하고 Log4j 의 단점을 보완하여 만들어졌다.보통 위 두 패키지를 사용하게 되고, 개발팀마다 사용하는게 다르지만 둘 다 알아놓으면 좋을거 같다.  Facade 패턴 - 패키지 끼리 서로 다른 인터페이스를 제공하여 모듈을 갈아끼울 때마다 코드를 변경해야 하는 불편함이 생긴다. 이러한 불편함을 중간에 클래스를 두어 인터페이스를 통합하는 책임을 주어 해당 통합된 인터페이스를 사용하여 유지보수를 높인다.Logger 사용해보기@RestControllerpublic class LogExampleController {    // Logger 생성 (클래스 기준)    private static final Logger logger = LoggerFactory.getLogger(LogExampleController.class);    @GetMapping(\"/log-test\")    public String logTest() {        logger.trace(\"TRACE 레벨 로그 - 가장 상세한 로그\");        logger.debug(\"DEBUG 레벨 로그 - 개발 중 디버깅용\");        logger.info(\"INFO 레벨 로그 - 일반 정보 출력\");        logger.warn(\"WARN 레벨 로그 - 경고 상황\");        logger.error(\"ERROR 레벨 로그 - 오류 발생\");        return \"로그 출력 완료! (콘솔에서 확인)\";    }}이제 application.yml 로 로그가 출력 될 수준을 정해준다. 쉽게 말해서 중요한 정도를 정해준다고 보면된다. 5 정도면 1, 2, 3, 4, 5 의 수준의 적은 중요도 순서로 로그를 출력하게 된다.  1: TRACE,  2: DEBUG  3: INFO  4: WARN  5: ERROR  6: FATAL(Log4j 에만 있음)순으로 중요하며 FATAL 이 가장 중요한 것으로 본다. 이는 심각한 오류를 뜻한다.application.ymllogging:  level:    root: info        # 전체 기본 로그 레벨    com.example.demo: debug  # 특정 패키지만 DEBUG 레벨  file:    name: logs/app.log # 로그 파일 저장 경로Spring Boot 로깅 설정SLF4J API 를 통해 로그를 남기고, 실제 로깅은 구현체(Logback) 이 이를 처리한다, SLF4J 에 설정만 가하면 다양한 로그 커스터마이징 기능들을 사용할 수 있게 된다.로그 설정 방식은 크게 두 가지이다:  application.properties / application.yml: 간단 설정  logback-spring.xml / log4j2-spring.xml: 정교한 제어properties, yml 을 통한 설정레벨 설정  logging.level.root=INFO: info 이하는 모두 출력  logging.level.com.example=DEBUG: 패키지/클래스 단위로 사용 가능파일/콘솔  logging.file.name=logs/app.log: 파일 하나에 기록  logging.file.path=/var/log/myapp: 디렉토리 지정  logging.file.max-size=10MB  logging.file.max-history=30패턴(포맷)  logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %logger{36} - %msg%n  logging.pattern.file출력할 포맷을 지정할 수 있는데, 콘솔과 파일 별로 가능하다.xml 을 통한 고급설정xml 을 굳이 사용하는 이유는 롤링, 포맷, 서로 다른 appender 분리, 비동기 설정 등의 세세한 제어를 다 가져갈 수 있게 하기 위해 사용한다.&lt;configuration scan=\"true\" scanPeriod=\"30 seconds\"&gt;  &lt;property name=\"LOG_HOME\" value=\"./logs\" /&gt;  &lt;!-- 패턴 정의 --&gt;  &lt;property name=\"PATTERN\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\"/&gt;  &lt;!-- 콘솔 appender --&gt;  &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;    &lt;encoder&gt;      &lt;pattern&gt;${PATTERN}&lt;/pattern&gt;    &lt;/encoder&gt;  &lt;/appender&gt;  &lt;!-- 롤링 파일 appender --&gt;  &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;    &lt;file&gt;${LOG_HOME}/app.log&lt;/file&gt;    &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt;      &lt;!-- 7일치 보관, 하루 단위로 롤링 --&gt;      &lt;fileNamePattern&gt;${LOG_HOME}/app.%d{yyyy-MM-dd}.log.gz&lt;/fileNamePattern&gt;      &lt;maxHistory&gt;7&lt;/maxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder&gt;      &lt;pattern&gt;${PATTERN}&lt;/pattern&gt;    &lt;/encoder&gt;  &lt;/appender&gt;  &lt;!-- 비동기 wrapper (성능) --&gt;  &lt;appender name=\"ASYNC_FILE\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt;    &lt;appender-ref ref=\"FILE\"/&gt;    &lt;queueSize&gt;5000&lt;/queueSize&gt;    &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt;  &lt;/appender&gt;  &lt;!-- 로거 레벨 설정 --&gt;  &lt;root level=\"INFO\"&gt;    &lt;appender-ref ref=\"STDOUT\"/&gt;    &lt;appender-ref ref=\"ASYNC_FILE\"/&gt;  &lt;/root&gt;  &lt;!-- 특정 패키지 DEBUG --&gt;  &lt;logger name=\"com.example.demo\" level=\"DEBUG\"/&gt;&lt;/configuration&gt;LogbackSpring Boot 에서는 Logback 이 SLF4J 의 기본값이며, Spring Boot 는 로거의 설정을 아래 파일들을 통해 자동으로 탐색한다.  logback-spring.xml (Spring Boot 전용)  logback.xml  logback-test.xml (테스트 환경용)logback-spring.xml 을 사용하면 Spring Profile, Property Placeholder 등을 지원하기 때문에 해당 파일을 사용하는게 더 좋을것이다.logback-spring.xml 로딩 과정스프링 부트 실행 시에 SpringApplication.run() 내부에서 LoggingApplicationListener 가 등록된다.이때 클래스가 어플리케이션 초기 단계에서 로깅 시스템을 설정하게 된다(이벤트가 들어오면 로그 설정 동작이 실행됨).동작  로깅 초기화 트리거  LoggingSystem 결정: Logback, Log4j2, Java Util Logging 순으로 구현체 탐색  Logback 이 선택됐다면 LogbackLoggingSystem 초기화@Overridepublic void initialize(LoggingInitializationContext initializationContext,                       String configLocation, LogFile logFile)  Spring Boot 전용 설정 처리          &lt;springProfile&gt; 태그 지원      ${} property placeholder 지원      Spring Environment 연결        실제 Logback 구성 로딩(xml 내부의 LoggerContext, Appender, Logger, Layout 로딩)⭐️ Logback 클래스 구조LoggerContext (ch.qos.logback.classic.LoggerContext)│├── Logger (ch.qos.logback.classic.Logger)│    ├── Appenders (ConsoleAppender, FileAppender, RollingFileAppender)│    └── Level (TRACE, DEBUG, INFO, WARN, ERROR)│├── AppenderBase (ch.qos.logback.core.AppenderBase)│    ├── ConsoleAppender│    ├── FileAppender│    └── RollingFileAppender│└── Layout (ch.qos.logback.classic.PatternLayout)  LoggerContext: Logback 전체 설정 컨테이너  Logger: 패키지별 로거  Appender: 로그를 출력 할 대상(File, Console 등등)          파일이면 파일 어펜더, 콘솔이면 콘솔 어펜더라고도 부름        Encoder/Layout: 로그 메시지 포맷 지정⭐️ logback-spring.xml 예시&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt;    &lt;!-- 변수 정의 --&gt;    &lt;property name=\"LOG_DIR\" value=\"logs\"/&gt;    &lt;property name=\"LOG_FILE\" value=\"application\"/&gt;    &lt;!-- 콘솔 Appender --&gt;    &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;        &lt;encoder&gt;            &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %highlight(%-5level) %cyan(%logger{36}) - %msg%n&lt;/pattern&gt;            &lt;charset&gt;UTF-8&lt;/charset&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- 파일 롤링 Appender --&gt;    &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;        &lt;file&gt;${LOG_DIR}/${LOG_FILE}.log&lt;/file&gt;        &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\"&gt;            &lt;!-- 일별 롤링 및 크기 제한 --&gt;            &lt;fileNamePattern&gt;${LOG_DIR}/archived/${LOG_FILE}-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt;            &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt;            &lt;maxHistory&gt;30&lt;/maxHistory&gt;            &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;        &lt;/rollingPolicy&gt;        &lt;encoder&gt;            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;            &lt;charset&gt;UTF-8&lt;/charset&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- 에러 전용 Appender --&gt;    &lt;appender name=\"ERROR_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;        &lt;file&gt;${LOG_DIR}/error.log&lt;/file&gt;        &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;            &lt;level&gt;ERROR&lt;/level&gt;        &lt;/filter&gt;        &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt;            &lt;fileNamePattern&gt;${LOG_DIR}/archived/error-%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;30&lt;/maxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;encoder&gt;            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- 비동기 Appender (성능 향상) --&gt;    &lt;appender name=\"ASYNC_FILE\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt;        &lt;appender-ref ref=\"FILE\"/&gt;        &lt;queueSize&gt;512&lt;/queueSize&gt;        &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt;        &lt;includeCallerData&gt;false&lt;/includeCallerData&gt;    &lt;/appender&gt;    &lt;!-- Spring Profile별 설정 --&gt;    &lt;springProfile name=\"dev\"&gt;        &lt;logger name=\"com.example\" level=\"DEBUG\"/&gt;        &lt;logger name=\"org.springframework.web\" level=\"DEBUG\"/&gt;    &lt;/springProfile&gt;    &lt;springProfile name=\"prod\"&gt;        &lt;logger name=\"com.example\" level=\"INFO\"/&gt;        &lt;logger name=\"org.springframework\" level=\"WARN\"/&gt;    &lt;/springProfile&gt;    &lt;!-- 패키지별 로거 설정 --&gt;    &lt;logger name=\"org.hibernate.SQL\" level=\"DEBUG\" additivity=\"false\"&gt;        &lt;appender-ref ref=\"FILE\"/&gt;    &lt;/logger&gt;    &lt;logger name=\"com.example.service\" level=\"DEBUG\" additivity=\"false\"&gt;        &lt;appender-ref ref=\"FILE\"/&gt;        &lt;appender-ref ref=\"CONSOLE\"/&gt;    &lt;/logger&gt;    &lt;!-- Root 로거 --&gt;    &lt;root level=\"INFO\"&gt;        &lt;appender-ref ref=\"CONSOLE\"/&gt;        &lt;appender-ref ref=\"ASYNC_FILE\"/&gt;        &lt;appender-ref ref=\"ERROR_FILE\"/&gt;    &lt;/root&gt;&lt;/configuration&gt;Logger 가져오기저 정도 설정을 하면 이제 로거를 들고올 준비가 끝났으며, 클래스 내부에서 로그를 찍어볼 수 있다. 이전에 봤던 필드 변수로 선언하여 LoggerFactory.getLogger() 를 사용하여 들고올 수 있지만, 더 쉽게 @Slf4j 어노테이션을 클래스에 붙이는 것만으로 클래스 내부에서 log 를 통해 사용할 수 있다.@Controller@Slf4jpublic class WelcomeController {    ...    public String hello() {        log.info(\"Welcome to the WelcomeController.\");\t\tlog.info(message);        ...MDC 를 통한 멀티 스레드 환경, 사용자/요청 단위의 로그 추적하기MDC 는 Mapped Diagnostic Context 의 약자로 스레드 로컬 기반의 로그 컨텍스트 저장소이다.  현재 스레드에서만 유효한 key-value 데이터를 저장  로그 패턴에서 그 값을 자동으로 출력할 수 있도록 하는 기능따라서 MDC 는 내부적으로 ThreadLocal&lt;Map&lt;String, String&gt;&gt; 구조를 사용하게 된다.MDC.put(\"userId\", \"A123\");MDC.put(\"requestId\", \"req-20251016\");log.info(\"사용자 요청 처리 중...\");MDC.clear();// 2025-10-16 13:45:12 [INFO] [userId=A123] [requestId=req-20251016] 사용자 요청 처리 중...위와 같이 출력이 되게 된다. 여기서 출력 포맷은 logback-spring.xml 에서 %X{key} 형태로 사용한다면, 다음과 같이 출력된다.// &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger - %msg [%X{userId}] [%X{requestId}]%n&lt;/pattern&gt; 일때13:45:12.234 [http-nio-8080-exec-1] INFO  c.e.UserController - 요청 처리 중 [A123] [req-20251016]X 를 스레드라고 보면 되고, 거기에 해당하는 userId, requestId 는 코드 내에서 put 했던 값을 호출하여서 출력하게 할 수 있다.Thead 간 MDC 주의점MDC 는 ThreadLocal 기반임을 주의하자. 스레드가 바뀌면 값이 전파되지 않기 때문에 다음 코드를 쳐도 traceId 는 null 로 되게 된다.MDC.put(\"traceId\", \"abc-123\");CompletableFuture.runAsync(() -&gt; {    log.info(\"비동기 로그\"); // traceId 출력 ❌ (전파 안됨)});위를 해결하려면 수동 복사를 통한 방법이 있다. 비동기나 Reactor, WebFlux 등 환경에서 MDC context 전파를 수동 또는 자동으로 하도록 한다.개념  @Async (Spring MVC 내에 있는): 단일 스레드 풀 기반 비동기 처리 (기존 MVC 구조 유지)  Reactor (Project Reactor): Reactive Streams 기반의 비동기 데이터 처리 라이브러리  Spring WebFlux: Reactor 위에 만들어지는 비동기/논블로킹 웹 프레임워크, Spring MVC 대체 가능Map&lt;String, String&gt; context = MDC.getCopyOfContextMap();CompletableFuture.runAsync(() -&gt; {    MDC.setContextMap(context);    log.info(\"비동기 로그\");    MDC.clear();});Spring Cloud Sleuth / Micrometer Tracing 을 사용할 수도 있다. 이는 나중에 여유 시간이 되면 봐도 좋다. 당장 안사용한다.  MDC 를 사용할 일이 잘 없다.MDC 구조org.slf4j.MDC └── static MDCAdapter mdcAdapter = new LogbackMDCAdapter();ch.qos.logback.classic.util.LogbackMDCAdapter └── ThreadLocal&lt;Map&lt;String, String&gt;&gt; copyOnThreadLocal  SLF4J 의 MDC API 는 인터페이스 수준의 표준  Logback 이 실제 구현  스레드 별로 Map 을 보관SLF4J Parameterized LoggingSLF4J 에서는 플레이스 홀더 기능을 제공한다. String.format() 처럼 + 연산이나 문자열 합치는 연산 없이도 {} 를 통해 lazy evaluation 을 하도록 한다.이를 통해 성능을 최적화할 수 있고, 또 is(LOG_LEVEL)Enable() 함수를 통해 로그 레벨이 활성화 된 경우에만 평가하도록 할 수 있다.// BAD - 항상 문자열 연결 수행logger.debug(\"Processing \" + expensiveMethod() + \" items\");// GOOD - 로그 레벨 체크 후 실행if (logger.isDebugEnabled()) {    logger.debug(\"Processing {} items\", expensiveMethod());}// BETTER - 파라미터화된 메시지 사용logger.debug(\"Processing {} items for user {}\",             itemCount, userId);// BEST (Java 8+) - Supplier 사용logger.debug(\"Processing items: {}\",             () -&gt; expensiveMethod());✒️ 용어Property PlaceholderSpring 및 Logback 설정에서 자주 사용되는 기능으로, 외부에 정의된 값을 설정 파일이나 환경 변수에서 참조할 수 있도록 해주는 플레이스홀더(변수 대체) 기능이다.즉, 반복적으로 사용되는 값(예: 로그 디렉토리, 포트 번호, 파일 이름 등)을 한 곳에서 정의하고 다른 곳에서 ${} 문법으로 참조할 수 있게 해줌"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 35일차 Spring Core Container",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/14/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-35%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-14",
      "content": "📂 목차  Spring Core          IoC                  Dependency Injection                    Bean                  Bean 등록          Bean Scope                    ComponentScan                  Annotation 정의          @SpringBootApplication          ComponentScan 어노테이션 정의          SpringBootApplication 의 ComponentScan                    @Configuration                  ⭐️ @Configuration 의 CGLIB 프록시 메서드 proxyBeanMethods()                    @Scope 애너테이션으로 Bean 생명주기와 공유 범위 제어                  @PostConstruct 와 @PreDestroy 사용하여 생명주기에 대한 로그 찍어보기                    Properties 를 사용해 키 값을 Config 로 등록하기                  @Value 로 프로퍼티 주입해보기          @ConfigurationProperties 를 사용해 key 를 기준으로 값 들고오기                    DI 시 주의점                  @Lazy                    Spring Application 의 실행 과정 중 실행 코드 넣기                  CommandLineRunner                    ⭐️ Spring Event System                  Asynchronized Event 로 구성하기          Transaction Event Listener          Spring 내장 EventListener                    📚 본문Spring CoreIoC, DI 에 대해 살펴본다.IoC객체의 생성과 의존성 관리를 개발자가 직접하는 것이 아니라 프레임워크가 대신 관리해주는 원리를 IoC 라고 한다.전통적으로는 new 를 통해 객체의 생성과 의존성을 개발자가 관리했지만, 프레임워크가 객체를 생성하고 연결시키는 책임을 받게 된다.장점  객체 간 결합도를 낮추고, 유지보수를 쉽게 할 수 있음  코드 재사용성을 높이고 테스트를 쉽게 할 수 있음IoC 를 달성하기 위해서는 주로 DI(Dependency Injection) 기술로 구현하게 된다.Dependency Injection스프링에서는 3가지의 의존성 주입이 있다. 마지막 방식은 안쓰이니 그냥 삭제한다.생성자 주입@Componentpublic class Car {    private final Engine engine;    @Autowired    public Car(Engine engine) {        this.engine = engine;    }}세터 주입@Componentpublic class Car {    private Engine engine;    @Autowired    public void setEngine(Engine engine) {        this.engine = engine;    }}  생성자가 하나인 경우에는 @Autowired 를 생략 가능하다.BeanIoC 가 관리하는 객체를 Bean 이라고 하고, 이 Bean 이 살고 있는 곳이 IoC 컨테이너이다. Bean 은 그냥 구현체이며 Bean 으로 등록된 객체들은 다음 특징을 가진다:  생명주기 관리 대상: IoC 컨테이너가 객체의 생성부터 소멸까지 관리  재사용 가능: 필요할 때마다 컨테이너에서 가져다 쓸 수 있음  의존성 주입 지원: 다른 Bean 과 연결할 때 DI 를 통해 주입 가능결국에는 Bean 으로 등록되어야 DI 의 대상이 된다는 것이다.Bean 등록IoC 컨테이너에 Bean 을 등록하기 위해 3가지 방법이 있다.어노테이션 기반@Component      // 일반적인 Bean@Service        // 비즈니스 로직 Bean@Repository     // DAO Bean@Controller     // MVC Controller BeanJava Config 기반@Configurationpublic class AppConfig {    @Bean    public Car car() {        return new Car(engine());    }    @Bean    public Engine engine() {        return new Engine();    }}  함수를 빈으로 하여서 함수 시그니처(함수명, 반환값) 을 토대로 의존성 주입을 할 수 있다. ApplicationContext.getBean() 메서드를 통해 들고 올 수 있다.XML 기반옛날 방식이며 지금은 잘 안쓰인다.&lt;bean id=\"car\" class=\"com.example.Car\"/&gt;&lt;bean id=\"engine\" class=\"com.example.Engine\"/&gt;Bean Scope보통 Bean 으로 등록된 객체들은 Singleton 패턴을 따르게 된다. 따라서 @Bean, @Component, @Service 등등에는 다음 어노테이션이 포함되어 있다.@Component@Scope(\"singleton\") // 생략 가능, 기본값이 singletonpublic class Car { }@Scope 어노테이션은 인자로 다음을 넣을 수 있다.  prototype: 요청할 때마다 새로운 Bean 생성  request: HTTP 요청 당 하나의 Bean 생성  session: HTTP 세션 당 하나의 Bean 생성  application: ServletContext 범위에서 하나의 Bean 생성  websocket: WebSocket 세션 당 하나의 Bean 생성ComponentScan빈만 이렇게 선언해놓고 전부 등록된다면 정말 좋겠지만, Bean 들이 각 파일들로 흩어져 있는 것을 Spring Boot 가 일일히 전부 들어가서 찾아내진 않는다. 우리가 찾을 범위를 지정해주어야 한다. 이를 ComponentScan 어노테이션이 하는 일인데 이는 SpringBootApplication 어노테이션이 가지고 있으므로 그 내부를 파헤쳐보자.Annotation 정의자바에서는 특별한 형태의 인터페이스가 있는데 바로 애너테이션이다. 애너테이션은 보통 클래스, 메서드, 필드 등에 대한 부가 정보(메타 데이터)를 제공하고 싶을 때 사용하는 문법이며, 프로그램의 실행 로직에는 직접 영향을 주지 않지만, 컴파일러나 프레임워크가 해석할 때 특별한 동작을 수행하도록 할 수 있다. 즉, 런타임 이전에 특수한 동작을 하여 런타임 때 의도한 동작을 수행하도록 할 수 있다는 것이다.애너테이션의 선언은 다음과 같다.// @interface 가 선언 키워드public @interface MyAnnotation {    String value(); // &lt;- 속성임, 요소라고도 불림    int count() default 1; // default 로 기본값 지정 가능}개념을 보자면 애너테이션 정의 내부에 들어가는 함수를 보통 속성 이라고 하며 이 속성은 필드와 유사하여 어노테이션의 소괄호 블록에 들어갈 인자로 사용되게 된다.여기서 value() 는 무조건 있어야 하며, @MyAnnotation(\"value 입니다.\") 처럼 붙일 수 있다(암묵적 표기). 명시적으로 다음과 같이 선언하는 것도 동일한 결과이다.@MyAnnotation(\"value 입니다.\") // == @MyAnnotation(value = \"value 입니다.\")class Hello {    ...특히 애너테이션을 정의할 때 그 위에 붙이는 자주 쓰이는 메타 애너테이션 4개가 있다.Meta Annotation  @Target: 애너테이션을 붙일 수 있는 범위 지정, ElementType 열거형 클래스를 통해 상수 설정          ElementType.TYPE      ElementType.FIELD      ElementType.PARAMETER      ElementType.CONSTRUCTOR      ElementType.ANNOTATION_TYPE      ElementType.PACKAGE      기본값은 모든 곳 사용 가능        @Retention: 애너테이션의 생명주기가 어디까지 유지가 되는지 RetentionPolicy 설정          RetentionPolicy.RUNTIME      RetentionPolicy.CLASS      기본값은 CLASS        @Documented: javadoc 등 문서에 포함되도록 표시          기본값은 docs 에 안나타나도록        @Inherited: 이 애너테이션이 서브 클래스에 자동 상속되도록 함          기본값은 없는 걸로, 상속되지 않는게 기본값      위를 토대로 아래를 읽어보자.@SpringBootApplication스프링부트 어플리케이션 애너테이션은 @SpringBootConfiguration 을 가지며, 이 Configuration 은 위에 배웠던 IoC 의 기술 중 한 방법으로 Config 방식임을 볼 수 있다.@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\t\t@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication {여기서 SpringBootConfiguration 이 있음을 볼 수 있는데, SpringBootConfiguration 은 다시 @Configuration 애너테이션이 붙어있음을 볼 수 있다. 즉, @SpringBootConfiguration 자체가 스프링 설정 클래스로 인식을 하며, 추가로 @SpringBootConfiguration 은 인자로 proxyBeanMethods 를 받을 수 있으며, true, false 를 가짐을 볼 수 있다.  proxyBeanMethods - CGLIB 프록시를 통해 @Bean 메서드 간 호출 시 싱글톤 보장, true 가 기본값이며, 이때 Bean 들은 Singleton 이게 됨또 ComponentScan 이 있음을 볼 수 있다. 이름 그대로 컴포넌트들을 스캔하는 방식을 지정하는 역할을 한다.ComponentScan 어노테이션 정의SpringBootApplication 이 쓰는 ComponentScan 어노테이션을 이해하기 전에 ComponentScan 을 파헤쳐보자@AliasFor(\"basePackages\")String[] value() default {};@AliasFor(\"value\")String[] basePackages() default {};Class&lt;?&gt;[] basePackageClasses() default {};Filter[] includeFilters() default {};Filter[] excludeFilters() default {};boolean lazyInit() default false;자주 쓰이는 것들만 모았다. 우선 AliasFor 은 “이 속성은 다른 속성과 의미적으로 동일하다” 라는 의미를 가지는 어노테이션임을 알려준다. 따라서 value= 로 하던 basePackages= 로 선언하던 동일하다(value 이기에 명시적 속성 표기 생략 가능).      basePackages: String[] 을 인자로 받고, package 명들을 넣어주면 해당 패키지들을 스캔 대상으로 Component 들을 가져오게 된다.        basePackageClasses: 위 기능과 유사하지만 단위를 클래스 별로 가져오게 할 수 있다. @ComponentScan(basePackageClasses = MyApp.class), 문자열보다는 컴파일 단계에서 타입 안전성을 보장 받기 때문에 안전하다        includeFilters: ComponentScan 내부에 선언되어져 있는 Filter 어노테이션 을 보면 알 수 있다. 예제를 보면서 설명한다.  Filter 어노테이션 정의@Retention(RetentionPolicy.RUNTIME)@Target({})@interface Filter {    FilterType type() default FilterType.ANNOTATION;    Class&lt;?&gt;[] classes() default {};    String[] pattern() default {};}위는 필터 가 정의되어 있는 방식을 볼 수 있다.  type: 필터를 거를 방식에서 조건의 대상에 대한 형태를 정한다.  classes: 그 type 을 가지는 class 를 넣어준다.  pattern: 클래스 이름을 기준으로 정규식(Regex) 매칭, 배열 가능이제 컴포넌트 스캔을 보자.@ComponentScan(    includeFilters = @ComponentScan.Filter(        type = FilterType.ANNOTATION,        classes = CustomAnnotation.class    ))type 은 필터 방식을 지정하는 옵션인데 아래에 정리해 두었다, classes 로 @CustomAnnotation 이 붙은 클래스도 Bean 등록 대상에 포함하겠다는 의미이다.  FilterType.ANNOTATION: 지정한 애너테이션이 붙은 경우에만 필터  FilterType.ASSIGNABLE_TYPE: 지정한 클래스 또는 그 자식 클래스만 필터  FilterType.REGEX: 클래스 이름이 정규식과 매칭되는 경우 필터  FilterType.ASPECTJ: AspectJ 라는 표현식에 맞는 필터  FilterType.CUSTOM: TypeFilter 를 구현한 커스텀 필터 클래스 사용따라서 맨 위 includeFilters 는 CustomAnnotion 이 붙은 클래스만 포함하겠다 라는 의미가 된다.  excludeFilters: include 와 동일하지만 제외하는 경우다  ComponentScan 은 그냥 스캔만 할 뿐이다. 해당 어노테이션이 붙었다고 하여서 그 클래스가 Bean 으로 등록되는건 아니다. 따라서 다음과 같이 사용한다고 하여서 config 가 bean 으로 등록되진 않는다.@ComponentScan(basePackages = {\"sample\"})public class UserConfig { }SpringBootApplication 의 ComponentScan아래 애너테이션을 토대로 SpringApplication 이 컴포넌트를 읽게 된다. 컴포넌트를 읽는 범위는 자기 자신 클래스가 있는 패키지와 그 하위 패키지를 기본적으로 스캔하는 방식이다.@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\t\t@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })CUSTOM 으로 Filter 타입이 지정되었다면, classes 에 오는 클래스들은 전부 TypeFilter 인터페이스를 구현하는 클래스가 와야 한다.@FunctionalInterfacepublic interface TypeFilter {    boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory)            throws IOException;}타입 필터는 match 를 구현하도록 되어 있다. 이제 SpringBootApplication 에서의 TypeExcludeFilter 를 보자.public class TypeExcludeFilter implements TypeFilter, BeanFactoryAware {...(중간 생략)@Overridepublic boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory)        throws IOException {    if (this.beanFactory instanceof ListableBeanFactory     &amp;&amp; getClass() == TypeExcludeFilter.class) {        for (TypeExcludeFilter delegate : getDelegates()) {            if (delegate.match(metadataReader, metadataReaderFactory)) return true;        }    }    return false;}각 클래스에서 필터 조건에 해당하는지 확인하는 매서드인데, true 면 스캔에서 제외되고, false 면 포함되는 형태이다. 인자를 먼저 보자.  metadataReader: 현재 검사 중인 클래스의 메타데이터(클래스명, 어노테이션 등) 을 읽어들이는 객체  metadataReaderFactory: 다른 클래스 정보를 가져오는 도구  beanFactory 가 ListableBeanFactory 인지 확인          Bean 목록을 조회할 수 있는 타입인지 체크한다.        현재 객체가 정확히 TypeExcludeFilter 클래스인지 확인          getClass() == TypeExcludeFilter.class      따라서 기본 TypeExcludeFilter 만 처리하고, 서브 클래스는 여기서 패스하게 된다.  필터도 여러 개 일텐데 TypeExcludeFilter 인 애만 처리하고 그 하위 클래스는 넘어가겠다는 의미이다.AutoConfigurationExcludeFilter 에 대한 것도 그러면 유추해볼 수 있을 것이다. Spring Boot 에서는 기본적으로 IoC 에 대한 자동적인 Bean 설정이 들어가기에 내부 구현을 따로 읽어서 어떤걸 제외시키고 있는지 보면 될 것이다.이렇게 SpringBootApplication 이 동작하게 된다.@Configuration이제 Configuration 을 이해할 수 있다. Configuration 의 의미는 구성, 설정이다. 구성은 객체 간의 이루어져있는 다이어그램 형태를 의미할 수 있다. Spring 에서의 객체는 Bean 이기 때문에 Bean 간의 이루어져있는 관계들을 말할 수 있다. 따라서 Configuration 애너테이션은 Bean 의 구성 관계들을 전부 아우르는 책임을 가지는 클래스여야 한다. 따라서 @Configuration 과 @Bean 애너테이션을 통해 이 클래스는 configuration 이며, 그 내부에 bean 들을 토대로 구성 설정을 할 것이다 라는 의미이다.@Configurationpublic class AppConfig {    @Bean    public Engine engine() {        return new Engine();    }    @Bean    public Car car() {        // car는 engine Bean을 의존        return new Car(engine());    }}따라서 SpringBootApplication 에 SpringBootConfiguration 애너테이션이 들어가 있었음을 알 수 있다.⭐️ @Configuration 의 CGLIB 프록시 메서드 proxyBeanMethods()실습을 하면서 느꼈던 의아했던 점을 적어본다. 중요한 내용일 수 있고, IoC 의 핵심 동작 부분을 건드린거 같기도 하다.@Configurationpublic class OrderConfig {\t@Bean//\t@Scope(\"prototype\")\tpublic Drink coffee() {\t\treturn new Coffee();\t}\t@Bean//\t@Scope(\"prototype\")\tpublic Drink tea() {\t\treturn new Tea();\t}\t@Bean//\t@Scope(\"singleton\")\tpublic OrderHistory orderHistory() {\t\treturn new OrderHistory();\t}\t@Bean\t@Scope(\"prototype\")\tpublic OrderService orderService() {\t\treturn new OrderServiceImpl(orderHistory());\t}}위 코드는 그냥 Config 를 통한 의존성 주입을 위해 bean 을 정의하는 클래스이다. 실습 문제는 다음과 같다.  여러 OrderService 에서 주문해도 주문 내역이 공유되도록 구현하세요그냥 Scope 를 prototype 으로 만들고 해버리면 되긴 된다. 여기서 궁금했던 점은 만약 @Configuration 을 없앴을 때 어떤 동작을 하는지이다. 실제로 @Configuration 을 없애도 기본적으로 context 를 통해 getBean 을 하면 @Scope(\"prototype\") 이 없는 이상 동일한 bean 을 반환하게 된다. 즉 기능은 아무 이상이 없었다.하지만, 서비스를 여러개 만들었을때 서비스 간에 가지고 있는 orderHistory 의 주입이 다 다른 객체로 들어가게 되었다. 즉 @Scope(\"singleton\") 이었음에도 불구하고 여러 객체가 생성되어 주입이 된 것이다. 이에 대한 분석으로는 다음과 같다.우선 Configuration 이 있을때를 보자. @Configuration 이 붙은 클래스는 Spring 이 CGLIB 프록시 를 만들어서 관리한다(중요). 이때 @Bean 메서드 호출이 내부적으로 프록시를 거치므로, 스프링 컨테이너에서 관리되는 싱글톤(@Bean 기본 scope)을 항상 반환하게 된다.  예: orderService() 에서 orderHistory()를 호출해도, 이미 생성된 singleton OrderHistory 를 주입받음그래서 @Configuration 이 없는 클래스에서 @Bean 메서드를 호출하면, 단순한 일반 메서드 호출처럼 동작하며, 따라서 orderHistory() 를 호출할 때 새로운 인스턴스가 생성됨. 결과적으로 prototype OrderService 가 생성될 때마다 각기 다른 OrderHistory 를 참조하게 되어, 스레드별로 다른 저장소처럼 동작하는 현상이 발생할 수 있음.핵심 요약:  @Configuration + @Bean → 프록시가 호출을 가로채고 스코프 규칙 적용 → singleton 보장  일반 클래스 + @Bean → 프록시 없음 → 단순 메서드 호출 → 매번 새 객체 생성          매번 새 객체 생성이지만 @Scope 는 적용됨      ⭐️ 하지만, getBean 을 사용할 때 가져오는 것은 동일 인스턴스를 가져오게 된다. 이건 getBean 내부에서 일어나는 어떤 과정이 있어서 그런 듯하다.        따라서 singleton 을 보장하고 prototype 빈에서 주입받도록 하려면 @Configuration 을 반드시 사용해야 함이제 다음으로 @Bean 과 함수 정의 스니펫 사이에 @Scope 를 통해 조금이나마 생명주기를 제어할 수 있다.@Scope 애너테이션으로 Bean 생명주기와 공유 범위 제어SpringBootApplication 이 Configuration 을 가지고 ComponentScan 을 통해 Configuration 에 Bean 으로 등록될 각각의 클래스들을 스캔하는 것을 보았다.이번에는 Bean 의 생명주기를 제어해보자. @Scope 애너테이션은 class 와 method 범위에 사용할 수 있는 애너테이션이며, 다음 value 를 가진다.            Scope      설명      사용 환경                  singleton      컨테이너당 하나의 Bean만 생성 (기본값)      모든 환경              prototype      요청할 때마다 새 Bean 생성      모든 환경              request      HTTP 요청당 하나의 Bean 생성      웹 애플리케이션              session      HTTP 세션당 하나의 Bean 생성      웹 애플리케이션              application      ServletContext 단위로 하나의 Bean 생성      웹 애플리케이션              websocket      WebSocket 세션당 하나의 Bean 생성      웹 애플리케이션      @PostConstruct 와 @PreDestroy 사용하여 생명주기에 대한 로그 찍어보기  Bean 정의 읽기: @Component 애너테이션 및 @Bean 메서드 등, XML 설정 파일을 읽어 Bean 정의를 스프링이 파악  Bean 인스턴스 생성: 컨테이너가 실제 객체를 생성  의존성 주입: 필요한 의존성 주입: @Autowired 나 생성자 / 세터를 통하여 차례차례 필요한 다른 Bean 주입  초기화: @PostConstruct 메서드 실행: Bean 이 생성되고 의존성이 주입된 후에 실행  사용: 애플리케이션에서 Bean 사용  소멸: Bean 이 종료될 때 호출(실질적으로는 IoC 컨테이너가 종료될 때 함께 소멸되기 때문에 IoC 컨테이너가 종료될때 호출)@Componentpublic class LifecycleBean {    public LifecycleBean() {        System.out.println(\"1. Constructor called\");    }    @PostConstruct    public void init() {        System.out.println(\"2. @PostConstruct - Bean initialized\");    }    public void doSomething() {        System.out.println(\"3. Bean is being used\");    }    @PreDestroy    public void cleanup() {        System.out.println(\"4. @PreDestroy - Bean cleanup\");    }}Properties 를 사용해 키 값을 Config 로 등록하기Config 는 Bean 을 위한 파일이다. Bean 에 대한 책임만을 가지지 얘가 key-value 와 같이 env 변수나 그런 형태의 값을 저장하는 것은 따로 없다. 이를 하고자 순수 자바 라이브러리는 표준 클래스로 Properties 라는게 있다(java.util.Properties).Key-Value 쌍으로 데이터를 저장하는 특수한 Map 이다. 주로 설정 파일(.properties) 을 읽어오거나 환경 변수 같은 설정을 관리하고 싶을 때 사용한다.// 마비노기 최고Properties props = new Properties();props.setProperty(\"game.name\", \"Mabinogi\");props.setProperty(\"game.level.max\", \"50\");String name = props.getProperty(\"game.name\"); // \"Mabinogi\"프로퍼티는 코드 단에서 뿐 아니라 파일을 자동으로 읽어들여서 사용할 수도 있다.public class Exam {\tpublic static void main(String[] args) throws IOException {\t\tProperties props = new Properties();\t\tprops.load(new FileInputStream(\"config.properties\"));\t}}이제 application.properties 를 어떻게 읽어들이는지 파악될 것이다.@Value 로 프로퍼티 주입해보기Spring Boot 에서는 기본적으로 application.properties 를 자동으로 읽어온다(따로 어디에도 이를 읽는 코드를 찾을 수 없지만, 내부적으로 어딘가에 읽는 코드가 있을 것이다). 이를 Bean 으로 정의된 클래스 내부에 @Value 를 통해 간단하게 읽어들여서 쓸 수 있다.application.properties 파일# 서버 설정server.port=8080server.servlet.context-path=/api# DB 설정spring.datasource.url=jdbc:mysql://localhost:3306/shopspring.datasource.username=rootspring.datasource.password=1234# 커스텀 프로퍼티shop.name=MyCafeshop.owner=Seonghunshop.maxCustomers=50코드import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;@Componentpublic class ShopInfo {    @Value(\"${shop.name}\")    private String name;    @Value(\"${shop.owner}\")    private String owner;    @Value(\"${shop.maxCustomers}\")    private int maxCustomers;    public void printInfo() {        System.out.println(\"Shop: \" + name);        System.out.println(\"Owner: \" + owner);        System.out.println(\"Max Customers: \" + maxCustomers);    }}실무에서는 커스텀 프로퍼티(application.properties 를 제외한 개발자가 서비스를 위해 임의로 만든 프로퍼티들)을 @ConfigurationProperties로 그룹화하여 설정 주입을 한다.@ConfigurationProperties 를 사용해 key 를 기준으로 값 들고오기아래를 보면 알겠지만 ConfigurationProperties 는 key 의 prefix 를 기준으로 쌍을 들고올 수 있다. 이는 전부 필드와 매핑되게 되는데, shop.name, shop.owner, shop.maxCustomers 로 매핑됨을 볼 수 있다.@Component@ConfigurationProperties(prefix = \"shop\")public class ShopProperties {    private String name;    private String owner;    private int maxCustomers;    // getter / setter 필수    public String getName() { return name; }    public void setName(String name) { this.name = name; }    public String getOwner() { return owner; }    public void setOwner(String owner) { this.owner = owner; }    public int getMaxCustomers() { return maxCustomers; }    public void setMaxCustomers(int maxCustomers) { this.maxCustomers = maxCustomers; }}// ============================@Servicepublic class ShopService {    private final ShopProperties shopProperties;    public ShopService(ShopProperties shopProperties) {        this.shopProperties = shopProperties;    }    public void info() {        System.out.println(\"Shop: \" + shopProperties.getName());        System.out.println(\"Owner: \" + shopProperties.getOwner());        System.out.println(\"Max Customers: \" + shopProperties.getMaxCustomers());    }}이렇게 가져간다면 컴파일 수준에서 타입 안전성을 가져갈 수 있어 실무에서 자주 사용한다.  @PropertySource 라는 것도 있는데, 굳이 싶다. application.properties 혹은 application.yml 에 key-value 를 체계적으로 써 놓고, 그걸 가져오는 편이 더 좋을 듯하다. 개발자 마음대로 사용하면 되는 듯하다. 하지만 만약 Spring 이 자동으로 로드하지 않는 별도의 properties 나 yml 파일을 읽어들이고 싶을때 사용할 수 있을거 같다. 또한 Property 를 따로 클래스를 두어 가져간다면 Bean 으로 등록하여 POJO 를 Bean 으로 연결시킬 수도 있을거 같다.DI 시 주의점기본적으로 다음 규칙이 있다.  생성자 주입은 생성자 하나에 대해 주입 동작이 실행된다. 만약 2개가 있다면 default 생성자를 기준으로 한다(인자가 없는).  @Autowired 를 생성자에 명시하면, 여러 생성자 중 어디에 주입할지 명확히 지정 가능하다.  세터 주입은 선택적 의존성(optional) 주입에 유용하며, 순환 의존성이 있는 경우 유리하다.  순환 의존성(Circular Dependency): 두 개 이상의 Bean 이 서로를 참조하는 경우 생성자 주입에서는 에러가 발생할 수 있으므로 세터 주입이나 @Lazy 옵션을 고려해야 함@LazyBean 의 초기화 시점을 늦춰 순환 참조를 막고자 할 때 사용하는 어노테이션이다. Bean 의 생성을 실제 사용 시점때 생성해달라고 스프링에게 요청하는 것이다.대상  무거운 초기화 작업이 필요한 Bean  순환 의존성을 피하고 싶은 Bean클래스 레벨에서 사용import org.springframework.context.annotation.Lazy;import org.springframework.stereotype.Component;@Component@Lazypublic class HeavyBean {    public HeavyBean() {        System.out.println(\"HeavyBean 생성됨!\");    }}의존성 주입에 Lazy 사용@Componentpublic class UserService {    private final HeavyBean heavyBean;    public UserService(@Lazy HeavyBean heavyBean) {        this.heavyBean = heavyBean;    }}Bean 에 사용@Configurationpublic class AppConfig {    @Bean    @Lazy    public HeavyBean heavyBean() {        return new HeavyBean();    }}에러 발생@Componentpublic class A {    private final B b;    @Autowired    public A(B b) {        this.b = b;    }}@Componentpublic class B {    private final A a;    @Autowired    public B(A a) {        this.a = a;    }}세터로 해결해결 방법: Spring 이 Bean 인스턴스를 생성(생성자 실행) -&gt; 세터를 통해 서로 주입import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Componentpublic class A {    private B b;    @Autowired    public void setB(B b) {        this.b = b;    }}@Componentpublic class B {    private A a;    @Autowired    public void setA(A a) {        this.a = a;    }}Lazy 를 통해 해결한쪽만 붙이면 된다.@Componentpublic class A {    private final B b;    @Autowired    public A(@Lazy B b) {        this.b = b;    }}@Componentpublic class B {    private final A a;    @Autowired    public B(A a) {        this.a = a;    }}장점  어플리케이션 시작 속도 향상  순환 의존성 해결  메모리 최적화주의점  싱글톤 Bean 과 잘 맞지만, 프로토타입 Bean 에는 사용 안함Spring Application 의 실행 과정 중 실행 코드 넣기가끔 어플리케이션이 실행되는 도중에 특정 시점에 특정 코드를 실행시키고 싶을 수 있을 것이다. 이를 위해 Spring Application 의 실행과정을 먼저 살펴보자.Spring Application순수 스프링은 보통 AnnotationConfigApplicationContext(컨피그를 넣어서 사용) 나 ClassPathXmlApplicationContext(xml 파일 넣어서 사용) 를 통해 IoC 를 직접 띄우게 된다.실행 순서는 다음과 같다:순수 Spring  SpringApplication 실행(SpringAppication.run())          ClassPathXmlApplicationContext 또는 AnnotationConfigApplicationContext 생성      BeanFactory 생성        Bean Definition 메타데이터 읽기          XML 파싱 또는 Java Config 클래스 스캔      @Component, @Service, @Repository 등 어노테이션 스캔      Bean 메타데이터를 BeanDefinition 객체로 변환        Bean 생성 및 의존성 주입          BeanFactory 에서 Bean 인스턴스 생성      생성자 주입, 세터 주입, 필드 주입 처리      BeanPostProcessor 실행        초기화 콜백          @PostConstruct 메서드 실행      InitializingBean.afterPropertiesSet() 실행      init-method 실행      Spring Boot Application  SpringApplication 실행          SpringApplication.run(MyApplication.class, args) 호출      실행 환경(Web, Reactive, None) 결정      ApplicationContextInitializer 로 초기화 인스턴스 로드      ApplicationListener 로 이벤트 리스너 로드      메인 애플리케이션 클래스 결정        Environment 준비          application.properties / application.yml 로딩      활성 프로파일(Profile) 적용      커맨드라인 인자, 시스템 프로퍼티, 환경 변수 바인딩      PropertySource 우선순위 적용        ApplicationContext 생성          웹 애플리케이션: AnnotationConfigServletWebServerApplicationContext      리액티브: AnnotationConfigReactiveWebServerApplicationContext      일반(non-web): AnnotationConfigApplicationContext        Auto-Configuration 적용          @EnableAutoConfiguration 처리      spring.factories에서 Auto-Configuration 클래스 로드      조건부 빈 등록:                  @ConditionalOnClass: 특정 클래스 존재 여부          @ConditionalOnMissingBean: 특정 빈 부재 여부          @ConditionalOnProperty: 프로퍼티 값 존재 여부                      ComponentScan          @SpringBootApplication 위치 기준 하위 패키지 스캔      @Component, @Service, @Repository, @Controller 등 감지        Bean 생성 및 의존성 주입          일반 Spring과 동일      Auto-configured Bean들이 먼저 등록      생성자 주입, 세터 주입, 필드 주입 수행      BeanPostProcessor 실행        내장 웹 서버 시작          ServletWebServerFactory 빈을 통해 Tomcat/Jetty/Undertow 시작      기본 포트 8080, server.port 프로퍼티로 변경 가능        CommandLineRunner / ApplicationRunner 실행          모든 Bean 초기화 완료 후 실행      애플리케이션 시작 직후 초기화 로직 수행 가능      @Componentpublic class MyRunner implements CommandLineRunner {    @Override    public void run(String... args) throws Exception {        System.out.println(\"애플리케이션 시작 후 실행되는 코드\");    }}이 흐름을 가지고 다음을 읽자.CommandLineRunnerSpring Boot 어플리케이션이 완전히 실행된 직후(의존서 주입이 끝난 뒤) 자동으로 실행되는 초기화용 인터페이스이며, @FunctionalInterface이다.@FunctionalInterfacepublic interface CommandLineRunner {    void run(String... args) throws Exception;}  Spring Boot 가 실행될 때, SpringApplication.run() 이 끝난 뒤에 모든 CommandLineRunner Bean 들의 run() 메서드를 자동으로 호출한다.  @Order 을 통해 실행 순서도 지정할 수 있다.@Component@RequiredArgsConstructorpublic class StartupRunner implements CommandLineRunner {        private final RedisTemplate&lt;String, Object&gt; redisTemplate;    private final KafkaTemplate&lt;String, String&gt; kafkaTemplate;        @Override    public void run(String... args) throws Exception {        // 1. Redis 연결 확인        try {            redisTemplate.opsForValue().set(\"health:check\", \"ok\");            System.out.println(\"✓ Redis 연결 성공\");        } catch (Exception e) {            System.err.println(\"✗ Redis 연결 실패\");        }                // 2. Kafka 연결 확인        try {            kafkaTemplate.send(\"health-check\", \"ping\");            System.out.println(\"✓ Kafka 연결 성공\");        } catch (Exception e) {            System.err.println(\"✗ Kafka 연결 실패\");        }                // 3. 초기 데이터 로딩        loadInitialData();    }        private void loadInitialData() {        System.out.println(\"초기 데이터 로딩 중...\");    }}  기본적으로 CommandLineRunner 는 Bean 으로 등록되어야 실행이 되게 된다.⭐️ Spring Event SystemSpring의 이벤트 시스템은 Publisher-Subscriber 패턴을 구현한다. 이는 이벤트 기반 통신 구조를 구현하는 디자인 패턴이며, 역할은 다음과 같다.  Publisher(발행자): 이벤트를 발생시키는 주체  Subscriber(구독자): 이벤트가 발생하면 이를 감지하고 처리하는 주체들즉 이벤트라는 매개체로만 소통하는 구조이다.장점  느슨한 결합  코드의 유연성  이벤트 발생 시 여러 구독자가 동시에 반응 가능이벤트 정의// 1. 이벤트 클래스 정의 (POJO)public class UserRegisteredEvent {    private final String email;    private final String username;    private final LocalDateTime registeredAt;        public UserRegisteredEvent(String email, String username) {        this.email = email;        this.username = username;        this.registeredAt = LocalDateTime.now();    }        // Getters    public String getEmail() { return email; }    public String getUsername() { return username; }    public LocalDateTime getRegisteredAt() { return registeredAt; }}Publisher@Service@RequiredArgsConstructorpublic class UserService {        private final UserRepository userRepository;    private final ApplicationEventPublisher eventPublisher;        public User registerUser(String email, String username) {        // 1. 비즈니스 로직 실행        User user = new User(email, username);        userRepository.save(user);                // 2. 이벤트 발행        UserRegisteredEvent event = new UserRegisteredEvent(email, username);        eventPublisher.publishEvent(event);                return user;    }}Subscriber구독자의 구현은 다양하다. 선호에 따라 사용하자.@Component@Slf4jpublic class UserEventListener {        @Autowired    private EmailService emailService;        // 회원가입 시 환영 이메일 발송    @EventListener    public void handleUserRegistered(UserRegisteredEvent event) {        log.info(\"새로운 사용자 등록: {}\", event.getUsername());        emailService.sendWelcomeEmail(event.getEmail());    }        // 조건부 리스너    @EventListener(condition = \"#event.email.endsWith('@company.com')\")    public void handleCompanyUserRegistered(UserRegisteredEvent event) {        log.info(\"회사 이메일로 등록: {}\", event.getEmail());        // 특별한 처리    }}@Componentpublic class LegacyUserEventListener         implements ApplicationListener&lt;UserRegisteredEvent&gt; {        @Override    public void onApplicationEvent(UserRegisteredEvent event) {        System.out.println(\"레거시 방식 리스너: \" + event.getUsername());    }}Asynchronized Event 로 구성하기이벤트의 동작이 너무 무겁거나 오래 걸리는 작업이면 원래 작업이 지연되기 때문에 비동기로 처리할 수 있다.@Configuration@EnableAsyncpublic class AsyncConfig {        @Bean    public TaskExecutor taskExecutor() {        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();        executor.setCorePoolSize(5);        executor.setMaxPoolSize(10);        executor.setQueueCapacity(100);        executor.setThreadNamePrefix(\"event-\");        executor.initialize();        return executor;    }}@EnableAsync 는 Spring 에서 비동기 메서드를 실행을 활성화시키는 어노테이션인데, 쉽게 말하여 특정 메서드를 별도의 스레드에서 동시에 실행하도록 허용하는 기능이다. 이렇게 해두고 비동기 메서드에 @Async 만 붙이면 간단하게 비동기로 실행이 가능하게 된다. 우선 실행할 스레드 풀을 커스터마이징하여 선언해놓고, Subscriber 를 구현하면 된다.@Component@Slf4jpublic class AsyncEventListener {        // 비동기로 처리 - 메인 스레드 블로킹 없음    @Async    @EventListener    public void handleUserRegisteredAsync(UserRegisteredEvent event) {        log.info(\"비동기 이벤트 처리 시작: {}\", Thread.currentThread().getName());                // 시간이 오래 걸리는 작업        try {            Thread.sleep(3000);            sendSlackNotification(event);        } catch (InterruptedException e) {            Thread.currentThread().interrupt();        }                log.info(\"비동기 이벤트 처리 완료\");    }        private void sendSlackNotification(UserRegisteredEvent event) {        // Slack 알림 발송    }}Transaction Event Listener스프링은 트랜잭션 별로 세세한 컨트롤이 가능하도록 각 생명주기 사이사이에 코드를 실행할 수 있는 애너테이션들을 제공한다.@Component@Slf4jpublic class TransactionalEventListener {        // 트랜잭션 커밋 후에만 실행    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)    public void handleAfterCommit(UserRegisteredEvent event) {        log.info(\"트랜잭션 커밋 후 실행: {}\", event.getUsername());        // 외부 API 호출, 메시지 큐 발송 등    }        // 트랜잭션 롤백 시 실행    @TransactionalEventListener(phase = TransactionPhase.AFTER_ROLLBACK)    public void handleAfterRollback(UserRegisteredEvent event) {        log.error(\"트랜잭션 롤백됨: {}\", event.getUsername());        // 롤백 처리    }        // 트랜잭션 완료 후 실행 (커밋/롤백 상관없이)    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMPLETION)    public void handleAfterCompletion(UserRegisteredEvent event) {        log.info(\"트랜잭션 완료: {}\", event.getUsername());    }        // 트랜잭션 시작 전 실행    @TransactionalEventListener(phase = TransactionPhase.BEFORE_COMMIT)    public void handleBeforeCommit(UserRegisteredEvent event) {        log.info(\"트랜잭션 커밋 직전: {}\", event.getUsername());    }}활용 예시// 이벤트 정의public class OrderCreatedEvent {    private final Long orderId;    private final Long userId;    private final BigDecimal amount;    private final LocalDateTime createdAt;        public OrderCreatedEvent(Long orderId, Long userId, BigDecimal amount) {        this.orderId = orderId;        this.userId = userId;        this.amount = amount;        this.createdAt = LocalDateTime.now();    }        // Getters...}// 서비스에서 이벤트 발행@Service@RequiredArgsConstructor@Transactionalpublic class OrderService {        private final OrderRepository orderRepository;    private final ApplicationEventPublisher eventPublisher;        public Order createOrder(OrderRequest request) {        // 주문 생성        Order order = Order.builder()                .userId(request.getUserId())                .amount(request.getAmount())                .status(OrderStatus.PENDING)                .build();                orderRepository.save(order);                // 이벤트 발행        eventPublisher.publishEvent(            new OrderCreatedEvent(order.getId(), order.getUserId(), order.getAmount())        );                return order;    }}// 다양한 리스너들@Component@Slf4j@RequiredArgsConstructorpublic class OrderEventHandlers {        private final EmailService emailService;    private final InventoryService inventoryService;    private final PaymentService paymentService;    private final SlackService slackService;        // 1. 재고 차감 (동기)    @EventListener    public void handleInventoryDeduction(OrderCreatedEvent event) {        log.info(\"재고 차감 시작: Order {}\", event.getOrderId());        inventoryService.deductInventory(event.getOrderId());    }        // 2. 결제 처리 (트랜잭션 커밋 후)    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)    public void handlePayment(OrderCreatedEvent event) {        log.info(\"결제 처리 시작: Order {}\", event.getOrderId());        paymentService.processPayment(event.getOrderId(), event.getAmount());    }        // 3. 이메일 발송 (비동기)    @Async    @EventListener    public void sendOrderConfirmationEmail(OrderCreatedEvent event) {        log.info(\"주문 확인 이메일 발송: Order {}\", event.getOrderId());        emailService.sendOrderConfirmation(event.getUserId(), event.getOrderId());    }        // 4. Slack 알림 (비동기, 고액 주문만)    @Async    @EventListener(condition = \"#event.amount.compareTo(new java.math.BigDecimal('1000000')) &gt; 0\")    public void notifyLargeOrder(OrderCreatedEvent event) {        log.info(\"고액 주문 알림: Order {} - {}\", event.getOrderId(), event.getAmount());        slackService.sendMessage(\"고액 주문 발생: \" + event.getAmount() + \"원\");    }}Spring 내장 EventListener@Component@Slf4jpublic class ApplicationEventListener {        // 1. 애플리케이션 시작 중    @EventListener    public void handleContextRefreshed(ContextRefreshedEvent event) {        log.info(\"1. ApplicationContext가 초기화되거나 리프레시됨\");    }        // 2. 애플리케이션 준비 완료    @EventListener    public void handleApplicationReady(ApplicationReadyEvent event) {        log.info(\"2. 애플리케이션이 요청을 처리할 준비가 됨\");        // 헬스체크, 외부 시스템 연결 등    }        // 3. 애플리케이션 시작 완료    @EventListener    public void handleApplicationStarted(ApplicationStartedEvent event) {        log.info(\"3. 애플리케이션이 시작됨 (리스너 호출 전)\");    }        // 4. 애플리케이션 종료 시작    @EventListener    public void handleContextClosing(ContextClosedEvent event) {        log.info(\"4. ApplicationContext가 닫히는 중\");        // 리소스 정리, 연결 종료 등    }}✒️ 용어CGLIB 프록시Spring에서 실제 클래스 자체를 상속받아 동적으로 프록시 객체를 생성하는 기술을 의미한다.  Spring AOP, @Configuration(proxyBeanMethods = true) 등에서 사용  클래스 기반 프록시이기 때문에 인터페이스가 없어도 프록시를 만들 수 있음  Spring이 대상 클래스(예: AppConfig)를 상속한 서브클래스를 런타임에 생성  Bean 메서드 호출 시 원래 객체가 아닌 프록시 객체를 통해 호출  프록시가 메서드 호출을 가로채어 싱글톤 보장, AOP 적용 등 추가 기능 수행  프록시 객체를 호출한다는 점이 핵심, proxyBeanMethods = true → CGLIB 프록시를 통해 Bean 메서드 간 호출 시 동일한 싱글톤 인스턴스 반환제일 중요한 것은 ⭐️ Bean 메서드 간 호출 시 동일한 싱글톤 인스턴스 반환 의 문장이다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 34일차 Spring Boot 프로젝트 구조",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/spring/2025/10/13/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-34%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-13",
      "content": "📂 목차  Spring Boot          Spring Initializer 의 war 옵션      프로젝트 구조                  Gradle          Gradle Wrapper                    Sementic Versioning      Spring                  Spring Boot Starter          Spring 진입점                    📚 본문Spring BootSpring Boot 핵심 가치  Convention over Configuration: 개발자가 미리 알고 있다고 가정하고 기본 설정을 제공  Auto Configuration: classpath 기반으로 애플리케이션을 자동 구성  독립 실행 가능: 내장 서버로 별도의 WAS 없이도 서비스 실행 가능  Actuator: 모니터링 기능을 통한 운영 편이 제공Spring Initializer 의 war 옵션war 옵션은 어떻게 배포할지 결정하는 빌드 방식이며, 외부 WAS 쪽에 배포하고 싶을 때 사용하게 된다(외장 Tomcat, WebLogic, JEUS 등등).jar 은 내장 WAS 로 바로 실행될 수 있도록 한다. 즉, java -jar build/libs/myapp.jar 으로 실행을 바로 할 수 있는 형태로 제공해준다는 말이다.프로젝트 구조우선 생성된 Spring Initializer 에 대해 프로젝트 구조를 다시 정리하고 가자.Gradle  build.gradle: Gradle 빌드 도구 설정 파일          plugins: Gradle 에 어떤 기능을 쓸지 선언하는 영역      repositories: 외부 라이브러리를 어디서 다운로드할지 결정      dependencies: 프로젝트에서 사용할 외부 라이브러리 목록 정의      build: 자바 버전 설정, 프로젝트 명 등등        settings.gradle: 프로젝트 이름 및 포함 프로젝트 설정  gradlew: Unix / MacOS 용 Gradle 실행 스크립트 파일  gradlew.bat: Window 용 Gradle 실행 스크립트 파일  gradle          gradle-wrapper.jar: Gradle 실행용 JAR      gradle-wrapper.properties: Gradle 버전 및 배포 설정      build.gradle 을 보통 많이 수정하게 될텐데 많이 봐두자. 또한 다음과 같은 key-value 를 볼 수 있다.group = 'com.example'version = '0.0.1-SNAPSHOT'description = 'Demo'            항목      의미      실행과의 관계                  group      패키지 네임스페이스(보통 도메인 형태, 예: com.example.demo)      빌드 시 그룹 ID로만 사용됨 (실행과 무관)              version      애플리케이션 버전 정보 (ex: 0.0.1-SNAPSHOT)      빌드 결과물(.jar 이름 등)에 반영됨              description      프로젝트 설명      문서나 메타데이터 용도로만 사용됨      java pluginbuild.gradle 의 plugins 블럭에 java 가 들어가고 있음을 볼 수 있다. 다음 명령어를 제공하게 된다.  ./gradlew compileJava: 자바 소스코드 컴파일  ./gradlew test: 테스트 실행// build.gradletasks.named('test') { &lt;- test 명령 실행 전 어떤 구성 설정을 할 것인지    useJUnitPlatform()}  ./gradlew jar: JAR 파일 생성  ./gradlew build: 전체 빌드 프로세스 실행org.springframework.boot plugin  ./gradlew bootRun: 애플리케이션을 즉시 실행(개발 모드)  ./gradlew bootJar: 실행 가능한 Fat JAR 생성(모든 의존성 포함)          생성된 jar 파일은 build/libs/ 폴더에 저장됨      이름은 {프로젝트명}-{버전}.jar 으로 생성되며 프로젝트 명은 settings.gradle 에서 rootProject.name =  으로 설정할 수 있다.        ./gradlew bootWar: WAR 파일 생성 (외부 서블릿 컨테이너 배포용)  ./gradlew bootBuildImage: Cloud Native Buildpacks 를 이용한 Docker 이미지 생성io.spring.dependency-management pluginSpring Boot 와 호환되는 의존성 버전을 자동으로 관리해주는 플러그인이다. gradle 은 원래 의존성 버전 충돌을 자동으로 조정하지 않는다. 보통 각 라이브러리의 버전을 명시하고 서로 특정 버전에서 충돌이 일어날 것을 고쳐주지 않는다.이때 io.spring.dependency-management 는 버전을 직접 쓰지 않아도 되는 환경을 만들어서 Spring Boot 가 관리하는 BOM 파일을 자동으로 가져와서 의존성들의 버전 호환성을 보장해준다.그 외 자주 쓰이는 명령어# 전체 빌드 (컴파일 + 테스트 + JAR 생성)./gradlew build# 테스트 실행./gradlew test# 빌드 결과물 삭제 (clean build 시 유용)./gradlew clean# clean + build 한 번에 실행./gradlew clean build# 프로젝트 정보 확인./gradlew projects# 사용 가능한 모든 Task 확인./gradlew tasks# 테스트 스킵하고 빌드./gradlew build -x test# 병렬 빌드 (멀티 모듈 프로젝트)./gradlew build --parallel# 빌드 캐시 사용./gradlew build --build-cache# 의존성 새로 다운로드 (캐시 무시)./gradlew build --refresh-dependencies# 디버그 모드로 실행./gradlew bootRun --debug-jvm# 특정 설정(configuration)의 의존성만 확인./gradlew dependencies --configuration compileClasspath./gradlew dependencies --configuration runtimeClasspath# 의존성 충돌 확인./gradlew dependencyInsight --dependency spring-core# 사용되지 않는 의존성 확인 (플러그인 필요)./gradlew buildHealthGradle Wrappergradle 폴더에 gradle wrapper 라는 이름의 파일을 봤을 것이다. 용도는 다음과 같다:  프로젝트마다 지정된 Gradle 버전 사용 보장  Gradle 설치 불필요 (자동 다운로드)  팀원 간 일관된 빌드 환경 제공  CI/CD 환경에서도 동일한 버전 사용Sementic VersioningMajor.Minor.Patch 형식 사용  Major: 호환되지 않는 API 변경 (예: 1.0.0 → 2.0.0)  Minor: 하위 호환되는 기능 추가 (예: 1.0.0 → 1.1.0)  Patch: 하위 호환되는 버그 수정 (예: 1.0.0 → 1.0.1)  SNAPSHOT: 개발 중인 불안정 버전 (예: 0.0.1-SNAPSHOT)  예시:      0.0.1-SNAPSHOT: 초기 개발 버전    1.0.0: 첫 정식 릴리스    1.1.0: 새 기능 추가    1.1.1: 버그 수정  SpringSpring 3.x 에서 많이 바뀐 것은 다음과 같다.  Java 17 이상 필수: Java 8/11 지원 중단  Jakarta EE 사용: javax.* → jakarta.* 패키지 변경  Spring Framework 6.x 기반: 네이티브 이미지 지원 강화  GraalVM Native Image 공식 지원: 빠른 시작 시간과 적은 메모리 사용Spring Boot Starter특정 기능을 사용하기 위해 필요한 의존성을 묶어놓은 패키지이다. 어떤 기능을 구현하기 위해 다른 패키지가 필요할 수 있고 또 다른 패키지가 또 필요할 수 있다. 이를 Spring Boot Starter 라는 팩으로 필요한 기능들에 대한 패키지들을 묶어서 dependency 를 추가만 하면 다수의 관련된 기능 패키지들을 다 가져와서 자동으로 추가해준다.            Starter      용도      포함 라이브러리                  spring-boot-starter      핵심 기능      로깅, 자동 구성 등              spring-boot-starter-web      웹 애플리케이션      Spring MVC, Tomcat, Jackson              spring-boot-starter-data-jpa      JPA 사용      Hibernate, Spring Data JPA              spring-boot-starter-data-jdbc      JDBC 사용      Spring Data JDBC, HikariCP              spring-boot-starter-security      보안      Spring Security              spring-boot-starter-test      테스트      JUnit 5, Mockito, AssertJ              spring-boot-starter-validation      유효성 검증      Hibernate Validator              spring-boot-starter-actuator      모니터링      헬스체크, 메트릭 등              spring-boot-starter-thymeleaf      템플릿 엔진      Thymeleaf              spring-boot-starter-cache      캐싱      Spring Cache 추상화        ./gradlew dependencies 명령어를 통해 어떤 의존성들이 추가됐는지 확인할 수 있다.장점  필요한 의존성을 개별적으로 찾아 추가할 필요 없음  버전 호환성이 보장된 의존성 조합 제공  자동 구성(Auto-configuration) 포함  설정 최소화 (Convention over Configuration)Spring 진입점  application.properties: 애플리케이션 설정 파일 (yml로 변경 가능)  DemoApplication.java: Spring Boot 실행 클래스Spring Boot 프로젝트의 entry point 는 @SpringBootApplication 이 붙은 클래스이며, 내부의 main() 메서드에서 SpringApplication.run() 을 호출하는 부분이 실행 시작점이 된다. 헷갈릴 수 있는 것은 build.gradle 의 group, version, description 설정은 빌드 메타정보일 뿐, 진입점 결정에는 영향을 주지 않는다.Spring Bean✒️ 용어Cloud Native Buildpacks소스 코드로부터 컨테이너 이미지를 자동으로 빌드해주는 표준화된 도구 체계이다. 즉 Dockerfile 작성 없이도 어플리케이션 언어와 구조를 자동 인식해서 필요한 런타임, 의존성, 설정을 자동으로 포함시켜서 이미지를 만들어준다.BOMBill of Materials 의 약자이며, 여러 라이브러리의 호환 가능한 버전 세트를 모아둔 일종의 버전 관리표 이다. 스프링 부트는 내부적으로 spring-boot-dependencies 라는 BOM 을 사용한다.GraalVM Native ImageGraalVM Native Image 은 JVM 기반 어플리케이션을 미리 기계어로 컴파일해서 실행 속도와 메모리 효율을 극대화 시키는 기술 즉, JAR 로 실행하는 대신에 미리 운영체제용 실행 파일 형태로 변환해주는 Ahead-of-Time 컴파일 기술이다.만약 java -jar myapp.jar 로 JVM 위에서 실행할 수 있겠지만, 이 대신에./gradlew bootBuildImage \\    --imageName=myapp:native \\    --builder paketobuildpacks/builder:tiny \\    --env BP_NATIVE_IMAGE=true와 같이 빌드를 한다면, Spring 이 Spring AOT Engine 을 통해Spring Boot 앱을 Native Image 로 변환할 때 필요한 설정(리플렉션, 프록시 등)을 자동으로 생성해주고, GraalVM 으로 컴파일된 네이티브 Docker 이미지를 자동 생성된 것틀 실행할 수 있게 된다. (내부적으로 Paketo Buildpacks + GraalVM 사용// 네이티브 이미지 빌드./gradlew bootBuildImage --imageName=myapp:native --env BP_NATIVE_IMAGE=true// 또는 `GraalVM CLI` 직접 사용 시native-image -jar build/libs/myapp.jar myapp// 실행가능./myapp두 번째 방식은 GraalVM CLI 가 다운받아져 있어야 한다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 33일차 Java Network Programming - UDP",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/network/2025/10/02/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-33%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-02",
      "content": "📂 목차  UDP          예외처리      실습 코드들                  UDP Echo          UDP Client          UDP Broadcast                      심화          Transport Layer                  TCP          UDP                      Java 파일 경로 다루기          Path, Paths      Path 를 File 로 변환하기                  파일 쓰기          경로 결합 및 해석                    subPath()      URI                  Round-trip Guarantee                    WatchServer API                  예외 상황          WatchKey                    📚 본문UDPUser Datagram Protocol 의 약자로, 전송 계층 프로토콜 중의 하나이다. 여기서 TCP 는 데이터 단위가 패킷이었지만, UDP 만이 따로 보내는 데이터 단위를 Datagram 이라고 부른다.특징으로는  Connection 이 없이(3-Way Handshaking 없이) 전송한다  속도가 빠름  신뢰성이 낮음  데이터그램이 가볍다          헤더 크가기 8 바이트(TCP 는 최소 20 바이트)        1:n 의 브로드 캐스팅이 가능하다예외처리  IOException: 네트워크 연결 실패, 데이터 전송 중 오류 등 대부분의 입출력 문제  UnknownHostException: 호스트 이름(도메인)을 IP 주소로 변환할 수 없을 때 (DNS 조회 실패)  SocketTimeoutException: 지정된 시간 내에 연결 또는 데이터 읽기가 완료되지 않았을 때  ConnectException: 서버가 해당 포트에서 대기하고 있지 않거나 연결을 거부했을 때실습 코드들UDP Echoimport java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;public class UDPEchoServer {\tprivate static final int PORT = 7777;\tprivate static final int BUFFER_SIZE = 8192;\tpublic static void main(String[] args) {\t\ttry (var socket = new DatagramSocket(PORT)) {\t\t\tSystem.out.println(\"UDP Echo Server Starting...\");\t\t\tvar buffer = new byte[BUFFER_SIZE];\t\t\twhile (true) {\t\t\t\t// 클라이언트가 보낸 메시지를 받음\t\t\t\tvar packet = new DatagramPacket(buffer, buffer.length);\t\t\t\tsocket.receive(packet);\t\t\t\tvar message = new String(packet.getData(), 0, packet.getLength());\t\t\t\tSystem.out.println(\"받은 메시지 &gt; \" + message);\t\t\t\t// 클라이언트에게 받은 메시지를 다시 보냄\t\t\t\tvar responseMessage = \"Echo &gt; \" + message;\t\t\t\tbyte[] responseBuffer = responseMessage.getBytes();\t\t\t\tvar datagramPacket = new DatagramPacket(\t\t\t\t\t\tresponseBuffer,\t\t\t\t\t\tresponseMessage.length(),\t\t\t\t\t\tpacket.getAddress(),\t\t\t\t\t\tpacket.getPort());\t\t\t\tsocket.send(datagramPacket);\t\t\t\tSystem.out.println(\"전송 완료: \" + responseMessage);\t\t\t}\t\t} catch (IOException e) {\t\t\te.printStackTrace();\t\t}\t}}UDP Clientpublic class UDPEchoClient {\tprivate static final String SERVER_HOST = \"localhost\";\tprivate static final int SERVER_PORT = 7777;\tprivate static final int BUFFER_SIZE = 8192;\tpublic static void main(String[] args) {\t\ttry (var socket = new DatagramSocket();\t\t     var keyboard = new Scanner(System.in)) {\t\t\tvar address = InetAddress.getByName(SERVER_HOST);\t\t\tvar buffer = new byte[BUFFER_SIZE];\t\t\tSystem.out.println(\"서버에게 보낼 메시지를 입력해주세요.\");\t\t\twhile (true) {\t\t\t\tvar message = keyboard.nextLine();\t\t\t\tif (\"quit\".equalsIgnoreCase(message)) break;\t\t\t\tvar sendData = message.getBytes();\t\t\t\tvar sendPacket = new DatagramPacket(sendData, sendData.length, address, SERVER_PORT);\t\t\t\tsocket.send(sendPacket);\t\t\t\tvar datagramPacket = new DatagramPacket(buffer, buffer.length);\t\t\t\tsocket.receive(datagramPacket);\t\t\t\tnew String(datagramPacket.getData(), 0, datagramPacket.getLength());\t\t\t}\t\t} catch (IOException e) {\t\t\te.printStackTrace();\t\t}\t}}UDP Broadcastpublic class UDPBroadcast {    public static void main(String[] args) {        try (DatagramSocket socket = new DatagramSocket()) {            socket.setBroadcast(true);            String message = \"브로드캐스트 메시지입니다!\";            byte[] buffer = message.getBytes();            // 브로드캐스트 주소 (255.255.255.255)            InetAddress broadcastAddress =                InetAddress.getByName(\"255.255.255.255\");            DatagramPacket packet = new DatagramPacket(                buffer,                buffer.length,                broadcastAddress,                9876            );            socket.send(packet);            System.out.println(\"브로드캐스트 메시지 전송 완료\");        } catch (Exception e) {            e.printStackTrace();        }    }}심화Transport Layer 의 프로토콜로, OSI 7계층중 4계층에 위치한다.기본적으로 신뢰성이 있는 바이트 스트림 전송을 보장하며, IP 는 단순 패킷을 목적지까지 최선형 전달(best-effort delivery) 만 제공하므로 손실, 중복, 순서 뒤바뀜 문제가 발생하지만, TCP 는 이러한 문제를 해결하여 Application Layer 가 안정적인 통신을 수행할 수 있도록 한다.OSI 계층의 관점에서 더 살펴보자.Transport Layer어플리케이션(5-7 계층)과 네트워크(1-3 계층) 사이의 중개자 역할을 하는 이 계층은 프로세스 간 통신(IPC) 를 책임진다.단순히 컴퓨터와 컴퓨터 사이가 아니라 컴퓨터 내부의 프로세스와 상대방의 특정 프로세스를 연결하는 통로를 만든다. 이 통로를 통과하는 전송 계층의 데이터 단위는 Segement 이다.역할  전송 제어: 큰 데이터를 쪼개서(segment) 보내고, 다시 조립 가능한가?          파일 전송 중 “HelloWorld” 를 보내고, 세그먼트 단위가 “Hello”, “World” 로 쪼개짐      수신 측에서 순서가 꼬여 “WorldHello” 로 받아버리면서 데이터 무결성이 깨짐        오류 제어: 데이터가 중간에 손상되거나 유실되면 재전송 요구(ACK, NAK, Checksum 등)가 가능한가?          전송 중 bit-flip(1이 0으로 변하는 현상)이 생겨 은행 송금 중 10,000 원이 100,000 원으로 잘못 도착      문서 전송 중 “결재 승인” -&gt; “결재 취소” 로 바뀜        흐름 제어: 송신 측이 수신 측의 처리 속도를 고려하여 전송량을 조잘할 수 있는가?          클라이언트가 대용량 로그 파일을 초고속으로 전송해버림      서버는 디스크 I/O 가 느려서 못 따라감      결국 데이터 일부 손실(받을 수 있는 공간이 없으면 버려버림)      TCP  연결 지향(Connection-Oriented): 데이터를 전송하기 전 3-Way Handshake 로 연결을 성립시킨다.  신뢰성 보장(Reliable): 손실, 중복, 순서 꼬임을 모두 해결  흐름 제어(Flow Control): 수신 측의 처리 속도에 맞춰 전송 속도를 조절(Window Size)  혼잡 제어(Congestion Control): 네트워크가 붕괴되지 않도록 전송량을 자동 조절(AIMD 등 알고리즘)  스트림 기반(Stream-Oriented): 바이트 단위의 연속적 데이터 스트림으로 메시지 경계가 없음세그먼트 내부 구조0       7 8     15 16    23 24     31+--------+--------+--------+--------+|  Source Port    | Destination Port|+--------+--------+--------+--------+|          Sequence Number          |+--------+--------+--------+--------+|      Acknowledgment Number        |+--------+--------+--------+--------+|Off.|Res. |Flags |      Window     |+--------+--------+--------+--------+|    Checksum     |  Urgent Pointer |+--------+--------+--------+--------+|     Options (0~40B, 존재할 경우)     |+-----------------------------------+|               Data ...            |  Source Port(16bit) / Destination Port(16bit): 어떤 어플리케이션과 통신할지를 식별  Sequence Number(32bit): 바이트 스트림 순서 식별  Acknowledgement Number(32bit): 다음에 기대하는 바이트 번호  Data Offset(4bit): 헤더 길이를 나타냄 (예: 32비트 워드)  Reversed(6bit): 확장용, 예약 필드, 미래에 쓰일 필드  Flags(6bit - 9bit): SYN, ACK, FIN, RST 등 제어 플래그(URG, PSH, …)  Window Size(16bit): 흐름 제어  Checksum(16bit): 오류 검출을 위한 체크섬연결 절차  3-Way Handsake: SYN -&gt; SYN+ACK -&gt; ACK  시퀀스 번호 기반으로 세그먼트 전송          손실 시 ACK flag 사용하여 재전송 요청      윈도우 기반으로 속도 조절        4-Way Handsake: FIN -&gt; ACK -&gt; FIN -&gt; ACK사용 범위  웹, 파일 전송, 이메일 등으로 신뢰성이 필요할 때 사용  프로그래머가 직접 재전송, 순서 보장, 흐름 제어를 구현할 필요가 없음  HTTP(S), FTP, SMTP, SSH 등단점  헤더 크기가 최소 20 바이트  느림UDPUDP 는 Handsake 가 없어, 그냥 데이터 그램(세그먼트) 을 내보내게 된다. 이때 보내는 데이터들에서는 순서 보장이 안되며, 중복을 허용하게 된다. 보낸 메시지가 그대로 하나의 데이터그램이 되며 나가게 된다. TCP 와는 달리 전송 제어, 오류 제어, 흐름 제어가 없어서 데이터 무결성은 보장할 수 없다.[ Source Port | Destination Port | Length | Checksum ]  단순 포트, 길이, 체크섬만 있고, 순서, 재전송, 흐름 제어가 없다.연결 절차  연결 과정은 없고,  그냥 sendTo(), recvFrom() 으로만 받기만 한다.사용 범위  데이터 그램이 TCP 의 세그먼트 보다는 헤더가 작아서 빠르며  실시간 통신에 유리하다(손실 몇 개는 무시해도 무관)  DNS, VoIP, 온라인 게임, 영상 스트리밍장점  빠름Java 파일 경로 다루기Java 7 에서 부터는 java.nio.file 패키지를 통해 파일 경로를 다룰 수 있다.Path, Pathsimport java.nio.file.Path;import java.nio.file.Paths;import 를 통해 Path 를 가져올 수 있지만, Path 는 인터페이스만 제공을 하기 때문에 실제 구현체는 Paths 라는 유틸 클래스로 생성해줄 수 있다.Path relativePath = Paths.get(\"file/test.txt\");Path absolutePath = Paths.get(\"(경로 입력)/Desktop/network/file/test.txt\");System.out.println(\"상대경로 : \" + relativePath);System.out.println(\"절대경로 : \" + absolutePath);또한 경로는 존재하지 않는 경로에 대해서도 경로를 정할 수 있다. 무슨 말이냐면 foo 파일이 없음에도 불구하고, 해당 경로를 생성시킬 수 있다.Path path = Paths.get(\"file/foo\");System.out.println(path);아무 오류 없이 정상적으로 출력됨을 볼 수 있다. 이를 Path 가 가진 메서드들을 통해 정보를 출력해볼 수 있다.Path relativePath = Paths.get(\"file/test.txt\");Path absolutePath = Paths.get(\"~/Desktop/network/file/test.txt\");Path absentPath = Paths.get(\"hihi\");Path[] paths = new Path[] {relativePath, absolutePath, absentPath};for (Path path : paths) {\ttry {\t\tSystem.out.println(\"파일명 : \" + path.getFileName());\t\tSystem.out.println(\"부모 디렉터리 : \" + path.getParent());\t\tSystem.out.println(\"절대 경로 : \" + path.toAbsolutePath());\t\tSystem.out.println(\"존재 여부 : \" + Files.exists(path));\t\tSystem.out.println(\"파일 크기 : \" + Files.size(path) + \" bytes\");\t} catch (Exception e) {\t\tSystem.out.println(e);\t} finally {\t\tSystem.out.println();\t}}해당 파일의 존재 여부는 Files 유틸을 통해 존재하는지, size 가 얼마인지 등을 알 수 있고, 존재하지 않는 파일들에 대해서의 접근해야지만 얻을 수 있는 정보(Path.toFile(), Files.size() 등등) 에 대해 NoSuchFileException 이 뜸을 볼 수 있다.출력파일명 : test.txt부모 디렉터리 : file절대 경로 : /Users/(username)/Desktop/network/file/test.txt존재 여부 : true파일 크기 : 91 bytes파일명 : test.txt부모 디렉터리 : ~/Desktop/network/file절대 경로 : /Users/(username)/Desktop/network/~/Desktop/network/file/test.txt존재 여부 : falsejava.nio.file.NoSuchFileException: ~/Desktop/network/file/test.txt파일명 : hihi부모 디렉터리 : null절대 경로 : /Users/(username)/Desktop/network/hihi존재 여부 : falsejava.nio.file.NoSuchFileException: hihiPath 를 File 로 변환하기이제 해당 Path 를 파일로 변환시키는 방법을 살펴보자. Path 인터페이스의 toFile 메서드를 통해 파일을 얻을 수 있다.import java.io.File;...File file = relativePath.toFile();파일 쓰기파일을 생성할 때는 무조건 운영체제의 권한이 필요로 하게 됨을 알고 있자.Path path = Paths.get(\"data/output.txt\");// 디렉터리가 없다면 생성Files.createDirectories(path.getParent());// 파일에 문자열 쓰기Files.write(path,\t\t\tList.of(\"Hello\", \"World\"),\t\t\tStandardOpenOption.CREATE,\t\t\tStandardOpenOption.TRUNCATE_EXISTING);System.out.println(\"파일 저장 완료: \" + path.toAbsolutePath());  Files.createDirectories: 해당 부모 경로가 없다면 쭉 생성해준다.  Files.write: 파일에 내용을 쓴다.  StandardOpenOption: OpenOption 인터페이스를 구현하는 열거형 클래스이다. 옵션들은 밑에 정리해두었다.            옵션      설명      예시 사용 상황                  READ      파일을 읽기 전용으로 연다.      Files.newInputStream(path, READ)              WRITE      파일을 쓰기 전용으로 연다.      Files.newOutputStream(path, WRITE)              APPEND      파일의 끝에 데이터를 덧붙인다. (기존 내용 유지)      로그 파일 추가 기록              TRUNCATE_EXISTING      기존 파일이 존재하면 내용을 모두 비운 후 새로 쓴다.      파일 새로 덮어쓰기              CREATE      파일이 없으면 새로 만든다.      기본적인 파일 생성 시              CREATE_NEW      파일이 이미 존재하면 예외 발생.      중복 파일 방지 시              DELETE_ON_CLOSE      스트림을 닫을 때 파일을 자동 삭제.      임시 파일 처리              SPARSE      희소 파일(sparse file)로 생성. (대용량 비어있는 공간 절약)      대형 파일 테스트              SYNC      모든 데이터와 메타데이터를 디스크에 즉시 기록 (성능 ↓, 안정성 ↑)      DB나 로그의 안정적 쓰기              DSYNC      데이터만 디스크에 즉시 기록 (메타데이터는 나중에)      빠른 데이터 안정화        Files 와 Paths 의 메서드들은 다른 포스트에서 심도있게 다룬다.경로 결합 및 해석Path 의 resolve() 를 통해 경로를 얽힘 없이 자동으로 합쳐주고, normalize() 를 통해 현재 경로에서 불필요한 즉, 중복된 이름 요소 혹은, ., .. 등을 제거한 경로를 만들 수 있다.import java.nio.file.Path;import java.nio.file.Paths;public class PathJoin {    public static void main(String[] args) {\t\tPath base = Paths.get(\"/Users/user1/Desktop\");\t\tPath child = base.resolve(\"network/file.txt\");  // 결합\t\tSystem.out.println(\"결합된 경로: \" + child);\t\tPath p = Paths.get(\"/Users/user1/Desktop/network/../file.txt\");\t\tSystem.out.println(\"정규화 전: \" + p);\t\tSystem.out.println(\"정규화 후: \" + p.normalize());    }}subPath()API: Path subpath(int beginIndex, int endIndex);의 형태이고, 0부터 count 까지의 범위이다. endIndex 는 exclusive 하기 때문에 제외된다.  /Users/user1/Desktop/hello/example/test.txt/: 0/Users/: 1/Users/user1/: 2Path base = Paths.get(\"/Users/user1/Desktop\");System.out.println(\"서브 경로: \" + base.subpath(2, 3));// 서브 경로: DesktopURIURI 는 Uniform Resource Identifier 의 약자로, 자원에 대해 통합 자원 식별자를 매길 수 있게 한다. 이름 그대로 식별자 용도이다. 보통 다음과 같은 형태를 가지게 된다.  file:///Users/user1/Desktop/file.txtscheme://example.com:8080/path?query#fragment여기서 file:// 은 로컬 파일 시스템 스킴이고 그 뒤에는 경로가 따라온다.Scheme  file:///: 로컬 파일 시스템  http://: HTTP 프로토콜  ftp://: FTP 프로토콜  jar:file:///: JAR 파일 내부이러한 스킴을 정하는 것은 파일 시스템 제공자(FileSystemProvider) 에 의해 관리되고, 그 제공자가 사용하는 스킴으로 URI 를 만들게 된다.기본적으로 프로바이더는 OS 의 파일 시스템을 의미하기 때문에 Path.toUri() 의 경우에는 다음과 같은 특징을 가지게 된다:  absolute path 형태로 변환  query(?), fragment(#) 부분 없음  authority(//server 같은 부분)는 구현에 따라 다름  파일이 디렉터리라면 / 로 끝남  shceme: 프로토콜fragment: 문서 내의 특정 위치authority: 서버 주소와 포트Round-trip GuaranteePath.of(p.toUri()).equals(p.toAbsolutePath()) 가 보장된다는 의미이다. 즉, Path 를 URI 로 바꿨다가 다시 URI 에서 Path 로 바꾸어도 같은 절대 경로가 되어야 한다는 의미이다.  단, 같은 JVM 안에서만 이 보장이 유효함WatchServer APIjava.nio.file.Path 인터페이스 안에는 디렉터리 변경 감시 기능(파일 변경 이벤트 감시) 관련 메서드가 존재한다.자바의 WatchService API 와 함께 동작하며, 파일 시스템에서 파일 생성, 수정, 삭제 이벤트를 감시할 수 있도록 한다.WatchKey register(WatchService watcher,\t\t\t\t  WatchEvent.Kind&lt;?&gt;[] events,\t\t\t\t  WatchEvent.Modifier... modifiers) throwsIOException;위가 기본 API 이고, @Overriding 이 되어 있고, Watchable 인터페이스에도 있게 된다(아마 인터페이스를 @Override 한 이유는 굳이 Watchable 까지 들어가서 명세서를 보도록 안하기 위함이 아닐까 싶다 배울점).  Path: 감시할 디렉터리의 경로  WatchService: 이벤트를 모아주는 이벤트 통지 시스템  WatchKey: 등록된 디렉터리 1곳을 대표하는 키 (이를 토대로 이벤트를 꺼냄)  WatchEvent.Kind: 어떤 종류의 이벤트를 감시할지를 지정          ENTRY_CREATE: 새 파일이 생성되거나 디렉터리에 들어옴      ENTRY_DELETE: 파일이 삭제되거나 디렉터리에서 나감      ENTRY_MODIFY: 파일이 수정됨 (내용/속성 변경)        WatchEvent.Modifier: 이 디렉터리를 감시하되, 어떤 특별한 조건이나 방식으로 감시할 지를 정의          이 구체적인 구현체 인자는 OS 또는 파일시스템 제공자(provider)가 제공하므로 해당 OS 에 맞는 Modifier 를 가져와야 한다.        WatchEven.Modifier 는 deprecatedMac OS / Linux 예시import com.sun.nio.file.SensitivityWatchEventModifier;dir.register(watcher,             new WatchEvent.Kind&lt;?&gt;[]{ENTRY_CREATE, ENTRY_MODIFY, ENTRY_DELETE},             SensitivityWatchEventModifier.HIGH);  LOW: 10초에 한 번 정도 검사 (부하 적음)  MEDIUM: 2초 정도 간격으로 검사  HIGH: 거의 실시간 감지 (CPU 부하 큼)  여러개의 Modifier 옵션을 넣을 수 있게 가변 인자로 선언되어 있지만 대부분은 한 개만 쓴다고 하며, 최근 들어서 JDK 21 은 해당 Modifier 옵션을 지정하지 않는 것으로 두고, OS 가 알아서 주기적으로 검사하도록 하게 한다. 따라서 이 인자는 비워도 된다.예외 상황  UnsupportedOperationException: 지원되지 않는 Modifier 전달  ClosedWatchServiceException  NotDirectoryException  IOException  SecurityExceptionWatchKey이제 실제 활용을 해보자.try (WatchService watcher = FileSystems.getDefault().newWatchService()) {\tPath dir = Paths.get(\"/Users/user1/Desktop/network/file\");\tif (!Files.isDirectory(dir))\t\tthrow new IllegalArgumentException(\"지정한 경로가 디렉터리가 아닙니다: \" + dir);\tdir.register(watcher,\t\t\t\t\tStandardWatchEventKinds.ENTRY_CREATE,\t\t\t\t\tStandardWatchEventKinds.ENTRY_DELETE,\t\t\t\t\tStandardWatchEventKinds.ENTRY_MODIFY);\twhile (true) {\t\ttry {\t\t\tWatchKey key = watcher.poll(10, TimeUnit.SECONDS);\t\t\tif (key == null) break;\t\t\tfor (WatchEvent&lt;?&gt; event : key.pollEvents())\t\t\t\tSystem.out.println(\"이벤트: \" + event.kind() + \" | 파일: \" + event.context());\t\t\tif (!key.reset()) break;\t\t} catch (InterruptedException e) {\t\t\tThread.currentThread().interrupt();\t\t\tSystem.out.println(\"감시 스레드가 인터럽트 되었습니다.\");\t\t\tbreak;\t\t}\t}}  OS 의 파일시스템이 제공하는 새로운 WatchService 를 가져온다.  감시할 디렉토리를 Path 로 설정하고, 디렉터리인지 확인해준다.  Path.register 을 통해 감시 서비스에 등록해준다.          StandardWatchEventKinds 의 ENTRY_CREATE, ENTRY_MODIFY, ENTRY_DELETE 전부 등록해준다.      즉, 해당 종류들을 감시하는 것을 등록한다.        poll() 을 통해 로그를 들고온다.          watcher.poll(10, TimeUnit.SECONDS); 동기로 가져오기 때문에 10초까지 이벤트가 없다면 null 을 반환하게 된다.      무한 블로킹을 하지 않고 일정 시간 기다린 후 반환하는 제한 블로킹 구조를 사용      내부적으로는 폴링 스레드를 통해 따로 처리하는 스레드가 있음(개발자는 이를 볼 수 없음)        가져온 key 가 null 이면          이벤트가 진행된게 없기 때문에 수행 종료        이벤트가 발생하고 pollEvents()로 처리하면, 그 순간 WatchKey는 일시적으로 비활성 상태가 된다.          이때 이벤트 가 발생된 자원은 event.context() 를 통해 확인하고      이벤트 종류를 event.kind() 로 확인한다.        마지막으로 reset() 을 통해 다시 이벤트를 감시할 수 있도록 한다.          만약 false 를 리턴했다면, 디렉터리가 삭제되었거나 WatchService 가 닫힌 경우이기에 빠져나간다.        사실 상 만약 Interrupt 를 try 내부에서 처리하고 싶다면 다음 구문을 넣어야 한다: if (Thread.currentThread().isInterrupted()) break; 기본적으로 비동기 식이기 때문에 처리가 늦어진 이유가 interrupt 발생 때문이라면(외부 다른 스레드에서 현재 스레드의 종료, 시스템 신호나 JVM 종료 요청 때문에 종료 의 경우 혹은 예외 발생) break 를 하게 되는 코드인데, 이는 이미 catch 로 InterruptedException 을 처리할 수 있도록 하게 하였으니 필요 없는 옛구문이다.✒️ 용어동기 vs 비동기  완전 비동기: 메서드 호출 즉시 반환하고, 결과를 나중에 Callback 이나 Future 로 처리  완전 동기: 메서드 호출 시 결과가 나올 때까지 블로킹  제한 블로킹: 무한 블로킹하지 않고 일정 시간 기다린 후에 반환하는 구조위에서는 take() 보다는 poll() 방식을 사용하였고, timeout 까지 지정하여 제한 블로킹 형태로 되었다.  take(): 비동기는 아님, 호출 스레드 자체를 블로킹  poll(): 즉시 반환(non-blocking) 비동기임  poll(int, TimeUnit): 지정 시간 동안 대기 후 반환, 제한 블로킹이며 완전 비동기는 아님Polling Thread폴링 뜻은 주기적으로 상태를 확인하는 방식이다. 따라서 CPU 자원을 계속 소모하면서 이벤트가 없을 때도 반복적으로 확인하는 동작을 한다(OS 네이티브 이벤트를 쓰는 경우는 CPU 소모가 거의 없음).자바에서는 WatchService 에서 OS 가 지원하는 이벤트 감지 기능을 활용할 수도 있고, 일부 플랫폼에서는 자체 폴링 스레드를 사용하기도 한다. 어쨋든 간에 폴링 스레드는 WatchService 내부에서 주기적으로 실행되는 흐름이다.여기 나오는 예시는 다음 동작을 한다.  등록된 디렉터리를 주기적으로 체크  변경 사항이 있으면 이벤트 큐에 넣음  poll() 이나 take() 호출 스레드는 이 큐에서 이벤트를 가져오게 됨"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 32일차 Java Network Programming - TCP",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/network/2025/10/01/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-32%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-10-01",
      "content": "📂 목차  IP Address          Subnet Mask      사설 IP 와 공인 IP      포트 번호        TCP 통신  Java 네트워크 프로그래밍          InetAddress 클래스      Socket Programming                  TCP 소켓          UDP 소켓          TCP Echo 서버 구현          Multi-Threaded Server          TCP 채팅 서버                    📚 본문IP AddressIP 주소(Internet Protocol Address)는 인터넷에 연결된 모든 장치에 할당된 고유한 주소 이다.  IPv4: 127.0.0.1 -&gt; 8 비트씩 4개  IPv6: 2404:6800:400a:080a:0000:0000:0000:2004 -&gt; 16 비트씩 8개의 형태를 가진다. 여기서 보통 8비트 단위를 Octet 이라고 부르고 IPv6 에서는 :를 기준으로 각각을 필드라고 부른다.Subnet Mask서브넷 마스크는 네트워크 부분과 호스트 부분으로 나누는 기준을 나타내는 비트 패턴이며, 쉽게 말하면 주소의 어떤 부분이 네트워크인지, 어떤 부분이 장치인지를 나타내는 마스킹이다.  IPv4 예시          IP 주소 192.168.1.10: 11000000.10101000.00000001.00001010      서브넷 마스크 255.255.255.0: 11111111.11111111.11111111.00000000      자리수 끼리 &amp;(and) 연산을 통해 네트워크 부분을 구할 수 있다.사설 IP 와 공인 IP공인 IP  ISP(인터넷 서비스 공급자)가 제공하는 전세계적으로 유일한 IP 주소  외부에서 직접 접근 가능  방화벽 등의 보안 설정 필요  ISP 는 KT, SKT, LG U+ 등등 이 대표적이며, AWS, Azure 같은 클라우드 서버의 퍼블릭 IP 도 그 예이다.사설 IP  가정이나 회사 내부 네트워크에서 사용  외부에서 직접 접근 불가능  NAT(Network Address Translation)를 통해 인터넷 접속사설 IP 주소는 공인 IP 와 구분되어 다음 대역을 사용하기로 약속되어 있다.  Class A: 10.0.0.0 ~ 10.255.255.255  Class B: 172.16.0.0 ~ 172.31.255.255  Class C: 192.168.0.0 ~ 192.168.255.255이렇게 IP 를 통해 타고 들어가면 end user 에 닿을 수 있다.포트 번호end user 에 닿았다고 하여서 바로 데이터가 컴퓨터 내부로 들어가는건 아니다. 데이터가 들어갈 올바른 출입구인 포트 번호를 지정해주어야 데이터가 들어갈 수 있다.  0 ~ 1023: Well-known ports (HTTP:80, HTTPS:443, FTP:21)  1024 ~ 49151: Registered ports  49152 ~ 65535: Dynamic/Private ports위는 그 예시이다. 0-49151 까지는 이미 쓰이고 있기 때문에 보통 커스텀으로 포트를 열때(서버를 열때)는 49152 부터 65535 까지의 포트 번호 중 안쓰는 번호를 사용하여 열어주면 된다.이렇게 서버의 포트가 열리면 그 때부터 데이터가 들어올 통로를 마련하게 된다.TCP 통신신뢰성 있는 데이터 전송을 보장하는 연결 지향적 프로토콜이다.  연결 지향적: 데이터 전송 전 수신자와 송신자가 3-way handshake 로 연결  신뢰성 보장: 데이터가 유실되거나 순서가 바뀌면 재전송 순서 보정 등을 통해 보장  스트림 기반: 데이터를 패킷 단위가 아니라 바이트 스트림으로 다룸  혼잡 제어, 흐름 제어: 네트워크가 과부하되지 않도록, 수신자가 처리 가능한 만큼만 전송동작 과정  3-Way Handshake:          Client -&gt; Server: SYN (연결 요청 신호)      Server -&gt; Client: SYN + ACK (연결 허가 + 확인)      Client -&gt; Server: ACK (확인 완료)        데이터 전송          데이터를 세그먼트 단위로 잘라 보냄      각 세그먼트에 번호를 붙여 순서 확인      수신 측은 ACK 를 보내어 잘 받았음을 알림        연결 해제 (4-Way Handsake)          서로 FIN 과 ACK 를 주고 받으며 정상적으로 연결을 끊음      Java 네트워크 프로그래밍InetAddress 클래스IP 주소를 표현하고 다루는 클래스이다. java.net 패키지에 들어있고, 호스트 이름과 IP 주소간의 매핑을 처리하며, 로컬/원격 호스트의 IP 주소를 나타낼 수 있다.생성자를 호출하지 않고, 정적 메서드 호출을 하여 객체를 생성한다.  InetAddress.getByName(“www.google.com”)  InetAddress.getAllByName(“www.google.com”): 도메인 주소에 대한 모든 서버 IP 리턴  InetAddress.getLocalHost(): 현재 내 컴퓨터의 IPisReachable(int timeout)import java.net.*;public class ReachableExample {    public static void main(String[] args) {        try {            // 구글 서버 주소            InetAddress google = InetAddress.getByName(\"www.google.com\");            System.out.println(\"호스트 이름: \" + google.getHostName());            System.out.println(\"호스트 주소: \" + google.getHostAddress());            // 5초 동안 응답 여부 확인            if (google.isReachable(5000)) {                System.out.println(\"구글 서버에 연결 가능합니다!\");            } else {                System.out.println(\"구글 서버에 연결할 수 없습니다.\");            }            // 로컬호스트 테스트            InetAddress local = InetAddress.getLocalHost();            if (local.isReachable(2000)) {                System.out.println(\"로컬호스트 연결 가능!\");            }        } catch (Exception e) {            e.printStackTrace();        }    }}  방화벽에 막혀 있으면 실제로 연결 가능한데도 false 를 반환할 수 있으며, 내부적으로 ICMP 연결을 사용한다. ICMP 는 OS 권한이 필요하여 일부 환경에서는 false 가 나올 수 있다.  isLoopbackAddress(): 자기 자신의 주소인지 확인(localhost)  isSiteLocalAddress(): 이 주소가 사설 IP 주소인지 확인하는 메서드이다  IPv6 의 루프백 주소는 ::1 이다.Socket Programming먼저 소켓을 알아보자. 소켓은 네트워크 통신의 End-point 를 의미하며, 프로세스와 네트워크를 연결하는 추상화된 창구라고 할 수 있다.  IP 주소: 어느 컴퓨터인가?  Port 번호: 어떤 프로세스인가?  Socket: IP + Port 를 합친 네트워크 상의 출입구따라서 소켓은 두 프로세스가 네트워크를 통해 통신할 수 있게 하는 인터페이스이다. 또한 소켓을 사용하면 양방향 데이터 스트림을 제공하며, TCP 소켓, UDP 소켓의 타입도 결정할 수 있다.TCP 소켓  연결 지향적(3-way handshake)  신뢰성 보장(순서 보장, 무손실)UDP 소켓  비연결 지향적  빠르지만 신뢰성 없음  조금 손실이 일어나도 괜찮은 데이터라면 UDP 가 좋음TCP Echo 서버 구현에코 서버는 클라이언트가 서버에게 메시지를 보내면 서버가 클라이언트에게 동일한 메시지로 다시 보내는 구조이다.public class SimpleEchoServer {\tprivate final static int PORT = 7777;\tpublic static void main(String[] args) {\t\t// 호스트 지정이 없으면 서버가 모든 네트워크의 인터페이스에서 접속을 받을 수 있음\t\ttry (var serverSocket = new ServerSocket(PORT)) {\t\t\tSystem.out.println(PORT + \" 포트가 열렸습니다.\");\t\t\twhile (true) {\t\t\t\t/*\t\t\t\taccept() 로 클라이언트가 들어오길 기다림\t\t\t\t클라이언트가 접속을 했다면 client 소켓이 리턴됨\t\t\t\t클라이언트의 소켓을 통해서 in, out 의 연결 통로가 필요(양방향)\t\t\t\t항상 입출력은 하나의 통로에서 동작할 수 없다.\t\t\t\t */\t\t\t\ttry (Socket socket = serverSocket.accept();\t\t\t\t     BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()));\t\t\t\t     PrintWriter out = new PrintWriter(new BufferedOutputStream(socket.getOutputStream()), true)) {\t\t\t\t\tSystem.out.println(\"클라이언트 \" + socket.getRemoteSocketAddress() + \" 님 접속 완료\");\t\t\t\t\tString line;\t\t\t\t\twhile ((line = in.readLine()) != null) {\t\t\t\t\t\tSystem.out.println(\"클라이언트로부터 받은 메시지: \" + line);\t\t\t\t\t\tout.println(\"Echo \" + line);\t\t\t\t\t\tif (\"bye\".equalsIgnoreCase(line))\t\t\t\t\t\t\tbreak;\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t} catch (IOException e) {\t\t\tSystem.err.println(\"서버 시작 실패했습니다.\");\t\t}\t}}우선 Socket 은 accept() 를 통해 통신이 들어오는지 안들어오는지 판단하고, 들어온다면 그때 3-Way Handshake 가 일어나게 된다.정상적인 통신이 이루어졌다면, 올바른 소켓이 만들어지게 되고 여기서 소켓은 InputStream 과 OutputStream 을 반환하게 되는데, 이 두 통로가 바로 in, out 의 양방향 송수신을 하게 될 창구이다.socket.getRemoteSocketAddress()소켓은 접속한 클라이언트의 소켓 주소를 볼 수 있으며 위 메서드로 정보를 불러오게 된다. 이제 in.readLine() 을 무한히 반복하여 readLine() 에서 blocking 이 되어서 입력을 기다리고, 받은 입력을 다시 out 으로 내보내게 되면서 echo 기능을 수행함을 볼 수 있다.  PrintWriter out = new PrintWriter(new BufferedOutputStream(socket.getOutputStream()), true) 의 두 번째 인자는 println, printf, format 메서드를 호출하면 무조건 그 다음 자동 flush를 하도록 하는 옵션이다.서버를 다 만들었으니 이제 클라이언트 쪽도 만들어야 한다.public class SimpleEchoClient {\tprivate static final String HOST = \"localhost\";\tprivate static final int PORT = 7777;\tpublic static void main(String[] args) {\t\t// 호스트 지정이 있기에 서버가 특정 IP 주소에만 바인딩 됨\t\ttry (var socket = new Socket(HOST, PORT);\t\t     var in = new BufferedReader(new InputStreamReader(socket.getInputStream()));\t\t     var out = new PrintWriter(new BufferedOutputStream(socket.getOutputStream()), true);\t\t     var keyboard = new Scanner(System.in)) {\t\t\tSystem.out.println(\"접속 완료\");\t\t\tSystem.out.println(\"bye 를 입력하시면 종료됩니다.\");\t\t\twhile (true) {\t\t\t\t// 클라이언트의 입력을 전송\t\t\t\tSystem.out.print(\"서버에 전달할 메시지를 입력하세요: \");\t\t\t\tvar line = keyboard.nextLine();\t\t\t\tout.println(line);\t\t\t\t// 서버가 응답한 내용을 읽어옴\t\t\t\tvar response = in.readLine();                // [안정성] 서버가 연결을 먼저 끊었을 경우를 확인합니다.                if (response == null) {                    System.out.println(\"서버와의 연결이 끊어졌습니다.\");                    break;                }                System.out.println(response);\t\t\t\tif (\"bye\".equalsIgnoreCase(line))\t\t\t\t\tbreak;\t\t\t}\t\t} catch (IOException e) {\t\t\tthrow new RuntimeException(e);\t\t}\t}}거의 동일하지만 중요한 것은 var response = in.readLine(); 을 수행할 때 서버가 해당 유저의 연결을 강제로 끊어버렸을 때이다. 이때는 response 에 null 이 들어가게 되므로 끊었을 때는 유저의 연결도 끊어주어야 하기에 if 문으로 자원을 회수한다.Multi-Threaded Server위 예시는 사용자가 한 명만 접속을 하게 된다. 2명 부터는 접속이 안되게 되는데, accept() 를 통해 소켓을 만들지만 readLine() 의 blocking 때문에 이를 호출할 수 없다.따라서 유저의 입출력을 비동기로 받을 수 있도록 해야하며, 중첩 클래스로 다음과 같이 선언할 수 있다.static class ClientHandler implements Runnable {    private final Socket socket;    ClientHandler(Socket socket) {        this.socket = socket;    }    @Override    public void run() {        try (BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()));                PrintWriter out = new PrintWriter(socket.getOutputStream(), true);        ) {            SocketAddress clientAddress = socket.getRemoteSocketAddress();            System.out.println(clientAddress + \" 사용자 접속함\");            String inputLine;            while ((inputLine = in.readLine()) != null) {                System.out.println(clientAddress + \"로 부터 받은 메시지 :: \" + inputLine);                out.println(\"Echo::\" + inputLine);                if (\"bye\".equals(inputLine)) {                    break;                }            }            System.out.println(clientAddress + \" 연결 종료!!\");        } catch (Exception e) {            throw new RuntimeException(e);        } finally {            try {                socket.close();            } catch (IOException e) {                System.out.println(e.getMessage() + \"소켓 종료 오류!!\");            }        }    }}이렇게 되면 내부적으로 또 다른 처리 흐름으로 전환시켜 ClientHander 를 수행하도록 하면 된다.try (ServerSocket serverSocket = new ServerSocket(PORT)) {    System.out.println(\"에코서버 시작\");    while (true) {        Socket socket = serverSocket.accept();        //클라이언트별로 각각 통신 할 수 있는 쓰레드가 필요할 것 같아요.        Thread clientThread = new Thread(new ClientHandler(socket));        clientThread.start();    }} catch (Exception e) {    throw new RuntimeException(e);}여기서 Thread 는 스레드 풀로 동작하게 할 수 있으며, 만약 초과하는 클라이언트 접속에 대해서는 Waiting Queue 로 들어가게 해야하며, 클라이언트에게는 접속 기다리는 중... 등의 피드백 메시지를 띄워줘야 한다.ServerSocket serverSocket = new ServerSocket(PORT);System.out.println(\"에코 서버 시작, 포트: \" + PORT);// 스레드 풀과 큐 생성BlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;&gt;(10); // 큐 용량 10ThreadPoolExecutor pool = new ThreadPoolExecutor(        MAX_THREADS,        MAX_THREADS,        0L,        TimeUnit.MILLISECONDS,        queue);while (true) {    Socket socket = serverSocket.accept();    // 풀과 큐 상태 확인    if (pool.getActiveCount() &gt;= MAX_THREADS &amp;&amp; queue.remainingCapacity() == 0) {        // 스레드와 큐가 꽉 찼다면 대기 메시지 전송 후 연결 종료        try (PrintWriter out = new PrintWriter(socket.getOutputStream(), true)) {            out.println(\"서버 접속 대기 중입니다. 잠시 후 다시 시도해주세요.\");        } catch (IOException e) {            e.printStackTrace();        } finally {            socket.close();        }    } else {        // 처리 가능한 경우 스레드 풀에 제출        pool.submit(new ClientHandler(socket));    }}TCP 채팅 서버public class ChatServer {\tprivate static final int PORT = 7777;\tprivate static Set&lt;ClientHandler&gt; clients = ConcurrentHashMap.newKeySet();\tprivate static void broadcast(String message) {\t\tSystem.out.println(message);\t\tfor (var client : clients)\t\t\tclient.sendMessage(message);\t}\tpublic static void main(String[] args) {\t\tSystem.out.println(\"채팅 서버 시작\");\t\ttry (ServerSocket serverSocket = new ServerSocket(PORT)) {\t\t\twhile (true) {\t\t\t\tSocket socket = serverSocket.accept();\t\t\t\tClientHandler clientHandler = new ClientHandler(socket);\t\t\t\tclients.add(clientHandler);\t\t\t\tnew Thread(clientHandler).start();\t\t\t}\t\t} catch (IOException e) {\t\t\tthrow new RuntimeException(e);\t\t}\t}\tstatic class ClientHandler implements Runnable {\t\tprivate Socket socket;\t\tprivate PrintWriter pw;\t\tprivate String nickname;\t\tpublic ClientHandler(Socket socket) {\t\t\tthis.socket = socket;\t\t}\t\t@Override\t\tpublic void run() {\t\t\ttry(var br = new BufferedReader(new InputStreamReader(socket.getInputStream()))) {\t\t\t\tpw = new PrintWriter(new BufferedOutputStream(socket.getOutputStream()), true);\t\t\t\tString message;\t\t\t\twhile ((message = br.readLine()) != null &amp;&amp; message.trim().isEmpty())\t\t\t\t\tpw.println(\"올바르지 않은 닉네임입니다.\");\t\t\t\tnickname = message;\t\t\t\tbroadcast(nickname + \"님이 들어왔습니다.\");\t\t\t\tif (nickname != null)\t\t\t\t\twhile ((message = br.readLine()) != null) {\t\t\t\t\t\tif (message.trim().isBlank()) continue;\t\t\t\t\t\tbroadcast(nickname + \"\\t\" + message);\t\t\t\t\t}\t\t\t} catch (IOException e) {\t\t\t\tSystem.err.println(e);\t\t\t} finally {\t\t\t\tbroadcast(nickname + \"님이 나갔습니다.\");\t\t\t\tpw.close();\t\t\t\ttry {\t\t\t\t\tsocket.close();\t\t\t\t} catch (IOException e) {\t\t\t\t\te.printStackTrace();\t\t\t\t}\t\t\t}\t\t}\t\tprivate void sendMessage(String message) {\t\t\tif (pw != null) pw.println(message);\t\t}\t}}다른 코드들은 전부 해석하면 되며, private static Set&lt;ClientHandler&gt; clients = ConcurrentHashMap.newKeySet(); 쪽과 예외처리의 흐름을 잘 이해하고 코드를 짜야하는 것을 보아야 한다.만약 Collections.synchronizedSet(new HashSet&lt;&gt;()) 을 쓰게 된다면 이는 전체 Set 에 lock 을 걸기 때문에 성능 저하가 일어나게 된다. 하지만 ConcurrentHashMap.newKeySet() 은:  Fine-grained Lock, Segment Lock 등 내부에 동기화 구현이 최적화되어 있어서 높은 동시성을 지원한다.  멀티 스레드 환경에서 컬렉션 보다 더 효율적이게 된다.이러한 이유로 해당 정적 메서드를 통해 최적화된 동시성을 가진 Set 을 가질 수 있다.public class ChatClient {\tprivate static final String HOST = \"localhost\";\tprivate static final int PORT = 7777;\tpublic static void main(String[] args) {\t\ttry (Socket socket = new Socket(HOST, PORT);\t\t     BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()));\t\t     PrintWriter out = new PrintWriter(new BufferedOutputStream(socket.getOutputStream()), true);\t\t     Scanner sc = new Scanner(System.in);\t\t) {\t\t\tSystem.out.println(\"접속 성공 !\");\t\t\t// receiver\t\t\tThread thread = new Thread(() -&gt; {\t\t\t\tString message;\t\t\t\ttry {\t\t\t\t\twhile ((message = in.readLine()) != null)\t\t\t\t\t\tSystem.out.println(message);\t\t\t\t} catch (IOException e) {\t\t\t\t\tSystem.out.println(e);\t\t\t\t}\t\t\t});\t\t\tthread.start();\t\t\tSystem.out.print(\"닉네임을 입력해주세요: \");\t\t\tout.println(sc.nextLine());\t\t\t// sender\t\t\tString message;\t\t\twhile (true) {\t\t\t\tmessage = sc.nextLine();\t\t\t\tif (\"bye\".equalsIgnoreCase(message)) break;\t\t\t\tout.println(message);\t\t\t}\t\t\tSystem.out.println(\"종료 완료\");\t\t} catch (IOException e) {\t\t\te.printStackTrace();\t\t}\t}}클라이언트 입장가장 중요한 것은 서버 쪽과의 통신이다. 만약 연결을 끊고 싶을때는 socket.close() 를 호출하면 되나, try 로 묶었기 때문에 try-with-resources 블럭이 끝나면, 소켓, in, out 등 자원이 회수되게 되고 receive thread 는 자동적으로 닫히게 된다(in.readLine() 의 값이 null 이 되기 때문). FIN 패킷이 서버로 전송되어 4Way-handsake 가 되게 된다.서버 입장이제 서버 입장이다. 서버 쪽에서는 입력 스트림에 더 이상 읽을게 없다는 것을 깨닫고, br.readLine() 에서 블로킹 된 흐름에서 message 가 null 이 되기 때문에 try 문을 벗어나게 된다. 이후 pw.close() 를 통해 out 통로를 닫고, socket.close() 자원까지 호출하여 전부 닫게 된다.✒️ 용어Fine-grained LockLock 단위를 줄여서 작은 단위에 대한 Lock 을 걸어 동시성을 높이는 전략  여러 스레드가 서로 다른 key 를 수정할 때 충돌 없이 동시 접근이 가능  동시성 성능이 훨씬 좋음  ConcurrentHashMap 은 내부적으로 key들을 버킷(bucket) 단위로 나누고, 버킷마다 lock을 걸거나 원자적 연산을 사용Segment Lock내부적으로 Map 을 여러 개 Segment 로 나누고 각 세그먼트는 자체 Lock 을 가지며, 스레드가 Key 를 추가/삭제할 때 해당 Segment 만 lock 을 거는 것, 즉 세그먼트 개수만큼 동시 접근이 가능하다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 31일차 데이터 흐름 Stream ",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/30/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-31%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-30",
      "content": "📂 목차  Stream 심화          중간 연산                  distinct()          flatMap()          sorted()          peek()          reduce()          collect()                    최종 연산                  allMatch, anyMatch, noneMatch          findFirst, findAny          집계 연산          groupingBy          partitioningBy                    Parallel Stream                  언제 사용하면 좋을까?                    📚 본문Stream 심화데이터를 저장하지 않고 흐르듯이 처리하는 내장 API 이다.  List-&gt;Stream: stream() 메서드로 생성가능하다.  Array-&gt;Stream: Arrays.stream() 정적 메서드로 생성 가능하다.          Arrays.stream(, from, to) 부분 stream 생성도 가능하다.        Stream 정적 메서드          &lt;T&gt; Stream&lt;T&gt; iterate(final T seed, final UnaryOperator&lt;T&gt; f) 를 활용해 무한 집합에 가까운 처리도 가능하다      &lt;T&gt; Stream&lt;T&gt; generate(Supplier&lt;? extends T&gt; s) 동일한 무한 스트림을 생성하지만, 초기 값이 없다는 것이 차이다.        모든 생성된 Stream 은 내부적으로 Generic 타입에 알맞은 인자가 들어가게 된다.중간 연산중간 연산을 통해 적절한 데이터로 형변환, 필터링 등등을 수행한다. 중간 연산은 호출해도 즉시 실행되지 않고, 최종 연산이 수행될 때 적용된다.  Lazy Evaluation 이다distinct()중복값을 제거한다.class Person {    String name;    int age;    Person(String name, int age) {        this.name = name;        this.age = age;    }    @Override    public boolean equals(Object o) {        if (this == o) return true;        if (!(o instanceof Person)) return false;        Person p = (Person) o;        return age == p.age &amp;&amp; name.equals(p.name);    }    @Override    public int hashCode() {        return Objects.hash(name, age);    }    @Override    public String toString() {        return name + \"-\" + age;    }}public class DistinctObjectExample {    public static void main(String[] args) {        List&lt;Person&gt; people = Arrays.asList(            new Person(\"Alice\", 20),            new Person(\"Bob\", 25),            new Person(\"Alice\", 20)        );        List&lt;Person&gt; distinctPeople = people.stream()                                            .distinct()                                            .collect(Collectors.toList());        System.out.println(distinctPeople); // [Alice-20, Bob-25]    }}여기서 주의할 점은 내부 비교는 equals() + hashCode() 를 구현한 클래스에 대해서 중복 제거를 하게 된다.  java 16 부터는 collect(Collectors.toList()) 보다는 toList() 를 통해 더 간편하게 바꿀 수 있다.flatMap()stream 내부에서 collection 이 나올 때 이를 구조 분해하고 싶을 수도 있다. Collection 에서는 stream() 메서드를 활용하여 이를 평탄화 가능하다.import java.util.*;import java.util.stream.*;public class FlatMapExample {    public static void main(String[] args) {        List&lt;List&lt;String&gt;&gt; listOfLists = Arrays.asList(            Arrays.asList(\"A\", \"B\"),            Arrays.asList(\"C\", \"D\", \"E\"),            Arrays.asList(\"F\")        );        // flatMap 사용        List&lt;String&gt; flatList = listOfLists.stream()            .flatMap(List::stream)  // 각 리스트를 스트림으로 변환하고 평탄화            .collect(Collectors.toList());        System.out.println(flatList); // [A, B, C, D, E, F]    }}또한 내부적으로 Collection 이 아니더라도 해당 클래스에 대한 stream 으로 변환해주는 API 가 있다면 stream 내에서 구조 분해가 가능하다.class Student {    String name;    List&lt;String&gt; courses;    Student(String name, List&lt;String&gt; courses) {        this.name = name;        this.courses = courses;    }}public class FlatMapStudentExample {    public static void main(String[] args) {        List&lt;Student&gt; students = Arrays.asList(            new Student(\"Alice\", Arrays.asList(\"Math\", \"Physics\")),            new Student(\"Bob\", Arrays.asList(\"English\", \"History\")),            new Student(\"Charlie\", Arrays.asList(\"Math\", \"History\"))        );        // 모든 학생이 수강하는 과목을 하나의 스트림으로        List&lt;String&gt; allCourses = students.stream()            .flatMap(student -&gt; student.courses.stream())            .distinct()  // 중복 제거            .collect(Collectors.toList());        System.out.println(allCourses); // [Math, Physics, English, History]    }}sorted()중간 연산자인 정렬은 인자가 없는 것을 쓰려면 해당 stream 내부의 데이터에 대한 Comparable 이 정의되어 있어야 하며, 인자가 있을 때는 sorted(Comparator c) 의 Comparator 가 들어간다. 익명 객체를 통해 Comparator 를 생성해서 넣을 수도 있지만, Comparators.comparing() 을 통해 primitive 혹은 어떤 특정한 클래스의 정렬 조건을 따르게 간단히도 구현할 수 있다.List&lt;Integer&gt; numbers = Arrays.asList(5, 2, 8, 1);List&lt;Integer&gt; sortedDesc = numbers.stream()                                  .sorted((a, b) -&gt; b - a)                                  .toList();System.out.println(sortedDesc); // [8, 5, 2, 1]class Person {    String name;    int age;    Person(String name, int age) { this.name = name; this.age = age; }    @Override public String toString() { return name + \"-\" + age; }}List&lt;Person&gt; people = Arrays.asList(    new Person(\"Alice\", 25),    new Person(\"Bob\", 20),    new Person(\"Charlie\", 30));// 나이 순으로 정렬List&lt;Person&gt; sortedByAge = people.stream()                                 .sorted(Comparator.comparingInt(p -&gt; p.age))                                 .toList();System.out.println(sortedByAge); // [Bob-20, Alice-25, Charlie-30]// comparing 메서드List&lt;Person&gt; sortedByNameThenAge = people.stream()    .sorted(Comparator.comparing((Person p) -&gt; p.name)                      .thenComparingInt(p -&gt; p.age))    .toList();peek()peek 는 forEach 와 비슷하지만 forEach 는 최종 연산자로서 작용되고, peek 는 중간연산자로 작동한다. 중간에 데이터가 어떻게 처리되는지 보고 싶거나 중간데이터를 써야 할 경우에 사용한다.stream.peek(Consumer&lt;? super T&gt; action)내부적으로 Consumer 를 넣어야 하며, stream 내의 데이터에 대해 소비를 하는 functional interface 가 들어가면 된다.reduce()reduce 는 stream 의 데이터를 축소, 합치는 연산을 수행한다. 첫 번째 인자는 초기값인데 선택이다. 두 번째 인자는 BinaryOperator 함수형 인터페이스를 넣어주면 된다.public class ReduceExample {    public static void main(String[] args) {        List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);        // 합계 구하기 (초기값 있음)        int sum = numbers.stream()            .reduce(0, (a, b) -&gt; a + b);        System.out.println(\"합계: \" + sum); // 15        // 합계 구하기 (메서드 참조)        int sum2 = numbers.stream()            .reduce(0, Integer::sum);        System.out.println(\"합계2: \" + sum2); // 15        // 최댓값 구하기 (초기값 없음)        Optional&lt;Integer&gt; max = numbers.stream()            .reduce(Integer::max);        max.ifPresent(n -&gt; System.out.println(\"최댓값: \" + n)); // 5        // 문자열 연결        List&lt;String&gt; words = Arrays.asList(\"Hello\", \" \", \"World\", \"!\");        String sentence = words.stream()            .reduce(\"\", String::concat);        System.out.println(sentence); // Hello World!    }}collect()&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector)위 API 를 보기 전에 Collector 를 먼저 보자.public interface Collector&lt;T, A, R&gt; {    // ...}Collector 는 인터페이스로 선언되어 있다.  T: 스트림 요소 타입  A: 누적기, 스트림 요소를 임시로 모아두는 객체  R: 최종 반환 타입(collect 후 얻는 결과)Collector&lt;Employee, ?, Integer&gt; summingSalaries         = Collectors.summingInt(Employee::getSalary))컬렉터 는 3개의 parametric type 이 들어가긴 하지만 생략도 가능하다. 이렇게 ? 로 생략할 수 있는 이유는 내부적으로 Integer 를 누적하기 위해 어떤 객체 A 를 사용하겠지만, 외부에서는 R 만 알면 충분하기 때문이다. 이는 컴파일러가 자동으로 타입 유추를 하여 누적기 A 의 타입을 자동으로 결정하기 때문이다.위 내용을 몰라도 Collector 를 생성할 때는 Collectors 를 통해 더 쉽게쉽게 생성할 수 있다.public class CollectorsExample {    public static void main(String[] args) {        List&lt;Student&gt; students = Arrays.asList(            new Student(\"Alice\", 85, \"CS\"),            new Student(\"Bob\", 92, \"Math\"),            new Student(\"Charlie\", 78, \"CS\"),            new Student(\"David\", 88, \"Physics\"),            new Student(\"Eve\", 95, \"Math\")        );        // toList로 수집        List&lt;String&gt; names = students.stream()            .map(Student::getName)            .collect(Collectors.toList());        // toSet으로 수집        Set&lt;String&gt; departments = students.stream()            .map(Student::getDepartment)            .collect(Collectors.toSet());        // toMap으로 수집        Map&lt;String, Integer&gt; nameToScore = students.stream()            .collect(Collectors.toMap(                Student::getName,                Student::getScore            ));        // joining으로 문자열 결합        String allNames = students.stream()            .map(Student::getName)            .collect(Collectors.joining(\", \"));        System.out.println(\"모든 학생: \" + allNames);        // 모든 학생: Alice, Bob, Charlie, David, Eve    }    static class Student {        private String name;        private int score;        private String department;        public Student(String name, int score, String department) {            this.name = name;            this.score = score;            this.department = department;        }        // getter 메서드들        public String getName() { return name; }        public int getScore() { return score; }        public String getDepartment() { return department; }    }}최종 연산allMatch, anyMatch, noneMatchboolean allMatch(Predicate&lt;? super T&gt; predicate)boolean anyMatch(Predicate&lt;? super T&gt; predicate)boolean noneMatch(Predicate&lt;? super T&gt; predicate)Predicate 를 넣어 true/false 를 반환하도록 하며, all 은 모든, any 는 어떤, none 은 모든의 부정으로서 작용한다. stream 을 반환하지 않기 때문에 최종연산이다.import java.util.*;import java.util.stream.*;public class MatchExample {    public static void main(String[] args) {        List&lt;Integer&gt; numbers = Arrays.asList(2, 4, 6, 8, 10);        boolean allEven = numbers.stream()                                 .allMatch(n -&gt; n % 2 == 0);  // 모든 수가 짝수인가?        System.out.println(\"allEven: \" + allEven);  // true        boolean anyGreaterThan5 = numbers.stream()                                        .anyMatch(n -&gt; n &gt; 5);  // 5보다 큰 수가 있는가?        System.out.println(\"anyGreaterThan5: \" + anyGreaterThan5); // true        boolean noneNegative = numbers.stream()                                     .noneMatch(n -&gt; n &lt; 0); // 음수가 없는가?        System.out.println(\"noneNegative: \" + noneNegative); // true    }}findFirst, findAny최종 연산자이며, 메서드 명대로 첫번째를 찾거나  findFirst(): 스트림에 데이터가 없으면 Optional.&lt;T&gt;empty() 가 반환된다  findAny(): 어떤 요소든 하나를 반환한다(병렬 스트림에서 주로 사용하며, 성능 최적화가 가능하다)  즉, 순차 스트림에서는 findFirst = findAny 이고, 병렬 스트림에서는 findAny 가 순서를 보장하지 않고 그냥 빠르게 온 요소를 바로 반환하기 때문에 findFirst 보다 더 성능이 좋다.집계 연산집계 연산도 최종 연산에 포함된다. 하지만 집계를 한 후에도 다른 처리가 필요할 수도 있는데 그때는 stream 으로 다시 생성시켜줘야 한다.countimport java.util.*;import java.util.stream.*;public class CountExample {    public static void main(String[] args) {        List&lt;Integer&gt; numbers = Arrays.asList(2, 4, 6, 8, 10);        long count = numbers.stream()                            .filter(n -&gt; n &gt; 5)  // 5보다 큰 수만                            .count();        System.out.println(\"5보다 큰 수 개수: \" + count); // 3    }}maxOptional&lt;Integer&gt; maxValue = numbers.stream()                                    .max(Integer::compareTo);maxValue.ifPresent(v -&gt; System.out.println(\"최댓값: \" + v)); // 10minclass Person {    String name;    int age;    Person(String name, int age) { this.name = name; this.age = age; }}List&lt;Person&gt; people = Arrays.asList(    new Person(\"Alice\", 25),    new Person(\"Bob\", 20),    new Person(\"Charlie\", 30));Optional&lt;Person&gt; youngest = people.stream()                                  .min(Comparator.comparingInt(p -&gt; p.age));youngest.ifPresent(p -&gt; System.out.println(\"가장 어린 사람: \" + p.name)); // BobgroupingBycollect 와 함께 사용되는 최종 연산용 Collector 의 기능이다.Map&lt;K, List&lt;T&gt;&gt; grouped = stream.collect(    Collectors.groupingBy(classifier));기본적으로 Collectors.groupingBy 를 사용하여 K 에 대한 기준점을 classfier 로 잡고 묶고, K 에 해당하는 요소들을 List&lt;T&gt; 로 묶어 Map 을 반환하게 된다.import java.util.*;import java.util.stream.*;public class GroupingByExample {    static class Student {        String name;        int score;        String department;        Student(String name, int score, String department) {            this.name = name;            this.score = score;            this.department = department;        }        @Override        public String toString() {            return name + \"-\" + score;        }    }    public static void main(String[] args) {        List&lt;Student&gt; students = Arrays.asList(            new Student(\"Alice\", 85, \"CS\"),            new Student(\"Bob\", 92, \"Math\"),            new Student(\"Charlie\", 78, \"CS\"),            new Student(\"David\", 88, \"Physics\"),            new Student(\"Eve\", 95, \"Math\")        );        // 학과별로 그룹화        Map&lt;String, List&lt;Student&gt;&gt; grouped = students.stream()            .collect(Collectors.groupingBy(s -&gt; s.department));        System.out.println(grouped);    }}또한 단순히 Map 으로 grouping 을 하는 것 외에 두 번째 인자 downstream 으로 Collector 를 또 넣어서 집계 함수처럼 사용이 가능하다.  n 그룹으로 나뉨// 학과별 평균 점수 계산Map&lt;String, Double&gt; avgScore = students.stream()    .collect(Collectors.groupingBy(        s -&gt; s.department,        Collectors.averagingInt(s -&gt; s.score)    ));System.out.println(avgScore);partitioningBy특정 parameter 를 기준으로 분할 할 수 있는 기능 또한 있다.import java.util.*;import java.util.stream.*;public class PartitioningExample1 {    public static void main(String[] args) {        List&lt;Integer&gt; numbers = Arrays.asList(1,2,3,4,5,6,7,8,9,10);        Map&lt;Boolean, List&lt;Integer&gt;&gt; evenOdd = numbers.stream()            .collect(Collectors.partitioningBy(n -&gt; n % 2 == 0));        System.out.println(\"짝수: \" + evenOdd.get(true));  // [2, 4, 6, 8, 10]        System.out.println(\"홀수: \" + evenOdd.get(false)); // [1, 3, 5, 7, 9]    }}여기서 partitioningBy 는 무조건 Key 가 Boolean 형태로 나오게 되고, 이는 2개의 그룹으로만 나뉘는 것을 알 수 있다.  2개 그룹으로 나뉨Parallel Stream이런 stream 은 병렬 처리가 가능한데, 컬렉션 인터페이스에서는 디폴트 메서드로 parallelStream() 이라는 메서드를 지원한다. 또한 stream() 후에 parallel() 을 호출하여도 된다.생성 방법  parallelStream()  stream().parallel()이렇게 생성된 스트림들은 연산들이 병렬적으로 실행되게 되며 다음 주의사항을 포함한다:  작업 단위가 충분히 크지 않으면 성능 저하가 됨          내부적으로 ForkJoinPool 이라는 스레드 풀을 사용하는데, 스레드를 쪼개고 합치는 오버헤드가 있기에, 요소 수가 적어 연산이 가벼울 시 직렬 스트림보다 더 느리다.        공유 상태(Shared State) 접근 시 주의          병렬 스트림은 여러 스레드가 동시에 작업하기 때문에, 외부에서 공유되는 가변 상태(mutable state)(자바는 PF 가 아니기 때문)를 건드리면 동기화 문제가 발생한다.      Race Condition 을 막기 위해 동기화 메커니즘이 반드시 필요하다.        순서가 중요한 연산에서 주의          병렬 처리는 순서를 보장하지 않기에 결과 처리를 주의하자.        스레드 풀 제약          parallelStream 은 기본적으로 ForkJoinPool 을 사용한다      다른 병렬 작업과 공유될 수 있기 때문에, 예기치 않게 성능이 저하될 수 있으며, 직접 커스텀 ForkJoinPool 을 쓰고 싶다면 stream().parallel().collect(...) 대신 poolsubmit(() -&gt; stream.parallel()...) 과 같은 패턴을 사용해야 한다.        Boxing / Unboxing 비용          내부적으로 Stream 이라면 **Auto Boxing** 에서 (**-128 ~ 127** 는 객체 생성이 일어나지 않음, 이미 생성되어 있기 때문) 괜찮지만 큰 값은 매번 객체를 생성하여 Heap 을 사용하게 된다.      이 말은 기본형은 스택/레지스터 수준에서 처리되지만, 래퍼 타입은 힙 객체로 참조된다는 의미인데, int 의 primitive 는 기본적으로 4 byte 인데 반해 Integer 는 8 byte 의 레퍼런스형 이므로 힙에 생성되는게 당연하다. 하지만 Integer 에서도 작은 값(-128 ~ 127) 에 대해서는 캐싱이 되어서 힙을 사용하지 않아 비용이 그렇게 크지 않다라는 의미이다.      위와 같은 상황이 되면 GC 부하가 증가가되며, 불필요한 Boxing 으로 객체가 남발되어서 GC 부담이 커지게 된다.      기본형은 CPU 명령어 하나로 계산이 가능하고, 래퍼 타입은 Unboxing 후 계산을 하기 때문에 다시 Boxing 을 또 해야하므로 추가 오버헤드가 발생한다.        사실 Integer 에 헤더 자체가 보통 12 ~ 16 byte 가 될 수도 있고, 최소 16 byte 이상 차지할 수도 있다(JVM 구현에 따라 다르다).언제 사용하면 좋을까?⭕️ 기본적으로 다음을 전부 만족할 때 사용하면 좋다.  CPU Bound 연산          map()      filter()      reduce(): 순서 의존이 없는 경우만      collect(): 순서 없는 자료형의 collecting      distinct()        데이터 크기가 매우 클 때  순서가 중요하지 않은 연산  불변 데이터 사용 시❌ 다음에는 사용하지 말자  findFirst()  forEachOrdered()  groupingBy()  작은 데이터에 대한 모든 처리Boxing / Unboxing 을 피하는 방법을 보자.      Stream&lt;Integer&gt; 보다는 IntStream, LongStream, DoubleStream 으로 primitive stream 사용        Stream&lt;Integer&gt; 로 되었을 때는 .mapToInt 와 같은 Unboxing 기능으로 primitive 변환 후에 병렬 처리 사용 이후에는 .boxed() 로 다시 Boxing 처리        자바 표준에는 없지만, fastutil, Trove, HPPC 같은 외부 라이브러리는 IntList, IntSet, Int2IntMap 같은 primitive 컬렉션을 제공 → List보다 메모리 / 성능 효율        Integer.valueOf() 가 ~128 ~ 127 범위는 캐싱하는 것처럼 직접 캐시 테이블 구현 가능        Optional 도 primitive 버전을 활용          OptionalInt, OptionalLong, OptionalDouble      "
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 30일차 멀티스레딩 응용 클래스",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/29/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-30%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-29",
      "content": "📂 목차  쓰레드 심화          쓰레드와 자원      wait(), notify(), notifyAll()      Producer-Consumer Problems                  구현                    ExecutorService                  shutdown()          Callable &amp; Future                    ReentrantLock                  Condition                    CountDownLatch      BlockingQueue      CyclicBarrier        람다          First-Class Citizen      Functional Programming Language      익명 구현 객체      FunctionalInterfaces      📚 본문쓰레드 심화실무에 근거하여 더 잘 활용할 수 있게 다양한 메서드들을 본다.쓰레드와 자원쓰레드는 처리 흐름, 자원은 데이터로 확실히 구분시켜야 한다. 그런 관점에서 볼때, repository, service 등등은 전부 흐름이고(Inmemory 는 예외), db, 임시 저장 공간(세션, 구성 정보) 등등은 전부 자원이 될 것이다.synchronized 를 걸때는 트래픽이 많을 때 서버 성능이 느려지지 않을지를 고민해야 한다.public Book addBook(String title,                    String author) {    var builder = new Book.Builder().setTitle(title)                                    .setAuthor(author);    Book book;    // 동시성 이슈가 있는 부분의 코드만 lock 걸기    synchronized (bookRepository) {        book = builder.build(bookRepository.count() + 1);        if (bookRepository.add(book) == null)            throw new SystemException(\"책 저장 실패\");    }    return book;}wait(), notify(), notifyAll()wait, notify, notifyAll 은 모니터 락을 보유한 상태에서 호출 가능하며, critical region 에 들어가는 thread 만이 이 메서드들을 쓸 수 있다(Object 라고 다 쓸 수 있지만 코드 블럭 수준에 제약이 있음).  sleep(ms) 과의 차이는 lock 을 쥔 채로 대기하기에 얘는 critical region 에 없더라도 호출 가능하다.Producer-Consumer ProblemsObject 에는 wait, notify 가 있어서 모든 클래스들에 대해 해당 메서드를 수행함을 볼 수 있다.여기서는 Producer-Consumer 문제로 이를 다뤄보자. 생산자는 데이터를 생성하여 버퍼에 공급을 한다. 소비자는 Buffer 에서 데이터를 꺼내어 사용을 한다. 버퍼는 생산자와 소비자가 데이터를 주고받는 공유 공간이며, 진열대라고 생각하면 된다.다음과 같은 문제가 발생한다:  버퍼가 가득 찼을 때: 생산자가 데이터를 넣으려면 대기해야 한다  버퍼가 부족 할 때: 소비자가 데이터가 들어올 때까지 대기해야 한다  동시 접근 문제: 여러 소비자가 동시에 데이터를 소비하려고 할 때 데이터가 깨지거나 누락될 수도 있다구현우선 상황 세팅을 해주자. 기본적으로 진열대가 필요할 수 있다.static final Object lock = new Object();static final int MAX_SIZE = 10;static boolean[] buffer = new boolean[MAX_SIZE];static int consumeIdx;그 다음 생산자는 이 buffer 에 채우는 ‘행위’ 를 해야 한다.// 생산public static void produce() throws InterruptedException {    synchronized (lock) {        while(buffer[MAX_SIZE - 1])            lock.wait();        Arrays.fill(buffer, true);        lock.notifyAll();    }    System.out.println(\"생산 완료 !!!, 대기 모드 on\");}buffer 를 true 로 채운다.// 소비public static void consume() throws InterruptedException {    synchronized (lock) {        while (!buffer[MAX_SIZE - 1]) {            System.out.println(\"소비 대기중\");            lock.wait();        }        buffer[consumeIdx] = false;        consumeIdx = (consumeIdx + 1) % MAX_SIZE;        lock.notify();        System.out.println(\"소비함 현재 재고: \" + Arrays.toString(buffer) + \", consumeIdx: \" + consumeIdx);    }}소비자는 위와 같이 소비하게 된다. 메인에서는 재고를 채우고 소비하면서 값이 바뀐다Thread produce = new Thread(() -&gt; {    while(true) {        produce();        try {            Thread.sleep(1000);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }});Thread consume = new Thread(() -&gt; {    while(true) {        consume();        try {            Thread.sleep(100);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }});produce.start();consume.start();위와 같은 상황은 비정상적인 상황이 잘 만들어지지 않지만, 여러 소비자가 들어가게 되면 말이 다르다.Thread produce = new Thread(() -&gt; {    while(true) {        try {            produce();        } catch (InterruptedException e) {            throw new RuntimeException(e);        }        try {            Thread.currentThread().sleep(1000);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }});Thread consume1 = new Thread(() -&gt; {    while(true) {        try {            consume();        } catch (InterruptedException e) {            throw new RuntimeException(e);        }        try {            Thread.currentThread().sleep(1000);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }});Thread consume2 = new Thread(() -&gt; {    while(true) {        try {            consume();        } catch (InterruptedException e) {            throw new RuntimeException(e);        }        try {            Thread.currentThread().sleep(1000);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }});Thread consume3 = new Thread(() -&gt; {    while(true) {        try {            consume();        } catch (InterruptedException e) {            throw new RuntimeException(e);        }        try {            Thread.currentThread().sleep(1000);        } catch (InterruptedException e) {            throw new RuntimeException(e);        }    }});produce.start();consume1.start();consume2.start();consume3.start();consumer idx 가 적절하게 증가하지 않는 상황  소비함 현재 재고: [true, true, false, false, false, false, false, false, false, false], consumeIdx: 0소비함 현재 재고: [false, false, false, false, false, false, false, false, false, false], consumeIdx: 2소비함 현재 재고: [false, false, false, false, false, false, false, false, false, false], consumeIdx: 2생산되기도 전에 소비  소비함 현재 재고: [false, false, true, true, true, true, false, false, false, false], consumeIdx: 2소비함 현재 재고: [false, true, true, true, true, true, false, false, false, false], consumeIdx: 1소비함 현재 재고: [false, false, false, true, true, true, false, false, false, false], consumeIdx: 36 만큼 채움 현재 재고: [false, true, true, true, true, true, false, false, false, false], prodIdx: 6이를 정상적으로 만들기 위해 consumer 는 버퍼에 재고가 있을 때, 다시 말하면 없을 때는 대기 상태에 들어갔다가, producer 가 생산했을 때 일어나서 소비를 해야한다.producer 는 consumer 가 더 이상 소비할 수 있는 재고가 없을 때 일어나야 한다. 그렇다면 쓰레드 간에 서로 깨운다, 대기해라 라는 소통을 해야하는 창구가 필요하다. 그 창구가 바로 자원 lock 이다.static final Object lock = new Object();...public static void produce() throws InterruptedException {    synchronized (lock) {        while(buffer[MAX_SIZE - 1])            lock.wait();        Arrays.fill(buffer, true);        lock.notifyAll();    }    System.out.println(\"생산 완료 !!!, 대기 모드 on\");}public static void consume() throws InterruptedException {    synchronized (lock) {        while (!buffer[MAX_SIZE - 1]) {            System.out.println(\"소비 대기중\");            lock.wait();        }        buffer[consumeIdx] = false;        consumeIdx = (consumeIdx + 1) % MAX_SIZE;        lock.notify();        System.out.println(\"소비함 현재 재고: \" + Arrays.toString(buffer) + \", consumeIdx: \" + consumeIdx);    }}이제 계속적으로 생산 소비가 반복될 것이다.ExecutorService스레드 풀을 생성하여 놀고 있는 스레드에 명령을 간편하게 내릴 수 있다. 스레드 풀의 사이즈는 스레드 개수와 똑같고, 생성은 Executors 의 정적 메서드로 한다.// 고정 스레드 풀ExecutorService executor = Executors.newFixedThreadPool(4);// 단일 스레드 풀ExecutorService executor = Executors.newSingleThreadExecutor();// 캐시형 스레드 풀: 필요할 때 스레드 만들고 놀고 있는 스레드가 있으면 재사용ExecutorService executor = Executors.newCachedThreadPool();// 스케줄링 가능한 풀ScheduledExecutorService executor = Executors.newScheduledThreadPool(2);// 5초 뒤에 실행executor.schedule(() -&gt; System.out.println(\"5초 뒤 실행\"), 5, TimeUnit.SECONDS);// 1초 뒤 시작, 이후 2초 간격으로 반복 실행executor.scheduleAtFixedRate(() -&gt; System.out.println(\"주기 실행\"), 1, 2, TimeUnit.SECONDS);// 병렬 처리 특화 풀ExecutorService executor = ForkJoinPool.commonPool();위처럼 안하고 밑처럼 세밀한 조정으로 풀을 생성할 수 있다.Custom Thread Pool 생성ExecutorService executor = new ThreadPoolExecutor(        2,                // core pool size        4,                // maximum pool size        60L,              // idle thread keep-alive time        TimeUnit.SECONDS, // 시간 단위        new LinkedBlockingQueue&lt;&gt;(100) // 작업 큐);shutdown()스레드 풀을 종료하는 메서드이다.executor.shutdown();  이미 제출된 작업은 모두 끝까지 실행됨  새로운 작업 제출은 거부됨  shutdownNow() 는 강제로 모든 작업을 종료하며, 실행 중인 스레드는 인터럽트를 발생시켜 즉시 종료해버린다. 반환하는 건 List 인데 실행중인 스레드의 작업에 대한 것은 반환하지 않기 때문에 작업이 날라갈 수도 있다.Callable &amp; Future함수형 인터페이스 Callable&lt;V&gt; 은 V call() 을 구현해야 하며, 반환값이 있는 작업을 정의할 수 있다. 이를 통해 ExecutorService 에게 submit(Callable callable) 에 넣어 제출할 수 있다.import java.util.concurrent.*;public class SumExample {    public static void main(String[] args) throws Exception {        ExecutorService executor = Executors.newFixedThreadPool(3);        int[] numbers = new int[10];        for (int i = 0; i &lt; numbers.length; i++) numbers[i] = i + 1; // 1~10        // 배열을 3부분으로 나눠서 합 계산        Callable&lt;Integer&gt; sumPart1 = () -&gt; {            int sum = 0;            for (int i = 0; i &lt; 3; i++) sum += numbers[i];            return sum;        };        Callable&lt;Integer&gt; sumPart2 = () -&gt; {            int sum = 0;            for (int i = 3; i &lt; 7; i++) sum += numbers[i];            return sum;        };        Callable&lt;Integer&gt; sumPart3 = () -&gt; {            int sum = 0;            for (int i = 7; i &lt; 10; i++) sum += numbers[i];            return sum;        };        Future&lt;Integer&gt; f1 = executor.submit(sumPart1);        Future&lt;Integer&gt; f2 = executor.submit(sumPart2);        Future&lt;Integer&gt; f3 = executor.submit(sumPart3);        int totalSum = f1.get() + f2.get() + f3.get();        System.out.println(\"총 합계: \" + totalSum);        executor.shutdown();    }}제출 후에 얻으려면 Future&lt;V&gt; 이 필요한데, 비동기 작업에 대한 결과를 나타내는 객체이다. V get(), V get(long timeout, TimeUnit unit) 으로 값을 얻어올 수 있다.여러 개 값 가져오기ExecutorService executor = Executors.newFixedThreadPool(3);List&lt;Callable&lt;String&gt;&gt; tasks = List.of(    () -&gt; { Thread.sleep(1000); return \"A 완료\"; },    () -&gt; { Thread.sleep(2000); return \"B 완료\"; },    () -&gt; { Thread.sleep(1500); return \"C 완료\"; });List&lt;Future&lt;String&gt;&gt; futures = executor.invokeAll(tasks);for (Future&lt;String&gt; f : futures) {    System.out.println(f.get());}executor.shutdown();ReentrantLock자원에 대한 동시성 제어 메커니즘이다. 이전에는 흐름이 주된 제어 메커니즘이었다. ReentrantLock 은 이름 그대로 같은 스레드가 같은 락을 여러 번 획득 한다.java.util.concurrent.locks.ReentrantLock기본 사용import java.util.concurrent.locks.ReentrantLock;class SharedResource {    private final ReentrantLock lock = new ReentrantLock();    private int count = 0;    public void increment() {        lock.lock();        try {            count++;            System.out.println(Thread.currentThread().getName() + \" : \" + count);        } finally {            lock.unlock();        }    }}시간 제한if (lock.tryLock()) {    try {        // 락 얻었을 때만 실행    } finally {        lock.unlock();    }} else {    System.out.println(\"락을 얻지 못해 다른 작업 수행\");}// 일정 시간만 시도if (lock.tryLock(2, TimeUnit.SECONDS)) {    try {        // 2초 안에 락 얻으면 실행    } finally {        lock.unlock();    }}Conditionimport java.util.concurrent.locks.*;class BoundedBuffer {    private final ReentrantLock lock = new ReentrantLock();    private final Condition notFull  = lock.newCondition();    private final Condition notEmpty = lock.newCondition();    private final int[] buffer = new int[10];    private int count, putPtr, takePtr;    public void put(int x) throws InterruptedException {        lock.lock();        try {            while (count == buffer.length) {                notFull.await();  // 버퍼 꽉 차면 대기            }            buffer[putPtr] = x;            putPtr = (putPtr + 1) % buffer.length;            count++;            notEmpty.signal();   // 소비자 깨우기        } finally {            lock.unlock();        }    }    public int take() throws InterruptedException {        lock.lock();        try {            while (count == 0) {                notEmpty.await(); // 버퍼 비었으면 대기            }            int x = buffer[takePtr];            takePtr = (takePtr + 1) % buffer.length;            count--;            notFull.signal();    // 생산자 깨우기            return x;        } finally {            lock.unlock();        }    }}wait/notify/notifyAll 을 await/signal/signalAll 로 대체하고 여러 개의 Condition 을 나누어 관리하고 싶을 때 사용할 수 있다.CountDownLatchlock 을 여러개 놓을 수 있다고 보면 된다. 0이 될때까지 대기할 수 있는 메커니즘이 있으며, 초기화된 값을 다 count 했을 때는 사용이 더 이상 불가하다.import java.util.concurrent.CountDownLatch;public class CountDownLatchExample {    public static void main(String[] args) throws InterruptedException {        int nThreads = 3;        CountDownLatch latch = new CountDownLatch(nThreads);        for (int i = 0; i &lt; nThreads; i++) {            final int id = i;            new Thread(() -&gt; {                System.out.println(\"스레드 \" + id + \" 준비 완료\");                latch.countDown(); // 준비 완료            }).start();        }        System.out.println(\"모든 스레드 준비될 때까지 대기...\");        latch.await(); // 카운트가 0이 될 때까지 대기        System.out.println(\"모든 스레드 준비 완료! 작업 시작!\");    }}BlockingQueuepublic class BlockingQueueExample {    public static void main(String[] args) {        BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(5);        // 생산자        Thread producer = new Thread(() -&gt; {            try {                for (int i = 1; i &lt;= 10; i++) {                    String item = \"Item-\" + i;                    queue.put(item); // 큐가 가득 차면 대기                    System.out.println(\"생산: \" + item);                    Thread.sleep(500);                }            } catch (InterruptedException e) {                e.printStackTrace();            }        });        // 소비자        Thread consumer = new Thread(() -&gt; {            try {                for (int i = 0; i &lt; 10; i++) {                    String item = queue.take(); // 큐가 비면 대기                    System.out.println(\"소비: \" + item);                    Thread.sleep(1000);                }            } catch (InterruptedException e) {                e.printStackTrace();            }        });        producer.start();        consumer.start();    }}CyclicBarrierimport java.util.concurrent.*;public class CyclicBarrierExample {    public static void main(String[] args) {        int nThreads = 3;        CyclicBarrier barrier = new CyclicBarrier(nThreads, () -&gt; {            System.out.println(\"모든 스레드가 도착했습니다. 다음 단계로 진행!\");        });        for (int i = 0; i &lt; nThreads; i++) {            int id = i;            new Thread(() -&gt; {                try {                    System.out.println(\"스레드 \" + id + \" 작업 중...\");                    Thread.sleep((id + 1) * 1000);                    System.out.println(\"스레드 \" + id + \" barrier 도착\");                    barrier.await(); // 모든 스레드가 여기서 대기                    System.out.println(\"스레드 \" + id + \" 다음 단계 실행\");                } catch (Exception e) {                    e.printStackTrace();                }            }).start();        }    }}람다저번에 다뤘기에 이번에는 이론적으로 조금 빠삭하게 살펴보고 가자.First-Class Citizen조건  변수에 담을 수 있어야 함  함수의 인자로 전달할 수 있어야 함  함수의 반환값으로 전달할 수 있어야 함자바는 함수를 First-Class Citizen 으로써 사용 가능하지만, FP 언어는 아니다.Functional Programming Language자바는 함수형 프로그래밍이 아니다. 함수형 프로그래밍이 되려면 다음을 만족시켜야 한다.  순수 함수(Pure Function)          동일 입력 -&gt; 동일 출력      함수 내부에서 외부 상태를 변경할 수 없음(즉, side effect 없음)        불변성(Immutability)          데이터는 한 번 생성하면 변경하지 않음      상태 변경 대신 새로운 데이터 생성        고차 함수(Higher-order Function)          함수를 인자로 받거나 함수를 반환 가능        함수 조합(Function Composition)          작은 함수를 조합해 더 큰 함수를 만듦        선언형 프로그래밍(Declarative)          무엇을 할 지 중심, 어떻게 할 지는 최소화      자바에서는 순수 함수는 아니며, 객체 상태를 변경할 수 있기에 함수형 프로그래밍은 아니다. 다만 FP 를 흉내내고 있는 것이다.익명 구현 객체자바는 함수만 순수하게 존재할 수 없었기에 FP 흉내를 내려고 익명 구현 객체를 생성한다.// Runnable을 구현하는 이름 없는 객체Runnable r = new Runnable() {    public void run() {        System.out.println(\"익명 구현 객체가 출력합니다.\");    }};r.run();@FunctionalInterface 가 무엇인지, Runnable 이 무엇인지는 이미 전에 다뤘으므로 넘어간다. 또한 수많은 미리 정의된 FunctionalInterface 들은 다음과 같다.FunctionalInterfaces  Runnable: 입력 X, 반환 X      Callable: 입력 X, 반환 O, 비동기    Supplier: 입력 X, 반환 O          IntSupplier      LongSupplier      DoubleSupplier        Consumer: 입력 X, 반환 X          IntConsumer      LongConsumer      DoubleConsumer      ObjIntConsumer: 제너릭 객체 + int 값을 입력      ObjLongConsumer      ObjDoubleConsumer        Predicate          IntPredicate      LongPredicate      DoublePredicate        Function&lt;T, R&gt;          IntFunction      LongFunction      DoubleFunction      ToIntFunction      ToLongFunction      ToDoubleFunction        UnaryOperator          IntUnaryOperator      LongUnaryOperator      DoubleUnaryOperator        BiConsumer  BiPredicate  BiFunction  BinaryOperator          IntBinaryOperator      LongBinaryOperator      DoubleBinaryOperator      굳이 설명은 따로 하지 않으며, 그때그때 찾아서 쓰는 것으로 한다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 29일차 Java 멀티 스레드 활용 및 동시성 제어",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/25/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-29%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-25",
      "content": "📂 목차  Process  Thread          프로세스의 메모리 구조      IPC      Java Thread      Concurrency                  Deadlock          Starvation                    Concurrency 얻기                  ReentrantLock          Semaphore                    Java Thread 활용                  Thread run() vs start()          synchronized 예시          Block Synchronization                    📚 본문자바의 멀티스레딩을 보자. 보기 전에 우선 프로세스를 보자.Process프로세스는 운영체제에서 실행 중인 프로그램의 인스턴스를 의미한다. 프로그램이 단순히 파일이라면, 프로세스는 그것이 메모리에 적재되고 실행되고 있는 상태이다.정리  독립성: 각 프로세스는 자신만의 고유한 메모리 공간을 가진다  자원 단위: 운영체제가 CPU, 메모리, 파일 핸들 같은 할당을 하는 기본 단위이다  하나 이상의 스레드 포함: 프로세스 안에는 최소 1개의 스레드가 존재하여 멀티스레딩을 통해 여러 스레드가 동시에 실행될 수 있다프로세스의 메모리 구조일반적으로 운영체제에서 공부하는 하나의 프로세스는 다음과 같은 메모리 영역을 가진다.  Code: 실행할 프로그램 코드  Data: 전역 변수, static 변수  Heap: 동적으로 생성된 객체  Stack: 함수 호출 스택, 지역 변수, 매개변수하지만 운영체제가 아닌 자바에서는 예전에 JVM 의 메모리 구조를 살펴보았었다. 다시 정리하자.  Method Area: 클래스 메타데이터, static 변수, 상수 풀  Heap: new 로 생성된 객체  JVM Stack: 각 스레드별 호출 스택(지역 변수, 매개변수, return 값)          PC Register: 현재 실행 중인 명령어 주소      Native Method Stack: JNI 같은 네이티브 코드 실행 시 사용      운영체제의 입장에서는 자바 프로그램도 하나의 프로세스이고, Code/Data/Heap/Stack 구조를 가지며, 자바 프로그램 안에 JVM 이 관리하는 영역을 따로 구분을 또 하게 된다.즉 자바 내부에서는 보통 프로세스라는 단어 보다는 스레드 단위로 설명하는게 대부분이며, java.lang.Process 클래스 같은 경우는 운영체제 프로세스를 다루는 래퍼이다.자바에서는 운영체제에서 다루는 프로세스를 실행하고 다루기 위해서 java.lang.Process 를 정의하고, 만들어진 운영체제 프로세스를 자바 코드에서 제어할 수 있도록 감싼 클래스인 것이다. 실제로 자바 프로그램을 동작할 때 Runtime.getRuntime().exec() 또는 ProcessBuilder 를 사용하여서 JVM 이 운영체제보고 새로운 프로세스를 만들어 달라고 요청을 보내는 것이고, 만들어진걸 받아와 사용하는 것이다.  자바 프로그램이 올라가 프로세스로 되며 프로세스 내부적으로 다수의 스레드 활용 가능IPCInter Process Communication 이라고도 하며 프로세스 간의 상호작용을 하고 싶을때 쓰는 기술이다.  PIPE: 한쪽 프로세스의 출력 -&gt; 다른 프로세스로의 입력(부모-자식 프로세스 간에 사용할 수 있는 예시이다)  Socket: 네트워크를 이용한 통신 방식(TCP/UDP 기반)이며, 같은 컴퓨터 안 혹은 다른 컴퓨터와도 통신이 가능하다.  Message Queue: 운영체제가 제공하는 큐에 메시지를 넣고 빼면서 통신을 한다. 비동기 처리에 유용하다.  Shared Memory: 두 프로세스가 물리적으로 같은 메모리 영역을 공유하도록 설정하면 빠르게 통신할 수 있다. 하지만 동기화 문제를 잘 다스려야 한다.  Signal: 간단한 알림을 보내는 방식 (kill -9 PID)Thread스레드는 프로세스 내부의 메모리 공간 내에서 서로 다른 흐름을 처리하고 싶을 때 사용되는 처리 흐름의 추상화된 클래스다. 따라서 여러 자바 프로그램을 굳이 돌리지 않고 자바 프로그램 하나를 돌려 프로세스를 만든 뒤 프로세스 내의 다수의 스레드를 두어서 다수의 처리를 하도록 하는게 더 가볍다는 것이다.특징  경량 프로세스: 프로세스와 달리 Heap 과 같은 메모리 공간이나 Method Area 등을 가지지 않는다.  독립된 실행 흐름: 자신만의 Call Stack 이 있음  자원 공유 용이: 같은 프로세스의 여러 스레드는 같은 힙(Heap) 과 메서드(Method Area) 를 공유하기 때문에 서로 간의 데이터 교환이 빠르다.Java Thread자바는 Thread 라는 클래스를 기본적으로 내장시켜놨다. JVM 내부의 물리적인 thread 를 추상화 해놓은 클래스라고 보면 되고, 우리는 이를 사용하여 자바 프로그램을 실행할 때 기본적으로 메인 스레드 하나 뿐이 아니라 메인 스레드에서 가지치기 하듯이 여러 스레드를 생성시켜 동작하도록 할 수 있다.스레드의 물리적 메모리 영역  공유 영역: Heap, Method Area  개별 영역: Stack(메서드 호출, 지역 변수, 매개변수, return 값), PC Register그러면 우리가 만드는 자바 프로그램에 스레드를 여러개 만들어 놓고 많은 작업들을 많은 스레드들한테 처리하라고 시키면 굉장히 빠를거 같지만, 멀티 스레드에는 다음과 같은 장단점이 있다.장점  성능 향상: 여러 작업을 동시에 처리  자원 효율성: 프로세스보다 적은 리소스 사용  응답성 향상: UI 애플리케이션에서 빠른 응답단점  Concurrency 문제: 특정 자원에 대한 Race Condition 발생 가능  복잡성 증가: 디버깅이 어려움  Deadlock 위험: Circular Wait단점을 파훼해야 장점들을 유용하게 쓸 수 있다.Concurrency스레드를 여러개 가져가서 동시에 실행한다면 생길 수 있는 여러 문제점이 있다. Concurrency 는 동시성이고 여러 실행 흐름(스레드나 프로세스)이 동시에 자원에 접근하거나 작업을 수행하는 능력을 의미한다. 동시적으로 특정 자원에 대해 접근하고자 할 때 직관적으로 그 데이터가 자각하고 있는 데이터 값이어야 하고, 그 값에 대한 연산을 하고 올바른 결과가 도출되어야 할 것이다.반면 원자성이 부족한 int count 와 같은 것은 count++ 라는 연산을 할 때  count 읽기  count +1  count 쓰기세 단계로 이루어지므로 할 때 다른 스레드가 끼어들면 값이 꼬이게 된다. 이를 Race Condition 이라고 한다.  Race Condition: 공유 자원에 대해 접근 및 행위가 어떤 순서에 따라 이루어졌는지에 따라 실행 결과가 같지 않고 달라지는 현상. 실행 결과가 실행 순서에 의존하는 현상.즉, Race Condition 현상이 일어나지 않도록 보장하기 위해 Concurrency 라는 속성을 가져야 할 것이다. 하지만 이 Concurrency 를 얻기 위해서는 자원에 대한 접근 순서를 정렬할 필요가 있었고, 이를 바로잡기 위해 Lock 이라는 자료구조가 나오게 됐다.하지만 이 또한 문제가 있었다.Deadlock두 개 이상의 프로세스가 서로 가지고 있는 자원을 락을 걸었는데, 서로 두 자원을 요구한다면 이는 무한히 멈춰있는 상태가 된다. 두 프로세스는 서로 Deadlock 에 빠지게 된다. 이러한 문제를 다음과 같이 조건부로 정의하게 된다.Deadlock 발생 조건  Mutual Exclusion(상호 배제): 어떤 자원은 한 번에 한 프로세스만 사용 가능  Hold and Wait(점유 및 대기): 프로세스가 이미 점유한 자원을 놓지 않고 다른 자원을 기다림  No Preemption(비선점): 운영체제가 이미 점유한 자원을 강제로 빼앗을 수 없음  Circular Wait(상호 대기): 프로세스들이 원형으로 서로가 가진 자원을 기다리는 상태이 4가지 조건이 전부 충족될 때 Deadlock 이 발생할 수 있기 때문에 우리는 4개 중에 하나라도 파괴시켜야 Deadlock 을 막을 수 있다.보통은 Circular Wait 을 파괴하게 되는데, 나머지 3개는 자원의 본질적인 특성이거나 운영체제를 강제로 바꿔야 하는데 그러기 쉽지 않아서이다.그리고 멀티 스레딩을 사용할 때 데드락 이 외에도 다른 문제가 있을 수 있다.Starvation특정 스레드나 프로세스가 필요한 자원을 계속 얻지 못하여 실행되지 못하는 상태가 되어 무한정 대기하는 상태이다. 이는 스케줄링 우선순위나 자원 할당 정책 때문에 발생하게 되며, 실행 순서만 좀 바꿔주면 정상적으로 돌아온다.  이는 운영체제의 스케줄링 문제이기 때문에 그냥 가볍게 보고 넘어간다Concurrency 얻기자바에서는 다양한 해결 방법이 존재하는데  함수 및 변수 수준 락: synchronized  락 자료구조: ReentrantLock, Semaphore, Condition, Atomic 변수, Thread-safe 컬렉션  불변 객체(Immutable Object), record등으로 해결 가능하다.ReentrantLock자바에서 제공하는 락 클래스인데, 같은 슬데ㅡ가 이미 획득한 락을 다시 획득이 가능하다 해서 재진입 가능하기에 Reentrant 라는 수식어가 붙었고, Mutex 와 같은 역할을 한다.뮤텍스도 Critical Section 에 대해 하나의 스레드만이 허용 가능하도록 하기 때문에 ReentrantLock 또한 그 역할을 대신한다고 볼 수 있다.Semaphore공유된 자원의 데이터를 여러 스레드 혹은 프로세스가 접근하는 것을 막는 자료구조이다. 내부적으로는 리소스의 상태를 나타내는 간단한 카운터와 같고 카운터의 값에 따라, 하나의 공유 자원에 대해 여러 스레드가 들어갈 수도, 혹은 하나의 스레드만이 들어갈 수도 있다.Java Thread 활용우선 생성자를 보자.// ConstructorThread()Thread(Runnable runnable)Thread(Runnable runnable, String name)Java 에는 Runnable 인터페이스가 있고 클래스가 이를 구현하기만 한다면 Thread 의 생성자로 넣을 수 있다.Thread run() vs start()Runnable 한 것을 받았다면, 이를 실행할 수 있는데, run 과 start 로 실행할 수 있다. 다만 run 은 그냥 현재 스레드에서 실행하는 것이고, start 를 해야 또 다른 thread 를 생성시켜서 동시에 실행하게 된다.class MyThread extends Thread {    @Override    public void run() {        System.out.println(Thread.currentThread().getName() + \" is running\");    }}public class Main {    public static void main(String[] args) {        MyThread t1 = new MyThread();        System.out.println(\"Calling run():\");        t1.run(); // 그냥 메서드 호출 → main 스레드에서 실행됨        System.out.println(\"\\nCalling start():\");        MyThread t2 = new MyThread();        t2.start(); // 새로운 스레드 생성 → run() 메서드가 별도의 스레드에서 실행    }}synchronized 예시이는 이전에 다뤘기에 설명은 생략한다.class Counter {    private int count = 0;    // synchronized 메서드: 한 번에 한 스레드만 접근 가능    public synchronized void increment() {        count++;    }    public int getCount() {        return count;    }}public class Main {    public static void main(String[] args) throws InterruptedException {        Counter counter = new Counter();        Runnable task = () -&gt; {            for (int i = 0; i &lt; 1000; i++) {                counter.increment();            }        };        Thread t1 = new Thread(task);        Thread t2 = new Thread(task);        t1.start();        t2.start();        t1.join();        t2.join();        System.out.println(\"Final count: \" + counter.getCount());    }}Block Synchronization자바에는 synchronized 안에 모니터 락(Monitor Lock) 을 가질 수 있는 객체가 들어가야 한다. 여기서 Object 는 wait(), notify(), notifyAll() 을 가지고, 이는 모니터 락에 대한 API 이다.따라서 우리가 사용하는 모든 객체들에 대해 모니터락이 이미 참조되고 있는 것이고, synchronized 에 모든 객체를 넣을 수 있게 된다. 안되는 것들은 원시타입, null 등은 안될 것이다.public class BlockSynchronization {    private Object lock = new Object();    private int count = 0;    public void increment() {        // 필요한 부분만 동기화        synchronized(lock) {            count++;        }    }}"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 28일차 JavaScript 기초 문법",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/javascript/2025/09/24/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-28%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-24",
      "content": "📂 목차  스프레드 연산자  클래스          ES6 클래스 선언        프로토타입          프로토타입 체인      ES6 상속        에러 처리          ES2026 isError        동기 vs 비동기          setTimeout()                  Call Stack          Window Scheduler                    Promise                  Promise.all          Promise.race                    async/await      📚 본문스프레드 연산자자바스크립트에서 스프레드 연산자(…) 은 배열이나 객체 같은 이터러블 자료 구조를 펼쳐서 요소를 나열하거나, 얕은 복사 및 병합 등에 자주 쓰이게 된다.const arr = [1, 2, 3];console.log(...arr); // 1 2 3const arr = [1, 2, 3];const copy = [...arr];console.log(copy); // [1, 2, 3]const arr1 = [1, 2];const arr2 = [3, 4];const merged = [...arr1, ...arr2];console.log(merged); // [1, 2, 3, 4]const obj = { a: 1, b: 2 };const copy = { ...obj };console.log(copy); // { a: 1, b: 2 }const obj1 = { a: 1, b: 2 };const obj2 = { b: 3, c: 4 };const merged = { ...obj1, ...obj2 };console.log(merged); // { a: 1, b: 3, c: 4 } // 뒤에 오는 속성이 앞에 속성을 덮어씀function sum(x, y, z) {  return x + y + z;}const numbers = [1, 2, 3];console.log(sum(...numbers)); // 6클래스자바스크립트에서는 클래스보다는 객체를 만드는 함수를 정의하여 그 함수를 객체 생성자로 하여 사용한다.// 객체 생성자 함수function Animal(type, name, sound) {    this.type = type;    this.name = name;    this.sound = sound;    this.say = function() {        console.log(this.sound);    };}// 인스턴스 생성const dog = new Animal('개', '멍멍이', '멍멍');const cat = new Animal('고양이', '야옹이', '야옹');dog.say();  // 멍멍cat.say();  // 야옹위는 구버전에서의 클래스 선언이었다.ES6 클래스 선언class Animal {    constructor(type, name, sound) {        this.type = type;        this.name = name;        this.sound = sound;    }    say() {        console.log(this.sound);    }}// 인스턴스 생성const dog = new Animal('개', '멍멍이', '멍멍');const cat = new Animal('고양이', '야옹이', '야옹');dog.say();  // 멍멍cat.say();  // 야옹이제 overriding 기능을 수행 할 prototype 을 본다.프로토타입하지만 여기서 자바스크립트는 클래스 기반 언어와는 달리 프로토타입 기반 언어인데, 모든 객체는 자신을 생성한 함수의 prototype 객체를 참조하게 된다. 이 prototype 객체에 정의된 속성과 메서드는 해당 생성자로 만든 모든 인스턴스가 공유하게 된다.function Person(name) {  this.name = name;}// prototype에 메서드 정의Person.prototype.sayHello = function () {  console.log(`Hi, I'm ${this.name}`);};const p1 = new Person(\"Alice\");const p2 = new Person(\"Bob\");p1.sayHello(); // Hi, I'm Alicep2.sayHello(); // Hi, I'm Bob프로토타입 체인객체가 속성/메서드를 찾을 때, 다음과 같은 과정을 거친다.  자기 자신 속성 확인  없으면 _proto_(부모 프로토타입) 탐색  계속 올라가다가 최상위 Object.prototype 까지 감  그래도 없으면 undefinedES6 상속class Animal {    constructor(type, name, sound) {        this.type = type;        this.name = name;        this.sound = sound;    }    say() {        console.log(this.sound);    }}// extends로 상속class Dog extends Animal {    constructor(name, sound) {        super('개', name, sound);  // 부모 생성자 호출    }}class Cat extends Animal {    constructor(name, sound) {        super('고양이', name, sound);    }}const dog = new Dog('멍멍이', '멍멍');const cat = new Cat('야옹이', '야옹');const dog2 = new Dog('왈왈이', '왈왈');const cat2 = new Cat('냐옹이', '냐옹');dog.say();   // 멍멍cat.say();   // 야옹dog2.say();  // 왈왈cat2.say();  // 냐옹에러 처리java 와 유사하게 throw new Error() 라는 구문을 통해 에러를 던질 수 있다. 마찬가지로 상위 프로시저에서 try-catch 문을 사용해 에러를 잡을 수 있고, finally 도 똑같다. 던져지는 error 객체에는 message 가 있다.function divide(a, b) {  if (b === 0) {    throw new Error(\"0으로 나눌 수 없습니다.\");  }  return a / b;}try {  console.log(divide(10, 2)); // 5  console.log(divide(10, 0)); // 에러 발생} catch (err) {  console.error(\"에러 발생:\", err.message);} finally {  console.log(\"연산 완료\");}ES2026 isError어떤 객체가 에러 객체인지 판단할 수 있는 static 한 메서드가 있다. 거의 모든 브라우저에 지원하며, instanceof Error 보다 훨씬 낫다. 이 구문의 문제점은 다음과 같다:  프레임워크/환경 간 호환 문제: 브라우저, Node.js, iframe, Web Worker 등 서로 다른 실행 컨텍스트에 대해 Error 클래스가 달리 취급된다는 것  서브클래스 처리 문제: 커스텀 에러에 대한 처리가 제대로 동작하지 않음이 때문에 Error.isError() 함수로 위 한계를 피할 수 있게 되었다.console.log(Error.isError(e)); // true동기 vs 비동기원래 동기의 사전적 의미는 같은 시간에 맞춰 함께 움직이는 것을 의미한다. 즉, 코드가 순서대로 시간에 맞춰서 차근차근 작업이 되어야 함을 의미한다. 비동기라는 것은 이것을 부수고, 코드의 순서가 바뀌어진다는 것이다.지금까지는 자바스크립트는 싱글스레드로, 하나하나 순서대로 실행했다. 하지만 이는 굉장히 많은 데이터를 서버에 요청하였을때, 방대한 양의 데이터는 로딩하는데 조금 걸리게 된다. 이때 사용자는 멈춰있는 화면만 보게 된다면 처리에 대한 피드백이 되어지는지를 알 수 없다. 이를 처리하기 위해 비동기가 나왔고, 비동기를 구현하는 다양한 방법을 살펴보자.setTimeout()console.log(\"A\");setTimeout(() =&gt; {  console.log(\"B\");}, 1000); // 1000ms = 1초 후 실행console.log(\"C\");출럭은 A C B 순서로 된다. setTimeout 내부 함수는 타이머가 끝날 때까지 기다렸다가 실행되긴 하지만, 메인 스레드는 멈추지 않고 다음 코드(C) 를 바로 실행할 것이다. 타이머가 끝나면 이벤트 큐(Event Queue) 에 callback이 들어가고, 스택이 비워진 후 실행된다.여기서 의문을 가져야 할 것은 Call Stack 에 작업이 어떻게 쌓일지이다. 즉 코드가 길거나 무거워서 콜 스택이 꽉찬 상태에서 비동기 콜백이 어떻게 실행되는지 궁금할 수 있다.Call Stack자바스크립트는 기본적으로 싱글 스레드라고 했다. 한 번에 하나씩 작업을 수행하는데, 이러한 작업들은 Call Stack 이라고 불리우는 곳에 쌓이고 하나씩 처리된다. 여기서 setTimeout 과도 같은 비동기 콜백은 타이머가 끝난 후에 Event Queue 라는 곳에 들어가는데, 이 이벤트 큐라는 것은 콜 스택이 바쁘면 이벤트 큐에서 기다리는, 잠시 대기하는 대기실 용도이다.결과적으로 동기 작업이 길어진다면, setTimeout 도 지연이 된다. 또한 이 delay 뿐 아니라, setTimeout 은 약 4ms 정도 딜레이를 기본적으로 주어지게 했다고 한다(곧바로 실행시키게 되면 컴퓨터 자원을 혼자 자원을 너무 많이 차지해버리기 때문이라고 한다). 그렇다면 곧바로 실행되게 하려면 어떻게 해야할까?Window Scheduler윈도우 스케쥴러에는 postTask 라는 최신 브라우저 환경에서 제공하는 API 가 있다. 이는 즉시 이벤트 큐에 태스크를 등록하여 콜스택이 비워진 직후에 어떤 지연도 없이 즉시 실행에 가깝게 처리된다.console.log(\"A\");// postTask로 바로 실행if ('scheduler' in window) {  window.scheduler.postTask(() =&gt; {    console.log(\"B (postTask)\");  });} else {  console.log(\"postTask를 지원하지 않는 브라우저입니다.\");}console.log(\"C\");Promise비동기 작업을 행하는데 있어서 위처럼 쓰게 되면 여러 개가 겹칠 수 있는 상황이 발생한다. 이를 콜백 지옥이라고 하는데, 이를 막고자 자바스크립트에서는 Promise 라는 객체를 만들게 된다.우선 생명 주기에서 Promise 는 3가지 상태가 있다.  상태(State)          Pending: 대기 상태      Fulfilled: 작업 성공      Rejected: 작업 실패      위 상태를 가지고 Promise 가 어떻게 실행되는지 보자.Promise 생성const promise = new Promise((resolve, reject) =&gt; {  const success = true;  if (success) {    resolve(\"작업 성공!\");   // 작업 완료 시 호출  } else {    reject(\"작업 실패!\");   // 실패 시 호출  }});new Promise 생성자 안에는 executor 함수가 들어간다. executor 함수는 두 인자를 받는데 두 인자 또한 함수이다.  resolve(value) -&gt; Fulfilled 상태로 변환  reject(error) -&gt; Rejected 상태로 변환만약 그럼 성공했다면(fulfilled 라면) 그 다음 실행하고 싶은 함수는 promise 객체 다음 chaining method 로 then 을 쓰면 된다(then 다음 또 then 을 쓸 수 있다). 만약 실패했다면 catch 를 써서 reject 상태를 처리할 수 있다.new Promise((resolve) =&gt; resolve(1))  .then(result =&gt; {    console.log(result); // 1    return result + 1;  })  .then(result =&gt; {    console.log(result); // 2    return result + 1;  })  .then(result =&gt; {    console.log(result); // 3  })  .catch(error =&gt; {    console.error(\"실패: \", error);  })  .finally(() =&gt; {    console.log(\"작업 끝\")  });Promise.all모든 Promise 가 완료되면 Fulfilled 상태가 됨Promise.all([  Promise.resolve(1),  Promise.resolve(2),  Promise.resolve(3)]).then(results =&gt; console.log(results)); // [1, 2, 3]Promise.race어떤 Promise 라도 완료되면 해당 Promise 완료되는 값을 가져와 사용Promise.race([  new Promise(res =&gt; setTimeout(() =&gt; res(\"첫 번째\"), 1000)),  new Promise(res =&gt; setTimeout(() =&gt; res(\"두 번째\"), 500))]).then(result =&gt; console.log(result)); // \"두 번째\"async/awaitPromise 는 async 와 await 랑 결합을 하여 사용할 수 있다. async 는 말 그대로 비동기로 실행하라는 소리이며, 이는 콜백이 다 끝나고 나서 실행하라는 소리이다.await 는 의미 자체로 기다리라는 의미이다. Promise 가 fulfilled 될 때까지 기다리고, 프로미스는 1초 후 “데이터” 를 넘겨주는 약속을 하고 있다. 여기서 스레드는 그 다음 코드를 실행하지 않고 이를 기다리게 된다.async function fetchData() {  try {    const result = await new Promise(resolve =&gt; setTimeout(() =&gt; resolve(\"데이터\"), 1000));    console.log(result); // 데이터  } catch (err) {    console.error(err);  }}fetchData();그럼 실행의 시간적인 순서로 따진다면  동기 코드(Callback 이든 일반 코드든) 먼저 실행  기다리고 있는 비동기 fetchData() 를 실행 -&gt; async 함수 내부 실행 시작  실행할 때 await 를 만나 함수의 나머지 실행만 일시 중단 Promise 객체가 fulfilled 될 때까지 기다리게 됨          이때 주의점은 전체 스레드를 멈추는게 아니기 때문에 해당 스레드만 멈추고 다른 이벤트 루프는 게속 진행된다.      브라우저의 API 내부에 컨텍스트가 생성되어 그 결과를 넘겨주는 것이기 때문        1초 후에 “데이터” 를 넘겨 받고, 다음 명령문을 실행하게 된다.async function example() {  console.log(\"A\");  const result = await new Promise(resolve =&gt;     setTimeout(() =&gt; resolve(\"B\"), 1000)  );  console.log(result); // B  console.log(\"C\");}example();console.log(\"D\");✒️ 용어callback다른 함수의 인자로 전달되어서 특정 시점에 호출되는 함수를 콜백 함수라고 하는데 주로 비동기 처리에서 작업이 끝난 뒤에 후속 작업이나 에러 처리 작업을 수행하도록 할 때 일컫는 모든 함수들을 말한다.동기 콜백function greet(name, callback) {  console.log(`안녕하세요, ${name}!`);  callback();}greet(\"Alice\", () =&gt; console.log(\"인사 완료!\"));// 출력:// 안녕하세요, Alice!// 인사 완료!비동기 콜백setTimeout(() =&gt; {  console.log(\"1초 후 실행되는 콜백\");}, 1000);"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 27일차 JavaScript 데이터 타입",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/javascript/2025/09/23/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-27%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-23",
      "content": "📂 목차  Node JS 를 통한 터미널 실행          let, const      데이터 타입                  Number          String          Boolean          Undefined                    비교 연산자      JS 함수      JS 객체      📚 본문여기선 자바와 그렇게 다르지 않은 문법들은 다루지 않는다 예를 들어 for, 산술 연산, 삼항 연산, 조건문 등이다.Node JS 를 통한 터미널 실행터미널을 키고 node 를 치자.node이제 명령어들을 입력 가능하다. 기본적으로 javascript 는 인터프리터언어이기에 한 문장씩 읽고 실행하고 한다.let, constlet 은 변수, const 는 상수 예약어이다.let a = 1;console.log(a);a = 2;console.log(a);const b = 100;console.log(b);b = 101; // Uncaught TypeError: Assignment to constant variable.  명령어를 칠 때마다 undefined 라는 것을 볼 수 있는데 js 에서는 undefined 라는 타입이 있다. 함수 호출이나 let, const 등 특정 코드를 실행하는 것을 입력할 때마다 함수의 반환값을 출력하는데 그게 undefined 인 것이다. 즉, const, let, console.log 는 반환으로 undefined 이지만, 대입연산자 = 은 대입 후에 자기 자신을 반환하는 것을 볼 수 있다.데이터 타입NumberJavascript 는 숫자를 전부 통일해놨다.let age = 25;let pi = 3.14;String백틱을 통해서 변수를 집어넣을 수 있다. String.format 과도 유사하다.let name = \"Seonghun\";let greeting = `Hello, ${name}!`;Booleanlet isActive = true;let hasPermission = false;Undefined값이 할당되지 않은 상태임을 나타내는 타입인데, 변수를 선언만 하고 값을 넣지 않으면 자동으로 undefined 가 된다.let x;console.log(x); // undefined비교 연산자비교연산자에서 === 이 있는데, 이는 값 뿐 아니라 값과 타입까지 비교하며 엄격한 비교이다. !== 도 마찬가지이다. 이게 굉장히 헷갈리는데, 다음과 같은 상황이다.5 == \"5\"      // true, 문자열을 숫자로 변환해서 비교null == undefined // true, 특별 규칙 적용5 === 5       // true, 값도 같고 타입도 같음5 === \"5\"     // false, 값은 같아 보여도 타입(Number vs String)이 다름true === 1    // false, Boolean vs Numbernull === undefined // false, 타입이 다름기본적으로 Number 과 String 이 각각 5를 표현한다면 이는 == 으로는 참이 되게 된다. 따라서 == 보다는 ===이 더 좋다.JS 함수자바스크립트는 함수 자체를 일급 객체로 다룬다. 즉, 함수는 변수에 할당할 수 있고, 다른 함수의 인자로 전달할 수 있으며, 함수의 반환값으로도 사용할 수 있다.마치 자바에서 BiFunction, Function, Runnable 등등과도 유사한 기능들을 주게 된다.// 함수 선언식function add(a, b) {    return a + b;}console.log(add(5, 3));  // 8// 함수 표현식const multiply = function(a, b) {    return a * b;};console.log(multiply(4, 5));  // 20따라서 밑의 표현식과 같이 변수에 할당을 할 수 있다. 또 자바에서는 -&gt; 의 표현식으로 가능한데, 이 또한 js 에서는 =&gt; 로 쓸 수 있다.// 기본 형태const subtract = (a, b) =&gt; {    return a - b;};// 간단한 형태const double = n =&gt; n * 2;// 여러 줄const greet = name =&gt; {    const message = `안녕하세요, ${name}님!`;    console.log(message);    return message;};JS 객체마치 json 을 쓰는 것처럼 선언할 수 있다.// 객체 생성const person = {    name: '김철수',    age: 25,    city: '서울',    isStudent: true};// 속성 접근console.log(person.name);     // 김철수console.log(person['age']);   // 25// 속성 수정person.age = 26;// 속성 추가person.email = 'kim@example.com';신기한 것은 js 에서는 구조 분해 할당이라는 것이 있어서 객체를 손 쉽게 각각 변수에 할당시키게 할 수 있다.const user = {    username: 'john',    email: 'john@email.com',    age: 30};// 구조 분해 할당const { username, email, age } = user;console.log(username);  // john// 함수 파라미터에서 구조 분해function printUser({ username, age }) {    console.log(`${username}님은 ${age}살입니다.`);}printUser(user);getter &amp; setterconst user = {    _name: '김철수',    _age: 25,    // Getter    get name() {        console.log('name getter 호출');        return this._name;    },    // Setter    set name(value) {        console.log('name setter 호출');        if (value.length &lt; 2) {            console.log('이름은 2글자 이상이어야 합니다.');            return;        }        this._name = value;    },    get age() {        return this._age;    },    set age(value) {        if (value &lt; 0) {            console.log('나이는 0보다 커야 합니다.');            return;        }        this._age = value;    }};// 사용console.log(user.name);  // getter 호출user.name = '이영희';    // setter 호출user.age = -5;          // 에러 메시지"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 26일차 CSS 심화",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/css/2025/09/23/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-26%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-23",
      "content": "📂 목차  CSS 심화          Flex Box      Grid Layout      Animation &amp; Transition      상속과 우선순위                  상속          우선순위                    CSS 함수 및 유틸리티      📚 본문CSS 심화Flex Box플렉스 박스는 1차원 레이아웃 시스템으로, 행, 열을 단위로하여서 컨텐츠를 정렬시킨다.CSS properties  display: flex          flex-direction: row, column        justify-content: main axis(start, center, space-between 등)  align-items: cross axis 정렬 (stretch, center 등)  flex-grow, flex-shrink, flex-basis: 공간 분배 제어  order: DOM 순서와 관계없이 배치 순서 변경Grid Layout2차원 레이아웃 시스템, 행과 열 모두 정의 가능.CSS properties  display: grid  grid-template-columns, grid-template-rows : 열/행 정의  gap : 행과 열 간격  grid-template-areas : 영역 이름을 통해 레이아웃 정의  minmax(), auto-fit, auto-fill : 반응형 그리드 구현Animation &amp; Transition트랜지션은 상태 변화에 대한 애니메이션 효과를 적용함을 이전 포스트에서 봤었다. 이번에는 더 자세히 보자.  모든 변화에 대한 0.3 초 동안 이동하는 방법 ease-in-out 으로 설정  transition: all 0.3s ease-in-out애니메이션은 키프레임 기반으로 자유로운 애니메이션을 구현할 수 있다. 여기서 all 이라는 것은 모든 태그가 변경되는 것을 트리거 하겠다는 의미다./* 키프레임 정의: 위아래로 튀는 효과 */@keyframes bounce {  0%, 100% { transform: translateY(0); }  50% { transform: translateY(-20px); }}/* div 요소에 애니메이션 적용 */div {  animation-name: bounce;              /* 어떤 키프레임을 적용할지 */  animation-duration: 1s;              /* 한 번 애니메이션이 완료되는 시간 */  animation-timing-function: ease-in-out; /* 속도 패턴 지정 */  animation-delay: 0s;                 /* 애니메이션 시작 지연 시간 */  animation-iteration-count: infinite; /* 반복 횟수 (무한 반복) */  animation-direction: alternate;      /* 정방향 ↔ 역방향 반복 */  animation-fill-mode: forwards;       /* 종료 상태 유지 */}infinite 를 적용시키면 계속 반복하는 것을 알 수 있다. 속도는 timing-function 으로 설정할 수 있다.  keyframes 로 시간 별 transition 을 설정하고, 설정 후 선택자 내부의 속성-값으로 animation 을 이용해 해당 keyframes 를 가져와 사용상속과 우선순위상속CSS 상속에는 일부 속성만 상속한다.  color: 글자 색  font-family: 글꼴  font-size: 글자 크기  font-style: 글자 스타일  font-variant: 글자 변형  font-weight: 글자 두께  line-height: 줄 높이  letter-spacing: 글자 간격  …글자에 대한건 전부 상속됨을 알 수 있다. 상속되지 않는 속성은 명시적으로 속성-값을 통해 CSS 설정을 해주어야 한다.우선순위  !important  inline style: 태그 자체에 직접 넣는 것  ID selector  Class/Attribute/Pseudo-class  Element/Pseudo-element!important 는 CSS 에서 가장 최우선적으로 적용할 수 있도록 하는 애다. 하지만 이미 다른 곳에서 해당 선택자의 속성-값으로 !important 를 하고 있다면 그 아래 순서를 또 따르게 된다.CSS 함수 및 유틸리티CSS 변수:root {  --primary-color: #3498db;  --secondary-color: #2ecc71;  --base-font-size: 16px;}button {  background-color: var(--primary-color);  color: white;  font-size: calc(var(--base-font-size) * 1.2);}  컨벤션은 변수명은 –로 시작한다는 점이다.calc().container {  width: calc(100% - 40px);  height: calc(50vh - 20px);}clamp()p {  font-size: clamp(14px, 2vw, 20px);}최소, 권장값, 최대 를 설정한다.유틸리티  overflow: hidden / auto / scroll : 스크롤 관리  text-overflow: ellipsis : 글자 줄임표  pointer-events: none : 특정 요소 클릭 방지 (무쓸모)  user-select: none : 텍스트 선택 방지 (무쓸모)"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 25일차 CSS",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/css/2025/09/23/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-25%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-23",
      "content": "📂 목차  CSS 적용방법          인라인 스타일      내부 스타일시트      외부 스타일 시트        CSS 기본 문법          선택자      At-Rule      Vendor Prefix      Position      📚 본문CSS 는 HTML 문서를 이쁘게 보여주는 스타일시트 언어이다.CSS 적용방법인라인 스타일html tag 자체에다가 다음과 같이 style 옵션을 통해 줄 수 있다.&lt;p style=\"color: red; font-size: 16px;\"&gt;인라인 스타일&lt;/p&gt;이렇게 되면 style 이 굉장히 긴 코드에서는 유지보수가 어렵고, 눈빠지게 태그들을 들여다 봐야 한다.내부 스타일시트아래와 같이 head 태그 내부에 style 태그를 넣어서 문서 전체에 영향을 주는 스타일시트 코드들을 넣을 수 있다.&lt;head&gt;    &lt;style&gt;        p {            color: blue;            font-size: 16px;        }    &lt;/style&gt;&lt;/head&gt;이 방법도 나쁘진 않지만, html 파일에는 html 구조와 관련된 코드만 있어야 하기 때문에 맞지 않다.외부 스타일 시트&lt;head&gt;    &lt;link rel=\"stylesheet\" href=\"styles.css\"&gt;&lt;/head&gt;가장 좋은 방법은 파일을 따로 빼내서 style 과 관련된 코드들만 모아놓는 것이다.CSS 기본 문법(선택자) {    속성: 값;}정도로 생각하면 된다. 선택자 블럭 내부에는 다수의 (속성: 값) 들이 올 수 있다.선택자기본 선택자  *: 전체 선택  (tag): html 태그를 직접 입력해 해당 태그에 대한 스타일 입히기 가능  .(class): 특정 클래스를 가진 요소들에게 적용 가능  #(id): id 선택자로 태그 내에 id 옵션을 토대로 id 를 가진 요소에 적용 가능그룹/결합 선택자  A, B: 여러 선택자를 한 번에 지정  A B: A 안에 있는 모든 B 선택자들만 선택(하위 모든 계층의 것들)  A &gt; B: 자식 선택자 A의 바로 아래 B 선택자만 선택(하위 A 태그 밑의 바로 밑 계층 위와 다른 점은 하위 모든 계층에 대한게 아니라는 것)  A + B: 인접 형제 선택, A 바로 뒤의 B  A ~ B: 일반 형제 선택, A 뒤에 오는 모든 형제 B속성 선택자여기서 속성은 html 태그 내의 key=value 의 key 에 해당하는걸 속성이라고 한다.            가상 선택자  :hover: 마우스 올렸을 때  :active: 클릭 중일 때  :focus: 포커스가 있을 때  :first-child / :last:child: 의미 그대로  :nth-child(n) / :nth-of-type(n): 의미 그대로  :not(selector): 특정 선택자가 아닌 모든 선택자가상 요소 선택자  ::before: 요소 내용 앞에 삽입  ::after: 요소 내용 뒤에 삽입  ::first-line: 첫 줄만  ::first-letter: 첫 글자만p#unique.highlight[data-type=\"example\"]:first-child:nth-child(1):not(.skip)::before::after::first-line::first-letter {위처럼 모든 걸 다 쓴 표현이다.At-Rule@로 시작하는 문법들을 앳 룰이라고 부르며, css 에게 특별한 지시를 내리는 규칙이다.@font-face@font-face {  font-family: 'MyFont';  src: url('fonts/myfont.woff2') format('woff2');}body {  font-family: 'MyFont', sans-serif;}위와 같이 폰트 경로를 길게 늘려뜨려서 매번 정의해주면 힘들다. 따라서 MyFont 라는 별칭을 써서 적용시킬 수 있다.@import@import url('reset.css');@import url('theme.css') screen and (min-width: 768px);다른 CSS 파일을 불러올 수도 있다.@media@media (max-width: 768px) {  body {    background-color: lightgray;  }}미디어 쿼리라고도 하며, 화면 크기나 장치 조건에 따라서 스타일을 적용하겠다는 의미다.@keyframes@keyframes slide {  from { transform: translateX(0); }  to { transform: translateX(100px); }}div {  animation: slide 2s linear infinite;}CSS 로 애니메이션처럼 요소를 움직이는 느낌을 주게 할 수 있다.@supports@supports (display: grid) {  div {    display: grid;  }}브라우저마다 css 속성 지원 여부가 다르다. 이 여부에 따라 해당 태그를 적용시키게 할 수 있다.Vendor PrefixVendor Prefix 는 브라우저 별로 실험적으로 제공되는 CSS 속성을 쓸 때 붙이는 접두어이다./* 벤더 프리픽스 (구형 브라우저) */.gradient-compatible {    background: -webkit-linear-gradient(left, red, blue);    background: -moz-linear-gradient(left, red, blue);    background: -o-linear-gradient(left, red, blue);    background: linear-gradient(to right, red, blue);}css 표준화가 아직 완전히 끝나지 않았거나 브라우저마다 구현방식이 다르다거나 미래에 표준이 될 기능을 미리 쓸 수 있게 하기 위해 나왔다. 대표적인 prefix 로는 다음과 같이 있다.  -webkit-: 크롬, 사파리, iOS 사파리, 안드로이드  -moz-: 파이어폭스 전용  -ms-: 인터넷 익스플로러, 엣지 구버전  -o-: 오페라 구버전Positioncss 속성에는 position 이 있는데, static, relative, absolute, fixed 가 있다.static&lt;!DOCTYPE html&gt;&lt;html lang=\"ko\"&gt;&lt;head&gt;&lt;meta charset=\"UTF-8\"&gt;&lt;title&gt;Position 예시&lt;/title&gt;&lt;style&gt;  body {    height: 2000px; /* 스크롤 테스트용 */    padding: 20px;  }  .box {    width: 150px;    height: 80px;    color: white;    padding: 10px;    margin-bottom: 20px;  }  .static {    position: static;    background-color: gray;  }  .relative {    position: relative;    top: 20px;    left: 20px;    background-color: blue;  }  .absolute-container {    position: relative; /* 기준점 */    height: 150px;    background-color: lightgray;    margin-bottom: 20px;  }  .absolute {    position: absolute;    top: 10px;    right: 10px;    background-color: red;  }  .fixed {    position: fixed;    top: 10px;    left: 10px;    background-color: green;  }  .sticky-container {    height: 300px;    background-color: #f2f2f2;    margin-top: 20px;  }  .sticky {    position: sticky;    top: 0;    background-color: orange;    padding: 10px;  }&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"box static\"&gt;Static&lt;/div&gt;&lt;div class=\"box relative\"&gt;Relative (top:20px, left:20px)&lt;/div&gt;&lt;div class=\"absolute-container\"&gt;  Absolute Container  &lt;div class=\"box absolute\"&gt;Absolute&lt;/div&gt;&lt;/div&gt;&lt;div class=\"box fixed\"&gt;Fixed (뷰포트 기준)&lt;/div&gt;&lt;div class=\"sticky-container\"&gt;  &lt;div class=\"box sticky\"&gt;Sticky (scroll에 따라 고정)&lt;/div&gt;  아래로 스크롤 해보세요.&lt;/div&gt;&lt;p&gt;스크롤 테스트용 내용...&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;이건 직접 써보면서 배우는게 가장 빠르다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 24일차 프론트 개발 환경 구축 및 HTML 기초",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/html/2025/09/21/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-24%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-21",
      "content": "📂 목차  개발 환경 구축          Node      NVM        HTML          Open Graph 메타 태그      Form Tag      Semantic Tag      멀티미디어 태그      Search Engine Optimization      📚 본문back 으로의 query 를 보내기 위한 간단한 front 부분을 살펴본다.개발 환경 구축NodeChrome V8 엔진 기반 자바스크립트 런타입 환경을 제공하며, 비동기 I/O, 이벤트 기반 구조를 통해 요청을 동시에 많이 처리할 수 있게 하여서 외부에서도 자바스크립트를 실행할 수 있게 해주는 프로그램이다.brew install nodeNVMjavascript 가 발전하면서 전 세계 개발자들이 만든 서드파티 라이브러리들을 쉽게 설치하고 빠르게 적용하고 관리할 수 있게 해주는 패키지 매니저이며, 다음 명령어로 설치할 수 있다.brew install nvm# 프로젝트 디렉토리 생성mkdir my-html-projectcd my-html-project# npm 초기화npm init -y# 개발 서버 설치npm install lite-server --save-devjava 에는 gradle 이 있다면, 여기에는 npm 이 있듯이, npm 도 프로젝트를 단위로 패키지를 관리하도록 할 수 있다. 만든 디렉토리에서 npm init 을 해주면 된다(-y 옵션은 실행했을 때 나오는 질의에 대해 yes 옵션을 준다).npm install lite-server 는 가장 간단한 웹서버를 구동시키고 싶을때 사용한다.  Live Reloading: 파일이 수정되면 브라우저가 자동으로 새로고침  간단한 설정: bs-config.json 설정 파일로 루트 디렉토리, 라우팅 지정 가능기능이 있다(--save-dev 는 개발 환경에서만 해당 패키지, 라이브러리를 쓰겠다는 의미다).{  \"scripts\": {    \"start\": \"lite-server\",    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"  }}package.json 에는 커스텀 스크립트를 넣을 수 있는 기능도 있는데, npm test 를 하면 테스트 정의가 안되어 있다는 메시지가 뜨게 되고, start 라는 커스텀 명령을 프로젝트 디렉토리에서 npm start 를 입력하게 되면 lite-server 가 자동으로 서버 수행을 하게 된다.  node 서버는 3000 포트를 보통 쓴다.HTML기본 문법은 생략한다.Open Graph 메타 태그웹페이지가 SNS 에 공유될 때 어떻게 보여질지에 대한 정의를 하는 태그이다.&lt;meta property=\"og:title\" content=\"내 블로그 제목\" /&gt;&lt;meta property=\"og:description\" content=\"이 페이지의 간단한 설명\" /&gt;&lt;meta property=\"og:image\" content=\"https://example.com/image.png\" /&gt;&lt;meta property=\"og:url\" content=\"https://example.com/post/123\" /&gt;  og:title: 공유될 때 표시할 제목  og:description: 페이지 요약  og:image: 썸네일 이미지  og:url: 원본 주소 (정규화된 url)  og:type: website, article 등 컨텐츠 타입Form Tag폼은 요청을 전송하는 편지 역할이다. back 으로의 전송을 위해 있으며, 우리가 로그인 할 때도 이 태그가 들어가게 된다.&lt;form action=\"/submit\" method=\"post\"&gt;    &lt;label for=\"username\"&gt;사용자명:&lt;/label&gt;    &lt;input type=\"text\" id=\"username\" name=\"username\" required&gt;    &lt;label for=\"password\"&gt;비밀번호:&lt;/label&gt;    &lt;input type=\"password\" id=\"password\" name=\"password\" required&gt;    &lt;button type=\"submit\"&gt;제출&lt;/button&gt;&lt;/form&gt;  form의 action: (루트 디렉터리)/submit 으로 post 방식으로 전송한다  form의 method: 데이터를 전송할 HTTP 방식 (GET/POST 등)을 지정한다  label의 for: 어떤 input과 연결되는지를 지정한다 (접근성 ↑)  input의 id: 해당 input을 고유하게 식별하는 값  input의 name: 서버에서 받을 때 사용할 파라미터 이름  required: 해당 입력 필드가 반드시 입력되어야 함을 의미  button type=”submit”: 폼 데이터를 action에 지정된 경로로 전송한다&lt;!-- 텍스트 입력 --&gt;&lt;input type=\"text\" placeholder=\"이름을 입력하세요\"&gt;&lt;!-- 이메일 --&gt;&lt;input type=\"email\" placeholder=\"email@example.com\"&gt;&lt;!-- 숫자 --&gt;&lt;input type=\"number\" min=\"1\" max=\"100\"&gt;&lt;!-- 날짜 --&gt;&lt;input type=\"date\"&gt;&lt;!-- 체크박스 --&gt;&lt;input type=\"checkbox\" id=\"agree\" name=\"agree\"&gt;&lt;label for=\"agree\"&gt;동의합니다&lt;/label&gt;&lt;!-- 라디오 버튼 --&gt;&lt;input type=\"radio\" id=\"male\" name=\"gender\" value=\"male\"&gt;&lt;label for=\"male\"&gt;남성&lt;/label&gt;&lt;input type=\"radio\" id=\"female\" name=\"gender\" value=\"female\"&gt;&lt;label for=\"female\"&gt;여성&lt;/label&gt;&lt;!-- 파일 업로드 --&gt;&lt;input type=\"file\" accept=\"image/*\"&gt;다양한 파일 입력을 할 수 있도록 태그들이 많이 있다(다 외우지 말고 그때그때 필요한 걸 검색해서 쓰자).Semantic Tag시맨틱 태그는 태그 이름 그 자체에 의미가 있는 태그를 말한다. 예를들어서 div 태그는 그냥 의미가 없는 태그인 단순 영역 구분이다.하지만 다음 태그들은 다음 의미를 가진다:  header: 머리말, 제목 영역  nav: 네비게이션 링크들 나열한 영역(nav 태그 안에는 무조건 ul, ol 이 들어가야 함)  section: 주제별 콘텐츠 그룹  main: 이 문서에서 제일 주요한 콘텐츠  article: 독립된 콘텐츠  aside: 부가 콘텐츠(사이드 바)  address: 연락 정보전형적인 HTML 구조는 다음과 같다:&lt;!DOCTYPE html&gt;&lt;html lang=\"ko\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;title&gt;시맨틱 구조&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;header&gt;        &lt;h1&gt;사이트 제목&lt;/h1&gt;        &lt;nav&gt;            &lt;ul&gt;                &lt;li&gt;&lt;a href=\"#home\"&gt;홈&lt;/a&gt;&lt;/li&gt;                &lt;li&gt;&lt;a href=\"#about\"&gt;소개&lt;/a&gt;&lt;/li&gt;                &lt;li&gt;&lt;a href=\"#contact\"&gt;연락처&lt;/a&gt;&lt;/li&gt;            &lt;/ul&gt;        &lt;/nav&gt;    &lt;/header&gt;    &lt;main&gt;        &lt;section&gt;            &lt;h2&gt;메인 섹션&lt;/h2&gt;            &lt;article&gt;                &lt;h3&gt;글 제목&lt;/h3&gt;                &lt;p&gt;글 내용...&lt;/p&gt;            &lt;/article&gt;        &lt;/section&gt;        &lt;aside&gt;            &lt;h3&gt;사이드바&lt;/h3&gt;            &lt;p&gt;관련 링크나 광고&lt;/p&gt;        &lt;/aside&gt;    &lt;/main&gt;    &lt;footer&gt;        &lt;address&gt;            연락처: example@email.com        &lt;/address&gt;        &lt;p&gt;&amp;copy; 2024 My Website&lt;/p&gt;    &lt;/footer&gt;&lt;/body&gt;&lt;/html&gt;멀티미디어 태그영상&lt;video width=\"320\" height=\"240\" controls&gt;    &lt;source src=\"movie.mp4\" type=\"video/mp4\"&gt;    &lt;source src=\"movie.ogg\" type=\"video/ogg\"&gt;    브라우저가 video 태그를 지원하지 않습니다.&lt;/video&gt;&lt;!-- 자동 재생, 음소거, 반복 --&gt;&lt;video autoplay muted loop&gt;    &lt;source src=\"background.mp4\" type=\"video/mp4\"&gt;&lt;/video&gt;오디오&lt;audio controls&gt;    &lt;source src=\"audio.mp3\" type=\"audio/mpeg\"&gt;    &lt;source src=\"audio.ogg\" type=\"audio/ogg\"&gt;    브라우저가 audio 태그를 지원하지 않습니다.&lt;/audio&gt;Search Engine Optimization검색이 잘되기 위한 문서는 SEO HTML 구조 표준을 짜야 한다. 구조는 물론 위와 같이 Semantic 하게 가져가야 한다.  메타 태그 필요          title: 검색 엔진 결과의 제목      &lt;meta name=\"description\"&gt; : 검색결과에 보이는 설명      &lt;meta name=\"keywords\"&gt; : (지금은 큰 영향 없음)      Open Graph 필요        h1 은 딱 한 번만  이미지에는 무조건 alt 속성 달기  링크(anchor) 는 의미 있는 텍스트로  중복 콘텐츠 피하기등등 이 있다. 더 많은 태그를 알고 싶으면 그때그때 검색하면서 배우는게 좋다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 23일차 ThreadLocal 과 Serializable",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/21/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-23%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-21",
      "content": "📂 목차  ThreadLocal          Member Variables      ThreadLocalMap        sealed  Serializable 의 재현성  DTO 와 DAO📚 본문프로젝트 진행에 있어 다양한 자바의 내장 클래스들을 살펴보면서 코드를 업그레이드 하기 위해 본다.ThreadLocalpublic class ThreadLocal&lt;T&gt;  T 타입을 가지는 스레드 로컬 변수를 구현한다.  각 스레드마다 독립적인 값을 저장하는 것이 핵심이며,  다른 스레드와 공유되지 않는다  이때 스레드마다 하나의 ThreadLocal 을 가진다는 말은 거짓이다. 1:n 의 관계다Member Variablesprivate static final boolean TRACE_VTHREAD_LOCALS = traceVirtualThreadLocals();private final int threadLocalHashCode = nextHashCode();private static final AtomicInteger nextHashCode = new AtomicInteger();private static final int HASH_INCREMENT = 0x61c88647;  threadLocalHashCode: 각 ThreadLocal 인스턴스 별 고유 해시 값 -&gt; 해시 맵에서 key 로 사용하게 된다.  nextHashCode &amp; HASH_INCREMENT: 해시 충돌 최소화를 위한 고유값을 생성          여기서 HASH_INCREMENT 의 0x61c88647 은 황금 비율 상수이며, 연속 생성되는 ThreadLocal 에서도 충돌을 최소화하는 상수이다.      HASH_INCREMENTprivate static int nextHashCode() {    return nextHashCode.getAndAdd(HASH_INCREMENT);}위 메서드에서 HASH_INCREMENT 를 통해 다음 hashCode 를 가져오는것을 볼 수 있는데 연속되게 생성되는 ThreadLocal 속에서 hashCode 값의 충돌을 최소화 하려면 누적하여 더해지는 값마다 다른 값을 나타내게 해야 하며, 이때 HashMap 에서는 동일 값에 대한 충돌이 없이 잘 퍼지도록 설계할 수 있게 된다.따라서 ThreadLocalMap 에서 키 값에 대한 황금비를 계속 더하며 슬롯 충돌을 최소화하게 되며, 2의 제곱 크기의 배열에서 고유 ID 가 균등하게 퍼지도록 해준다.protected T initialValue() {    return null;}public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) {    return new SuppliedThreadLocal&lt;&gt;(supplier);}기본 초기값은 null 이 되지만, SuppliedThreadLocal 팩터리 패턴으로 초기화를 할 수 있다. 우리는 withInitial 을 통해 초기화 할 수 있다.public T get() {    return get(Thread.currentThread());}private T get(Thread t) {    ThreadLocalMap map = getMap(t);    if (map != null) {        ThreadLocalMap.Entry e = map.getEntry(this);        if (e != null) {            @SuppressWarnings(\"unchecked\")            T result = (T) e.value;            return result;        }    }    return setInitialValue(t);}값 읽기에 해당하는 메서드이다. 두 번째 메서드는 ThreadLocalMap 에서 값 검색을 하며, 없으면 initialValue() 로 초기화 하여 저장하게 된다.public void set(T value) {    set(Thread.currentThread(), value);}private void set(Thread t, T value) {    ThreadLocalMap map = getMap(t);    if (map != null) map.set(this, value);    else createMap(t, value);}현재 스레드의 값을 토대로 ThreadLocalMap 의 값을 변경하게 된다. 여기서 this 가 의미하는 것이 바로 hashCode 가 되게 된다.결국에는 ThreadLocalMap 이 핵심인데, 이를 더 살펴보자.ThreadLocalMap이 클래스는 ThreadLocal 안에 선언되어 있는 static class 이다. 밖에서는 그래서 참조를 할 수 없고, ThreadLocalMap 은 논리 스레드 마다 적어도 하나씩 존재함을 알 수 있다.ThreadLocalMap 은 핵심 클래스 Entry 를 가진다.static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {    Object value;    Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; }}엔트리는 ThreadLocalMap 의 슬롯을 추상화한 클래스이며, Key 를 약한 참조를 통해 ThreadLocal 객체가 없다면 null 을 반환한다. 이를 stale entry 라고 한다.특이한 것은 ThreadLocal 객체 그 자체로 Key 가 됨을 알 수 있다. 그렇다면 이게 어떻게 동작하는지 의문인데, 해당 key 는 ThreadLocal 에서의 hashCode 로 식별함을 볼 수 있었다.int index = key.threadLocalHashCode &amp; (table.length - 1);  key.threadLocalHashCode: 스레드 로컬 객체가 가진 고유 해시코드      table.length - 1: 스레드 로컬 맵 내부 배열 크기를 통해 해시 값을 배열 인덱스로 변환    key.threadLocalHashCode &amp; (table.length - 1): % 대신 &amp; 를 쓰는 이유는 table.length 가 2의 제곱이기 때문에 1을 뺀 값은 비트가 전부 1이 되고, 이는 % 의 결과랑 &amp;의 결과랑 같게 된다.ThreadLocal&lt;String&gt; userId = ThreadLocal.withInitial(() -&gt; \"user1\");ThreadLocal&lt;Integer&gt; counter = ThreadLocal.withInitial(() -&gt; 0);Thread t = new Thread(() -&gt; {    System.out.println(userId.get());  // \"user1\"    System.out.println(counter.get()); // 0    userId.set(\"userA\");    counter.set(42);    System.out.println(userId.get());  // \"userA\"    System.out.println(counter.get()); // 42});t.start();sealedJava 17 문법에서 도입된 문법으로 봉인된이라는 의미를 가진다.public abstract sealed class Reference&lt;T&gt;    permits PhantomReference, SoftReference, WeakReference, FinalReference {클래스 혹은 인터페이스가 상속 또는 구현 될 수 있는 범위를 제한하는 문법이다.permits 예약어를 통해서 이를 상속하거나 구현하는 클래스의 범위를 제한시켜 명시적으로 지정된 클래스들만이 이를 사용할 수 있게 된다.  Reference 는 GC 와 밀접히 연결된 핵심 클래스라 임의의 사용자가 마음대로 상속해서 써버리게 되면 GC 시스템이 깨질 수 있기에 봉인해놓은 것.Serializable 의 재현성Serializable 을 구현한다고 해서, 재현성을 얻는 것은 아니다. 클래스의 구조가 바뀌거나 JVM 이 자동으로 새 serialVersionUID 을 계산하는데, 이 값은 JVM 마다 컴파일 환경마다 달라질 수 있기 때문에 그 때마다 InvalidClassException 의 예외가 발생할 수 있다.private static final long serialVersionUID = 어떤 값;해당 값을 멤버 변수로 추가만 해준다면 역직렬화, 직렬화를 재현할 수 있게 되며, 클래스 구조가 조금 바뀌더라도 가능하게 된다.  무조건 static final 로 선언하자.DTO 와 DAODAO 는 Data Access Object 의 약자로, 실제로 DB 에 접근할 수 있는 권한을 가지는 객체이다. 즉, 얘는 실제 Connection 인터페이스를 가지고 있으며, 이 기능들을 제공해주는 애여야 함을 개념적으로 알 수 있다.DAO 는 보통 infrastructure 패키지에 위치되어서 데이터베이스 접근을 전담하는 객체로 있는게 좋다.  domain 쪽은 비즈니스 로직의 중심  infrastructure 는 DB, 외부 API, 메시지 브로커 등 구체적 기술 의존성이 들어가는 곳DTO 는 Data Transfer Object 이다. 데이터를 전달하기 위한 용도로만 쓰며, 불변이 특징인 객체이다. 따라서 보통 record 로 작성하면 편하며, equals, hashCode 등은 필수이다.  필자는 보통 Service &lt;-&gt; Controller 사이만 DTO 를 사용하고 Service 에서는 비즈니스 엔티티와 DTO 를 혼용하여 사용하였지만,이는 전역적으로 사용하는 클래스라 따로 빼는게 좋다.✒️ 용어Stale Entry오래되거나 최신 상태가 아닌, 더 이상 유효하지 않은 데이터나 항목을 의미한다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 22일차 Hikari Connection Pool",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/database/2025/09/16/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-22%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-16",
      "content": "📂 목차  HikariCP          HikariCP 의존성 추가      Hikari Configuration                  HikariConfig          HikariDataSource                    📚 본문HikariCP데이터베이스와 어플리케이션을 통신할 때, Connection 이라는 추상화 된 연결시켜주는 인터페이스를 통해 통신을 할 수 있음을 볼 수 있었다. 내부적인 구현은 DriverManager 을 통해서 외부의 인스턴스를 들고와서 구현하였음을 알 수 있다.  외부의 인스턴스를 들고오기 위해 mysql-connector 라는 것을 사용했다.여기서 Connection 이라는 하나의 객체를 생성하면 해당 클래스로만 요청을 할 수 있는데, 이는 요청할 수 있는 입구가 하나뿐임을 뜻한다. 그러면 요청이 더 많이 들어올 때마다 Connection 을 생성시켜서 요청을 받을 수 있게 하면 되지만, Connection 을 새로 생성하는 비용이 매우 커서, 이를 서버 실행 이전에 미리 다 만들어두고 사용하는 방식을 채택하게 된다.이것이 바로 Connection Pool 이며, 자바 진영에서는 이 이론을 토대로 가장 빠르고 가벼운 커넥션 풀 구현체 중에 Hikari Connection Pool 을 사용하게 된다.HikariCP 의존성 추가// https://mvnrepository.com/artifact/com.zaxxer/HikariCPimplementation 'com.zaxxer:HikariCP:7.0.2'이는 보통 Spring Boot 2.0 이후에 전부 내장되어 있기 때문에 따로 추가해주지 않아도 기본값이 hikari cp 를 사용하도록 되어 있다.Hikari Configuration커넥션 풀은 여러 개의 스레드를 통해 커넥션의 수를 정할 수 있다.이런 커넥션 수는 properties 파일로 환경 변수처럼 미리 설정하여 HikariCP 모듈에게 전달할 수 있다.# resources/hikari.propertiesdataSourceClassName=com.mysql.cj.jdbc.MysqlDataSourcedataSource.url=jdbc:mysql://localhost:3306/library?serverTimezone=Asia/Seoul&amp;useSSL=false&amp;allowPublicKeyRetrieval=truedataSource.user=liondataSource.password=1234# Statement 캐시 관련 설정dataSource.cachePrepStmts=truedataSource.prepStmtCacheSize=250dataSource.prepStmtCacheSqlLimit=2048# 풀 사이즈 &amp; 타임아웃maximumPoolSize=4minimumIdle=4connectionTimeout=30000idleTimeout=600000maxLifetime=1800000poolName=MyHikariPool이는 HikariCP 만의 독립적인 설정 방식이고, Spring 에서는 위 설정과는 또 다르게 입력해줘야 한다.Spring 에서의 HikariCP 설정spring.datasource.url=jdbc:mysql://localhost:3306/testdbspring.datasource.username=testuserspring.datasource.password=testpassspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.hikari.maximum-pool-size=10spring.datasource.hikari.minimum-idle=5spring.datasource.hikari.idle-timeout=600000spring.datasource.hikari.max-lifetime=1800000spring.datasource.hikari.connection-timeout=30000  maximum-pool-size:          DB 서버가 가용하는 코어 수 * 스레드로 경험적으로 정함      쿼드 코어 &amp; 멀티 스레드 = 4 * 2 = 8        minimum-idle: 최소 유지 커넥션 수(같게 두면 모든 커넥션이 돌아감)  idle-timeout: 유휴 커넥션 제거 밀리 초          보통 10분으로 둠(600000 으로 설정 = 10 분)        max-lifetime: 커넥션 최대 생존 밀리 초          1800000 = 30 분        connection-timeout: 커넥션 최대 대기 밀리초          30000: 30 초      HikariConfigHikariConfig class 를 뜯어보자.HikariConfig Member Var.@SuppressWarnings({\"SameParameterValue\", \"unused\"})public class HikariConfig implements HikariConfigMXBean { ... }Hikari 를 뜯어보면 최상위에 HikariConfig 가 있음을 볼 수 있다.   private static final char[] ID_CHARACTERS = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\".toCharArray();   private static final long CONNECTION_TIMEOUT = SECONDS.toMillis(30);   private static final long VALIDATION_TIMEOUT = SECONDS.toMillis(5);   private static final long SOFT_TIMEOUT_FLOOR = Long.getLong(\"com.zaxxer.hikari.timeoutMs.floor\", 250L);   private static final long IDLE_TIMEOUT = MINUTES.toMillis(10);   private static final long MAX_LIFETIME = MINUTES.toMillis(30);   private static final long DEFAULT_KEEPALIVE_TIME = MINUTES.toMillis(2);   private static final int DEFAULT_POOL_SIZE = 10;멤버 변수로는 기본값들이 들어 있음을 볼 수 있다.   // Properties changeable at runtime through the HikariConfigMXBean   //   private volatile String catalog;   private volatile long connectionTimeout;   private volatile long validationTimeout;   private volatile long idleTimeout;   private volatile long leakDetectionThreshold;   private volatile long maxLifetime;   private volatile int maxPoolSize;   private volatile int minIdle;   private final AtomicReference&lt;Credentials&gt; credentials = new AtomicReference&lt;&gt;(Credentials.of(null, null));그 밑은 우리가 properties 에 입력했던 값들이 들어가는 변수들을 선언했다. volatile 이어서 변수 수준에서 원자적인 연산을 수행함도 알 수 있다(수정과 삭제에 있어 data concurrent 하다).생성자 부분      var systemProp = System.getProperty(\"hikaricp.configurationFile\");      if (systemProp != null) {         loadProperties(systemProp);      }생성자 에는 기본적으로 Hikari 에서 제공하는 상수들을 기본 값으로 초기화하는 것을 볼 수 있고, 그 이후에 위의 코드를 볼 수 있다.해당 부분은 System.getProperty 라는 것을 통해 property라는 설정 사항을 추상화 해놓은 Property 인스턴스를 얻어옴을 볼 수 있다. 만약 null 이라면 그냥 지나치며, 아니라면 loadProperties 로 넘어가게 된다.HikariDataSourceHikariDataSource 를 보기 전에 구현하고 있는 인터페이스인 DataSource 를 보자.원래 DataSource 는 DB 를 연결하여 객체를 얻는 방법을 추상화한 인터페이스인데, 자바에서는 DriverManager.getConnection 으로 매번 직접 커넥션을 작성해야 했다. 하지만 이거는 다음과 같은 단점이 있다:  매번 새로운 커넥션을 만들 때 비용이 큼  커넥션 풀링(pooling) 이나 트랜잭션 관리 같은 고급 기능을 붙이기 어려움  설정 정보(URL, 사용자, 비밀번호) 가 코드에 박혀서 재사용성이 떨어지며, 보안적으로도 문제가 있음이런 문제를 해결하기 위해 JDBC 2.0 에서 javax.sql.DataSource 가 도입된다.Connection getConnection() throws SQLException위와 같은 인터페이스가 있으며 우리는 설정 정보만 다른 파일에 입력해주고, dataSource.getConnection() 만 호출한다면 실제 구현체에 따라 적절한 커넥션을 반환받게 된다.HikariDataSource 는 DataSource 를 구현하는 구현체이다. 뜯어보면, HikariConfig 를 확장하고 있고, 이 말은 HikariConfig 가 가지고 있는 모든 설정 정보들을 가져올 수 있다는 의미이다.public class HikariDataSource extends HikariConfig implements DataSource, Closeable{   private static final Logger LOGGER = LoggerFactory.getLogger(HikariDataSource.class);   private final AtomicBoolean isShutdown = new AtomicBoolean();   private final HikariPool fastPathPool;   private volatile HikariPool pool;여기서 얻어갈 것들은 자바 프로그래밍에서의 다양한 기법들을 얻을 수 있다. 나머지는 그냥 제공해주는 것을 이용하면 되는 부분이며, 그 안에 코드를 어떻게 짜서 넣었는지를 보자.Initialization-on-demand Holder Idiomclass Foo {    private static class Holder {        public static final Foo INSTANCE = new Foo();    }    public static Foo getInstance() {        return Holder.INSTANCE;    }}싱글턴을 가져가는 코드 방식 중 하나이다. 여기서는 nested class 를 썼는데, 이때 객체가 클래스 로더 단위로 하나만 생성되게 된다.또한 Holder 내부에서 초기화를 딱 한 번만 하게 되며, new Foo() 방식으로 초기화하기 때문에 지연 초기화 기능도 가져가게 된다. 당연하게도 static final 하기에 스레드 안전이 자동으로 보장되게 된다.  코드가 깔끔  스레드 안전 + 지연 초기화 자동 보장  synchronized 사용이 없어 성능이 최적화 됨Double-Checked Locking위 글을 보면 J2SE 5.0 부터 volatile 키워드는 메모리 배리어(memory barrier)를 만들도록 정의되었는데, 이를 통해 여러 스레드가 싱글턴 인스턴스를 올바르게 다루도록 보장하는 코딩을 칠 수 있게 되었다.// Works with acquire/release semantics for volatile in Java 1.5 and later// Broken under Java 1.4 and earlier semantics for volatileclass Foo {    private volatile Helper helper;    public Helper getHelper() {        Helper localRef = helper;        if (localRef == null) {            synchronized (this) {                localRef = helper;                if (localRef == null) {                    helper = localRef = new Helper();                }            }        }        return localRef;    }    // other functions and members...}Java 1.5 이상에서의 코드에서 안전하게 동작하는 코드이며, Helper 라는 volatile(최신 값을 읽을 수 있는, 가시성을 보장하는) 로 선언되었고, 초기화 과정에서 reordering 을 방지하기 때문에 수정할 때 다른 스레드가 접근하지 못하게 한다.이때 Helper 를 반환하고 싶은 메서드가 있을 때(지연 초기화를 하고 싶을때), localRef 로 helper 의 주소값을 참조해온다. 이는 멀티 스레드 환경에서 성능을 최적화하기 위해서 임시로 가져오는 것이다(volatile 필드를 여러 번 읽는 것보다 로컬 변수에 복사 후 사용하는게 효율이 좋음).그 후 helper 가 초기화되지 않았다면, 해당 객체를 기준으로 동기화 블록을 시작한다. 즉, 여러 스레드가 동시에 들어왔을 때, 한 번만 객체를 생성하도록 보장한다. 이때 localRef 를 통해 helper 값을 다시 한 번 확인하는데, 이유는 critical criteria 안에 들어오기 전에 다른 스레드가 이미 helper 를 초기화 했을 수도 있기 때문에 두 번 체크하게 되는 것이다.따라서 첫 번째는 전역 스레드에서 값을 체크, 두 번째는 동기화 블럭 안에서 오로지 체크가 되게 된다. 이렇게 되면 synchronized 에 들어오기 전에 첫번째 localRef == null 검사 때 통과를 하였더라도 synchronized 에서 두 번째 초기화가 안되게 걸러지게 된다.그 이후 helper = localRef = new Helper(); 를 통해 값을 동시에 할당시키면 된다.  이를 통해 성능이 최대 40% 까지 오른다고 한다.위 두가지 방식은 둘 다 괜찮은 방법이지만, 유지보수성이나 코드 가독성 측면에서는 nested class 를 사용하는 Initialization-on-demand Holder Idiom 이 훨씬 좋아보인다.FastList그 다음으로 모듈 내에서 가져갈 수 있는 최적화 방식은 FastList 가 있었다.@Overridepublic boolean add(T element){    if (size &lt; elementData.length) {        elementData[size++] = element;   // 범위 체크 없이 바로 추가    }    else {        // 배열 크기 확장        final var oldCapacity = elementData.length;        final var newCapacity = oldCapacity &lt;&lt; 1;        @SuppressWarnings(\"unchecked\")        final var newElementData = (T[]) Array.newInstance(clazz, newCapacity);        System.arraycopy(elementData, 0, newElementData, 0, oldCapacity);        newElementData[size++] = element;        elementData = newElementData;    }    return true;}  System.arraycopy(Object src, int srcPos, Object dest, int destPos, int length): 복사할 원본 배열 src 에, 원본 배열에서 복사 시작 위치 srcPos 부터 복사할 대상 배열 dest 을 복사해서 넣고, 대상 배열에서 붙여넣기 시작 위치 destPos 에서 부터 복사할 요소 수 length 만큼 복사하게 된다.          결국엔 둘은 같게 된다. 하지만 dest 가 현재 더 많은 메모리를 할당받을 수 있게 했기 때문에 메모리 용량만 다르다.      요소를 제거할 때도 해당 리스트는 굉장히 빠른데, 다음과 같다.@Overridepublic T remove(int index) {    final T old = elementData[index];    final var numMoved = size - index - 1;    if (numMoved &gt; 0) {        System.arraycopy(elementData, index + 1, elementData, index, numMoved);    }    elementData[--size] = null;    return old;}중간 요소 제거 시에 실제 제거를 하지 않고 System.arraycopy 를 통해 덮어쓰는 연산을 수행하고, 해당 함수는 JVM 내부에서 최적화된 네이티브 코드(C/C++) 로 구현되어 있어 빠를 수 있는 것이다.Effectively Final자바 8 이후에 도입된 개념으로, 명시적으로 final 을 붙이지 않아도 사실상 final 처럼 동작하는 변수를 effectively final 이라고 한다.즉, 한 번 초기화 된 이후 값이 바뀌지 않으면 effectively final 이며, 이는 람다 또는 익명 클래스에서 사용할 수 있는 값이 되게 된다.✒️ 용어varvar 예약어는 Java 10 에서 처음 도입되었고, 지역 변수를 선언할 때 컴파일러가 타입을 추론하게 해주는 키워드인데, 개발자가 명시적으로 타입을 적지 않아도 컴파일러가 초기값을 보고 타입을 결정하게 된다.잘못된 예var x; // ❌ 컴파일 에러, 초기값이 필요함class Test {    var field = 10; // ❌ 컴파일 에러, 지역 변수가 아님}잘된 예var map = new HashMap&lt;String, List&lt;Integer&gt;&gt;(); // 대신에 HashMap&lt;String, List&lt;Integer&gt;&gt; map = new HashMap&lt;&gt;(); 라고 써야 함  코드 간결성 증가  타입 길거나 복잡할 때 코드 가독성 개선주의 사항  타입 추론은 컴파일 타임에 결정되기 때문에 런타임에는 타입이 바뀌지 않음  null 로 초기화하면 타입을 추론할 수 없어 사용할 수 없음."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 21일차 SQL 심화",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/database/2025/09/16/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-21%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-16",
      "content": "📂 목차  SQL 명령 정리  INDEX 깊이 있게 다루기          EXPLAIN      FULLTEXT INDEX                  MATCH … AGAINST 구문          제약사항                      Data Types 심화          Date and Time Types in SQL      Default Values      Large-Object Types      User-Defined Types                  Domain          Generating Unique Key Values                      JDBC          Connecting to the DB      Statement      Exception      PreparedStatement      Callable Statements                  자동 생성된 키 가져오기                    📚 본문SQL 명령 정리  CREATE TABLE: 테이블 생성  ALTER TABLE: 테이블 구조 변경  DROP TABLE: 테이블 삭제  RENAME: 이름 변경  TRUNCATE: 테이블의 모든 데이터 삭제  COMMENT: 테이블에 설명 추가INDEX 깊이 있게 다루기인덱스는 테이블의 검색 속도를 향상시키기 위해 특정 컬럼에 대해 생성하는 자료구조이다.-- 복합 인덱스 생성create index emp_name_sal_idxon employees(name, salary);-- 인덱스 확인show index from employees;-- 인덱스 삭제alter table employeesdrop index emp_name_sal_idx;  유니크 값이 많은 컬럼이 효율적이다.이제 인덱스 실행 계획을 보자.EXPLAIN쿼리의 성능을 분석하고 병목 구간을 찾기 위해 사용하는 구문이다. db 가 테이블 스캔 방식이나 인덱스 사용 여부, 조인 순서 등을 어떻게 결정했는지 확인이 가능하다.-- 인덱스 사용 전EXPLAIN SELECT * FROM employees WHERE hire_date = '2005-01-01';-- 인덱스 생성CREATE INDEX emp_hire_idx ON employees(hire_date);-- 인덱스 사용 후EXPLAIN SELECT * FROM employees WHERE hire_date = '2005-01-01';  여기서 index 로 설정된 열의 값을 where 절에서 변질시키면 안된다. 예를들어서 index 가 있는 name 이라는 속성을 where 절에 썼다고 해보자. 그러면 substring(name, 1, 1) 등으로 이를 변질시키면 index 를 사용하지 못하게 된다. LIKE 를 써서 이를 변질시키지 말고 해야한다.FULLTEXT INDEX문자열 컬럼(CHAR, VARCHAR, TEXT)를 대상으로 빠른 키워드 검색을 지원하는 인덱스이다. LIKE '%keyword%' 보다 훨씬 효율적이고, 자연어 처리 기반으로 동작하며, 단어 단위로 인덱스를 생성한다.  MySQL 5.6 이상에서 InnoDB 엔진에서도 FULLTEXT 지원-- 테이블 생성할 때 생성create table t1 (    varchar(36) id primary key,    varchar(20) username not null,    varchar(255) password not null,    text introduction not null,    fulltext idx_intro (introduction));-- 테이블 생성 후 인덱스 생성create fulltext index idx_introon t1(introduction)MATCH … AGAINST 구문fulltext 로 인덱스를 생성했다면 해당 컬럼에 대한 검색을 수행할 수 있다.-- 자연어 모드select * from t1where match(introduction)against('hello, ');-- boolean 모드select * from t1where match(introduction)against('+hello -name' in boolean mode);-- query expansion 모드select * from articlewhere match(introduction)against('database' with query expansion);  Natural Language Mode: 단어의 등장 빈도(TF-IDF) 기반으로 점수 계산 -&gt; 연관도 높은 순으로 결과를 반환  Boolean Mode: +(필수 포함), -(제외), *(와일드카드), “(정확히 일치)  Query Expansion: 첫 검색 결과의 연관 단어들을 다시 확장하여 검색(추천 검색과 유사)제약사항이러한 FULLTEXT 는 다음과 같은 제약사항을 따른다.  ft_min_word_len 보다 짧으면 인덱싱이 안됨          최소 단어 길이 변수는 MySQL 서버 시스템 변수를 따라가며 기본값은 4로 되어 있다.      DB 서버 재시작 후 다시 적용해야 한다(rebuilding 필요)        기본적으로 불용어(a, an, the, …)등은 기본적으로 무시한다  collation 의 문자 정렬 규칙에 따라 대소문자 구분 여부를 정할 수 있다.          utf8_general_ci: 대소문자는 구분하지 않음      utf8_bin 계열: 대소문자 구분        영어/라틴 문자 중심으로 설계가 되어서 한국어/일본어/중국어 등등의 언어들은 n-gram 파서를 활성화해야 한다.collation-- Collations 확인show full columns from t1;-- 변경alter table t1modify introduction varchar(255)collate utf8_bin;n-gram 사용-- MySQL 5.7 부터 지원create fulltext index idx_teston t1(introduction)with parser ngram;Data Types 심화Date and Time Types in SQL  date: 연도, 월, 일  time: 시, 분, 초, time(p) 사용 시 초의 소수 자릿수를 지정 가능 또한 time with timezone 을 사용시 시간대 정보도 함께 저장 가능  timestamp: 날짜와 시간을 결합, timestamp(p) 도 사용가능(기본값 6), timestamp with timezone 을 지정 시 시간대 정보도 함께 저장중요  MySQL 은 datetime 타입을 제공해저서 timestamp with timezone 과 같은 기능을 얻을 수 있다.Default Valuesdefault 는 속성에 기본값을 지정하도록 하는 제약조건이다. create 문에서 지정할 수 있으며, 다음과 같이 선언한다.create table student(  ID varchar(5),  name varchar(20) not null,  dept_name varchar(20),  tot_cred numeric(3,0) default 0,  primary key (ID));tot_cred 속성의 기본값은 0이기에 레코드를 삽입할 때, 값을 제공하지 않으면 자동으로 0으로 설정된다.Large-Object Types사진, 고해상도 의료 이미지, 동영상 등과 같은 큰 데이터 항목을 도메인으로 갖는 속성을 저장하고 싶을 때는 다음을 사용한다:  CLOB: 문자 데이터용 대형 객체  BLOB: 이진 데이터용 대형 객체book_review CLOB(10KB)image BLOB(10MB)movie BLOB(2GB)여기서 이들을 결과로 내보낼때 대형 객체를 메모리 상에 올리는 것은 현실적으로 불가능하기에 이 대신 Locator 라는 것을 주고 로케이터를 통해 어플리케이션이 작성된 호스트 언어에서 객체를 참조하는 형태로 조작하게 된다.  운영체제의 read 와 유사하다.User-Defined TypesSQL 은 두 가지 형태의 사용자 정의 데이터 타입을 지원한다.  distinct type  structured data type: 중첩된 레코드 구조, 배열, 멀티셋 등distinct typecreate type Dollars as numeric(12,2) final;create type Pounds as numeric(12,2) final;create table department(  dept_name varchar(20),  building varchar(15),  budget Dollars);  개념적으로 서로 달라야 하지만 타입은 유사한 것들은 distinct type 을 쓰자.단점으로는 위 예시에서는 (department.budget + 20) 이라는 표현식이 strong type checking 때문에 허용되지 않는 표현식이다. 따라서 다음 식을 통해 바꾸는 것을 수행해줘야 한다.cast(department.budget as numeric(12,2))이렇게 하면 숫자로 바꿔서 결과를 낼 수 있지만 이를 다시 저장할 때는 또 바꿔줘야 한다.Domain이 대안으로 domain 을 만들 수 있는데,create domain DDollars as numeric(12,2) not null;DDollars 는 다음 차이점이 있다.Domain 특징  Dollars 와는 달리 not null 제약조건을 추가가능, primary key 로 정의 가능  강력한 타입이 아니기 때문에 기본 타입이 호환되는 한 한 도메인 타입의 값을 다른 도메인 타입에 할당할 수 있음예시-- 범위 제한create domain YearlySalary numeric(8,2)constraint salary_value_test check(value &gt;= 29000.00);-- 특정 값으로의 제한create domain degree_level varchar(10)constraint degree_level_testcheck (value in ('Bachelors', 'Masters', 'Doctorate'));Generating Unique Key Values표준 SQL 에서는 다음과 같이 값을 unique 하게 생성하여 저장할 수 있도록 하는 옵션이 있다.ID number(5) generated always as identity여기서 주의할 점은 이는 숫자형 키 값에 대해서만 작동한다.generated as identity  PostgreSQL: SERIAL 을 쓴다.  MySQL: AUTO_INCREMENT 를 쓴다.JDBC이제 이 sql 서버를 구동중이고 이를 다루는 다양한 기술들 중 JDBC를 본다.기본적으로 sql 만으로는 표현할 수 있는 것에 한계가 있기 때문에 이러한 쿼리를 작성하려고 하면 embedded 하여 사용해야 한다. 또한, 비선언적 작업은 SQL 만으로 수행할 수 없다. 따라서 보고서를 출력하거나, 사용자와 상호작용하거나, 쿼리를 GUI 에 전달하는 등의 작업이다. 나머지 구성 요소는 범용 프로그래밍 언어로 작성되므로 통합된 어플리케이션을 만드려면 SQL 과 범용 프로그래밍 언어를 결합할 수단이 필요하다.이때 JDBC를 활용하여 SQL 과 소통을 할 수 있다.Connecting to the DB// https://mvnrepository.com/artifact/mysql/mysql-connector-javaimplementation 'mysql:mysql-connector-java:8.0.33'우선 위를 gradle.build 에 넣어 mysql driver 를 추가하자.Java 에서 java.sql 패키지에서는 db 와 연결할 수 있는 커넥션이라는 인터페이스를 제공한다. 여기서 커넥션의 설정을 DriverManager 로 설정하고 설정된 Connection 을 가져올 수 있다.Connection = DriverManager.getConnection(    \"jdbc:mysql://localhost:3306/hr\", // url    userid, // user    passwd // password);  url 매개변수: 서버가 실행중인 url, 포트 번호, db 이름 을 차례대로 입력해주면 해당 DB로 넘어가게 된다. db 는 생략되도 된다.  user 매개변수: 문자열을 넣고 db 사용자 id 를 입력  password 매개변수: 유저에 대한 비밀번호이다. 보통은 Java 에 직접치지 않고 따로 저장하여 운용한다.  오라클 프로토콜은 jdbc:oracle:thin 이다.StatementDB 연결이 됐다면, 이제 SQL 문을 실행할 준비가 된 것이다.java 에서는 이 DB에게 명령을 내리기 위해 Statement 클래스가 있는데, 이를 통해서 전송하고 실행할 수 있게 된다.Statement stmt = conn.createStatement();stmt.executeUpdate(\"insert into instructor values(’77987’,’Kim’,’Physics’,98000)\");Statement 는  executeQuery()  executeUpdate()메서드를 가지고 있어 이를 호출할 수 있는데 query 로 메서드를 실행하면 ResultSet 을 반환하며, 쿼리문이 아닌 문장은 결과 집합을 반환하지 않고 int 를 반환하게 된다. 이때는 삽입, 갱신, 삭제 된 튜플 수를 반환하게 된다.  업데이트 값이 너무 많아 int 값 범위를 벗어날 때, executeLargeUpdate() 를 쓸 수 있다.ExceptionSQL 메서드를 실행할 때에는 반드시 예외처리를 해주어야 하는데, SQLException 의 처리를 통해 try-catch 를 해주면 되겠다.또한, Connection, Statement, 기타 JDBC를 여는 객체는 시스템 자원을 소모하기 때문에 프로그래머는 반드시 close() 를 호출해주어야 한다. 이때는 try-resource-with 과 함께 사용한다.PreparedStatementStatement 만 계속 사용하면 특정 sql 문장을 여러개 사용하고 싶을때, 수행하고 싶은 만큼의 문장들을 선언해주어야 한다. 이를 방지하기 위해 java 에서는 PreparedStatement 를 제공해준다.conn.prepareStatement(\"insert into instructor values(?,?,?,?)\");? 를 파싱하여 다른 값들로 대체하여 넣을 수 있도록 해준다.pStmt.setString(1, \"88877\");pStmt.setString(2, \"Perry\");pStmt.setString(3, \"Finance\");pStmt.setInt(4, 125000);pStmt.executeUpdate();pStmt.setString(1, \"88878\");pStmt.executeUpdate();마지막에서는 1번 파라미터만 88878 로 바꾸고 나머지는 동일하게 한 후 실행하게 할 수 있다.Callable StatementsDBMS 측에 선언된 함수와 프로시저에 대한 수행을 하라고도 할 수 있다.CallableStatement cStmt1 = conn.prepareCall(\"{? = call some_function(?)}\");CallableStatement cStmt2 = conn.prepareCall(\"{call some_procedure(?,?)}\");자동 생성된 키 가져오기add, update, delete 와 같은 처리는 반환 값이 굳이 없어도 되지만(boolean 으로 처리 완료를 나타내는 값을 반환하기도 한다), 가끔 DB 자체에서 생성하는 고유한 ID 들은 프로그래밍 단에서는 ID를 생성하지 않기 때문에 가져올 수 없다. 이 기본키가 가장 중요한 값인데, 이를 가져오지 못하면 저장한 행에 대해 후처리를 할 수가 없다. 이를 위해서  Statement 에서는 RETURN_GENERATED_KEYS 를 제공하고 있다.사용법은 다음과 같다:public Long insertAndGetId(String email, String name, String password) {    String sql = \"INSERT INTO user (email, name, password) VALUES (?, ?, ?)\";    Long generatedId = null;    try (Connection conn = getConnection();         PreparedStatement ps = conn.prepareStatement(sql,                 Statement.RETURN_GENERATED_KEYS)) {        ps.setString(1, email);        ps.setString(2, name);        ps.setString(3, password);        int updateCount = ps.executeUpdate();        // 생성된 키 가져오기        if (updateCount &gt; 0) {            try (ResultSet rs = ps.getGeneratedKeys()) {                if (rs.next()) {                    generatedId = rs.getLong(1);                }            }        }    } catch (SQLException e) {        e.printStackTrace();    }    return generatedId;}"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 20일차 DDL",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/database/2025/09/12/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-20%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-12",
      "content": "📂 목차  DDL 심화          ALTER TABLE        MySQL 데이터 타입  NULL 타입  Unknown 타입  인덱스 최적화  설계 단계  트랜잭션 제어📚 본문DDL 심화ddl 을 이제 응용 관점에서 살펴보기 전에 기본적인 MySQL 이 지원하는 데이터 타입이 얼마나 있는지 보자.ALTER TABLEALTER TABLE tbl_name    [alter_option [, alter_option] ...]    [partition_options]ALTER TABLE 은 위 문법을 따르게 된다. alter_option 을 여러개 나열시키게 된다.alter_option: {    table_options  | ADD [COLUMN] col_name column_definition        [FIRST | AFTER col_name]  | ADD [COLUMN] (col_name column_definition,...)  | ADD {INDEX | KEY} [index_name]        [index_type] (key_part,...) [index_option] ...  | ADD {FULLTEXT | SPATIAL} [INDEX | KEY] [index_name]        (key_part,...) [index_option] ...  | ADD [CONSTRAINT [symbol]] PRIMARY KEY        [index_type] (key_part,...)        [index_option] ...  | ADD [CONSTRAINT [symbol]] UNIQUE [INDEX | KEY]        [index_name] [index_type] (key_part,...)        [index_option] ...  | ADD [CONSTRAINT [symbol]] FOREIGN KEY        [index_name] (col_name,...)        reference_definition  | ADD [CONSTRAINT [symbol]] CHECK (expr) [[NOT] ENFORCED]  | DROP {CHECK | CONSTRAINT} symbol  | ALTER {CHECK | CONSTRAINT} symbol [NOT] ENFORCED  | ALGORITHM [=] {DEFAULT | INSTANT | INPLACE | COPY}  | ALTER [COLUMN] col_name {        SET DEFAULT {literal | (expr)}      | SET {VISIBLE | INVISIBLE}      | DROP DEFAULT    }  | ALTER INDEX index_name {VISIBLE | INVISIBLE}  | CHANGE [COLUMN] old_col_name new_col_name column_definition        [FIRST | AFTER col_name]  | [DEFAULT] CHARACTER SET [=] charset_name [COLLATE [=] collation_name]  | CONVERT TO CHARACTER SET charset_name [COLLATE collation_name]  | {DISABLE | ENABLE} KEYS  | {DISCARD | IMPORT} TABLESPACE  | DROP [COLUMN] col_name  | DROP {INDEX | KEY} index_name  | DROP PRIMARY KEY  | DROP FOREIGN KEY fk_symbol  | FORCE  | LOCK [=] {DEFAULT | NONE | SHARED | EXCLUSIVE}  | MODIFY [COLUMN] col_name column_definition        [FIRST | AFTER col_name]  | ORDER BY col_name [, col_name] ...  | RENAME COLUMN old_col_name TO new_col_name  | RENAME {INDEX | KEY} old_index_name TO new_index_name  | RENAME [TO | AS] new_tbl_name  | {WITHOUT | WITH} VALIDATION}ALTER table_name 문은 기본적으로 가져가고, 그 이후에 나오는 alter_option 이 핵심임을 기억하고 sql 문을 짠다.                              ADD [COLUMN] col_name column_definition [FIRST          ALTER col_name]: 컬럼을 새로 추가                                                  CHANGE [COLUMN] old_col_name new_col_name [FIRST          ALTER col_name]: 컬럼 이름 및 데이터 타입 변경 시 사용                                                  MODIFY [COLUMN] col_name column_definition [FIRST          ALTER col_name]: 컬럼 이름 및 데이터 타입 변경 시 사용                      DROP [COLUMN] col_name  ALTER [COLUMN] col_name {  SET DEFAULT {literal | (expr)}| SET {VISIBLE | INVISIBLE}| DROP DEFAULT}: 기본값 가시성 설정인덱스 수정                              ADD {INDEX          KEY} [index_name] (key_part,…) [index_option …]                                                  DROP {INDEX          KEY} index_name                                                  ADD {FULLTEXT          SPATIAL} [INDEX          KEY] …                    제약조건 수정  ADD [CONSTRAINT [symbol]] PRIMARY KEY(…)  ADD [CONSTRAINT [symbol]] UNIQUE(…)  ADD [CONSTRAINT [symbol]] FOREIGN KEY(…)  DROP PRIMARY KEY  DROP FOREIGN KEY fk_symbolMySQL 데이터 타입            분류      타입      설명                  숫자형      INT, BIGINT, DECIMAL      정수, 실수              문자형      VARCHAR, CHAR, TEXT      문자열              날짜형      DATE, TIME, DATETIME, TIMESTAMP      날짜와 시간              기타      JSON, BLOB      JSON 데이터, 바이너리      NULL 타입null 은 의미적으로 분명하지만, 연산하는데 있어 정의가 직관적이지 않아 문제를 일으킨다.  산술 식(+, -, *, /) 에서 결과는 입력값이 하나라도 NULL 이면 결과도 NULL  비교 연산에서는 NULL 이 포함되면 unknown(알 수 없음) 값으로 처리한다. 즉 논리 리터럴에 대해 true, false, unknown 이 3가지의 논리값으로 처리된다.Unknown 타입  true and unknown: unknown  false and unknown: false  true or unknown: true  false or unknown: unknown  not unknown: unknown  null = null: unknown  어떤 값인지 모르기에 unknown 으로 나오는건 당연한 의미이다. 또한 처리할 때 (‘A’, NULL), (‘A’, NULL) 은 동일한 값이기에 distinct 옵션을 쓸 때 두 튜플 중 하나만 남게 된다.unknown 처리 예시select namefrom instructorwhere salary &gt; 10000 is unknown;인덱스 최적화  인덱스 사용 시 주의사항          컬럼의 좌변을 변형하면 인덱스를 사용할 수 없음                  ❌ WHERE SUBSTRING(hire_date, 1, 4) = '2005'          ✅ WHERE hire_date LIKE '2005%'                      복합 인덱스 활용          자주 함께 조회되는 컬럼들을 묶어서 인덱스 생성      WHERE절에서 사용 빈도가 높은 컬럼 순서대로 인덱스 구성      선택도가 높은(데이터 분포가 다양한) 컬럼을 앞쪽에 배치        인덱스 성능 관리          SHOW INDEX FROM 테이블명 : 인덱스 상태 확인      EXPLAIN 쿼리 : 실행 계획 분석      불필요한 인덱스는 제거 → INSERT/UPDATE 성능 저하 방지      설계 단계  요구조건 분석: 데이터 및 처리 요구 조건  개념적 설계: E-R 다이어그램, DBMS 독립적  논리적 설계: 정규화, 목표 DBMS에 맞는 스키마  물리적 설계: 반정규화, 인덱스 설계  구현: DDL로 스키마 작성트랜잭션 제어기본적으로 MySQL은 자동 커밋이 되는데, 트랜잭션 제어를 위해 AUTOCOMMIT 옵션을 수정하여 수동으로 커밋을 관리할 수 있다.SELECT @@AUTOCOMMIT;SET AUTOCOMMIT = 0;START TRANSACTION;INSERT INTO user (email, name, password)VALUES ('test@test.com', '테스트', '1234');COMMIT; -- 변경사항 확정ROLLBACK; -- 변경사항 취소, START TRANSACTION 이전으로 돌아감SET AUTOCOMMIT = 1;정확히는 START TRANSACTION 이후의 INSERT, DELETE, UPDATE 등의 데이터 변경 수행만 취소하게 된다.이때 SET AUTOCOMMIT 을 하는 것은 해당 열려있는 세션에 대해 설정이 변경되는 것이다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 19일차 SQL JOIN, Schema, Key",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/database/2025/09/11/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-19%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-11",
      "content": "📂 목차  JOIN          CROSS JOIN      INNER JOIN                  JOIN 성능 측면                    OUTER JOIN      SELF JOIN        Sub Query  Correlated Subquery  다양한 기능들          Set Operation      Window 함수        Schema          Relation Schema      Key                  Candidate Key          Primary Key          Foreign Key                      Schema Diagrams  Relational Query Languages          SQL Languages Parts        SQL Data Definition          Basic Types      Basic Schema Definition      📚 본문JOINJOIN은 여러 테이블의 데이터들을 연결시켜 하나의 결과 집합으로 만드는 방법이다.table_references:    escaped_table_reference [, escaped_table_reference] ...escaped_table_reference: {    table_reference  | { OJ table_reference }}table_reference: {    table_factor  | joined_table}table_factor: {    tbl_name [PARTITION (partition_names)]        [[AS] alias] [index_hint_list]  | [LATERAL] table_subquery [AS] alias [(col_list)]  | ( table_references )}joined_table: {    table_reference {[INNER | CROSS] JOIN | STRAIGHT_JOIN} table_factor [join_specification]  | table_reference {LEFT|RIGHT} [OUTER] JOIN table_reference join_specification  | table_reference NATURAL [INNER | {LEFT|RIGHT} [OUTER]] JOIN table_factor}join_specification: {    ON search_condition  | USING (join_column_list)}join_column_list:    column_name[, column_name] ...index_hint_list:    index_hint[ index_hint] ...index_hint: {    USE {INDEX|KEY}      [FOR {JOIN|ORDER BY|GROUP BY}] ([index_list])  | {IGNORE|FORCE} {INDEX|KEY}      [FOR {JOIN|ORDER BY|GROUP BY}] (index_list)}index_list:    index_name [, index_name] ...MySQL 문법 정의서 인데, FROM 절에서 테이블 참조 를 어떻게 쓸 수 있는지에 대한 규칙을 나열한 것이다. SELECT 문에서도 당연히 봤을 것이다.CROSS JOIN카테시안 곱이며, 그냥 가능한 모든 조합의 경우를 결과로 내뱉는다. 하지만 이는 잘 사용하지 않으며, 여러 열이 있다면 굉장히 많은 행이 생성되므로 성능적으로 문제가 있다.크로스 조인은 그냥 두 테이블을 FROM 절에 놓으면 된다.SELECT *FROM customers c, orders o;  -- 조인 조건 없음보통은 JOIN 을 할 때는 그래서 조건을 주는게 오버헤드가 없다.  만약 여러 테이블을 JOIN한다면, N개의 테이블을 JOIN할 때 최소 (N-1)개의 조인 조건이 필요, 그래야 불필요한 Cartesian Product 를 방지할 수 있다.INNER JOIN-- 전통적인 조인 방식SELECT     e.first_name,    e.last_name,    d.department_nameFROM     employees e,     departments dWHERE     e.department_id = d.department_id;예전에는 위처럼 코딩을 했지만, 테이블을 FROM 에 나열하고 WHERE 조건을 지정하게 되면 조인 조건과 필터 조건이 섞여 있어서 헷갈릴 수가 있다. 또한 실수로 조인 조건을 빼먹으면 CROSS JOIN 이 되어버려 모든 조합의 데이터가 만들어지게 된다.따라서 지금은 ANSI SQL 표준 JOIN 문법을 사용한다.-- JOIN ~ ONSELECT     e.first_name,    e.last_name,    d.department_nameFROM employees eJOIN departments d ON e.department_id = d.department_id;-- JOIN ~ USING (동일한 컬럼명일 때)SELECT     e.first_name,    e.last_name,    d.department_nameFROM employees eJOIN departments d USING(department_id);-- NATURAL JOIN (자동으로 같은 이름 컬럼 조인)SELECT * FROM employees NATURAL JOIN departments;JOIN 성능 측면INDEXINGINNER JOIN 은 조건이 잘 걸려있으면 효율적이다. 예를 들어 대상 테이블의 index 가 걸려있었다고 해보자. 이때 필터링을 주는 테이블의 값들을 기준으로 이들을 찾아내기만 하면 되는데, 찾아낼 때도 searching 작업이 필요하기에 여기에 index 를 걸어주면 더 빠르게 찾아낼 수 있게 되는 것이다.indexing 이 안걸려 있었다면 searching 작업이 느려지게 되어서 성능 이점을 볼 수가 없게 된다. 또한 JOIN 없이 쓰면 기본적으로 cartesian 이 수행되는데 이는 굉장히 느리다. JOIN 이 있기에 가능하다.테이블 크기와 순서에 따른 성능조인하는 테이블이 크면 클수록 성능 영향이 크다. 일부 DBMS는 조인 순서를 바꿔 최적화하는 기능이 있어 상관이 없지만, 큰 테이블을 먼저 JOIN 하면 임시 테이블이 커져서 느려질 수 있게 된다.예를 들어 customers 테이블에 1000 개의 레코드가 있고, orders 테이블에 1000000 레코드가 있다고 하자.-- orders(100만 행) 기준으로 먼저 customers 와 JOINSELECT o.id, o.order_date, c.nameFROM orders oJOIN customers cON o.customer_id = c.id;무조건 대상 테이블은 작아야 한다. 위처럼 order 테이블을 먼저 가져와버리면 많이 가져온 행에 대해서 검색해야 할 양이 늘어나게 된다. 또한 작은 테이블을 index 를 생성해야 index 크기가 작아져서 검색할 양이 줄어들기에 customers 의 테이블이 먼저 작성되어야 하는 것이다.SELECT o.id, o.order_date, c.nameFROM customers cJOIN orders oON c.id = o.customer_id위처럼 작성해주면 되겠다. 그리고 WHERE 을 써서 넣는다면 대상 테이블 크기가 더 작아져서 더 효율적이게 되겠다. 밑은 그 예시다.-- 특정 VIP 고객의 주문만 찾고 싶을 때SELECT o.id, o.order_date, c.nameFROM customers cJOIN orders oON c.id = o.customer_idWHERE c.vip = true;Sub Query, CTEOUTER JOIN아우터 조인에는 LEFT JOIN 과 RIGHT JOIN 이 있는데 기준만 다를 뿐 둘의 동작 방식은 동일하다.LEFT JOIN 은 왼쪽 테이블의 모든 행이 전부 결과 테이블에 포함되어야 되며 RIGHT JOIN 은 그 반대다.LEFT JOIN-- 부서가 없는 직원도 포함SELECT     e.employee_id,    e.first_name,    d.department_nameFROM employees eLEFT OUTER JOIN departments d ON e.department_id = d.department_id;-- LEFT JOIN으로 축약 가능SELECT     e.employee_id,    e.first_name,    d.department_nameFROM employees eLEFT JOIN departments d ON e.department_id = d.department_id;RIGHT JOIN-- 직원이 없는 부서도 포함SELECT     e.employee_id,    e.first_name,    d.department_nameFROM employees eRIGHT OUTER JOIN departments d ON e.department_id = d.department_id;가령 두 테이블의 튜플들 전부를 결과 테이블에 나오도록, 즉 LEFT, RIGHT 둘 다 되도록 하게 하고 싶을 수 있다. 이를 FULL OUTER JOIN 이라고 하는데 이는 MySQL 에서는 지원하지 않기 때문에 LEFT JOIN, RIGHT JOIN, UNION 을 합쳐서 사용할 수 있겠다.-- 방법 1: LEFT JOIN + RIGHT JOIN + UNIONSELECT     e.employee_id,    e.first_name,    d.department_nameFROM employees eLEFT JOIN departments d ON e.department_id = d.department_idUNIONSELECT     e.employee_id,    e.first_name,    d.department_nameFROM employees eRIGHT JOIN departments d ON e.department_id = d.department_idWHERE e.department_id IS NULL;  -- 중복 제거를 위해 추가Postgres, Oracle 등등-- PostgreSQL, SQL Server, Oracle에서 가능한 구문SELECT     e.employee_id,    e.first_name,    d.department_nameFROM employees eFULL OUTER JOIN departments d ON e.department_id = d.department_id;SELF JOIN자기 자신을 그냥 JOIN 절의 테이블로 넣어버리면 된다.-- 직원과 상사 정보 조회SELECT     e.employee_id AS 사원ID,    e.first_name AS 사원이름,    m.employee_id AS 상사ID,    m.first_name AS 상사이름FROM employees eJOIN employees m ON e.manager_id = m.employee_id;Sub Querynested class 처럼 여기서는 쿼리를 중첩시키도록 할 수 있다. 보통 sub query 는 잘 쓰지는 않는다. 그냥 Join 이 더 최적화에 좋고, 재사용이 어려우며, 디버깅이 불편하다는 단점이 있다. 그럼에도 불구하고 단일 값만을 가져오고 싶을 때는 sub query 를 쓰는게 더 좋을 수도 있고, 상황마다 가끔 쓰긴 한다.Single-row Subquery-- 평균 급여보다 적은 급여를 받는 사원SELECT ename, salFROM empWHERE sal &lt; (    SELECT AVG(sal)    FROM emp);-- 가장 먼저 입사한 사원SELECT ename, hiredateFROM empWHERE hiredate = (    SELECT MIN(hiredate)    FROM emp);Multi-row Subquery-- IN 연산자 사용SELECT ename, sal, deptnoFROM empWHERE deptno IN (    SELECT deptno    FROM dept    WHERE loc IN ('NEW YORK', 'DALLAS'));-- ANY 연산자 사용SELECT ename, salFROM empWHERE sal &gt; ANY (    SELECT sal    FROM emp    WHERE deptno = 30);-- ALL 연산자 사용SELECT ename, salFROM empWHERE sal &gt; ALL (    SELECT sal    FROM emp    WHERE deptno = 30);Correlated Subquery외부 쿼리와 내부 쿼리가 서로 연관되어 있는 서브쿼리이다.-- 자신이 속한 부서의 평균 급여보다 많이 받는 사원SELECT o.ename, o.sal, o.deptnoFROM emp oWHERE o.sal &gt; (    SELECT AVG(i.sal)    FROM emp i    WHERE i.deptno = o.deptno);별 특별할건 없다.다양한 기능들Set Operation  UNION  MINUS  INTERSECTWindow 함수보통 OVER 과 함께 동반되며, 사용할 때는 검색 후에 사용하는게 좋다.  RANK  ROW_NUMBER  DENSE_RANKSchema이제 이론을 들어가보자.데이터를 DB에 저장할 때 그러면 테이블을 각각 만들어줘야 하는데, 이 테이블을 만들기 위해 사전 작업들(설계)이 많이 들어간다.만약 이를 잘못 설계하면 나중에는 데이터 구조 자체를 변경하는데 굉장히 많은 비용이 들어가게 된다(이미 저장되어 있는 데이터 구조를 다른 데이터 구조로 바꿔야 하기 때문). 따라서 초기 설계가 중요하다. 그 기반이 되는 Schema 부터 본다.데이터베이스를 얘기할 때는 항상 스키마 와 인스턴스를 구분해야 한다. 스키마는 DB 의 논리적인 설계를 의미하며, DB 인스턴스는 특정 시점에 DB 안에 담긴 데이터의 snapshot 을 의미한다.데이터를 저장할 때는 relation 에 저장하게 되는데 relation 의 schema 를 보자.Relation Schemarelation 이라는 개념은 프로그래밍 언어에서 변수 개념과 대응되게 되며, 릴레이션 스키마의 개념은 프로그래밍 언어에서의 타입 정의와 대응되게 된다.  Relation - Variable  Relation Schema - Type Definition여기서 relation schema 라는 개념은 속성들과 그에 대응되는 도메인들의 목록으로 구성되게 된다. 각 속성의 도메인에 대한 정확한 정의는 추후에 다룬다.relation instances 의 개념은 프로그래밍 언어에서 변수의 값에 해당하게 된다.  relation schema: section (course_id, sec_id, semester, …)relation instance: (CS-101, 1, Fall, …)Key관계들의 인스턴스들을 보면 모든 행들은 서로 다 달라야 한다. 중복된 값이 계속해서 들어가게 되면 이는 자원 낭비이고 데이터가 우리에게 혼동을 줄 수 있다.따라서 관게는 튜플을 구별할 수 있는 방법을 반드시 가져야 하고, 이는 Super Key 라는 하나 이상의 속성 집합을 써서 각 튜플을 유일하게 식별 가능하다.  $t1 \\neq t2 \\implies t1.K \\neq t2.K$Candidate Key슈퍼키는 불필요한 속성들을 포함 할 수가 있다. 예를들어 ID 와 name 이라는 attr. 를 가지는 테이블 t1 이 있다고 하자.슈퍼키는 ID로 두게 된다면 모든 행들을 고유하게 식별할 수 있지만, (ID, name) 으로 둬도 모든 행들을 고유하게 식별할 수 있다.따라서 만약 K가 슈퍼키라면, K의 어떤 superset 또한 역시 슈퍼키가 된다. 보통 superset 보다는 더 이상 줄일 수 없는 최소 슈퍼키(Minimal Superkey) 에 더 관심을 가지고, 이러한 최소 슈퍼키를 Candidate Key 라고 부르게 된다.여기서 또 다른 후보키의 예시로는 서로 다른 여러 속성 집합이 후보키가 될 수도 있는데, 예를들어 (name, dept_name) 과 ID 두 조합이 수퍼키가 될 수 있다고 해보자. 그러면 둘 다 후보키가 되는 셈이다.Primary Key이러한 후보키 중에서 DB Designer 가 relation 내의 tuple 을 식별하는 주요 수단으로 선택한 것을 Primary Key 로 부르게 된다.  $Super Key \\subset Candidate Key \\subset Primary Key$그리고 Primary Key 를 Relation Schema 로 표기할 때 밑줄을 통해 표현하게 된다.  classroom (building, room_number, capacity)이러한 기본키는 신중하게 선택해야 하는데, primary key 가 매우 드물게 변경되어야 하기 때문이다. 변경이 된다면 다음과 같은 문제가 생긴다.  참조 무결성: 기본키는 다른 테이블의 외래키로 참조될 수 있는데 값이 바뀌면 참조 관계가 깨질 수도 있다. 그렇다고 기본키 값을 업데이트하면 다른 참조하고 있는 외래키를 업데이트하면 되지 않냐고 하는데 이러면 비용적으로 부담이다.  데이터 일관성: 여러 테이블, 인덱스, 뷰, 어플리케이션 코드 등에서 해당 키를 기준으로 데이터를 찾는데, 계속 값이 바뀌면 시스템 전체에서 불일치가 발생할 수 있다.  성능 저하: 기본키는 보통 인덱스로 관리되는데, 기본키 값이 변경되면 인덱스도 다시 갱신해야되며, 대량 업데이트 시에 성능에 큰 영향을 주게 된다.  비즈니스 로직 혼란: 기본 키는 “변하지 않는 식별자” 라는 전제를 기반으로 여러 로직이 설계되기 때문에, 값이 바뀐다면 전제가 무너져 혼란을 초래할 수 있다.primary key 는 그래서 다음과 같은 제약조건이 필요하다.  UNIQUE: 테이블에 오직 하나만 존재  NOT NULL: NULL 값 X  INDEX: 기본키로 등록되면 자동으로 인덱스를 생성한다.Foreign KeyForeign-key Constraints 를 살펴보자. t2 테이블에서 t1 테이블의 속성 값이 필요하다고 해보자. 그런데 해당 값이 t1 의 어디에도 존재하지 않는다면 이는 타당하지 않다. 즉 t2는 t1에 존재하는 값을 가져야 한다.외래키 제약조건은 릴레이션 r1 속성 A 가 릴레이션 r2 의 기본키 B를 참조한다고 할 때, 어떤 데이터베이스 인스턴스에서도 r1 의 각 튜플이 가지는 A 값은 반드시 r2 의 어떤 튜플의 B 값과 일치해야 함을 의미한다.  Referential Integerity:  NULLITY: NULL 값을 가질 수 있음  CASCADE, RESTRICT, SET NULL: 참조 대상이 삭제되거나 변경될 경우 동작을 설정할 수 있음Schema Diagrams  기본키는 밑줄로  릴레이션의 외래키는 참조되는 릴레이션의 기본키로 향하는 화살표로  외래키 제약조건이 아닌 참조 무결성 제약조건을 표현할 때는 양쪽 화살표로  현재는 E-R 다이어그램을 많이 쓴다.Relational Query Languages쿼리 언어는 사용자가 DB 로 부터 정보를 요청할 때 사용하는 언어를 말하는데, 이러한 언어들은 일반적인 프로그래밍 언어보다 높은 수준에서 동작한다.쿼리언어는  imperative(명령형): 사용자가 DB에서 원하는 결과를 계산하기 위해 특정 연산의 순서를 시스템에 지시할 수 있음(일반적으로 상태 변수를 가짐)  functional(함수형): DB의 데이터나 다른 함수의 결과에 대해 동작하는 함수들의 평가(evaluation) 으로 표현된다. side-effect 가 거의 없어 프로그램 상태를 갱신하지 않는다.  declarative(선언형): 구체적인 연산 순서나 함수 호출을 명시하지 않고, 단순히 원하는 정보만을 기술한다.으로 분류할 수 있다.SQL Languages Parts  DDL  DML  Integrity  View Definition  Transaction Control  Embedded SQL &amp; Dynamic SQL  AuthorizationSQL Data DefinitionDB 의 관계들의 집합은 DDL 을 사용하여 지정되는데, SQL DDL 은 단순히 릴레이션 집합뿐 아니라 각 릴레이션에 대한 다양한 정보를 정의할 수 있다.  relation schema  attribute type  integrity constraints  index set  physical storage structure여기서는 스키마와 데이터타입만 보자.Basic Types  char(n): 무조건 n byte 의 문자열이 할당, “ABC” 를 저장시 뒤에 공백 7개 문자가 추가됨  varchar(n): 공백이 추가되지 않음 n 이하의 문자열로 저장 가능  char, varchar 타입을 비교할 때 사용하는 DB 에 따라 직관적으로는 결과가 같아 보여도 실제로는 false, true 가 될 수도 있다. 이러한 문제 때문에 varchar 를 권장하는 편이다. 또한 다국어 데이터 저장을 위해 nvarchar 도 있다.  int  smallint  numeric(p, d): p자리.d자리  real, double precision  float(n)  각 타입은 null 값을 가질 수 있다.Basic Schema Definitioncreate table department(dept_name varchar(20), building varchar(15), budget numeric(12,2), primary key (dept_name));자바랑 동일하게 sql 문은 항상 문장의 끝에 ;가 붙으며, 맨 마지막에 integrity constraints 들을 더 넣을 수 있다(primary key 처럼). 이러한 자주 쓰이는 constriaints 는 다음과 같다:  primary key ($A_1, A_2, …, A_m$)  foreign key ($A_1, A_2, …, A_m$) references  not null다음 장에서 DDL 을 더 자세히 다루자."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 18일차 Database 활용",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/database/2025/09/11/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-18%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-11",
      "content": "📂 목차  System Table/Metadata Table          유저 생성      권한 부여      권한 삭제        SQL 기초          DDL                  CREATE DATABASE          CREATE PROCEDURE and CREATE FUNCTION          CREATE TABLE                    DML                  SELECT          함수          UPDATE          DELETE          INSERT          DO          CALL                      Relational Model          Structure of Relational Databases                  Domain Atomicity          Domain Nullity                    Relational Model 의 한계      📚 본문System Table/Metadata Table보통 기본적으로 생성되어 있는 테이블을 시스템 테이블, 메타데이터 테이블이라고 부른다.여기에는 mysql. 의 명칭으로 시작하는  사용자 계정  권한  스토리지 엔진 정보  테이블 구조등등의 관리에 필요한 정보들이 테이블로 정의되어 있고, 이를 수정하면 사용자 계정이 추가된다던지, 권한이 바뀐다던지 할 때 이 테이블이 수정되게 된다. 하지만 이를 직접 접근해서 수정하면 권한에 문제가 생기기 때문에 보통은 create user / grant / drop user 등으로 관리한다.유저 생성-- 모든 호스트에서 접속 가능한 사용자CREATE USER 'seonghun'@'%' IDENTIFIED BY '1234';-- 로컬에서만 접속 가능한 사용자CREATE USER 'seonghun'@'localhost' IDENTIFIED BY '1234';여기서 seonghun 이라는 user 속성 그리고 host 속성으로는 localhost 로 지정하여 mysql.user 라는 테이블에 유저를 생성함을 볼 수 있다. 이렇게 생성된 유저는 localhost 에서만 접속 가능하다.모든 호스트에서 접속이 가능하게 하려면 전자의 명령어에서 와일드카드 %를 쓰자.권한 부여-- 특정 데이터베이스에 대한 모든 권한GRANT ALL PRIVILEGES ON liondb.* TO 'seonghun'@'%';GRANT ALL PRIVILEGES ON liondb.* TO 'seonghun'@'localhost';GRANT ON TO 문을 사용하여 특정 데이터베이스 개체에 대한 특정 유저의 접근 권한을 설정할 수 있다.위 예제는 liondb 라는 명을 가지는 database 의 하위(테이블, 레코드) 모든 개체에 대한 권한을 주는 것을 볼 수 있다.-- 사용자 확인SELECT user, host FROM mysql.user WHERE user = 'carami';-- 사용자 삭제DROP USER 'carami'@'%';DROP USER 'carami'@'localhost';전자의 명령어는 직접 메타테이블을 조회하는 쿼리이지 수정은 하지 않는다. 따라서 그렇게 주의할 작업은 아니며, 하위 제공되어지는 명령어을 사용하자.권한 해제권한을 주는게 있었다면 권한을 빼는 것도 있어야 한다.-- 모든 권한 취소REVOKE ALL PRIVILEGES ON liondb.* FROM 'carami'@'%';-- 특정 권한만 취소REVOKE INSERT, UPDATE ON liondb.* FROM 'carami'@'%';-- 권한 적용FLUSH PRIVILEGES;여기서 FLUSH PRIVILEGES 가 궁금할 수 있는데 bash 같은 거의 환경 변수 설정 수정을 다 하고 실제로 ./zshrc 와 같이 실행을 시켜줘야 적용되는 것처럼 이 또한 해당 명령어를 넣어주어야 한다.이제 본격적으로 Mysql 을 사용하자.SQL 기초SQL 도 언어이기 때문에 계산이 된다.-- 수식 계산SELECT 3 + 5;SELECT 10 * 2.5;-- 함수 사용SELECT SIN(PI()/4), (4+1)*5;-- 여러 문장 실행SELECT VERSION(); SELECT NOW();-- 여러 줄에 걸쳐 작성SELECT     USER(),    CURRENT_DATE;구문은 보통 ; 로 구분된다. 또한 정해놓은 함수(SIN, COS 등등) 을 사용할 수 있다. 하지만 굳이 이 정도의 계산을 할거였으면 이런 어플리케이션을 만들지 않았을 것이다.DDL데이터 정의어로 테이블을 생성하자.-- employees 테이블 생성CREATE TABLE employees (    employee_id INT(11) UNSIGNED NOT NULL,    first_name VARCHAR(20),    last_name VARCHAR(25) NOT NULL,    email VARCHAR(25) NOT NULL,    phone_number VARCHAR(20),    hire_date DATE NOT NULL,    job_id VARCHAR(10) NOT NULL,    salary DECIMAL(8, 2) NOT NULL,    commission_pct DECIMAL(2, 2),    manager_id INT(11) UNSIGNED,    department_id INT(11) UNSIGNED,    PRIMARY KEY (employee_id));-- 테이블 목록 확인SHOW TABLES;-- 테이블 구조 확인DESC employees;NOT NULL 로 보이는 것이 integrity constraints 중 하나이다.CREATE DATABASECREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name    [create_option] ...정의서를 보면 create database 나 create schema 는 동일하게 동작한다. if not exists 옵션을 통해 이미 같은 데이터베이스가 존재할 시 생성하지 않도록 할 수 도 있다.create_option: [DEFAULT] {    CHARACTER SET [=] charset_name  | COLLATE [=] collation_name  | ENCRYPTION [=] {'Y' | 'N'}}데이터베이스 생성 시 추가 설정 옵션이다. =은 생략 가능하며, 문자열 세트로 사용할 문자 인코딩이나, COLLATE 와 같은 문자 비교 방식(정렬 순서, 대소문자 구분 등) 을 정할 수 있다.  CHARACTER SET: DB 에서 사용할 문자 인코딩 설정  COLLATE: 문자 비교 방식 설정 (정렬 순서, 대소문자 구분 등)  ENCRYPTION: DB 파일 자체를 암호화할지 여부각 옵션에는 DEFAULT 라는 옵션을 넣을 수 있고, charset_name, collation_name 은 다음을 통해 볼 수 있다.SHOW CHARACTER SET;+---------+----------------------+----------------+| Charset | Description          | Default collation |+---------+----------------------+----------------+| utf8mb4 | UTF-8 Unicode        | utf8mb4_0900_ai_ci || latin1  | cp1252 West European | latin1_swedish_ci  |+---------+----------------------+----------------+SHOW COLLATION;+---------------------+---------+---------+----------+---------+| Collation           | Charset | Default | Compiled | Sortlen |+---------------------+---------+---------+----------+---------+| utf8mb4_general_ci  | utf8mb4 | Yes     | Yes      | 1       || utf8mb4_unicode_ci  | utf8mb4 | No      | Yes      | 8       |+---------------------+---------+---------+----------+---------+CREATE PROCEDURE and CREATE FUNCTIONCREATE    [DEFINER = user]    PROCEDURE [IF NOT EXISTS] sp_name ([proc_parameter[,...]])    [characteristic ...] routine_bodyCREATE    [DEFINER = user]    FUNCTION [IF NOT EXISTS] sp_name ([func_parameter[,...]])    RETURNS type    [characteristic ...] routine_bodyproc_parameter:    [ IN | OUT | INOUT ] param_name typefunc_parameter:    param_name typetype:    Any valid MySQL data typecharacteristic: {    COMMENT 'string'  | LANGUAGE SQL  | [NOT] DETERMINISTIC  | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }  | SQL SECURITY { DEFINER | INVOKER }}routine_body:    SQL routine길지만 거의 모든 옵션들이 유사하다. DEFINER 는 프로시저를 정의한 계정을 지정할 수 있다.  ([proc_parameter[,…]]): 입력/출력 파라미터 목록    routine_body; 실제 실행할 SQL 코드 블록function 은 procedure 와 비슷하지만 무조건 반환값이 있어야 한다.[ IN | OUT | INOUT ] param_name type  IN: 입력용  OUT: 출력용  INOUT: 입출력용  type: INT, VARCHAR 등 타입  Any valid MySQL data type: MySQL 에서 지원하는 모든 데이터 타입 가능characteristics{    COMMENT 'string'  | LANGUAGE SQL  | [NOT] DETERMINISTIC  | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }  | SQL SECURITY { DEFINER | INVOKER }}  추후에 공부해도 됨CREATE TABLE가장 중요한 DDL 이다.check_constraint_definition:    [CONSTRAINT [symbol]] CHECK (expr) [[NOT] ENFORCED]reference_definition:    REFERENCES tbl_name (key_part,...)      [MATCH FULL | MATCH PARTIAL | MATCH SIMPLE]      [ON DELETE reference_option]      [ON UPDATE reference_option]reference_option:    RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT하나하나씩 살펴본다.일반 테이블 생성CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name    (create_definition,...)    [table_options]    [partition_options]  TEMPORARY: 임시 테이블 생성  create_definition: 컬럼, 인덱스, 제약 조건 등등 정의  table_options: 문자셋, 정렬, 스토리지 엔진 등 테이블 옵션  partition_options: 파티션 기능 사용 시 옵션table optionstable_options:    table_option [[,] table_option] ...table_option: {    AUTOEXTEND_SIZE [=] value  | AUTO_INCREMENT [=] value  | AVG_ROW_LENGTH [=] value  | [DEFAULT] CHARACTER SET [=] charset_name  | CHECKSUM [=] {0 | 1}  | [DEFAULT] COLLATE [=] collation_name  | COMMENT [=] 'string'  | COMPRESSION [=] {'ZLIB' | 'LZ4' | 'NONE'}  | CONNECTION [=] 'connect_string'  | {DATA | INDEX} DIRECTORY [=] 'absolute path to directory'  | DELAY_KEY_WRITE [=] {0 | 1}  | ENCRYPTION [=] {'Y' | 'N'}  | ENGINE [=] engine_name  | ENGINE_ATTRIBUTE [=] 'string'  | INSERT_METHOD [=] { NO | FIRST | LAST }  | KEY_BLOCK_SIZE [=] value  | MAX_ROWS [=] value  | MIN_ROWS [=] value  | PACK_KEYS [=] {0 | 1 | DEFAULT}  | PASSWORD [=] 'string'  | ROW_FORMAT [=] {DEFAULT | DYNAMIC | FIXED | COMPRESSED | REDUNDANT | COMPACT}  | START TRANSACTION   | SECONDARY_ENGINE_ATTRIBUTE [=] 'string'  | STATS_AUTO_RECALC [=] {DEFAULT | 0 | 1}  | STATS_PERSISTENT [=] {DEFAULT | 0 | 1}  | STATS_SAMPLE_PAGES [=] value  | tablespace_option  | UNION [=] (tbl_name[,tbl_name]...)}넘어간다.create_definitioncreate_definition: {    col_name column_definition  | {INDEX | KEY} [index_name] [index_type] (key_part,...)      [index_option] ...  | {FULLTEXT | SPATIAL} [INDEX | KEY] [index_name] (key_part,...)      [index_option] ...  | [CONSTRAINT [symbol]] PRIMARY KEY      [index_type] (key_part,...)      [index_option] ...  | [CONSTRAINT [symbol]] UNIQUE [INDEX | KEY]      [index_name] [index_type] (key_part,...)      [index_option] ...  | [CONSTRAINT [symbol]] FOREIGN KEY      [index_name] (col_name,...)      reference_definition  | check_constraint_definition}기본적으로 정의서에서 {} 로 되어 있는건 여러 개가 올 수 있다는 의미다.  컬럼 정의: col_name column_definition          여러개 올 수 있음                                    인덱스: INDEX          KEY [index_name] [index_type] (key_part, …) [index_option]                      FULLTEXT / SPATIAL 인덱스: 텍스트 검색 또는 공간 데이터 용  PRIMARY KEY, UNIQUE, FOREIGN KEY 는 가볍게 읽고 넘기자. symbol 은 해당 constraint 명칭이다.indexindex_type:    USING {BTREE | HASH}index_option: {    KEY_BLOCK_SIZE [=] value  | index_type  | WITH PARSER parser_name  | COMMENT 'string'  | {VISIBLE | INVISIBLE}  |ENGINE_ATTRIBUTE [=] 'string'  |SECONDARY_ENGINE_ATTRIBUTE [=] 'string'}BTREE, HASH 둘 중 사용할 수 있는데 보통은 HASH 를 사용하는게 빠르지만, 범위 검색이나 정렬에는 부적합하게 된다. 따라서 대부분 BTREE 를 사용하며 이게 기본값이다.  KEY_BLOCK_SIZE: 인덱스 블록의 크기를 바이트 단위로 지정가능column_definitioncolumn_definition: {    data_type [NOT NULL | NULL] [DEFAULT {literal | (expr)} ]      [VISIBLE | INVISIBLE]      [AUTO_INCREMENT] [UNIQUE [KEY]] [[PRIMARY] KEY]      [COMMENT 'string']      [COLLATE collation_name]      [COLUMN_FORMAT {FIXED | DYNAMIC | DEFAULT}]      [ENGINE_ATTRIBUTE [=] 'string']      [SECONDARY_ENGINE_ATTRIBUTE [=] 'string']      [STORAGE {DISK | MEMORY}]      [reference_definition]      [check_constraint_definition]  | data_type      [COLLATE collation_name]      [GENERATED ALWAYS] AS (expr)      [VIRTUAL | STORED] [NOT NULL | NULL]      [VISIBLE | INVISIBLE]      [UNIQUE [KEY]] [[PRIMARY] KEY]      [COMMENT 'string']      [reference_definition]      [check_constraint_definition]}  NULL &gt; DEFAULT &gt; AUTOINCREMENT &gt; UNIQUE &gt; PRIMARY 혹은AS &gt; UNIQUE &gt; PRIMARY 순서SELECT를 통한 테이블 생성CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name    [(create_definition,...)]    [table_options]    [partition_options]    [IGNORE | REPLACE]    [AS] query_expression  AS SELECT 문을 통해 SELECT 결과를 바로 테이블로 생성  IGNORE / REPLACE: 기존 테이블과 충돌 처리LIKE를 통한 기존 테이블을 복제CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name    { LIKE old_tbl_name | (LIKE old_tbl_name) }기존 테이블 구조(컬럼, 인덱스)만 복제하며, 데이터는 복제되지 않는다. 즉 스키마만 복제DML데이터 조작어를 살펴보자.SELECTMySQL 8.4 SELECT 문, 위 테이블에 들어갈 레코드들을 조회하는 SELECT 문을 보자.SELECT    [ALL | DISTINCT | DISTINCTROW ]    [HIGH_PRIORITY]    [STRAIGHT_JOIN]    [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT]    [SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS]    select_expr [, select_expr] ...    [into_option]    [FROM table_references      [PARTITION partition_list]]    [WHERE where_condition]    [GROUP BY [ {col_name | expr | position}, ... [WITH ROLLUP]              | ROLLUP ({col_name | expr | position}, ...)] ]    [HAVING where_condition]    [WINDOW window_name AS (window_spec)        [, window_name AS (window_spec)] ...]    [ORDER BY {col_name | expr | position}      [ASC | DESC], ... [WITH ROLLUP]]    [LIMIT {[offset,] row_count | row_count OFFSET offset}]    [into_option]    [FOR {UPDATE | SHARE}        [OF tbl_name [, tbl_name] ...]        [NOWAIT | SKIP LOCKED]      | LOCK IN SHARE MODE]    [into_option]into_option: {    INTO OUTFILE 'file_name'        [CHARACTER SET charset_name]        export_options  | INTO DUMPFILE 'file_name'  | INTO var_name [, var_name] ...}export_options:    [{FIELDS | COLUMNS}        [TERMINATED BY 'string']        [[OPTIONALLY] ENCLOSED BY 'char']        [ESCAPED BY 'char']    ]    [LINES        [STARTING BY 'string']        [TERMINATED BY 'string']    ]기본적으로 위처럼 MySQL 문 정의서가 작성되어 있는데, 기본 구조는 다음과 같다:SELECT    [ALL | DISTINCT | DISTINCTROW ]    [HIGH_PRIORITY]    [STRAIGHT_JOIN]    [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT]    [SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS]    select_expr [, select_expr] ...            [             ] 는 BNF 에서 쓰이는 표기법인데, 그냥 Data Dictionary 와 유사하다.      는 or 을 의미하기 때문에 안의 요소중 하나가 들어간다고 볼 수 있다.        ALL / DISTINCT / DISTINCTROW: 중복 행 처리 옵션  HIGH_PRIORITY: 테이블이 바쁠 때 먼저 처리  STRAIGHT_JOIN: 조인 순서를 강제시키는 옵션  SQL_SMALL_RESULT, SQL_BIG_RESULT, SQL_BUFFER_RESULT: 결과 집합 최적화 힌트, 세 옵션 전부 다 들어갈 수 있음  SQL_NO_CACHE: 쿼리 캐시 사용 안함  SQL_CALC_FOUND_ROWS: LIMIT 와 함께 전체 행 수 계산  select_expr [, select_expr] … : 선택할 컬럼 또는 계산식[into_option]...into_option: {    INTO OUTFILE 'file_name'        [CHARACTER SET charset_name]        export_options  | INTO DUMPFILE 'file_name'  | INTO var_name [, var_name] ...}export_options:    [{FIELDS | COLUMNS}        [TERMINATED BY 'string']        [[OPTIONALLY] ENCLOSED BY 'char']        [ESCAPED BY 'char']    ]    [LINES        [STARTING BY 'string']        [TERMINATED BY 'string']    ]into 는 결과를 내보낼 때 다시 보면 좋을 듯 하다.[FROM table_references  [PARTITION partition_list]][WHERE where_condition]FROM 뒤에 여러 태이블 참조 및 필요 시 특정 파티션 선택 가능[GROUP BY [ {col_name | expr | position}, ... [WITH ROLLUP] | ROLLUP ({col_name | expr | position}, ...)] ][HAVING where_condition]groupby 와 having 은 서로 같이 사용하며 groupby 만 사용해도 무관하다. having 은  where 절과 마찬가지로 조건문을 넣는다.사용할 때 살펴보기[WINDOW window_name AS (window_spec)    [, window_name AS (window_spec)] ...][ORDER BY {col_name | expr | position}  [ASC | DESC], ... [WITH ROLLUP]][LIMIT {[offset,] row_count | row_count OFFSET offset}]  SELECT 문은 옵션 → 컬럼 → INTO → FROM → WHERE → GROUP BY → HAVING → WINDOW → ORDER BY → LIMIT → FOR UPDATE 순서로 구성되며 이 순서를 반드시 지키자.DUAL 테이블SELECT 1 + 1 FROM DUAL;    -&gt; 2보통 SELECT 만 사용하고 싶을때 뒤에 FROM DUAL 이 생략된다. 즉 단순 계산할 때 SELECT 1+1 만 넣으면 알아서 FROM DUAL 이 들어가게 된다.  보통 SELET 절에 있는 1+1 과 같은 수식을 expr 라고 하는데, 값을 계산하거나 반환하는 식을 의미한다.SELECT 1;          – 숫자 상수SELECT ‘hello’;    – 문자열 상수SELECT TRUE;       – 논리값SELECT 3 + 5;          – 산술 연산SELECT salary * 1.1;   – 컬럼과 수치 연산SELECT salary / 12;    – 나눗셈SELECT SIN(PI()/4);                  – 수학 함수SELECT UPPER(first_name);            – 문자열 함수SELECT DATE_ADD(hire_date, INTERVAL 1 YEAR);  – 날짜 함수SELECT salary &gt; 5000;                        – TRUE/FALSESELECT department_id IN (10, 20, 30);       – IN 연산SELECT first_name LIKE ‘S%’;                 – 패턴 매칭SELECT NOT (department_id = 90);             – NOT 연산SELECT commission_pct IS NULL;      – NULL 체크SELECT IFNULL(commission_pct, 0);   – NULL 대체명명된 테이블의 모든 열들을 가져오기SELECT t1.*, t2.* FROM t1 INNER JOIN t2 ...명명된 테이블의 모든 열을 가져오되 순서를 정하기SELECT id, t1.* FROM t1이때 t1.* 이 아닌 그냥 *로 하면 오류가 발생한다.AS 사용하여 별칭 지정하기SELECT CONCAT(last_name,', ',first_name) AS full_name  FROM mytable ORDER BY full_name;AS 를 통해 열 이름을 정할 수 있고, 이를 다시 절에 활용할 수도 있다. 이는 FROM 절에서도 사용가능하다.SELECT CONCAT(last_name,', ',first_name) AS full_name  FROM mytable AS t ORDER BY full_name;  테이블 별칭은 AS 를 생략해도 자동으로 적용이 됨을 알고 있자.SELECT WHERESELECT t1.name, t2.salary FROM employee AS t1, info AS t2  WHERE t1.name = t2.name;SELECT t1.name, t2.salary FROM employee t1, info t2  WHERE t1.name = t2.name;조건문 또한 WHERE 절을 통해 추가 가능하다.-- AND 연산SELECT * FROM employees WHERE salary &gt;= 10000 AND department_id = 90;-- OR 연산SELECT * FROM employees WHERE department_id = 90 OR department_id = 100;-- NOT 연산SELECT * FROM employees WHERE NOT department_id = 90;-- 복합 조건SELECT * FROM employees WHERE (department_id = 90 OR department_id = 100)  AND salary &gt;= 10000;자바와는 다르게 OR, AND 를 통해 명제끼리 연결시킨다.-- IN 사용SELECT * FROM employees WHERE department_id IN (90, 100, 110);-- NOT IN 사용SELECT * FROM employees WHERE department_id NOT IN (90, 100);-- 범위 검색SELECT * FROM employees WHERE salary BETWEEN 5000 AND 10000;-- 날짜 범위SELECT * FROM employees WHERE hire_date BETWEEN '2005-01-01' AND '2005-12-31';날짜 범위는 위와 같이 사용된다.LIKE정규표현식처럼 문자열에 대해 문자열의 패턴이 맞는지 확인하도록 조건을 줄 수 있다.-- S로 시작하는 이름SELECT * FROM employees WHERE first_name LIKE 'S%';-- n으로 끝나는 이름SELECT * FROM employees WHERE first_name LIKE '%n';-- a를 포함하는 이름SELECT * FROM employees WHERE first_name LIKE '%a%';-- 두 번째 글자가 o인 이름SELECT * FROM employees WHERE first_name LIKE '_o%';-- 정확히 5글자인 이름SELECT * FROM employees WHERE first_name LIKE '_____';-- a로 시작하고 5글자인 이름SELECT * FROM employees WHERE first_name LIKE 'a____';ORDER BYSELECT college, region, seed FROM tournament  ORDER BY region, seed;SELECT college, region AS r, seed AS s FROM tournament  ORDER BY r, s;SELECT college, region, seedFROM tournamentORDER BY 2, 3;SELECT first_name, last_name, ageFROM mytableORDER BY last_name ASC, age DESC;맨 하위가 의문일 수 있는데, 기본적으로 MySQL 은 중복된 열의 이름을 허용한다. 따라서 이를 index 로 지정하는 것을 볼 수 있다.GROUP BY, HAVINGSELECT COUNT(col1) AS col2 FROM t GROUP BY col2 HAVING col2 = 2;col2 가 2인 레코드들을 집계하여 보여주는 쿼리이다. 이때 having 절은 group by 와 함께 가져가는 predicate 이다. group by 가 없는데도 having 을 쓰게 되면 문제가 생길 수 있다.LIMITSELECT * FROM tbl LIMIT 5,10;  # Retrieve rows 6-155 이후부터 10개를 가져온다.Placeholders플레이스 홀더는 프로그래밍 언어에서 변수와 비슷한 개념이다.SET @a=1;PREPARE STMT FROM 'SELECT * FROM tbl LIMIT ?';EXECUTE STMT USING @a;STMT 를 중간 코드와 같이 저으이하고, 해당 STMT 를 EXECUTE 문으로 실행함을 볼 수 있다. 인자를 넣을 때는 USING 을 통해 넣어주게 된다.DISTINCT-- 중복된 값 제거SELECT DISTINCT department_id FROM employees;-- 여러 컬럼의 조합으로 중복 제거SELECT DISTINCT department_id, job_idFROM employees;NULL 처리자바와는 다르게 sql 은 NULL 을 비교연산자 =, != 으로 못한다. 지정해놓은 IS NULL, IS NOT NULL 을 통해 비교할 수 있다.-- NULL인 데이터 찾기SELECT * FROM employees WHERE commission_pct IS NULL;-- NULL이 아닌 데이터 찾기SELECT * FROM employees WHERE commission_pct IS NOT NULL;함수  UPPER  LOWER  CONCAT  SUBSTRING  LENGTH  TRIM, LTRIM, RTRIM      LPAD, RPAD    ROUND, CEIL, FLOOR  ABS  MOD  POWER  SQRT      GREATEST, LEAST    CURDATE, CURTIME, NOW  DATE_FORMAT  DATE_ADD, DATE_SUB  DATEDIFF  YEAR, MONTH, DAY, DAYOFWEEK위 내용들은 전부 응용 개념이라 많이 사용해봐야 외어지므로 그냥 그러려니 하고 넘어간다.UPDATEupdate-set-where 의 구문으로 보통 외우고 있으면 다 된다. where 절의 expression 넣는 구문은 select 구문과 동일하다. 실제 API 를 보자.UPDATE [LOW_PRIORITY] [IGNORE] table_reference    SET assignment_list    [WHERE where_condition]    [ORDER BY ...]    [LIMIT row_count]  [LOW_PRIORITY] : 다른 쿼리보다 실행 우선순위를 낮춤  [IGNORE] : 업데이트 중 발생하는 일부 오류를 무시하고 계속 실행  table_reference : 업데이트 할 테이블 이름  SET assignment_list : 수정할 컬럼과 값을 지정  [WHERE where_condition] : 조건을 만족하는 행만 업데이트  [ORDER BY …] : 특정 순서대로 행을 업데이트 (특히 LIMIT과 함께 사용)  [LIMIT row_count] : 한 번에 업데이트할 행 수 제한assignment_list 에는 수정할 컬럼들이 들어가는데, assignment 각각은 다음과 같이 정의된다.assignment:    col_name = valuevalue:    {expr | DEFAULT}한 컬럼에 대해 어떤 값으로 변경할지 지정하는 곳이다. 여기서 value는 DEFAULT 혹은 표현식이 들어가면 된다.DELETEDELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name [[AS] tbl_alias]    [PARTITION (partition_name [, partition_name] ...)]    [WHERE where_condition]    [ORDER BY ...]    [LIMIT row_count]LOW_PRIORITY 설명은 생략  QUICK: 인덱스가 존재하면 더 빠르게 삭제  IGNORE: 삭제 과정에서 오류가 발생 시 무시하고 계속 진행할지 여부FROM tbl_name [[AS] tbl_alias][PARTITION (partition_name [, partition_name] ...)][WHERE where_condition]삭제할 테이블 이름 지정 및 파티션 테이블에서 특정 파티션만 대상으로 삭제 가능하며 조건을 만족하는 행만 삭제가 가능하다(생략시 테이블 전체가 삭제되버림).[ORDER BY ...][LIMIT row_count]삭제 순서를 ORDER 을 통해 지정할 수 있고, 주로 LIMIT 와 함께 사용가능하다.INSERTinsert 동작은 좀 복잡하다.INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]    [INTO] tbl_name    [PARTITION (partition_name [, partition_name] ...)]    [(col_name [, col_name] ...)]    { {VALUES | VALUE} (value_list) [, (value_list)] ... }    [AS row_alias[(col_alias [, col_alias] ...)]]    [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]    [INTO] tbl_name    [PARTITION (partition_name [, partition_name] ...)]    SET assignment_list    [AS row_alias[(col_alias [, col_alias] ...)]]    [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE]    [INTO] tbl_name    [PARTITION (partition_name [, partition_name] ...)]    [(col_name [, col_name] ...)]    { SELECT ...       | TABLE table_name       | VALUES row_constructor_list    }    [ON DUPLICATE KEY UPDATE assignment_list]value:    {expr | DEFAULT}value_list:    value [, value] ...row_constructor_list:    ROW(value_list)[, ROW(value_list)][, ...]assignment:    col_name =           value        | [row_alias.]col_name        | [tbl_name.]col_name        | [row_alias.]col_aliasassignment_list:    assignment [, assignment] ...INSERT 문은 크게 3가지로 나뉘는데 각각을 보자.VALUES 를 사용하는 일반 INSERTINSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]    [INTO] tbl_name    [PARTITION (partition_name [, partition_name] ...)]    [(col_name [, col_name] ...)]    { {VALUES | VALUE} (value_list) [, (value_list)] ... }    [AS row_alias[(col_alias [, col_alias] ...)]]    [ON DUPLICATE KEY UPDATE assignment_list]  DELAYED: 테이블이 바쁠 때 INSERT 를 지연시킨다.  IGNORED: 삽입 중 오류 발생 무시하고 실행  VALUES / VALUE (value_list) : 삽입할 값          여러 행 삽입 가능: (v1, v2, …) , (v3, v4, …)        ON DUPLICATE KEY UPDATE: 기본키/유니크키 충돌 시 수행 할 업데이트  INSERT-INTO-VALUES 로 자주 사용한다.ON DUPLICATE KEY UPDATEINSERT INTO t1 (a,b,c) VALUES (1,2,3)  ON DUPLICATE KEY UPDATE c=c+1;UPDATE t1 SET c=c+1 WHERE a=1;기존에 primary key 혹은 unique 가 a 라는 attribute 이고, 초기 데이터가 a=1 인 행이 이미 있다고 치자, 그러면 (1, 2, 3) 이라는 행을 insert 하는 작업은 비정상적이다. 이때 ON DUPLICATE KEY UPDATE 절로 기존에 있던 행에 대해 업데이트하는 작업을 수행할 수 있다.SET을 사용하는 INSERTINSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]    [INTO] tbl_name    [PARTITION (...)]    SET assignment_list    [AS row_alias[(col_alias ...)]]    [ON DUPLICATE KEY UPDATE assignment_list]SELECT / TABLE / VALUES 를 이용한 INSERTINSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE]    [INTO] tbl_name    [PARTITION (...)]    [(col_name [, ...])]    { SELECT ...       | TABLE table_name       | VALUES row_constructor_list    }    [ON DUPLICATE KEY UPDATE assignment_list]value:    {expr | DEFAULT}value_list:    value [, value] ...row_constructor_list:    ROW(value_list)[, ROW(value_list)][, ...]DO표현식을 실행하지만 결과를 반환하지 않는 명령이다.SELECT SLEEP(5);위의 구문과 아래 구문의 차이는 출력이 있냐 없냐 뿐이다.DO SLEEP(5);CALL이전에 정의해놓은 프로시저(함수)를 호출하고 싶을 때 사용한다.CALL sp_name([parameter[,...]])CALL sp_name[()]여기서 [()] 가 되어 있는데, 이는 인자가 필요 없는 함수에 대해 소괄호를 생략해도 된다는 의미이다.인자를 placeholder 로 사용하여 넣고 함수를 호출하는 예제이다.DELIMITER //CREATE PROCEDURE p (OUT ver_param VARCHAR(25), INOUT incr_param INT)BEGIN  # Set value of OUT parameter  SELECT VERSION() INTO ver_param;  # Increment value of INOUT parameter  SET incr_param = incr_param + 1;END //DELIMITER ;  DELIMITER //: 문장 구분자를 바꾸는 명령, ; 를 //로 바꾸겠다OUT: 출력용 파라미터INOUT: 입력과 출력 둘 다 가능한 파라미터BEGIN: 프로시저 시작END //: 프로시저 끝 및 문장의 종료DELIMITER ;: 문장의 구분자를 // 에서 ; 로 바꾸겠다.mysql&gt; SET @increment = 10;mysql&gt; CALL p(@version, @increment);mysql&gt; SELECT @version, @increment;+----------+------------+| @version | @increment |+----------+------------+| 8.4.6   |         11 |+----------+------------+Relational Model기본적인 SQL 문을 다루는 법은 살펴봤으니 그 뒷단의 이론을 보자.Structure of Relational DatabasesRelational DB 는 여러 개의 테이블로 이루어져 있고, 이런 테이블들의 한 행은 특정 ID 와 그에 대응되는 열들의 값들 간의 Relation 으로 표현되는 것을 볼 수 있다.이러한 Relation 을 기본적으로 수학적 개념이고, 이 관계들에 실체 값들을 즉, 행들을 Tuple 이라고 부르며, 테이블의 개념은 이러한 관계들의 Set 이 되겠다.  Tuple $\\in$ Relation $\\subset$ Table여기서 튜플은 우리가 다루는 데이터들 일텐데, 데이터의 상태는 항상 바뀌기 마련이다. 따라서 이를 구분하기 위해 Relation Instance 라는 개념이 있는데, Relation 의 특정 한 시점을 나타내게 된다.또한 튜플들의 각 성분에 대해 가질 수 있는 값들의 범위를 Attribute 이라고 한다.Domain Atomicity도메인이 원자적이어야 한다는 것은 도메인 원소가 더 이상 쪼갤 수 없는 단위(indivisible unit)로 되어야 함을 의미한다.여기서 중요한 점은 도메인 자체가 무엇이냐가 아니라, 우리가 데이터베이스에서 도메인 원소를 어떻게 다루느냐 이다. 가령 phone_number 속성이 단일 전화번호 하나만 저장한다고 하더라도, 만약 우리가 그 값을 국가 코드, 지역 코드, 국번호 등으로 쪼개어 다룬다면 이는 여전히 비원자적(non-atomic) 값으로 취급되는 것이다.Domain Nullity이런 원자성만 갖추면 될 것 같지만, 값에는 아무 것도 없는 null 이라는 의미를 가진 값이 존재할 수 있다. 초반의 예제에서는 이게 없다고 가정하고 다루지만, 보통은 null 값을 어떻게 다룰지, 조회하거나 갱신할 때 null 이 미치는 영향들을 추후에 살펴보자.Relational Model 의 한계관계형 모델의 비교적 엄격한 구조는 데이터 저장과 처리에서 여러 가지 중요한 실질적 장점을 가져오지만, 엄격한 구조는 잘 정의되어 있고 비교적 정적인 응용 분야에는 적합하지만, 데이터뿐만 아니라 데이터의 유형과 구조 자체가 시간에 따라 변하는 응용 분야에는 적합하지 않다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 17일차 Database 이론",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/database/2025/09/11/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-17%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-11",
      "content": "📂 목차  Database          DBMS      Abstraction and DB      DB 의 변천사      Purpose of DB      View of Data      Data Abstraction                  물리적 수준          Instances and Schemas                      Database Languages          DDL                  Domain Constraints          Referential Integrity          Authorization          SQL DDL                    DML                  Query          SQL DML                      Database Access from Application Programs📚 본문Database데이터를 체계적으로 저장하고 관리하는 시스템이다.주로 다루는 데이터들의 특징은 다음과 같다.DB가 다루는 데이터 3V  매우 가치가 높은 데이터  상대적으로 큰 규모의 데이터  동시에 여러 사용자와 응용 프로그램에서 접근하는 데이터최근에는 데이터의 특성에서 보다 복잡한 관계나 가변적 구조의 데이터들까지도 포함된다.DBMS데이터베이스 관리 시스템은 서로 연관된 데이터의 집합과 그 데이터를 접근하기 위한 프로그램의 집합이다.목표는 정보를 편리하고 효율적으로 저장하고 검색할 수 있는 방법을 제공하는 것을 목표로 한다.Abstraction and DB이러한 데이터베이스 시스템은 다음 특징이 있다.  공통된 데이터 구조를 활용해 효율성 확보  약하게 구조화된 데이터, 다양한 형식의 데이터도 처리 가능  방대한 데이터 집합을 관리하는 대규모, 복잡 소프트웨어 시스템여기서 다양한 데이터들, 대규모 등 복잡한 어플리케이션이 필요한데 이러한 복잡성을 관리하는 핵심이 추상화이다. 따라서 DB 시스템 내에서 사용자와 개발자에게 데이터 저장, 조직화 등의 방식을 숨김으로써 데이터를 간단히 조작 할 수 있게 한다.DB 의 변천사초기 DB 는 백오피스 시스템으로 운영되었지만, 사용자는 인쇄된 보고서나 이벽용 종이 양식을 통해 간접적으로만 상호작용을 했다.현대에 와서는 DB를 다룰 수 있는 다양한 언어가 나오고, DB 접근의 세부사항은 감추되 다양한 인터페이스와 손 쉬운 인터페이스를 제공하게 되었고, 현재는 2개의 방식을 지원하는데:      OLTP: 다수의 사용자가 동시에 DB 를 사용하며 각 사용자는 비교적 소량의 데이터를 조회하거나 작은 단위의 갱신 작업을 수행한다.        Data Analytics: 데이터를 처리, 결론을 도출하여 규칙이나 의사결정 절차를 추론한 뒤, 이를 바탕으로 비즈니스 의사결정을 내리는 것  Purpose of DB시스템은 여러 개의 응용 프로그램을 두어서 파일을 다루게 되는데, 운영체제에는 파일 처리 시스템이 있어 이 안에 다양한 프로그램을 통해 다루게 되는 것이 그 예이다. 하지만 보통 정보를 파일 처리 시스템으로 보관하게 된다면 문제점이 있다.운영체제의 3V 데이터 처리 문제점  Data Redundancy and Inconsistency: 여러 프로그래머가 장기간에 걸쳐 파일과 응용 프로그램을 작성하기 때문에 파일 구조가 제각각이며, 프로그램 또한 서로 다른 프로그래밍 언어 혹은 다른 확장자로 작성될 수 있다.  2015-12-29.txt, …, 2020-12-29.json, …확장자 다름  Diﬃculty in Accessing Data: 대학의 한 행정 직원이 특정 우편번호 지역에 사는 학생들의 이름을 알고 싶어한다고 치면, 데이터 처리 부서에 해당 목록을 요청하면 되지만, 원래 시스템 설계자가 이를 염두 안해두고 이런 파일들을 따로 모아놓지 않았다면 일일히 하나하나 다 찾아가면서 해야 한다.  2025/12월/* &lt;- 접근 용이, 2025 년에 접속 횟수 5회 이상 유저 &lt;- 힘듦  Data Isolation: 파일 여러 개가 흩어져 있으면 파일 형식이 다를 수 있기 때문에 필요한 데이터를 검색하기 위한 새로운 응용 프로그램을 작성하는 것이 어려움  2015-12-29.txt, 2020-12-29.txt어떤건 ANSI, 어떤건 UTF-8 등  Integrity Problems: 데이터베이스에 저장된 값은 특정한 일관성 제약 조건을 만족해야 한다. 하지만, 이러한 새로운 제약 조건이 추가될 때, 기존 프로그램을 수정하여 이를 강제하는 것은 어렵다.  2021-12-31 John 1002011 11 11 🦁 -193.13위 데이터는 두 형식이 완전 다름.      Atomicity Problems: 항상 언급되는 자원 관리에 대한 처리 방식이다. Atomicity 는 원자성이다. 원자는 더이상 쪼개지지 않으며 분리되지 않는다. 그 자체로 하나이며, 만약 어떤 연산을 되돌리고 싶을때 Atomic 한 연산들을 단위로 되돌려야 함을 말한다. 하지만, 운영체제의 파일 처리 시스템은 여러 연산을 한 번에 되돌리고 한 번에 처리하기가 힘들 것이다.        Concurrent-Access Anomlies: 시스템의 전반적인 성능과 빠른 응답을 위해 많은 시스템은 여러 사용자가 동시에 데이터를 갱신할 수 있도록 시스템을 운영해야 한다.  위 문제들을 다 해결할 수 있을 때 비로소 DB 라고 할 수 있다.View of Data      Relational Model: 관계형 모델은 데이터를 표현하고, 그 데이터들 간의 관계를 표현하기 위한 테이블 집합을 사용한다.        Entity-Relational Model: 개체라 불리는 기본 객체들과, 이 객체들 간의 관계 집합을 사용한다(E-R 다이어그램이다)        Semi-structured Data Model: 반구조적 데이터 모델은 동일한 유형의 데이터 항목이더라도 서로 다른 속성 집합을 가질 수 있도록 허용한다. 이는 모든 데이터 항목이 반드시 동일한 속성 집합을 가지지 않아도 된다는 뜻이다(JSON, XML 등이 그 예이다).        Object-Based Data Model: 객체 기반 데이터 모델이며, 처음에 객체지향 데이터 모델이라는 별도의 모델 개발로 이어졌지만, 객체 개념이 관계형 데이터베이스에 잘 통합되어 있다.여기서는 Procedure 를 데이터베이스 내에 저장하고, 시스템 자체에서 실행할 수 있도록 허용하게 된다.  우리가 주로 볼 것은 첫번째이다.Data Abstraction시스템이 사용 가능하려면 데이터를 효율적으로 검색할 수 있어야 한다. 이러한 효율성은 데이터베이스 시스템 개발자들이 데이터베이스 내 데이터를 표현하기 위해 복잡한 자료구조를 사용하게 만들었다.하지만, 많은 사용자들이 컴퓨터 전공자가 아니다. 따라서 데이터 추상화를 통해 복잡성을 감추게 된다.추상화 수준은 3가지가 있다.      Physical Level: 가장 낮은 수준의 추상화로, 데이터가 실제로 어떻게 저장되는지 설명한다, 복잡하고 저수준의 자료구조를 상세히 기술        Logical Level: 한 단계 높은 추상화로 DB에 어떤 데이터가 저장되는지와 데이터 간의 관계를 설명, 물론 논리적 수준의 단순한 구조 설계가 실제 물리적 수준의 복잡한 구조의 이해를 수반할 수 있지만, 논리적 수준의 사용자는 이러한 복잡성을 알 필요가 없다.        View Level: 가장 높은 추상화로, 전체 데이터베이스의 일부만을 설명한다. 논리적 수준이 비교적 단순한 구조를 사용한다고 해도, 대규모 데이터베이스에 저장되는 정보가 다양하기 때문에 여전히 복잡성이 존재한다.    data type 에 따른 java 에서의 record 정의를 보면 이걸 data abstraction 에 비유할 수 있다.예시를 보자.  department, with fields dept_name, building, and budget.  course, with fields course_id, title, dept_name, and credits.  student, with fields ID, name, dept_name, and tot_cred.물리적 수준department, department, student 는 물리적 수준에서 연속된 바이트 블록으로 표현될 수 있다. 이러한 연속된 바이트 블록으로 표현되어 있다는 것은 프로그래머에게 숨기게 된다.또한 DBA 는 데이터의 물리적 조직에 관한 일부 세부사항을 인지하고 싶을 수 있다. 이때 테이블을 파일에 저장하는 방법은 여러가지가 있는데      테이블을 파일 내 레코드의 연속으로 저장(쉼표, 특수문자, 줄바꿈 등 활용)        모든 속성이 고정 길이인 경우, 속성의 길이를 별도로 저장하고, 구분자 생략        가변 길이 속성은 길이를 먼저 저장 후 데이터를 저장하는 방식으로 처리  그리고 DB는 인덱스라는 자료구조를 사용하여 레코드를 효율적으로 검색할 수 있도록 지원하며, 이러한 인덱스도 물리적 수준에 포함된다.  물리적 수준 = 바이트 블록 + 저장 구조 + 인덱스Instances and SchemasDB 에는 정보가 삽입되고 삭제됨에 따라 시간이 지나면서 변한다.특정 시점의 데이터베이스에 저장된 정보의 집합을 Instance 라고 한다. 그라고 DB의 전체 설계를 DB Schema 라고 부른다.스키마와 인스턴스 개념을 프로그래밍 언어에 비유해서 보면 다음과 같다:  DB Schema 는 프로그램의 변수 선언에 해당, 각 변수들은 특정 시점에 고유한 값을 가짐  프로그램 내 변수들의 값은 특정 시점의 DB Instance 에 해당함.이러한 스키마는 DB 시스템에서의 추상화 수준에 따라 여러 스키마가 존재하게 되며, 물리적 스키마, 논리적 스키마, 뷰 스키마 등이 있다.Database LanguagesDB를 이제 다룰 수 있는 언어를 보자.  DDL: 데이터 정의어라고 부르며, DB 스키마를 지정한다.  DML: 데이터 조작어라고 부르며, 조회(query) 와 갱신(update)를 표현할 수 있다.  DCL: 데이터 제어어라고 부르며, 보통 권한, 보안을 담당하게 된다.DDLDDL 은 데이터 추가 속성을 지정하는 데에 사용된다. 이때 우리는 안에 어떻게 정의를 해야하는지 알 필요 없고, DDL 이라는 인터페이스를 통해 명령만 내리면 된다.여기서 저장되는 값들은 Consistency Constraints 를 만족해야 한다(특정 값은 음수가 안되어야 하고, 자수를 넘기면 안되고 등등). 이러한 제약조건을 지정할 수 있는 기능을 제공하는게 DDL 이다.일반적으로 제약 조건은 데이터베이스와 관련된 임의 조건(predicate) 일 수 있는데, 임의 조건의 검사는 비용이 많이 들기 때문에 DB 시스템에서는 최소한의 비용으로 검사 가능한 무결성 제약(Integrity Constraints)만 구현하고 우리에게 제공한다.Domain Constraints모든 속성에는 가능한 값의 범위가 지정되어야 함의 제약조건이다.Referential Integrity특정 속성 집합에 나타난 값이 다른 릴레이션의 특정 속성 집합에도 존재해야 함을 보장하고자 할 때 사용한다.Authorization데이터베이스 내 다양한 데이터 값에 대해 사용자가 허용되는 접근 유형을 구분할 수 있다.  읽기 권한(read authorziation)  삽입 권한(insert authorization)  수정 권한(update authorization)  삭제 권한(delete authorization)DDL 문을 처리하는 과정은 다른 프로그래밍 언어와 마찬가지로 출력을 생성한다. 이러한 출력은 보통 Data Dictionary 에 저장되며, 데이터 사전은 Metadata 즉, 데이터에 대한 데이터를 포함하며, 데이터 사전은 특수한 유형의 테이블로 간주되고, 일반 사용자가 접근하거나 수정할 수 없고 오로지 DBMS 자체만 접근 및 갱신 할 수 있다.SQL DDLDB Languages 중 하나인 SQL 은 데이터 정의어를 풍부하게 제공하며, 이를 통해 테이블, 데이터 타입 무결성 제약 조건을 정의할 수 있다.예를들어 다음 department 테이블을 정의할 수 있다.create table department(    dept_name char(20),    building char(15),    budget numeric(12,2));또한 SQL DDL 은 다양한 유형의 무결성 제약 조건을 지원한다.  기본키, 외래키, NOT NULL 등등DML데이터 조작어는 적절한 데이터 모델로 조직된 데이터를 접근하거나 조작할 수 있게 해주는 언어이다.목적  Data Retrieval: 데이터 조회  Data Insertion: 데이터 삽입  Data Deletion: 데이터 삭제  Data Modification: 데이터 수정여기서 DML 은 다시 두 가지 유형으로 나뉘는데  Procedural DML: 사용자가 필요한 데이터와 그 데이터를 얻는 방법을 지정  Declarative DML: 사용자가 필요한 데이터만 지정하고, 데이터를 얻는 방법은 지정하지 않음로 나뉜다. 보통 선언적 DML 이 일반적으로 절차적 DML 보다 배우기 쉽고 사용하기 쉽다. 하지만 사용자가 데이터를 얻는 방법을 명시하지 않기 때문에 DBMS 가 효울적인 데이터 접근 방법을 스스로 결정해야 한다.Query쿼리는 정보를 조회하는 요청문이다. DML 에서 정보 조회와 관련된 부분을 Query Language 라고 한다.정확하지 않지만, 일반적으로 쿼리 언어와 데이터 조작어를 동일하게 보기도 한다.SQL DMLSQL은 비절차적 언어이며, 쿼리를 날릴 때 여러 테이블로부터 입력을 받고, 항상 단일 테이블을 반환하도록 되어 있다.select instructor.namefrom instructorwhere instructor.dept_name = 'History';Database Access from Application ProgramsSQL 과 같은 비절차적 쿼리 언어는 범용 튜링 기계 만큼 강력하진 않다. 이는 프로그래밍 언어로 할 수 있는 연산들은 SQL 로는 불가능 할 수 있다는 것이다.이러한 걸 극복하기 위해 어플리케이션 프로그램이 DB 와 상호작용하는 프로그램을 말하고, 개발되게 된다. DB 에 접근하려면 DML 문을 호스트에서 DB로 전송하여 실행해야 한다(API 사용).  ODBC: C 및 여러 언어에서 사용가능한 어플리케이션 프로그램 인터페이스 수준  JDBC: Java 언어에서 사용할 수 있는 인터페이스 표준MySQL여기서는 우선 MySQL 을 사용하며, 관계형 DB 이다. 이름에서 보다시피 SQL 을 사용하게 되며, 웹어플리케이션 스택에 널리 사용되어 진다(LAMP 스택).  MySQL 5.x - 널리 사용되던 안정 버전 - 기본 캐릭터셋: latin1 - JSON 타입 미지원 (5.7부터 지원)MySQL 8.0 (현재 최신 LTS 버전) - 기본 캐릭터셋: utf8mb4 - CHECK 제약조건 완전 지원 (8.0.16부터) - 윈도우 함수 지원 - 개선된 성능과 보안 - 새로운 인증 플러그인 (caching_sha2_password)이를 실습하기 위해 Docker 을 이용해 구성해보자.docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=1234 mysql:8.0d 는 백그라운드 옵션, p는 포트 설정, e는 환경 변수를 설정할 수 있게 한다. 두번째 인자로는 가져올 이미지 이름과 그에 해당하는 태그를 달 수 있다.도커는 이러한 프로그램을 image 형태로 제공하여 다수의 사용자에게 간편하게 프로그램을 올릴 수 있도록 한다.  나는 Docker Desktop 에 이미 다운받은 이미지가 있어서 그걸로 구동했다.Docker Compose매번 위 옵션들을 다 치기에는 버거울 수 있다.도커는 docker-compose.yml 을 통해 쉽게 도커를 실행할 수 있도록 한다.version: \"3.8\"services:  ms-mysql-practice:    image: mysql:latest    container_name: ms-mysql-container    restart: always    environment:      MYSQL_ROOT_PASSWORD: \"1234\"      MYSQL_DATABASE: \"liondb\"      MYSQL_USER: \"lion\"      MYSQL_PASSWORD: \"1234\"      TZ: Asia/Seoul    command:      - --character-set-server=utf8mb4      - --collation-server=utf8mb4_unicode_ci    volumes:      - ./database/init/:/docker-entrypoint-initdb.d/      - ./database/datadir/:/var/lib/mysql    platform: linux/x86_64    ports:      - 3306:3306생소한 명령어를 파헤쳐보자.컨테이너가 MySQL 서버를 시작할 때 추가 옵션을 전달하는 부분  –character-set-server=utf8mb4          MySQL 서버의 기본 문자셋(charset)을 utf8mb4로 설정      utf8mb4는 모든 유니코드 문자를 포함할 수 있어서 이모지, 특수문자도 저장 가능        –collation-server=utf8mb4_unicode_ci          기본 정렬 규칙(collation)을 utf8mb4_unicode_ci로 설정      대소문자를 구분하지 않고(ci = case-insensitive) 유니코드 기준으로 문자열 비교      호스트와 컨테이너 내부 디렉토리를 연결하는 부분  ./database/init/:/docker-entrypoint-initdb.d/          컨테이너 시작 시 MySQL이 docker-entrypoint-initdb.d/ 안에 있는 SQL 파일이나 스크립트를 자동으로 실행        ./database/datadir/:/var/lib/mysql          MySQL의 실제 데이터가 저장되는 디렉토리      호스트 디렉토리(./database/datadir/)와 연결해서 컨테이너가 삭제되어도 데이터 유지      이제 접속은 터미널에서 다음을 입력하면 된다.  docker exec -it ms-mysql-container mysql -ulion -p1234 liondb여기서 exec 는 이미 실행중인 컨테이너 안에서 명령어를 실행할 때 사용하며-interactive, -tty 옵션을 통해 STDIN 으로 사용자의 입력을 받고, 터미널 환경을 에뮬레이션하여 명령어 실행 결과가 깔끔하게 보이도록 한다.ms-mysql-container 한테 명령어 mysql -ulion -p 1234 liondb 를 실행하라는 명령이며, liondb 라는 데이터베이스를 사용할 수 있게 된다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 16일차 GoF 디자인 패턴(생성, 구조)",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/05/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-16%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-05",
      "content": "📂 목차  GoF 디자인 패턴          생성 패턴                  Singleton          Factory          Builder          Prototype          Abstract Factory                    구조 패턴                  Adapter          Bridge          Composite          Decorator          Facade          Proxy                    📚 본문GoF 디자인 패턴정처기에서 정리를 다 했지만, 다시 본다. 글 보다는 이번에는 코드 위주로 설명한다.생성 패턴객체를 생성할 때 마주할 수 있는 프로그래밍 문제를 해결할 솔루션이며객체 생성 과정을 캡슐화해서 유연하고 재사용 가능한 객체 생성을 돕는 패턴이다.Singleton public class Example {    private static Example instance;    private Example() { /* 생성은 감추고 */ }    // synchronized 를 쓰는건 때에 따라서    public synchronized static Example getInstance() {        instance = Objects.requiredNonNullElseGet(instance, () -&gt;            new Example()        );    }}Factoryinterface Phone {    void call();}class IPhone implements Phone {    void call() {        System.out.println(\"아이폰 짱\");    }}class Galaxy implements Phone {    void call() {        System.out.println(\"갤럭시 짱\");    }}public interface PhoneFactory {    // 어떤 제품이 나올지 모르니 공통적인 제품에 대해    // 추상화를 반환하도록    Phone createPhone();}// 서브 클래스가 이를 구현하여 다양한 Factory 구현public GalaxyFactory implements PhoneFactory {    public Phone createPhone() {        return new Galaxy();    }}public IPhoneFactory implements IPhoneFactory{    public Phone createPhone() {        return new IPhone();    }}Builderpublic class Person {    // 전부 private final 하게    private final long id;    private final String name;    private final int height;    private final int weight;    private final String phoneNumber;        // 생성자를 encapsulation    private Person(long id, String name, int height, int weight, String phoneNumber) {        this.id = id;        this.name = name;        this.height = height;        this.weight = weight;        this.phoneNumber = phoneNumber;    }    // Getter 만 구현    public static class Builder {        private long id;        private String name;        private int height;        private int weight;        private String phoneNumber;        // 기본 생성자로        // Lombok 에서는 set 없이 id() 로 가져가기는 한다.        public Builder id(long id) {            this.id = id;        }        // ... 이하 setter 생략        public Person build() {            return new Person (id, name, height, weight, phoneNumber);        }    }}Prototypepublic class Rectangle implements Cloneable {    private int height;    private int weight;    public Rectangle(int height, int weight) {        this.height = height;        this.weight = weight;    }    // 생성자로 복제하기    public Rectangle(Rectangle rectangle) {        this.height = rectangle.height;        this.weight = rectangle.weight;    }    // 메서드로 복제하기 (Clonable 구현)    @Override    public Rectangle clone() {        // 깊은 복사 로직도 필요 시 추가        // 상위 구현체에 cloneable 하다면 해당 메서드를 써도 됨        // 단, 캐스팅을 할지 말지는 선택        return new Rectangle(this);    }}Abstract Factory다수의 부품들을 유연하게 제작하고 싶을때 가져가는 패턴이다.// 1️⃣ Product 인터페이스interface Chair {    void sitOn();}interface Sofa {    void lieOn();}// 2️⃣ ConcreteProduct 클래스class ModernChair implements Chair {    @Override    public void sitOn() {        System.out.println(\"앉는 중: 모던 체어\");    }}class ModernSofa implements Sofa {    @Override    public void lieOn() {        System.out.println(\"누워보는 중: 모던 소파\");    }}class VictorianChair implements Chair {    @Override    public void sitOn() {        System.out.println(\"앉는 중: 빅토리안 체어\");    }}class VictorianSofa implements Sofa {    @Override    public void lieOn() {        System.out.println(\"누워보는 중: 빅토리안 소파\");    }}// 3️⃣ AbstractFactoryinterface FurnitureFactory {    Chair createChair();    Sofa createSofa();}위처럼 쓰면 FurnitureFactory 의 하위로 다수의 다양한 가구들을 만들어내는팩토리들을 생성시킬 수 있을 것이다.구조 패턴클래스와 객체를 조합하여 더 큰 구조를 만들 때 사용하는 패턴이다.Adapter호환되지 않는 인터페이스를 맞춰주고 싶을 때 사용하는 패턴이다.// 기존 클래스 1class KakaoRemote {    public void turnOn() {        System.out.println(\"카카오 TV ON\");    }    public void turnOff() {        System.out.println(\"카카오 TV OFF\");    }}// 기존 클래스 2class NaverRemote {    public void on() {        System.out.println(\"네이버 TV ON\");    }    public void off() {        System.out.println(\"네이버 TV OFF\");    }}위 두 인터페이스는 기능은 동일하되 인터페이스는 맞지 않으므로 인터페이스를 하나 더 추가하여 위 API를 통일시켜준다.interface Remote {    void on();    void off();}// Adapter: KakaoRemote를 Remote 인터페이스로 변환// has-a 로 느슨하게 연결class KakaoRemoteAdapter implements Remote {    private final KakaoRemote kakaoRemote;    public KakaoRemoteAdapter(KakaoRemote kakaoRemote) {        this.kakaoRemote = kakaoRemote;    }    @Override    public void on() {        kakaoRemote.turnOn();    }    @Override    public void off() {        kakaoRemote.turnOff();    }}// Adapter: NaverRemote를 Remote 인터페이스로 변환// has-a 로 느슨하게 연결class NaverRemoteAdapter implements Remote {    private final NaverRemote naverRemote;    public NaverRemoteAdapter(NaverRemote naverRemote) {        this.naverRemote = naverRemote;    }    @Override    public void on() {        naverRemote.on();    }    @Override    public void off() {        naverRemote.off();    }}// Clientpublic class Main {    public static void main(String[] args) {        Remote kakao = new KakaoRemoteAdapter(new KakaoRemote());        Remote naver = new NaverRemoteAdapter(new NaverRemote());        kakao.on();   // \"카카오 TV ON\"        kakao.off();  // \"카카오 TV OFF\"        naver.on();   // \"네이버 TV ON\"        naver.off();  // \"네이버 TV OFF\"    }}Bridge실체과 실행을 분리시켜 독립적으로 확장시키도록 하는 패턴이다.여기서 실행은 어떤 것이든 될 수 있다. 어쨋든 분리시키는게 중요한 것이다.interface Renderer {    void renderCircle(float x, float y, float radius);}class VectorRenderer implements Renderer {    @Override    public void renderCircle(float x, float y, float radius) {        System.out.println(\"Vector 방식으로 원 그리기 at (\" + x + \",\" + y + \") radius \" + radius);    }}class RasterRenderer implements Renderer {    @Override    public void renderCircle(float x, float y, float radius) {        System.out.println(\"Raster 방식으로 원 그리기 at (\" + x + \",\" + y + \") radius \" + radius);    }}Renderer 는 실행하는 인터페이스 이다. 즉 특정 행위를 하는 인터페이스를 정의하고,특정 행위를 하는 구현체를 VectorRenderer, RasterRenderer 로 가져가고 있다.여기서 이 행위의 중심에 있는, 행위를 하는 주체가 없다. 즉, 실체가 없다는 뜻이다.해당 실체를 Renderer 을 has-a 로 가지게 하여서 구현하면 되겠다.abstract class Shape {    protected Renderer renderer;    protected Shape(Renderer renderer) {        this.renderer = renderer;    }    abstract void draw();    abstract void resize(float factor);}class Circle extends Shape {    private float x, y, radius;    public Circle(Renderer renderer, float x, float y, float radius) {        super(renderer);        this.x = x;        this.y = y;        this.radius = radius;    }    @Override    void draw() {        renderer.renderCircle(x, y, radius);    }    @Override    void resize(float factor) {        radius *= factor;    }}public class Main {    public static void main(String[] args) {        Renderer vector = new VectorRenderer();        Renderer raster = new RasterRenderer();        Circle circle1 = new Circle(vector, 5, 5, 10);        Circle circle2 = new Circle(raster, 10, 10, 20);        circle1.draw(); // Vector 방식        circle2.draw(); // Raster 방식        circle1.resize(2);        circle1.draw(); // Vector 방식, radius 20    }}Composite말 그대로 그냥 객체를 조립하여서 부분-전체 관계로 표현하는 것이다.Application에 DI 를 할 때 해당 instance 들을 다 들고 있는 클래스를 생각해보자.이는 쉬우니 그냥 넘어간다.Decorator이는 Java IO 로 많이 보았을 것이다.객체에 새로운 책임을 추가할 수 있는 패턴이며, 상속 대신 구성(has-a 관계) 를 사용하여 기능을 확장한다.  Interface Component  Concrete Component  Decorator Class  Decorator Concrete ClassInterface Component// Componentinterface Coffee {    String getDescription();    int cost();}기본 뼈대를 정의하고, Concrete Component 실체를 구현한다.Concrete Componentclass BasicCoffee implements Coffee {    @Override    public String getDescription() {        return \"기본 커피\";    }    @Override    public int cost() {        return 2000;    }}여기까지는 일반적인 클래스 설계 및 구현과 다를 바가 없다. 하지만 그 이후 Decorator(추상 클래스) 를 통해  Component 를 상속하여 내부에 Concrete Component 를 두고,  해당 기능들을 전부 유지시키며 Overriding 을 한다.Decoratorabstract class CoffeeDecorator implements Coffee {    protected Coffee coffee;    protected CoffeeDecorator(Coffee coffee) {        this.coffee = coffee;    }    @Override    public String getDescription() {        return coffee.getDescription();    }    @Override    public int cost() {        return coffee.cost();    }}여기서 이 추상 클래스의 하위 클래스도 base object(Concrete component) 를 사용할 수 있도록 protected 로 구성해야 한다.그 이후는 추가하고 싶은 기능들을 Decorator 를 통해 다양한 기능을 가진 클래스들로 확장해나가면 된다.class MilkDecorator extends CoffeeDecorator {    public MilkDecorator(Coffee coffee) {        super(coffee);    }    @Override    public String getDescription() {        return coffee.getDescription() + \", 우유 추가\";    }    @Override    public int cost() {        return coffee.cost() + 500;    }}class SugarDecorator extends CoffeeDecorator {    public SugarDecorator(Coffee coffee) {        super(coffee);    }    @Override    public String getDescription() {        return coffee.getDescription() + \", 설탕 추가\";    }    @Override    public int cost() {        return coffee.cost() + 200;    }}Facade복잡한 서브시스템을 단순화된 인터페이스로 제공하기 위해(여러 라이브러리를 하나의 API로 통합하기 위해) 사용된다.Adapter 랑 다른 점은 Adapter 는 유사한 기능을 가진 클래스 끼리 메서드 시그니처가 다를 때 사용하고,Facade 는 다수의 다양한 기능들과 복합적이고 복잡한 인터페이스들을 제공하는 시스템에 대해 여러 객체를 단일 접근점을 통해단순하게 접근할 수 있도록 사용하는 것이다. 즉 Facade 는 종합 리모컨 느낌이면 Adapter 는 연결만 시켜주는 애다.class TV {    public void on() { System.out.println(\"TV 켜기\"); }    public void off() { System.out.println(\"TV 끄기\"); }}class SoundSystem {    public void on() { System.out.println(\"사운드 시스템 켜기\"); }    public void off() { System.out.println(\"사운드 시스템 끄기\"); }}class DVDPlayer {    public void on() { System.out.println(\"DVD 플레이어 켜기\"); }    public void off() { System.out.println(\"DVD 플레이어 끄기\"); }    public void play(String movie) { System.out.println(movie + \" 재생\"); }}다수의 기기들이 다양한 기능들을 제공함을 볼 수 있지만 각각 메서드 시그니처가 다를 수도, 같을 수도 있다.Facadeclass HomeTheaterFacade {    private final TV tv;    private final SoundSystem sound;    private final DVDPlayer dvd;    public HomeTheaterFacade(TV tv, SoundSystem sound, DVDPlayer dvd) {        this.tv = tv;        this.sound = sound;        this.dvd = dvd;    }    public void watchMovie(String movie) {        tv.on();        sound.on();        dvd.on();        dvd.play(movie);        System.out.println(\"영화 시작 준비 완료!\");    }    public void endMovie() {        dvd.off();        sound.off();        tv.off();        System.out.println(\"영화 종료!\");    }}Facade 를 두어 모든 기능들을 조합하여 다양한 기능들을 생성해낼 수 있다.Proxy실체 객체에 접근하기 전에 대리 객체를 두어 제어한다. 목표하는 기능으로는 다음과 같다:  접근 제어  지연 로딩  로깅, 캐싱구조는 Subject(inteface), RealSubject, Proxy(RealSubject 를 감싸고 접근 제어) 로 가져간다.Lazy Proxy필요할 때만 초기화를 수행하도록 하여 메모리를 최적화 할 수 있다.// Subjectinterface Image {    void display();}// RealSubjectclass RealImage implements Image {    private String filename;    public RealImage(String filename) {        this.filename = filename;        loadFromDisk();    }    private void loadFromDisk() {        System.out.println(\"이미지 로딩: \" + filename);    }    @Override    public void display() {        System.out.println(\"이미지 표시: \" + filename);    }}// 아직 생성되지 않은 상태// Proxy 를 통해 has-a 관계로 RealImage 를 부르기 전까지는 초기화 Xclass ProxyImage implements Image {    private RealImage realImage;    private String filename;    public ProxyImage(String filename) {        this.filename = filename;    }    @Override    public void display() {        if (realImage == null) { // Lazy initialization            realImage = new RealImage(filename);        }        System.out.println(\"프록시를 통해 접근 중...\");        realImage.display();    }}Protection Proxy사용자의 권한에 따라 접근을 제어한다.class ProtectedImageProxy implements Image {    private RealImage realImage;    private String filename;    private String userRole;    public ProtectedImageProxy(String filename, String userRole) {        this.filename = filename;        this.userRole = userRole;    }    @Override    public void display() {        if (\"ADMIN\".equals(userRole)) {            if (realImage == null) realImage = new RealImage(filename);            realImage.display();        } else {            System.out.println(\"권한 없음: 이미지 접근 불가\");        }    }}Virtual Proxy필요한 기능만을 가져오고 싶을 때 사용한다. 이때는 Subject 가 분리가 잘 되어 있어야 한다.// Subjectinterface Image {    void display();}// RealSubjectclass RealImage implements Image {    private String filename;    public RealImage(String filename) {        this.filename = filename;        loadFromDisk();    }    private void loadFromDisk() {        System.out.println(\"원본 이미지 로딩: \" + filename);    }    @Override    public void display() {        System.out.println(\"이미지 표시: \" + filename);    }}// Virtual Proxyclass VirtualImageProxy implements Image {    private RealImage realImage;    private String filename;    private boolean showThumbnailOnly;    public VirtualImageProxy(String filename, boolean showThumbnailOnly) {        this.filename = filename;        this.showThumbnailOnly = showThumbnailOnly;    }    @Override    public void display() {        if (showThumbnailOnly) {            System.out.println(\"썸네일 표시: \" + filename);        } else {            if (realImage == null) {                realImage = new RealImage(filename);            }            realImage.display();        }    }}Smart Proxy실 객체에 접근할 때 추가 기능을 제공하는 프록시이며, 캐싱 기능, 로깅 기능 등등을 예로 들 수 있겠다.interface Image {    void display();}// 실제 객체class RealImage implements Image {    private final String filename;    public RealImage(String filename) {        this.filename = filename;        loadFromDisk();    }    private void loadFromDisk() {        System.out.println(\"이미지 로딩: \" + filename);    }    @Override    public void display() {        System.out.println(\"이미지 표시: \" + filename);    }}// Smart Proxyclass SmartImageProxy implements Image {    private RealImage realImage;    private final String filename;    private boolean cached = false;    public SmartImageProxy(String filename) {        this.filename = filename;    }    @Override    public void display() {        System.out.println(\"[Smart Proxy] display 호출 기록\");        if (!cached) {            realImage = new RealImage(filename);            cached = true;        } else {            System.out.println(\"[Smart Proxy] 캐시된 이미지 사용\");        }        realImage.display();    }}행위 패턴은 다음 장에서.."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 15일차 Java IO 심화",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/04/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-15%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-04",
      "content": "📂 목차  Java IO 심화          InputStream(Byte Stream)                  FileInputStream          FilterInputStream          ObjectInputStream                    Reader(Char Stream)      OutputStream      Writer                  PrintWriter          BufferedWriter                    📚 본문Java IO 심화해당 패키지는 기본적으로 실습을 많이 하여야 익숙해지는 듯하니, 다양한 입출력들을 연습해보길 바란다.우선 다음 흐름을 가져가자.  InputStream -&gt; Reader -&gt; System -&gt; Writer -&gt; OutputStreamInputStream(Byte Stream)이전 포스트에서 스트림 자체는 byte 씩 읽어오는 것이라고 했다.입력 스트림은 Java 애플리케이션에서 소스로부터 데이터를 읽는 데 사용되고 데이터는 파일, 배열, 주변 장치 또는 소켓 등 무엇이든 될 수 있다.Java 에서 java.io.InputStream 클래스 는 모든 Java IO 입력 스트림의 기본 클래스이며 하위 클래스는 다음과 같이 있다.  AudioInputStream  ByteArrayInputStream  FileInputStream  FilterInputStream  InputStream  ObjectInputStream  PipedInputStream  SequenceInputStream  StringBufferInputStream다 쓰진 않는다. 자주 쓰일거 같은 것들을 선택하여 쓰면 된다.FileInputStream당연하게도 File 을 입력 시킬 수 있다. 파일은 경로를 통해 설정할 수 있고, 설정 시에 소스가 정해진다.다음 생성자들을 통해 소스를 설정할 수 있다.생성자  FileInputStream(File file)  FileInputStream(String name)  FileInputStream(FileDescriptor fdObj)소스가 정해졌으면 stream 으로 데이터가 흐르도록 초기화가 끝난 것이고,주요 메서드  read(): 1 byte 읽기  read(byte[] b): b에 읽은 값들 저장  read(byte[] b, int off, int len): off 부터 len 길이 만큼의 byte 를 저장등을 통해 읽어들일 수 있다. 해당 class 는 @Closable 하기에 try-with-resources 문을 통해 자동으로 close() 메서드를 실행시켜준다.FilterInputStream해당 클래스는 추상 클래스이고 protected 로 생성자가 보호되고 있다.해당 클래스의 하위 클래스가 또 있는데, 다음 두 클래스가 자주 사용되는 듯하다.BufferedInputStream생성자로는 다음으로 초기화 가능하다.  BufferedInputStream(InputStream in)  BufferedInputStream(InputStream in, int size): size 는 버퍼사이즈이다.기본적으로 상위클래스인 FilterInputStream 이 read() 세가지 메서드를 구현하기에 다 사용 가능하다.DataInputStream마찬가지로 DataInputStream(InputStream in) 을 통해 초기화를 하며,특이하게도 여기에는 DataInput 이라는 인터페이스를 구현하고 있음을 볼 수 있다.DataInput 인터페이스를 구현하면 이는 binary stream 에서 바이트 단위로 데이터를 읽어와서그것을 자바의 기본 자료형으로 재구성 할 수 있게 해준다. 따라서 우리는 DataInputStream 으로읽어오기만 하더라도 자동으로 자바의 primitives 로 변환시켜준다는 것이다.예시를 보자.import java.io.DataInputStream;import java.io.FileInputStream;import java.io.IOException;public class DataInputExample {    public static void main(String[] args) {        try (DataInputStream dis = new DataInputStream(new FileInputStream(\"data.bin\"))) {            int number = dis.readInt();        // 4바이트 정수 읽기            double price = dis.readDouble();   // 8바이트 실수 읽기            boolean flag = dis.readBoolean();  // 1바이트 불리언 읽기            String text = dis.readUTF();       // Modified UTF-8 문자열 읽기            System.out.println(\"number = \" + number);            System.out.println(\"price = \" + price);            System.out.println(\"flag = \" + flag);            System.out.println(\"text = \" + text);        } catch (IOException e) {            e.printStackTrace();        }    }}위는 메서드들을 통해 쉽게 캐스팅을 하지 않고도 값을 읽어올 수 있음을 볼 수 있다.  readBoolean()  readByte()  readChar()  readDouble()  readFloat()  readFully(byte[] b)  readFully(byte[] b, int off, int len)  readInt()  readLine()  readLong()  readShort()  readUnsignedByte()  readUnsignedShort()  readUTF()  skipBytes()기능들은 함수명 그대로이기에 설명은 생략한다.ObjectInputStream자바 객체를 읽어오는 스트림이며, 바이트 단위 스트림을 기반으로 파일, 네트워크 등에서 직렬화(serialized) 된 객체를 복원(deserialize) 하는 객체이다.primitive 로 읽어오고 싶다면 FilterInputStream 의 DataInputStream 을, Object 로 읽어오고 싶다면 ObjectInputStream 을 쓰면 되겠다.  readObject(): 객체를 읽어들인다. 이때 반환은 Object 이므로 명시적 형변환이 필요하다.  여기서 모든 InputStream 은 안에 InputStream 을 넣어 초기화를 할 수 있는 생성자가 있다는 것을 저번에 posting 으로 썼었는데, 이를 통해 기능들을 늘릴 수 있다고 말했었다. 따라서 ObjectInputStream 은 기본 생성자가 protected 라서 생성자 안에 InputStream 을 무조건 넣어야 함을 볼 수 있는데, 이는 ObjectInputStream 혼자서 초기화가 되는게 아님을 볼 수 있다.Reader(Char Stream)  Abstract class for reading character streams. The only methods that a subclass must implement are read(char[], int, int) and close(). Most subclasses, however, will override some of the methods defined here in order to provide higher efficiency, additional functionality, or both.추상 클래스이며, 문자열 흐름을 읽어오기 위해 쓰는 메서드이다. 즉 Char Stream 이라고 보면 된다.주요 메서드  read(char[] cbuf)  read(char[] cbuf, int off, int len)  read(CharBuffer target)주요 하위 클래스  InputStreamReader  BufferedReader  FileReader주요 예시들을 보자.Character 를 맞는 decording method 설정해서 가져오기public class InputStreamReaderExample {    public static void main(String[] args) {        try (            FileInputStream fis = new FileInputStream(\"example.txt\"); // 바이트 스트림            InputStreamReader isr = new InputStreamReader(fis, \"UTF-8\"); // 문자 변환            BufferedReader br = new BufferedReader(isr) // 한 줄씩 읽기 편하게        ) {            String line;            while ((line = br.readLine()) != null) {                System.out.println(line);            }        } catch (IOException e) {            e.printStackTrace();        }    }}File을 읽기 위한 BufferedReader 의 readLine 기능을 활용public class BufferedReaderExample {    public static void main(String[] args) {        try (            FileReader fr = new FileReader(\"example.txt\");      // 문자 스트림            BufferedReader br = new BufferedReader(fr)          // 버퍼링 + 편리한 readLine()        ) {            String line;            while ((line = br.readLine()) != null) {           // 한 줄씩 읽기                System.out.println(line);            }        } catch (IOException e) {            e.printStackTrace();        }    }}OutputStream주요 함수는 다음과 같다.  flush()  write(byte[] b)  write(byte[] b, int off, int len)  FlushableFlushable 은 플러시될 수 있는 클래스의 대상이다. flush 메서드는 버퍼링된 출력을 기본 스트림에 쓰기 위해 호출된다.WriterChaining Method  append(char c): 단일 문자 추가  append(CharSequence csq): 문자 시퀀스 전체 추가  append(CharSequence csq, int start, int end): 문자 시퀀스 일부 추가  반환값이 자기 자신이라 체이닝 가능  write(int c): 단일 문자 스트림에 쓰기  write(char[] cbuf): 문자 배열 전체 스트림에 쓰기  write(char[], int off, int len)  write(String str): 문자열 전체 스트림에 쓰기  write(String str, int off, int len)PrintWriter우리가 알고 있는 일반적인 print 기능이 들어가 있는 writer 이다. 필요하면 찾아서 쓰자.BufferedWriter단일 문자, 배열, 문자열 등을 효율적으로 읽고 쓸 수 있는 클래스이다.자바에서는 Writer 클래스가 문자를 출력 스트림에 바로 보내는 역할을 하는데, write() 를 호출하면 곧바로 해당 문자들이 기본 스트림(File, OutputStream) 으로 전달되게 된다.하지만 이렇게 바로 쓰면 특히 파일이나 네트워크 등에 비용이 큰 출력 작업에서는 굉장히 비효율적일 수 있다. 매번 writer() 가 호출될 때마다 문자를 byte 로 변환시키고 출력 스트림에 전송시켜야 하기에 이를 방지하고자 다음처럼 BufferedWriter 의 기능을 가지면서 일정량의 데이터가 모일 때 한 번에 출력하도록 하면 좋다.import java.io.*;public class BufferedWriterExample {    public static void main(String[] args) {        try (            PrintWriter out = new PrintWriter(                new BufferedWriter(                    new FileWriter(\"foo.out\")                )            )        ) {            out.println(\"Hello, BufferedWriter!\");            out.println(\"이제 출력이 훨씬 효율적입니다.\");        } catch (IOException e) {            e.printStackTrace();        }    }}"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 14일차 Java IO",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/03/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-14%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-03",
      "content": "📂 목차  Java IO          Decorator Pattern      Java IO Decorators                  Java IO 바이트 단위 입출력 Stream          Java IO 문자 단위 입출력 Reader, Writer                    📚 본문Java IO자바는 입출력을 세 가지 원칙에 따라 만든다  유연성  확장성  재사용성Decorator Pattern객체에 추가적인 기능을 동적으로 부여하면서도 기존 코드를 수정하지 않고 확장 가능하도록 하는 디자인 패턴이다.  상속 대신 위임(Composition)  객체를 감싸는 래퍼 객체를 만들어 새로운 기능 추가  원래 객체의 인터페이스를 유지하면서 부가 기능을 점진적으로 붙여나감구성 요소  Component: 기본 기능을 정의하는 인터페이스나 추상 클래스  ConcreteComponent: 실제로 구현되고 동작하는 구현체  Decorator: Component 를 구현하면서 내부에 Component 를 포함하는(has-a 관계)  ConcreteDecorator: 구체적인 데코레이터이며, 기존 기능에 추가 기능을 덧붙인다.예시를 보자.Componentpublic interface Printer {    void print(String message);}Concrete Componentpublic class BasicPrinter implements Printer {    @Override    public void print(String message) {        System.out.println(message);    }}public abstract class PrinterDecorator implements Printer {    protected Printer printer; // 위임    public PrinterDecorator(Printer printer) {        this.printer = printer;    }    @Override    public void print(String message) {        printer.print(message); // 기본 동작은 그대로 유지    }}public class BracketPrinter extends PrinterDecorator {    public BracketPrinter(Printer printer) {        super(printer);    }    @Override    public void print(String message) {        super.print(\"[\" + message + \"]\");    }}public class UpperCasePrinter extends PrinterDecorator {    public UpperCasePrinter(Printer printer) {        super(printer);    }    @Override    public void print(String message) {        super.print(message.toUpperCase());    }}위를 보면 한눈에 이해 될 것이다. 여기서 PrintDecorator 가 짜여지는 코드를 기억해야 한다. 위임받은 Printer 를 has-a 로 가져가고 있고, protected 로 선언 하여 하위 ConcreteDecorator 들이 쓸 수 있도록 하며, 이를 상속받은 다양한 프린터들이 확장을 가능하게 한다.이런 Decorator 패턴은 implements Printer 로 그치지 않고 Printer 외의 다수의 계약을 넣어서 조합하여 사용할 수 있는 활용도 할 수 있을 것이다.이를 이해하고 Java IO를 보자.Java IO Decorators  InputStream  OutputStream  Reader  Writer전부 추상 클래스들이다. 이는 Decorator 에 해당하는 것일 터이다. 그럼 이를 Concrete 로 만들어주는 하위 데코레이터들이 다음 그림에 나타나있다.여기서 Stream 을 먼저 보자.Java IO 바이트 단위 입출력 StreamStream 은 흐름인데, 기본적으로 컴퓨터가 주고 받는 흐름의 주된 개체는 데이터이다. 이 데이터는 바이트 단위로 주고 받으며, 그래서 단위도 바이트를 자주 쓰게 되고, 이런 바이트의 흐름을 관리하는 기능을 가진게 Stream 이 된다.우리가 쓰고 읽는 모든 것들은 사실상 바이트로 되어 있기에, Stream 을 쓴다면 모든 종류의 데이터들을 처리할 수 있는 도구를 얻는 것이다.Stream 은 보통 보는 관점에 따라 카테고리를 나눌 수 있는데, 입력이냐 출력이냐에 따라  Input  Output으로 나뉘고, 데이터 단위에 따라  Byte Stream: 1 byte  Character Stream: 2 bytes(UTF-16)으로 나눌 수 있겠다.여기서 이제 흐름(stream) 을 들고와서 데이터 소스에 꽂기만 하면 그 흐름을 타고 알아서 우리 프로그램으로 데이터를 받아오게 된다.다음은 예제이다:import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;public class ByteStreamExample {    public static void main(String[] args) {        // try-with-resources를 사용한 자동 리소스 관리        try (FileInputStream in = new FileInputStream(\"input.jpg\");             FileOutputStream out = new FileOutputStream(\"output.jpg\")) {            int byteData;            // 파일 끝(-1)까지 한 바이트씩 읽기            while ((byteData = in.read()) != -1) {                out.write(byteData);            }            System.out.println(\"파일 복사 완료!\");        } catch (IOException e) {            System.err.println(\"파일 처리 중 오류: \" + e.getMessage());        }    }}Decorator 패턴을 쓰기에 OutputStream 이라는 추상 클래스를 통해 하위 ConcreteDecorator 들로 FileOutputStream, ByteArrayOutputStream 등등 많은 변종이 나옴을 사진에서 볼 수 있다.Java IO 문자 단위 입출력 Reader, Writer문자 스트림은 텍스트 데이터 처리에 최적화되어 있는데,  바이트 스트림과 달리 2byte 단위로 문자 데이터를 처리  한글이나 유니코드 문자를 다루는데 적합의 특징이 있다. 입출력을 할 때마다 그때그때 맞는 ConcreteDecorator 를 쓰면 되겠다.예시try (BufferedReader reader = new BufferedReader(new FileReader(\"input.txt\"));     BufferedWriter writer = new BufferedWriter(new FileWriter(\"output.txt\"))) {    String line;    while ((line = reader.readLine()) != null) {        writer.write(line);        writer.newLine(); // 줄바꿈    }    System.out.println(\"파일 복사 완료!\");} catch (IOException e) {    e.printStackTrace();}  try 안에 자원 여러개 넣을 수 있음"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 13일차 Comparable",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/02/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-13%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-02",
      "content": "📂 목차  Comparator, Comparable  Exception  Dependency Injection 고찰          Port-Adapter 에서의 Service Layer 문제점?      📚 본문Comparator, Comparable  Comparator: 클래스로써 sort 를 할 때 어떤 형태로 정렬을 할지 넣어줄 수 있는 클래스이다.  Comparable: 인터페이스로써 해당 클래스가 비교 가능하다는 것을 의미하고, compareTo 를 구현하여 달성할 수 있다.  Comparable 과 Comparator 둘 다 구현되어 있을때는 sort(, Comparator) 를 먼저 따른다.Exception 체이닝public class MyException extends RuntimeException {    public MyException(String msg) {        super(msg);    }    public MyException(Exception ex) {        super(ex);    }}위 예제에서 밑의 생성자를 보자. 위처럼 exception 을 다시 exception 으로 감싸서 던지는 것을 볼 수 있다. 위를 밑의 예시와 같이 설명하면:try {    throw new IOException(\"파일을 읽을 수 없음\");} catch (IOException e) {    throw new MyException(e); // 원인 예외 e 를 감싸서 다시 던짐}예외는 IOException 이 났지만, 이를 MyException 으로 감싸서 IOException 은 원인(cause) 로 들어가게 할 수 있다. 이때 사용자에게 보여주는 e.printStackTrace() 는 MyException 이 최상위로 뜨는 예외, 그 하위로 IOException 도 같이 출력되게 된다.MyException    at ...Caused by: java.io.IOException: 파일 못 읽음    at ...보통 생성자에 다음 생성자도 있다.XXXXXXException(String message, Throwable cause)이는 cause 는 그대로 cause 고, 해당 감싸지는, 즉 상위 exception 의 예외 메시지랑 함께 전달하고 싶을때 사용된다.public class CustomException extends RuntimeException {    public CustomException(String msg) {        ...    }    public CustomException(Throwable throw) {        ...    }    public CustomException(String msg, Throwable throw) {        ...    }}  그냥 셋 다 구현하는게 POJO 에서도 그렇고 보편적인거 같다.Dependency Injection 고찰의존성 주입을 할 때 Spring 에서는 ApplicationContext 를 통해 의존성 주입을 하도록 하는데, 이번에 미니프로젝트를 할 때에도 어떤게 static final 이어야 하는지 static 이어야 하는지 final 이어야 하는지가 관건이었다.우선 보통 static final 처럼 아예 하나만 존재하고 값이 변경 될 수 없도록 하는 것은 드물다. TimeZone 같은 것들을 보면 상수들을 다 이렇게 선언하는데, 보통은 reference 변수 보다는 primitive 한 애들한테 적용시키는게 낫다.두 번째로 static 인데, 얘는 final 이 없기 때문에 이 값을 수정 할 수 있지만 오로지 하나만 존재하게 된다. 즉 Inject 의 대상으로 보기 보다는 공유 자원으로 보기에 걸맞다마지막으로 final 로 선언한 아이인데, 얘는 의존성 주입하기에 의미가 들어맞는다. 클래스를 초기화 할 때 그때 주입을 해놓으면 그 이후는 어디에서도 이를 변경할 수 없고, 초기화 될 때만 해당 값을 갖게 된다. 그렇다면 Application 을 실행을 할 때에 우선 초기화를 다 시켜두고, 그 이후에 초기화 된 애들을 각각 조립하는 것처럼 인자로 넣어주기만 한다면, static 과 final의 콜라보로 DI 를 달성할 수 있다.Context 초기화 및 필요 reference 들 인스턴스화 및 주입public class ApplicationContextImpl implements ApplicationContext {    private final BookRepository bookRepository;    private final MemberRepository memberRepository;    private final SessionContext sessionContext;    private final MemberService memberService;    private final LibraryService libraryService;    public ApplicationContextImpl() {        // Repository 싱글톤 사용        bookRepository = BookRepositoryImpl.getInstance();        memberRepository = MemberRepositoryImpl.getInstance();        sessionContext = SessionContextImpl.getInstance();        // Service 에 주입        memberService = MemberServiceImpl.getInstance(memberRepository, sessionContext);        libraryService = LibraryServiceImpl.getInstance(bookRepository, sessionContext);    }어플리케이션에서 필요한 값들을 가져와 주입public class LibraryApplication {    private final Map&lt;String, Supplier&lt;String&gt;&gt; commandMap;    private final OutputManager outputManager;    private final SessionContext sessionContext;    private final LibraryService libraryService;    private final MemberService memberService;    public LibraryApplication(ApplicationContext applicationContext) {        commandMap = new HashMap&lt;&gt;();        outputManager = new OutputManager();        // =================== DI ===================        sessionContext = applicationContext.getSessionContext();        libraryService = applicationContext.getLibraryService();        memberService = applicationContext.getMemberService();    }여기서 얻어갈 수 있는 것은 만약 static final 로 멤버변수에 그대로 넣고 생성자에서 초기화를 안했다고 한다면, 이는 나중에 테스트 단에서 Mock 이나 Stub 등으로 갈아끼우기가 힘들게 된다. 위처럼 가져가고 나중에 생성자에 인자를 더 넣어 주입하는 식으로 하면 더 편할 것이다.Port-Adapter 에서의 Service Layer 문제점?구현하다보니 Port-Adapter 에서 쓰이는 Service 포트를 구현하다 보면 DI를 할 때 몇 가지 의문이 생긴다.포트라는 것은 Adapter 로의 연결인데 안쓰는 getInstance() 라는 것으로 인터페이스에 메서드를 넣게 되면안되는데, 그렇게 되면 어플리케이션 초기화 시점에서 구현체를 통해 getInstance() 를 넣을 수 밖에 없는건가 싶었다.만약 그렇게 getInstance() 를 넣게 된다면(위처럼 코딩이 된다면) 내가 Service 만 갈아끼우고 싶을때어떻게 해야 하는건가 라는 의문이 생겼다…하지만 이런 의문은 괜한 의문이었는데, Port-Adapter 에서 ApplicationContext 라는 인터페이스를 두고 여기서 get(클래스)() 형식으로 Application 에게 인스턴스를 제공하는 포트를 주게 된다. 여기서 이미 설계도는 어플리케이션에게 줬고, 그 뒷단의 구현부는 ApplicationContextImpl 이 하기에 서비스가 바뀐다고 한들, 여기에서 생성자의 초기화 하는 곳만 바꿔주기만 하면 코드의 수정은 단어 하나만 바꾸고 추가하고 싶은 ServiceImpl.java 만 여기에 넣어주면 된다. 이래서 port-adapter 라고 하나보다.  지금으로써는 이 방법이 최우선인 듯하다. 스프링에서는 자동으로 이를 해준다는게 신기하다고 느낀 부분이다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 12일차 SOLID 규칙과 아키텍쳐",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/09/01/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-12%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-09-01",
      "content": "📂 목차  SOLID          Single Responsibility Principle      Open-Closed Principle      Liskov Substitution Principle      Interface Segregation Principle      Dependency Inversion Principle        패키지 혼동          VO 패키지      Domain 패키지      Entity 패키지      Data 패키지        구조 아키텍쳐          MVC 아키텍처      Domain-Driven Design 아키텍처      Port-Adapter 아키텍처                  Port          Adapter          primary                    Layered 아키텍처      FSD 아키텍처        접근제한자📚 본문미니프로젝트(도서 서비스, 멤버 서비스) 구현에 있어 겪었던 문제점과 해결책들을 적어보려고 한다.내가 느꼈던 혼란을 좀 정리하여서 다음에는 의미가 분명하도록 하기 위함이다.SOLIDSingle Responsibility Principle클래스 또는 모듈은 하나의 책임만을 가져야 하며,변경 사유가 여러 가지가 되면 안된다.  MemberService 는 회원 가입/탈퇴/조회만 하고,책 관리는 LibraryService 가 하도록나는 위를 Service 계층에서 적용시키지 못하여 추후에 수정하려고 한다.Open-Closed Principle확장에는 열려있고, 수정에는 닫혀 있어야 한다.새로운 기능을 추가할 때에는 기존 코드를 직접 수정하지 않고도 확장으로 해결 할 수 있도록 한다.  전략 패턴은 할인 정책을 바꾸려면 DiscountPolicy 인터페이스구현체만 추가 하여 새로운 기능을 추가할 수 있을 것이다.Liskov Substitution Principle상위 타입 객체를 하위 타입으로 바꿔도 프로그램 동작이 깨지면 안된다.즉 자식 클래스는 부모 클래스의 계약(기능)을 위반하지 않아야 한다.  Rectangle 의 자식이 Square 라면, setWidth() 와 setHeight() 동작이 부모의 기대를 충족해야 한다.즉 상위 동작이 하위 동작을 포함시키냐는 것이다.Interface Segregation Principle클라이언트는 자신이 사용하지 않는 기능에 의존적이지 않아야 한다.너무 많은 기능을 가진 인터페이스를 나눠서 꼭 필요한 것만 구현하도록 한다.  Printer 인터페이스는 print(), scan(), fax() 를 가지게 된다면 단순히 프린터만 하는 PurePrinter 는 위 세 개를 다 구현해야 한다.Dependency Inversion Principle의존관계를 맺을 때 변화하는 클래스와 관계를 맺기 보다 변화하지 않는 클래스와 관계를 맺는 것.패키지 혼동패키지 의미가 분명하지 않아 나도 클래스를 여기저기 의미가 이거겠지 하고 유추하며분배했던 기억이 나서 이를 확실히 하기 위해 다음처럼 나눈다.VO 패키지Value Object의 약자이며 멋사를 진행할 때 처음 보았던 패키지이다.  Equality 를 가지고 이 동등성을 식별자가 아니라 값 그 자체로 비교하는 객체  Immutable 로 설계하는 것이 바람직하며, 두 VO 는 필드 값이 같으면 같은 객체로 취급되게 된다.  equals/hashCode 오버라이드가 중요하다.내가 구현했던 Book 클래스는 record 를 사용해서 선언했으며 이는 3번의 수고를 덜 수 있어 괜찮았다.좋은 점은 불변이라서 값이 안변하여 로직에서 어떤 값이 들어가 있을지 예상이 간다는 것이다.Domain 패키지비즈니스 로직과 규칙과 함께 핵심적인 계층이다.포함되는 것  Entity 패키지  VO 패키지  Domain Service(특정 엔티티에 귀속되지 않는 도메인 로직)  Aggregate, Repository 인터페이스가 여기에 들어간다고 한다. 특히, 외부 기술에 의존하지 않아야 하며(POJO),시스템이 해결하는 문제의 본질적인 개념을 모델링한 공간이라고 한다.  내가 틀렸던 것은 Domain 을 Entity 와 혼동하고 있었기 때문이다.조금 더 국소적인 개념으로 바라본게 의사소통의 문제가 생겼던거 같다.Entity 패키지식별자(ID)를 가지며, 라이프 사이클이 관리되는 객체이다.  같은 ID = 같은 객체  DB 테이블과 1:1 매핑이 됨(JPA @Entity)  가변적(mutable) 일 수 있음Data 패키지데이터 전송, 저장 계층이며, DB, API 등 외부 저장소와의 상호작용을 담당하는 계층이다.포함되는 것  Repository 구현체 (JPA Repository)  DAO (Data Access Object) 패키지  DTO (Data Transfrer Object) 패키지특징으로는 아까와는 다르게 Repository 가 외부 라이브러리에 의존적임을 볼 수 있으며,domain 을 그대로 노출하지 않고, data 레이어에서 직접 변환 후 전달하는게 특징이다.구조 아키텍쳐MVC 아키텍처  Model: 핵심 데이터와 비즈니스 로직을 담당한다.DB 와 연결된 엔티티, 서비스 로직 등이 들어간다.  View: 사용자에게 보여질 화면이다.  Controller: 사용자의 요청을 받아 Model 을 조작하고 결과를 View 에 전달한다.  대규모 프로젝트에서는 맞지 않다. Controller 가 비대해지게 되고, 서비스/도메인 계층이 부족하면 Model 과 Controller 간의 경계가 모호해진다.Domain-Driven Design 아키텍처비즈니스 로직을 중심으로 설계하는 아키텍쳐이다.  Domain: 엔티티, VO, 도메인 서비스 등등  Application: 유스케이스, 흐름 제어  Infrastructure: DB, Messaging, 외부 API 등  Interface: UI, Controller도메인 개념이 코드에 녹아들어 협업, 유지보수에 좋다.여기서 특이하게 유스케이스, 흐름 제어가 보이는데,Port-Adapter 아키텍처어플리케이션을 비즈니스 로직과 외부 의존성으로 분리하는 아키텍처이다. 이번에 리팩터링 해야 할 아키텍처 대상이다.  Port: 도메인이 외부와 통신하는 인터페이스(추상화)  Adapter: 외부 구현체(DB, API, UI)장점으로는 DB, UI, 메시징 같은 외부 기술을 교체하기가 쉽다.그리고 테스트하기에도 유리하다(mock adapter).Port포트는 꽂는 그 장소를 말한다. 우리의 프로그래밍에서는 특정 함수를 예로 들 수 있는데 가령 login() 이라는 함수가 있다면 우리의 요청이 여기에 들어가 꽂히게 되는 것이다. 이런 것을 Port 라고 한다.그렇다면 이런 함수를 구현하는 아이는 Interface 이기에 Port 가 자바의 interface 임을 알 수 있다.Adapter위에서 login() 이 포트였다면 여기에 들어갈 어댑터가 필요하다. 어댑터는 포트로 연결해주는 아이라고 보면 된다. 따라서 이를 연결시켜주는 것은 MVC 패턴에서 Controller 가 했음을 볼 수 있다. 따라서 Controller 가 어댑터 기능을 하게 된다.  MemberController  MemberService          MemberServiceImpl      이 있다고 하자. 여기서 MemberService 는 포트, MemberController 는 어댑터가 되는 것이다.primary위 포트, 어댑터 개념에서 외부의 요청을 직접 받아 동작하는 포트와 어댑터를 주포트, 주어댑터라고 하고 통틀어서 주요소(primary) 라고 한다.주요소 외에도 이러한 포트 어댑터는 요청 앞단만 있는게 아니라 뒷단에도 있다.예를 들어 MemberService 라는 서비스는 특정 레포지토리에 접근하여 실제 DB 로의 연결을 통해 데이터를 주고 받게 된다.이를 접근하게 해주는 것이 Service 인터페이스, Repository 인터페이스 이므로 MemberService 기준으로 이 둘은 포트가 된다.또한 DB에서의 API 가 Port, 중간에 껴있는 MemberRepository 구현체가 Adapter 가 되게 된다.Layered 아키텍처가장 전통적이고 흔한 방식이다.  Presentation: Controller, View  Application, Service: 유스케이스  Domain: 엔티티, 도메인 로직  Infrastructure: DB, 외부 시스템단순하고 직관적이며, 계층 간 의존성이 단방향이다.FSD 아키텍처프론트엔드에서 주로 사용하는 방식이며, 기능 단위로 모듈을 나누는 구조이다.  App  Process: Deprecated  Pages  Widgets  Features  Entities  Shared단방향이며 모놀리식 서비스에서 기능 단위 패키징 방식으로 사용이 가능하다.접근제한자static final을 Service, Repository 등에 사용하는 것을 구현했는데, 이때 굳이 상수로 취급하여서 둔 이유가 있을까? 가 질문이었다.우선은 구현 의도는 다음과 같았다.  싱글톤 의도에 더 적합하고  멀티 스레드 환경에서 실수로 참조를 바꿔치기 하는 것을 막는다.하지만 이렇게 구현하면 다음과 같은 단점이 생긴다.  테스트에 불편하다(Mock 이나 Stub 으로 교체가 안된다)  재설정이 불가능하다  DI 의존성 주입 패턴과 충돌하게 된다.후자가 더 유연하고 맞는거 같아 후자를 택하여 다시 리팩터링했다.✒️ 용어모놀리식 서비스어플리케이션을 하나의 통합된 코드베이스와 단일 배포 단위로 구성하는 아키텍처이다. 기능이 많더라도 모두 한 프로젝트 안에 들어가고, 하나의 실행 파일로 배포되게 된다.장점  단순  개발 속도가 빠름  디버깅 쉬움  배포가 간단단점  서비스가 커질수록 빌드/배포 시간이 느려짐  코드베이스가 거대해져 유지보수가 어려워짐(스파게티 코드화)  특정 기능에 장애가 나면 전체 서비스가 다운됨  기술 스택을 기능 별로 다르게 쓰기 힘듦마이크로 서비스기능을 서비스 단위로 쪼개서 독립적으로 배포하고 운영한다.회원서비스 따로, 주문 서비스 따로 등등"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 11일차 Context 와 ThreadLocal",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/31/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-11%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-31",
      "content": "🪛 한계점실무에서 이론을 적용시키기에는 몸이 단련이 되어 익숙해있어야 한다.미니 프로젝트를 통해서 체화 되도록 연습해야한다.📂 목차  Context          ThreadLocal      ExecutorService      Modern Java Concurrent 버전                  allOf(), anyOf()          exceptionally()                    📚 본문미니프로젝트를 하면서 필요했던 것들을 구현해보자. 여기서는 순수 자바에 대한 구현에 대해 말한다.Context어플리케이션의 상태, 환경 정보, 공통 리소스 등을 중앙에서 관리하는 역할을 한다.  RequestContext: 요청별 정보(사용자, 세션, 트랜잭션) 등을 저장한다.  ThreadPool + Context: 스레드 풀에서 작업을 실행할 때,작업이 필요한 환경 정보나 리소스를 컨텍스트에서 가져오게 된다.두 번째 형태는 보통 순수 자바 서버에서 특정 시스템을 구현할 때 사용한다고 한다.ThreadLocal우선 작업을 처리할 스레드 여러 개를 다룰 수 있게 스레드 한 단위를 구현해보자.순수 자바에서는 ThreadLocal 이라는 클래스를 제공하는데, 해당 인스턴스는 독립적으로변수 저장소를 가지고, 일반적인 인스턴스 변수나 static 변수와는 달리 thread 마다 별도의 값을 지닌다.따라서 여러 스레드가 같은 ThreadLocal 객체를 공유해도, 실제 값은 스레드 별로 독립적이다.// ThreadLocal 선언ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();// 값 저장threadLocal.set(\"Alice\");// 값 읽기String user = threadLocal.get();System.out.println(user); // Alice// 값 제거 (필수는 아니지만 메모리 누수 방지를 위해 권장)threadLocal.remove();요약  각 thread 에서 get() 을 호출 시 자기 스레드 전용 값이 나옴  다른 스레드에서 set() 을 해도 다른 스레드 전용 값에는 영향을 안미침이를 토대로 RequestContext 에 해당 인스턴스를 적용시키면,public class RequestContext {    private static final ThreadLocal&lt;RequestContext&gt; context =        ThreadLocal.withInitial(RequestContext::new);    private String currentUser;    public static RequestContext get() {        return context.get();    }    public String getCurrentUser() {        return currentUser;    }    public void setCurrentUser(String user) {        this.currentUser = user;    }    public static void clear() {        context.remove();    }}위와 같이 선언하면 스레드 별로 다른 값들을 관리할 수 있게 된다.ExecutorService이제 로컬 스레드의 저장소 관리를 보았으니, 처리하는 프로세스를 정의 할 차례이다.순수 자바에서 ExecutorService 는 스레드 풀(Thread Pool)을 관리하고,스레드 작업을 쉽게 실행할 수 있게 해주는 핵심 클래스이다.여기에 작업을 제출하여 실행할 수 있게 된다.예시import java.util.concurrent.*;public class ExecutorServiceExample {    public static void main(String[] args) {        // 1. 고정 스레드 풀 생성 (스레드 3개)        ExecutorService executor = Executors.newFixedThreadPool(3);        // 2. 작업 제출        for (int i = 1; i &lt;= 5; i++) {            final int taskId = i;            executor.submit(() -&gt; {                System.out.println(Thread.currentThread().getName() + \" 처리중: Task-\" + taskId);            });        }        // 3. 종료        executor.shutdown();    }}위처럼 작업(Runnable, Callable)을 받아들여 작업 큐를 통해 3개의 스레드로 들어가 처리한다. 여기서 submit 은 비동기로 실행된다.ExecutorService 에 submit() 된 task 들은 전부 Future 를 통해 값을 받을 수 있다.Modern Java Concurrent 버전하지만 위와 같이 여러 개의 작업을 실행 후에 Future 로 받는다고 치면 Future 이 여러개 있어야 한다. 이를 한 변수로 담아서 한 번에 처리하려면 다음 코드를 보자:import java.util.concurrent.CompletableFuture;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ThreadLocalRandom;public class CompletableFutureExample {    public static void main(String[] args) {        ExecutorService executor = Executors.newFixedThreadPool(3);        System.out.println(\"작업 시작...\");        CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; {            System.out.println(Thread.currentThread().getName() + \"에서 비동기 작업 실행 중...\");            try {                Thread.sleep(ThreadLocalRandom.current().nextInt(1000, 3000));            } catch (InterruptedException e) {                Thread.currentThread().interrupt();            }            return \"작업 완료!\";        }, executor); // 사용 할 Executor를 명시적으로 지정        future.thenAccept(result -&gt; {            System.out.println(Thread.currentThread().getName() + \"에서 결과값 받음: \" + result);        });        System.out.println(\"메인 스레드는 다른 작업 진행 중...\");        try {            future.get(); // 작업이 끝날 때까지 기다림        } catch (Exception e) {            e.printStackTrace();        }        executor.shutdown();        System.out.println(\"모든 작업 종료.\");    }}위 예제에서는 CompletableFuture 라는 클래스의  thenAccept 를 통해 값이 들어올 때마다 consume 되도록 하는 함수를 볼 수 있고,  supplyAsync 함수를 통해 값을 Supplier 를 통해 ExecutorService 에게 제공함을 볼 수 있다.  만약 스레드 간의 각 task 를 처리 중에 있어 예외가 발생하면 자동적으로 스레드의 interrupt 값은 true -&gt; false 로 초기화가 된다. 이때 상위 호출자에게 하위 호출자가 interrupt 되었다는 것을 알리기 위해 interrupt() 를 호출하여 여기에 Exception 이 터졌다는 것을 알려주게 된다.allOf(), anyOf()  CompletableFuture.allOf() 인자로 받은 CompletableFuture 들에 대해 모든 결과가 성공적으로 완료됐을 때, CompletableFuture&lt;Void&gt; 를 생성하는 함수CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; \"결과1\");CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; \"결과2\");// 모든 작업이 끝날 때까지 기다림CompletableFuture&lt;Void&gt; allFutures = CompletableFuture.allOf(future1, future2);// 모든 작업이 완료된 후에 실행allFutures.thenRun(() -&gt; {    System.out.println(\"모든 작업이 완료되었습니다.\");});  CompletableFuture.anyOf() 인자로 받은 CompletableFuture 중에 하나라도 완료되면 해당 완료된 값을 담는 새로운 CompletableFuture&lt;Object&gt; 를 생성한다.CompletableFuture&lt;String&gt; futureA = CompletableFuture.supplyAsync(() -&gt; {    try { Thread.sleep(3000); } catch (Exception e) {}    return \"서버 A의 결과\";});CompletableFuture&lt;String&gt; futureB = CompletableFuture.supplyAsync(() -&gt; {    try { Thread.sleep(1000); } catch (Exception e) {}    return \"서버 B의 결과\"; // 더 빨리 끝남});// 둘 중 하나라도 먼저 끝나는 것을 기다림CompletableFuture&lt;Object&gt; anyFuture = CompletableFuture.anyOf(futureA, futureB);// 가장 먼저 완료된 작업의 결과값을 사용anyFuture.thenAccept(result -&gt; {    System.out.println(\"가장 먼저 완료된 결과: \" + result);});  이때 명시적 형변환이 불가피하다.exceptionally()CompletableFuture 에서 비동기 작업 중 예외가 발생했을 때 그 예외를 잡아서 처리하고, 정상적인 결과값으로 복구할 수 있게 해주는 메서드이다.import java.util.concurrent.CompletableFuture;import java.util.concurrent.Executors;public class ExceptionallyExample {    public static void main(String[] args) {        // 1. 의도적으로 예외를 발생시키는 CompletableFuture        CompletableFuture&lt;String&gt; futureWithException = CompletableFuture.supplyAsync(() -&gt; {            System.out.println(\"작업 시작: 예외를 발생시킵니다.\");            throw new RuntimeException(\"고의로 발생시킨 에러!\");        }, Executors.newSingleThreadExecutor());        // 2. exceptionally()를 사용하여 예외 처리        CompletableFuture&lt;String&gt; recoveredFuture = futureWithException.exceptionally(ex -&gt; {            System.out.println(\"예외를 잡았습니다: \" + ex.getMessage());            // 예외가 발생했을 때 대체할 값(정상 값)을 반환            return \"복구된 기본값\";         });        // 3. thenAccept()로 최종 결과를 받아서 출력        recoveredFuture.thenAccept(result -&gt; {            System.out.println(\"최종 결과: \" + result);        });                // main 스레드가 종료되지 않도록 잠시 대기        try {            Thread.sleep(1000);        } catch (InterruptedException e) {            Thread.currentThread().interrupt();        }    }}"
    },
  
    {
      "title": "Collection",
      "url": "/seonghun120614/computerscience/java/2025/08/28/collection.html",
      "date": "2025-08-28",
      "content": "📂 목차  Collection          Collections 활용      List Interface 에 대한 Collections 활용                  CopyOnWriteArrayList                    Set Interface 에 대한 Collections 활용                  TreeSet          EnumSet          LinkedHashSet                    Queue Interface 에 대한 Collections 활용                  LinkedList          PriorityQueue          BlockingQueue Interface                    📚 본문Collection참고: Java APICollections 활용  clear: c의 모든 요소에 대해 제거한다.  retainAll: c의 최대 공통 부분을 찾는다(교집합)  collection1.contains(collection2): 해당 원소가 포함되는지 찾는다.  Iterator&lt;E&gt; iterator(): 순회용 Iterator 를 반환한다.  Object[] toArray(): 배열로 변환한다.List Interface 에 대한 Collections 활용  Collections.sort(list): 주어진 리스트를 오름차순으로 정리한다.  Collections.rotate(list, movement): movement 만큼 오른쪽으로 2칸 회전한다.  Collections.shuffle(list): 원소들을 무작위로 섞는다.  Collections.fill(list, 0): list를 0으로 채운다.  ⭐️ Collections.synchronizedList(new ArrayList&lt;&gt;()): 동기화된 list 를 생성한다.  ⭐️ Collections.unmodifiableList(list): 읽기 전용 리스트를 만든다.  Collections.frequency(list, element): element 의 빈도를 반환한다.  Collections.max() / .min()  Collections.swap(list, idx1, idx2): idx1 과 idx2 자리의 값을 교환한다.CopyOnWriteArrayList동기화와 읽기 위주의 최적화를 제공하는 리스트이다. 멀티스레드 환경에서 읽기가 많을 때 사용한다.Set Interface 에 대한 Collections 활용  Collections.synchronizedSet(set): set을 받아 동기화되는 Set 을 반환한다.  Collections.unmodifiableSet(set): set을 받아 읽기 전용 Set 을 만든다.  unmodifiableXXXX 와 같이 쓰기 보다그냥 unmodifiableCollection 을 쓰면 된다.synchronized 도 마찬가지이다.TreeSetSet 인터페이스를 구현하는 클래스이며, ordered 의 특징을 가진다. Comparator 을 통해 정렬 순서를 정할 수 있다. 내부적으로는 이진 트리 기반의 레드-블랙 트리가 쓰인다.EnumSetenum 타입 전용의 Set 을 생성한다. enum 요소를 Set 으로 관리할 때 효율적이다.LinkedHashSetHashSet 인데 순서를 가지고 싶은 경우 사용한다.Queue Interface 에 대한 Collections 활용FIFO 구조를 가지는 인터페이스이며,  BlockingDeque  BlockingQueue  Deque  TransferQueue의 하위 인터페이스가 있다. 위에서의 add, remove 와는 좀 다르게 다음 행위를 한다.  offer(e): e 요소를 추가한다. 실패 시 false 를 반환한다.  poll(): 요소를 제거한다. 비어 있으면 null 을 반환한다.  peek(): 다음 요소를 확인하며 비어 있으면 null 을 반환한다.구현체를 보자.LinkedList여러 개의 Node 가 연결되어서 저장되는 구조로 확장이 용이하다.  읽기 성능 느림  첫 요소(addFirst(), removeFirst())  마지막 요소(addLast(), removeLast())PriorityQueue우선순위 큐라고 부르며, Comparable 을 구현하여 사용하거나 Comparator 기반의 정렬을 한다.import java.util.*;class Student {    int mathScore;    int englishScore;    public Student(int mathScore, int englishScore) {        this.mathScore = mathScore;        this.englishScore = englishScore;    }    @Override    public boolean equals(Object obj) {        if (this == obj) return true;        if (obj == null || getClass() != obj.getClass()) return false;        Student other = (Student) obj;        return this.mathScore == other.mathScore &amp;&amp;                this.englishScore == other.englishScore;    }    @Override    public int hashCode() {        return Objects.hash(mathScore, englishScore);    }}public class Solution {    public static void main(String[] args) {        Queue&lt;Student&gt; queue = new PriorityQueue&lt;&gt;((o1, o2) -&gt; {            if (o1.mathScore == o2.mathScore)                return o1.englishScore - o2.englishScore;            return o1.mathScore - o2.mathScore;        });        queue.add(new Student(90, 85));        queue.add(new Student(75, 95));        queue.add(new Student(90, 80));        queue.add(new Student(60, 70));        queue.add(new Student(75, 85));        // Queue 출력 (poll로 순서 확인)        while (!queue.isEmpty()) {            Student s = queue.poll();            System.out.println(\"Math: \" + s.mathScore + \", English: \" + s.englishScore);        }    }}BlockingQueue Interface큐가 비어있다면 take() 에서 대기하고 꽉 차면 put() 에서 대기한다.이를 blocking 이라고 한다.구현체  ArrayBlockingQueue: 고정 크기 배열 기반  LinkeBlockingQueue: 링크드 노드라 크기 유연  PriorityBlockingQueue: 우선순위 큐 + 블로킹  DelayQueue: 일정 시간 후에 요소가 처리되는 큐  SynchronousQueue: 요소가 들어오면 바로 Consumer 에게 전달Blocking큐가 가득 차 있으면 새로운 요소를 넣을 수 없게 된다.그 순간 put() 을 호출한 스레드는 블로킹이 되어 대기 큐로 이동하며,큐에 공간이 생길 시 자동으로 다시 ready queue 로 가서 실행될준비를 하게 된다. take() 도 동일실제로 코드를 보자.import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.BlockingQueue;class Producer implements Runnable {    private final BlockingQueue&lt;Integer&gt; queue;    public Producer(BlockingQueue&lt;Integer&gt; queue) {        this.queue = queue;    }    @Override    public void run() {        try {            for (int i = 1; i &lt;= 5; i++) {                System.out.println(\"Producer: \" + i + \" 생성\");                queue.put(i); // 큐가 꽉 차면 블로킹                Thread.sleep(500); // 생산 속도 조절            }        } catch (InterruptedException e) {            Thread.currentThread().interrupt();        }    }}class Consumer implements Runnable {    private final BlockingQueue&lt;Integer&gt; queue;    public Consumer(BlockingQueue&lt;Integer&gt; queue) {        this.queue = queue;    }    @Override    public void run() {        try {            while (true) {                Integer data = queue.take(); // 큐가 비면 블로킹                System.out.println(\"Consumer: \" + data + \" 소비\");                Thread.sleep(1000); // 소비 속도 조절            }        } catch (InterruptedException e) {            Thread.currentThread().interrupt();        }    }}public class BlockingQueueExample {    public static void main(String[] args) {        BlockingQueue&lt;Integer&gt; queue = new ArrayBlockingQueue&lt;&gt;(2); // 최대 2개 저장 가능        Thread producer = new Thread(new Producer(queue));        Thread consumer = new Thread(new Consumer(queue));        producer.start();        consumer.start();    }}"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 10일차 Reference 형 타입과 JMM 멀티 스레딩",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/28/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-10%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-28",
      "content": "📂 목차  Wrapper          캐싱 최적화        Record  Generic          Generic Method      Bounded Type      제너릭 타입 파라미터 vs 와일드카드(?)        Java Memory Model(JMM)          Ordering      Atomicity                  Atomic Class          Volatile                    동기화                  Synchronized                    Synchronized vs Volatile 적용 위치      📚 본문Wrapperprimitive 타입을 reference 타입으로 바꾸는 클래스이다.이 행위를 boxing 이라고 하며, Java 5 부터 boxing, unboxing 을 통해 자동으로 형변환을 해준다.메모리 및 참조 측면  primitive 는 스택(Stack) 메모리에 값 자체가 저장됨  wrapper 객체는 힙(Heap) 메모리에 생성되고, 변수에는 그 객체의 참조(reference)가 저장됨  따라서 wrapper 는 객체이므로 null 값을 가질 수 있고, 제너릭/컬렉션에서 객체로 다룰 수 있음  하지만 객체 생성/참조 때문에 primitive 에 비해 메모리 사용량과 성능 오버헤드가 있음캐싱 최적화캐싱 최적화는 Wrapper 클래스가 불필요하게 객체를 계속 생성하지 않도록 자주 쓰이는 값을 미리 캐싱해두는 것을 말하며, 다음 값들을 캐싱한다.  Byte, Short, Integer, Long: -128 - 127 범위를 캐싱  Character: 0 - 127 캐싱  Boolean: true, false 두 값만 캐싱  Double, Float: 캐싱 없음RecordJava 14 에 도입된 기능이며, Java 16 부터 정식으로 사용하게 된다. 데이터 전달 객체(VO, DTO) 등에 보일러 플레이트 코드를 줄여주는 문법이며, 다음 메서드를 자동으로 생성한다:  equals()  hashCode()  toString()예시public record Book(long id, String title, String author, boolean isRented) { }불변이기에 상속이 불가능하며, JPA 엔티티와 같은 mutable 한 객체에는 적합하지 않다.GenericJava 의 제너릭(Generic)은 클래스나 메서드가 사용할 타입을 외부에서 지정할 수 있도록 하는 기능이다.즉, 코드 재사용성과 타입 안전성을 높여준다.장점  타입 안정성 보장: 잘못된 타입을 넣으면 컴파일 타임에 에러 발생  형변환(Casting) 불필요  코드 재사용성 증가  제너릭은 기본적으로 reference 타입이 들어가야 한다.기본 문법// 제너릭 클래스public class Box&lt;T&gt; {    private T value;    public void set(T value) { this.value = value; }    public T get() { return value; }}// 사용Box&lt;String&gt; box = new Box&lt;&gt;();box.set(\"Hello\");String str = box.get();  // 형변환 필요 없음Generic Method특정 타입들에 대한 함수를 만들고 싶을때 선언할 수 있다. 이는 클래스 scope 에 선언된 제너릭 변수를 들고와도 되고, 쓰고 싶은 제너릭 변수를 함수 앞쪽에 선언해주어도 된다.// void 앞에 쓸 Generic 을 선언public static &lt;T&gt; void printArray(T[] array) {    for (T element : array) {        System.out.println(element);    }}Bounded Type모든 타입을 참조하여서 쓰는 것은 바람직하지 않다. 심지어 모든 타입을 그대로 그 함수가 받아서 올바른 행위를 수행할 수 있는 코드를 짤 수 있을지도 의문일 것이다.이를 제한시켜 사용할 수 있는 예약어가 extends, super 이다.extends 키워드  extends 는 특정 타입과 그 하위 타입만 허용하도록 제한할 수 있다.  주로 메서드의 파라미터 또는 제너릭 타입 선언에서 사용된다.// Number 와 그 하위 타입만 받을 수 있음public static &lt;T extends Number&gt; void showNumber(T num) {    System.out.println(num.doubleValue());}super 키워드  super 는 반대로 하위 타입까지 허용할 수 있도록 한다.  주로 메서드의 파라미터에서 사용된다.// Number 와 그 상위 타입을 받을 수 있음public static void addNumber(List&lt;? super Integer&gt; list) {    list.add(10);   // Integer 추가 가능    // list.get(0); // Object 로만 꺼낼 수 있음}제너릭 타입 파라미터 vs 와일드카드(?)T, E, K, V 등  제너릭 클래스나 메서드에서 타입을 선언할 때 주로 사용  의미를 명확히 나타내는 이름으로 바꿔서 사용 가능          T: Type      E: Element (컬렉션 요소)      K: Key      V: Value      (굳이 정해진 알파벳은 없고, 대문자에 한 문자로 쓰는게 관례이며, ID 이렇게 써도 된다.)      예시public class Box&lt;T&gt; {    private T value;    public void set(T value) { this.value = value; }    public T get() { return value; }}? (와일드카드)  특정 타입에 제한을 두지 않고 모든 타입을 참조할 수 있도록 할 때 사용  주로 메서드 파라미터에서 유연성을 주기 위해 사용public void printList(List&lt;?&gt; list) {    for (Object obj : list) {        System.out.println(obj);    }}차이 요약  T, E 등: 제너릭 타입 변수, 실제 타입이 지정될 때 구체적으로 결정됨  ? : 와일드카드, 메서드 호출 시점까지 정확한 타입을 알 수 없음,읽기 전용에 주로 사용Java Memory Model(JMM)Java Memory Model(JMM)은 Java에서 멀티스레드 환경에서 메모리 접근과 가시성, 순서 문제를 정의한 규격이다.즉,  CPU 캐시, 레지스터, 메인 메모리 간의 동기화 문제를 정의  스레드 간 Visibility 와 Ordering 을 보장하도록 설계한다.  여기서 visibility 란 한 스레드에서 값이 바뀌어도 다른 스레드의 값이 바로 보장되지 않을 수 있는데,이런 성질을 지키는 것이 바로 visibility 이다.Ordering여기서 왜 Visibility 가 깨질 수 있는지를 들여다 보자.컴파일러와 CPU는 명령 재정렬(Instruction Reordering)이 가능한데,이는 명령을 수행하는데 있어 최적화 되는 방향으로 JVM 이 실행 명령을 조정하는 행위이다.이로써 코드 수행을 더 빠르게 할 수 있는데, 문제는멀티 스레드 환경에서 의도치 않은 순서로 실행될 수 있다는 것이다.예시class ReorderExample {    int a = 0;    boolean flag = false;    public void writer() {        a = 1;        // ①        flag = true;  // ②    }    public void reader() {        if (flag) {   // ③            System.out.println(a); // ④        }    }}public class Main {    public static void main(String[] args) {        ReorderExample obj = new ReorderExample();        Thread t1 = new Thread(obj::writer);        Thread t2 = new Thread(obj::reader);        t1.start();        t2.start();    }}위의 예시를 보면 처음에는 0이라는 값이 등장 할 것으로 예상이 되지만,실제로 파보면 2번의 수행이 우선으로 재정렬되어 1이라는 값이 먼저 찍힐 수 있다는 것이다.이렇게 되면 visibility 는 무너지게 되며 우리가 코드를 보는 직관이 무너지게 된다.Atomicity스레드 간 공유 변수가 있어 연산에서 중간에 끼어들어 깨질 수 있는 문제가 발견된다(위 예시처럼).예시  count++ // read + increment + write 3단계실제로 위 같은 코드를 사용하면 더 깨지기 쉬울 것이며,이렇게 연산 도중 다른 스레드가 끼어들어서 값 보장을 망치는 행위를 Atomicity 가 깨졌다고 한다.이를 방지하기 위해 Java 는 Atomic 클래스와 Volatile 키워드 들을 제공하게 된다.Atomic ClassJava 에는 java.util.concurrent 패키지에 다양한 동시성 제어 기능들을 넣어놓았다.그 중에 AtomicXXXX 의 클래스 류들은 위와 같은 원자성을 보장하기 위해 사용된다.그 안에는 Lock 이라는 기능을 통해 Lock 을 얻은 스레드 만이 자원에 대해 접근할 수 있도록 한다.import java.util.concurrent.atomic.AtomicInteger;public class AtomicExample {    private AtomicInteger count = new AtomicInteger(0);    public void increment() {        count.incrementAndGet(); // atomic operation    }    public int getCount() {        return count.get();    }    public static void main(String[] args) throws InterruptedException {        AtomicExample example = new AtomicExample();        Thread t1 = new Thread(() -&gt; {            for(int i=0; i&lt;1000; i++) example.increment();        });        Thread t2 = new Thread(() -&gt; {            for(int i=0; i&lt;1000; i++) example.increment();        });        t1.start();        t2.start();        t1.join();        t2.join();        System.out.println(\"Final count: \" + example.getCount());    }}VolatileAtomic Class 외에도 자바에는 순서 보장과 값 갱신(Visibility)을 위해변수에 대해 volatile 을 선언하여 최신 값만 읽도록 할 수 있다.이는 변수에 대한 락을 구현하여 사용되어지며, 변수 타입 전에 volatile 을 써서 사용한다.volatile boolean flag = false;위 보다는 더 쉬울 것이다.동기화동기화라는 것은 스레드 간의 Mutual Exclusion 를 구현하는 것이다.위 값들은 전부 변수에 대한 접근에 있어서 변수 스코프에 대해 안전한 접근을 수행하도록 하였다.하지만, 이는 단일 연산 단위에서만 안전하게 된다.예시import java.util.concurrent.atomic.AtomicInteger;public class AtomicExample {    private AtomicInteger count = new AtomicInteger(0);    public void incrementTwice() {        count.incrementAndGet();  // 원자적 연산        count.incrementAndGet();  // 원자적 연산    }    public int getCount() {        return count.get();    }    public static void main(String[] args) throws InterruptedException {        AtomicExample example = new AtomicExample();        Thread t1 = new Thread(example::incrementTwice);        Thread t2 = new Thread(example::incrementTwice);        t1.start();        t2.start();        t1.join();        t2.join();        System.out.println(example.getCount());    }}위의 count 라는 것은 AtomicClass 로 원자성을 지닌 변수이다.이 값에 대한 연산들은 전부 원자적이며, 연산 수행 도중에는 아무도 끼어들 수 없을 것이다.하지만 이 연산을 두 번 수행하는 incrementTwice 에 대해서 getCount() 를 한다면직관적으로 봤을 때 우리의 눈에는 count.get() 에는 2의 배수만 찍혀야 하지만, 실제로 홀수가 찍힐 수 있다.이를 동기화가 안되었다고 한다. 즉, 스레드끼리 연산을 스레드의 다중 연산 코드를 수행함에 있어 원자적 연산을 연속으로 수행하다가 다른 스레드가 이를 침범하여 수행할 수 있다는 것이며,서로 스레드 끼리의 동기화가 되지 않았다는 것이다.이를 보장하기 위해 synchronized 라는 기능이 추가된다.Synchronized상호 배제와 락을 구현한 대표적인 키워드이며, Atomicity 문제를 해결하기 위한 가장 대표적인 방법이다.메서드나 블록 단위(코드 블록 말하는 것, 중괄호)로 스레드 간 상호 배제의 원칙을 지키며 코드를 처리한다. 보통 return type 이전에 synchronized 를 붙여 해당 함수는 쓰레드 A 가 들어왔을 때 해당 함수에 대한 Lock 을 얻어 다른 함수가 Lock 을 못 얻게(permission 을 못 얻게) 하여 thread-safety 를 얻게 된다.private static synchronized &lt;T extends List&gt; T func(T t) {        ...}  synchronized 는 락, 상호 배제를 둘 다 구현했기에이를 적용한다면 thread-safety 하다고 할 수 있다.Synchronized vs Volatile 적용 위치            키워드      적용 가능 위치      설명                  synchronized      메서드, 블록      - 메서드에 붙이면 해당 메서드 전체가 락을 획득  - 블록에 붙이면 특정 코드 블록에 대해서만 락 획득  - 함수나 객체 단위로 다중 연산 thread-safe 구현 가능              volatile      변수(필드)      - 멤버 변수에만 사용 가능  - 읽기/쓰기 시 메인 메모리에서 직접 접근 보장(Visibility)  - 단일 변수 단위로 최신 값 유지, atomic 연산 보장 X      "
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 9일차 열거형 클래스, 문자열 핸들링",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/27/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-9%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-27",
      "content": "📂 목차  Enum          enum 선언      java.lang.Enum      필드와 생성자      주의점        자주 사용하는 클래스          StringBuffer 와 String Builder      String Builder 의 thread unsafety 살펴보기      📚 본문Enumenum 으로 선언되어 있지만 사실상 class 이다.배경public class Direction {    public static final int NORTH = 0;    public static final int SOUTH = 1;    public static final int EAST = 2;    public static final int WEST = 3;}자바 1.5 이전에 상수를 보통 static final 로 정의했지만, 이에 대한 문제는  타입 안전성 보장 X  디버깅 시 상수 값만 보일 수 있음  유지보수가 어려움이러한 문제점 등으로 타입 안전성과 가독성을 해결하기 위해 enum 이 탄생했다.enum 선언public enum Direction {    NORTH, SOUTH, EAST, WEST}이는 컴파일러 차원에서 잘못된 값은 넣지 못하기 때문에 사전에 타입 안전성을 가져갈 수 있다.java.lang.Enum자바 enum 은 위 클래스를 상속하는 클래스이며, 사실상 위 Direction 의 코드는 컴파일 시 다음과 같다.public final class Direction extends Enum&lt;Direction&gt; {    public static final Direction NORTH = new Direction(\"NORTH\", 0);    public static final Direction SOUTH = new Direction(\"SOUTH\", 1);    public static final Direction EAST  = new Direction(\"EAST\", 2);    public static final Direction WEST  = new Direction(\"WEST\", 3);    private Direction(String name, int ordinal) {        super(name, ordinal);    }    public static Direction[] values() { ... } // 모든 enum 반환    public static Direction valueOf(String name) { ... } // 이름으로 검색}필드와 생성자실제로 클래스이기 때문에 필드와 생성자 또한 정의 할 수 있다.public enum Season {    SPRING(\"꽃이 피는 계절\"),    SUMMER(\"더운 계절\"),    FALL(\"단풍이 드는 계절\"),    WINTER(\"눈이 오는 계절\");    private final String description;    Season(String description) { // private 생성자        this.description = description;    }    public String getDescription() {        return description;    }}또한 아래와 같이 abstract 메서드로 오버라이딩도 가능하다. 즉, 각 상수가 서로 다른 동작을 가질 수 있는 다형성까지 가져갈 수 있다.public enum Operation {    PLUS {        public int apply(int x, int y) { return x + y; }    },    MINUS {        public int apply(int x, int y) { return x - y; }    };    public abstract int apply(int x, int y);}상속이 된다면 interface 도 집어넣을 수 있게 된다.public interface Printable {    void print();}public enum Color implements Printable {    RED, GREEN, BLUE;    @Override    public void print() {        System.out.println(\"Color: \" + this.name());    }}  Enum 은 보통 switch 가독성을 위해 쓰이게 된다.주의점  ordinal() 사용 지양: 상수의 순서가 바뀌면 로직이 깨지며 대신 name 과 같은 별도의 필드를 사용한다.  직렬화 시 주의해야 한다. enum 은 싱글턴 보장이라 역직렬화해도 같은 인스턴스가 유지된다.  상속 불가 enum 은 상속이 안된다(public final class 이기 때문).  ordinal() 은 enum 내부에 구현되어 있는 것이고 로직에 직접 사용되지 않기 때문에 보지도 않을 것이다.자주 사용하는 클래스StringBuffer 와 String BuilderStringBuffer  동기화를 지원함  성능이 느림  스레드 세이프  멀티 스레드 환경에서 사용하면 좋다.Serializable 이라는 인터페이스를 구현하지만 이는 메타데이터 용도로만 쓰이고StringBuilder  비동기  성능이 빠름  쓰레드 세이프하지 않음  단일 스레드 환경에서 사용하면 좋다.String Builder 의 thread unsafety 살펴보기이번엔 StringBuilder 가 두 개의 쓰레드를 사용했을때 데이터 일관성을 가져가지 못하는 상황을 재현해보자.public class Main {    static final StringBuilder SB = new StringBuilder();    public static void main(String[] args) throws InterruptedException {        Runnable run1 = () -&gt; {            for (int i = 0; i &lt; 1_000_000; i++) {                SB.append(\"a\");            }        };        Runnable run2 = () -&gt; {            for (int i = 0; i &lt; 1_000_000; i++) {                SB.append(1);            }        };        Thread t1 = new Thread(run1);        Thread t2 = new Thread(run2);        t1.start();        t2.start();        t1.join();        t2.join();        System.out.println(SB);        long a = SB.chars().filter(c -&gt; c == 'a').count();        long one = SB.chars().filter(c -&gt; c == '1').count();        long na = SB.chars().filter(c -&gt; c == '\\0').count();        System.out.println(a);        System.out.println(one);        System.out.println(na);        System.out.println(a+one+na);        System.out.println(SB.length());        System.out.println(SB.capacity());    }}위를 출력해보면 a가 먼저 출력이 된 후에 1이 출력이 되어야 하는데, a와 1이 번갈아가면서 되어지기도 하고, 어쩔때는 null 값이 들어가버리기도 한다..이 이유는 append 작업이 원자적이지 않은 작업이기에 StringBuffer 자체가 a 혹은 1을 저장하려고 할 때, 할당된 String 메모리가 부족하면 이를 더 늘리는 작업을 하는데 이 늘리는 작업 때문에 실제 문자열의 길이와 할당된 메모리의 크기가 달라 null 이 생성되게 된다.또한 a와 1의 저장된 숫자도 다른 것을 알 수 있는데,...111111111111111111150501494420731755148097614809762359294와 같이 출력됨을 볼 수 있다. 이는 출력할 때마다 바뀔 것이다(전체 capacity 는 일정한 값으로 증가하기 때문에 맨 마지막 값은 왠만해서는 안바뀐다).따라서 Spring 은 multi-thread 를 우선 지원하기에 어떤 컴포넌트가 어떤 방식으로(단일, 다중) 요청을 넣는지 잘 살피고 맞는 구현을 하면 될 것이다."
    },
  
    {
      "title": "Object 클래스 와 Objects 유틸",
      "url": "/seonghun120614/computerscience/java/2025/08/26/object-%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%99%80-objects-%EC%9C%A0%ED%8B%B8.html",
      "date": "2025-08-26",
      "content": "📂 목차  Object  Objects          Object.equals(Object o)      📚 본문Object모든 클래스의 수퍼 클래스이며, 보통 오버라이드하여 객체 동작을 커스터마이징한다.메서드  toString(): 객체를 문자로 표현하는 법 정의  equals(Object obj): 객체 비교 방법 정의  hash(Object... o):  hashCode(): 객체 해시코드 반환  getClass(): 객체의 Runtime 클래스 정보 반환  clone(): 객체 복제 방법 정의(깊은/얕은 복사 가능)  finalize(): GC가 객체를 수거하기 전에 호출  wait(), notify(), notifyAll(): 스레드 동기화에 사용ObjectsObject 를 다루기 위한 유틸성 함수들을 저장한다.  hash(Object... o): 여러 오브젝트로부터 하나의 해시코드를 만들어주는 유틸리티이다.  &lt;T&gt; T requireNonNull(T obj, String message): null 인지를 체크하고 아니면 반환한다. 만약 null 이라면 message 를 품은 NullPointerException 을 던진다  &lt;T&gt; T requireNonNullElse(T obj, T defaultObj): null 이라면 defaultObj 를 반환해주고 아니라면 그냥 해당 객체를 반환한다.      &lt;T&gt; int compare(T a, T b, Comparator&lt;? super T&gt; c): a와 b를 비교하고 a가 더 작으면 음수를 b가 더 작으면 양수를 반환하는 함수이다.    boolean deepEquals(Object a, Object b): 다차원의 Object 에 대한 깊이 있는 동등성을 비교한다.Object.equals(Object o)이번에는 equals(Object o) 에 대해 더 살펴본다. 개발자는 종종 Object.equals() 메서드를 오버라이드(override)하여 객체 고유의 동등성(equality) 기준을 정의해야 하는 순간이 온다. 이때 equals() 를 오버라이드할 때는 다음과 같은 5가지 계약(contract)을 준수해야 한다:  반사성(Reflexive): 모든 null이 아닌 참조 값 x에 대해, x.equals(x)는 true 여야 한다.  대칭성(Symmetric): 모든 null이 아닌 참조 값 x와 y에 대해, x.equals(y)가 true일 때만 y.equals(x)도 true여야 한다.  추이성(Transitive): 모든 null이 아닌 참조 값 x, y, z에 대해, x.equals(y)가 true이고 y.equals(z)가 true이면, x.equals(z)도 true여야 한다.  일관성(Consistent): 모든 null이 아닌 참조 값 x와 y에 대해, x.equals(y)를 반복적으로 호출해도 일관적으로 같은 값을 반환해야 한다.  Null과의 비교: 모든 null이 아닌 참조 값 x에 대해, x.equals(null)은 false여야 한다.  hashCode 오버라이딩: equals 를 구현하려면 해시코드를 오버라이딩 해야 한다.위를 고려하여 코딩하자.class Car {    private String brand;    public Car(String brand) {        this.brand = brand;    }    @Override    public boolean equals(Object o) {        // 1. 같은 객체인지 확인        if (this == o) return true;        // 2. null이거나 타입이 다른지 확인        if (o == null || getClass() != o.getClass()) return false;        // 3. 필드 값 비교        Car car = (Car) o;        return Objects.equals(brand, car.brand);    }    @Override    public int hashCode() {        return Objects.hash(brand);    }}"
    },
  
    {
      "title": "Reflect 패키지",
      "url": "/seonghun120614/computerscience/java/2025/08/26/reflect-%ED%8C%A8%ED%82%A4%EC%A7%80.html",
      "date": "2025-08-26",
      "content": "📂 목차  Reflect 패키지          Reflect 를 활용한 클래스 정보 조회      Reflect 를 활용한 필드 접근 및 조작      Reflect 를 활용한 인스턴스 생성      리플렉트를 사용해야 할 경우      📚 본문Reflect 패키지자바가 지원하는 문법에 대한 정보들을 제공하고 조작할 수 있는 패키지이며, 클래스와 객체에 대한 반사적 정보를 얻기 위한 클래스와 인터페이스를 제공하는 패키지이다. 여기서 일어나는 대부분은 Checked Exception 이고, 그만큼 컴파일러 단에서 예외처리를 잘 해주어야 한다.자주 사용되는 것들만 보자.Class  Class&lt;T&gt;: 클래스의 메타데이터를 담으며, Class.forName(\"패키지.클래스명\") 또는 obj.getClass() 로 얻을 수 있다.  AccessibleObject - Field, Method 및 Constructor 객체의 기본 클래스  Field: 클래스의 멤버 변수 정보를 다룬다. 클래스에서 getDeclaredFields(), getField(\"name\") 메서드를 통해 Field[] 를 얻을 수 있다.  Method: 클래스의 메서드 정보를 다루며, 클래스에서 getDeclaredMethods()로 배열을 가져올 수 있고, invoke() 로 실행을 할 수 있다.  Constructor&lt;T&gt;: 클래스의 생성자 정보  Modifier: public, private, static 등의 접근 제어자/수정자 정보를 확인한다.  Array: 리플렉션 기반의 배열 생성과 조작을 담당한다.  Parameter - 메서드 매개변수에 대한 정보Interface  Type - Java 프로그래밍 언어의 모든 유형에 대한 공통 부모 인터페이스  WhildCardType - ? 를 의미  GenericDeclaration - 타입형을 지칭하는 공통 인터페이스  …Reflect 를 활용한 클래스 정보 조회Class&lt;?&gt; clazz = Class.forName(\"java.util.ArrayList\");System.out.println(\"클래스 이름: \" + clazz.getName());이때 ClassNotFoundException 이 일어날 수 있다.Reflect 를 활용한 필드 접근 및 조작import java.lang.reflect.*;class Exam {    private static int size = 100;    public int getSize() {        return size;    }}public class Main {    public static void main(String[] args) throws Exception {        Class&lt;?&gt; clazz = Class.forName(\"Exam\");        Object examInstance = clazz.getDeclaredConstructor().newInstance();        System.out.println(\"클래스 이름: \" + clazz.getName());        Field field = clazz.getDeclaredField(\"size\");        field.setAccessible(true);  // private 접근 허용        field.set(examInstance, 1);        Exam exam = new Exam();        System.out.println(exam.getSize());    }}굳이 private 을 위와 같이 접근해서 쓰지는 말자.Reflect 를 활용한 인스턴스 생성Class clazz = Class.forName(\"클래스풀네임\");// Java 9 이후 권장 방법Object obj = clazz.getDeclaredConstructor().newInstance();// 또는 매개변수가 있는 생성자의 경우Object obj2 = clazz.getDeclaredConstructor(String.class, int.class).newInstance(\"값\", 10);리플렉트를 사용해야 할 경우주로 정적(compile-time)으로 타입을 확정하기 어려운 상황에서 동적으로 클래스/메서드/필드에 접근해야 할 때 활용되고, 의존성 주입, 테스트 코드에서 JUnit 등의 @Test 에서도 내부적으로 이를 사용한다. 또한 어노테이션, 동적 프록시 생성 등에서도 사용하게 된다.물론 reflect 가 캡슐화를 깨뜨리는 API를 제공하고, 직접 호출보다 성능이 더 느리지만, 코딩 시점에서 정해지는 정적 타입 언어에 동적 성격을 부여할 수 있기 때문에 더 이상 자바로 처리하기 힘든 타입 바인딩에 대해 해결할 수 있는 중요한 수단이 되겠다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 8일차 Java 추상화와 디자인 패턴",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/26/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-8%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-26",
      "content": "📂 목차  Abstract Class          Abstract Class 의 접근제한자      추상 클래스 구현 시 유의할 점      java.lang.Throwable      Checked Exception      Unchecked Exception      Error      Validator 계층        Interface          Interface Field      Interface Method        디자인 패턴          Template Method Pattern      Singleton Pattern      Abstract Factory Pattern      Buidler Pattern        더 얻어갈 것들          Reflect 패키지      Object 와 Objects 활용      📚 본문Abstract Class사실 추상 클래스는 잘못 구현되었다고 실제 James Gosling 이 말한 바 있다.문제는 다음과 같다:  다중 상속 불가: 다중 상속을 막은 것에서 부터 공통 기능과 계약(메서드 시그니처)을 섞어야 하는 경우, abstract class 는 불편함.// 계약만 정의interface Drivable {    void drive();}// 공통 기능 포함abstract class Vehicle {    String model;    public Vehicle(String model) {        this.model = model;    }    // 공통 기능    public void printModel() {        System.out.println(\"Model: \" + model);    }    // 추상 메서드 (계약)    public abstract void startEngine();}// Car는 Vehicle을 상속해야 하고 Drivable도 구현해야 함class Car extends Vehicle implements Drivable {    public Car(String model) {        super(model);    }    @Override    public void startEngine() {        System.out.println(\"Car engine started!\");    }    @Override    public void drive() {        System.out.println(\"Car is driving!\");    }}// 만약 다른 클래스도 상속해야 하면 abstract class 상속은 하나만 가능class SportsCar extends Car /*extends SomeOtherClass*/ {     // 자바는 다중 상속을 막아서, Vehicle + SomeOtherClass 동시에 상속 불가}이는 굉장히 유연하지 못함.      인터페이스와 혼동: default 가 있는데도 이는 추상 클래스의 목적을 인터페이스가 흡수하게 된 것.        기능 제한: 생성자, 필드, 메서드 구현 모두 가능하지만, 서브 클래스가 이미 다른 클래스를 상속하고 있다면 abstract class 를 못쓰는 구조적 제약이 있음  이러한 이유로 abstract class 는 진짜 최상단 부모가 아니라면 쓰지 않는 것이 좋다.Abstract Class 의 접근제한자abstract class 를 선언할 때에는 public, default 로만 선언할 수 있다. 당연히 두 접근제한자는 클래스에 적용되는 접근제한자 규약이랑 똑같다.  public: 모든 패키지 접근  default: 같은 패키지 내에 접근protected 가 없는 이유는 당연하다. 상속을 위한 기능인데 당연히 상속된 것들은 다 접근 가능해야 할 것이다.  메서드의 접근제한자는 private 를 제외하고 다 가능하다.이 이유는 서브클래스에서 이를 접근할 수 없게 되므로 구현하지 못하게 된다.Constructor 에서의 접근제한자는 private 까지 가능하지만, 호출이 불가하기 때문에 거의 쓰이지 않는다.추상 클래스 구현 시 유의할 점자바는 단일 상속만 지원하기 때문에 이미 다른 클래스를 상속받고 있는 경우 Abstract Class 를 추가로 상속할 수 없다. 따라서 공통 기능 + 계약을 묶어서 abstract class 로 만들면 유연성이 떨어진다.가능하면 공통 기능은 default 메서드가 있는 인터페이스로 대체한다.abstract class 는 진짜 상속 계층의 최상단 부모로서 common state나 field 가 필요할 때만 사용하는 것으로 한다.또한 추상 클래스는 static, final 이 붙을 수 있지만, 해당 개념의 의미를 정확히 파악하여 이게 정말로 초기화가 가능한지, 접근이 가능한지를 따지면 어디에 static 이 붙을 수 있고 안 붙을 수 있는지 파악 할 수 있다.java.lang.Throwable이제 자바에서 처리되는 유사 Trap 을 본다.java.lang.Throwable├── java.lang.Error                // 주로 JVM 레벨 문제│   ├── VirtualMachineError│   │   ├── OutOfMemoryError│   │   └── StackOverflowError│   ├── AssertionError│   └── LinkageError└── java.lang.Exception      // 프로그램에서 처리 가능한 예외    ├── java.lang.RuntimeException // Unchecked Exception    │   ├── NullPointerException    │   ├── IndexOutOfBoundsException    │   │   ├── ArrayIndexOutOfBoundsException    │   │   └── StringIndexOutOfBoundsException    │   ├── ArithmeticException    │   ├── ClassCastException    │   ├── IllegalArgumentException    │   │   └── NumberFormatException    │   ├── IllegalStateException    │   ├── UnsupportedOperationException    │   └── ConcurrentModificationException    ├── java.io.IOException          // Checked Exception (입출력 관련)    │   ├── FileNotFoundException    │   ├── EOFException    │   ├── InterruptedIOException    │   └── ObjectStreamException    │       ├── InvalidClassException    │       ├── NotSerializableException    │       └── OptionalDataException    ├── java.sql.SQLException    ├── ClassNotFoundException    ├── NoSuchMethodException    ├── NoSuchFieldException    ├── InstantiationException    └── ReflectiveOperationException        ├── IllegalAccessException        └── InvocationTargetException우리가 마주하는 대부분의 예외는 java.lang.RuntimeException, java.io.IOException 이다.여기서 Error 는 보통 처리하지 않고, Exception 을 try-catch 문으로 처리를 한다.Checked ExceptionChecked Exception 은 반드시 try-catch 문 혹은 throws 선언이 필요하다.필수  try-catch  throws 문이런게 없다면 컴파일이 실행되지 않는다.Unchecked Exception보통 처리하지 않으며, 선택적으로 try-catch 를 사용하여 에러 메시지를 띄울 수 있다.import java.io.*;public class ExceptionExample {    public static void main(String[] args) {        // Checked Exception 예시: 파일 읽기        try {            FileReader reader = new FileReader(\"nonexistent.txt\");            reader.read();            reader.close();        } catch (FileNotFoundException e) {            System.out.println(\"파일이 존재하지 않습니다: \" + e.getMessage());        } catch (IOException e) {            System.out.println(\"파일 입출력 오류 발생: \" + e.getMessage());        }        // Unchecked Exception 예시: 0으로 나누기        try {            int a = 10 / 0;        } catch (ArithmeticException e) {            System.out.println(\"산술 오류 발생: \" + e.getMessage());        }    }}Error보통 프로그램에서 처리하지 않고 JVM 레벨에서 실행이 종료된다거나 처리된다.필요시 catch 가 가능하긴 하지만 권장되지는 않는다.  실제로 Checked Exception 을 마주칠 일이 없는데 필자는 BufferedWriter 을 사용할 때, 해당 함수를 사용하는 다른 함수들한테 전부 throws IOException 시그니처를 적용시켜줘야 하여 번거로웠다. 이때는 try-catch 를 활용하여 catch 스코프에서 Unchecked Exception 으로 던져주는 것이 좋을 듯하다.Validator 계층실무에서 빠질 수 없다. servlet 을 통해 REST API를 사용하는 서버가 있다고 하자. 그러면 유저의 입력을 받아 서비스를 제공해주는 것이 목적일 터이다.여기서 유저의 입력은 과연 우리의 서비스의 함수 시그니처에 맞는 인자를 전달할지 안할지 체크를 해야 한다. 이때 자주 쓰이는 게 Validation 이며(Validator 라고도 하고 다양함), util 패키지에 저장되어 사용하는 것이 대부분이다.Validation 이 접근 하여 로직을 수행하는 곳은 다음과 같다.  controller  domain  (입력이 들어오는 곳 어디든?)유틸이기에 다방면으로 사용해도 상관은 없다.Interface인터페이스도 Abstract Class 와 마찬가지로  public  default를 사용 가능하다. 기능 목적은 똑같다.Interface Field인터페이스의 필드는 무조건 public static final 이어야 한다. 이는 별도로 명시하지 않아도 무조건 public static final 이 기본이 된다.Interface Method모든 인터페이스의 메서드는 기본적으로 public 이며, default, private 까지 사용 가능하다. static 도 당연 사용 가능하다.  default: 기본적으로 interface 에 선언되어 있고, 해당 메서드의 오버라이딩은 선택적  static: 오버라이딩은 못하지만 다른 곳에서 사용 가능디자인 패턴인터페이스와 상속을 더 배웠으니 객체 지향에서 마주칠 수 있는 주된 문제들에 대한 해결할 수 있는 개발 패턴을 본다.Template Method Patternpublic abstract class Game {    // 템플릿 메소드    public final void play() {        initialize();        startPlay();        endPlay();    }    // 추상 메소드들 (하위 클래스에서 구현)    abstract void initialize();    abstract void startPlay();    abstract void endPlay();}중요한 것은 추상화된 클래스가 직접 로직을 제공하고 그 부품들은 각자 구현된 하위 클래스에서 구현하도록 하는 것이다.이렇게 되면 하위 클래스는 굳이 상위 클래스의 전반적인 로직을 모르더라도 쪼개어진 기능들만 구현하면 제대로 동작하게 됨을 볼 수 있다.Singleton Pattern메모리 상에서 오로지 하나 생성하고, 더 이상의 생성을 제어하고 싶을 때 싱글톤 패턴을 사용한다.public class Singleton {    // 클래스 내부에서 단 하나의 인스턴스를 생성    private static final Singleton instance = new Singleton();    // private 생성자 → 외부에서 new Singleton() 불가능    private Singleton() {        System.out.println(\"Singleton 생성자 호출\");    }}Abstract Factory Pattern// 1. 추상 팩토리 인터페이스interface GUIFactory {    Button createButton();    Checkbox createCheckbox();}// 2. 구체 팩토리 (Windows)class WindowsFactory implements GUIFactory {    @Override    public Button createButton() {        return new WindowsButton();    }    @Override    public Checkbox createCheckbox() {        return new WindowsCheckbox();    }}// 3. 구체 팩토리 (Mac)class MacFactory implements GUIFactory {    @Override    public Button createButton() {        return new MacButton();    }    @Override    public Checkbox createCheckbox() {        return new MacCheckbox();    }}Buidler Pattern// Product 클래스class Computer {    private String cpu;    private String gpu;    private int ram;    private int storage;    private Computer(Builder builder) {        this.cpu = builder.cpu;        this.gpu = builder.gpu;        this.ram = builder.ram;        this.storage = builder.storage;    }    @Override    public String toString() {        return \"Computer [CPU=\" + cpu + \", GPU=\" + gpu + \", RAM=\" + ram + \"GB, Storage=\" + storage + \"GB]\";    }    // Builder 클래스    public static class Builder {        private String cpu;        private String gpu;        private int ram;        private int storage;        public Builder setCpu(String cpu) {            this.cpu = cpu;            return this;        }        public Builder setGpu(String gpu) {            this.gpu = gpu;            return this;        }        public Builder setRam(int ram) {            this.ram = ram;            return this;        }        public Builder setStorage(int storage) {            this.storage = storage;            return this;        }        public Computer build() {            return new Computer(this);        }    }}더 얻어갈 것들Reflect 패키지참고: reflect 패키지Object 와 Objects 활용참고: Object 와 Objects 활용"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 7일차 정적 바인딩, 동적 바인딩과 다형성",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/25/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-7%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-25",
      "content": "📂 목차  Inheritance          정적 바인딩과 동적 바인딩                  정적 바인딩(early binding, compile-time)          동적 바인딩(late binding, runtime)                    Constructor 관점      Field 관점      Method 관점      상속 주의점        Polymorphism          정적/컴파일에서의 다형성      동적/런타임에서의 다형성        Servlet📚 본문Inheritanceis-a 관계, kind-of 에서 사용.  부모가 자식을 참조 가능  필드는 참조변수 타입을 기준  메소드 오버라이딩 시 자식 것 사용  모든 class 는 Object 의 상속정적 바인딩과 동적 바인딩정적 바인딩(early binding, compile-time)컴파일 시점에 어떤 멤버/메서드를 사용할지 결정하는 것을 정적 바인딩이라고 한다.다음이 정적 바인딩에 해당:  필드 접근(멤버 변수) → 참조 변수의 타입을 따름  static 메서드(오버라이딩 X, 메서드 숨김/hiding) → 참조 변수의 타입을 따름  private 메서드, final 메서드(재정의 불가) → 호출 지점에서 이미 고정  오버로딩(이름 같고 매개변수 시그니처 다른 메서드) → 인자와 참조의 정적 타입으로 선택  super.someMethod() 호출 → 상위 클래스 구현으로 고정동적 바인딩(late binding, runtime)런타임 시점에 어떤 멤버/메서드를 사용할지 결정하는 것을 동적 바인딩이라고 한다.  런타임에 실제 객체의 타입을 보고 어떤 인스턴스 메서드를 호출할지 결정  기본적으로 오버라이딩 가능한 인스턴스 메서드는 모두 동적 바인딩 대상핵심 규칙 요약  “필드/static/private/final/super/오버로딩” → 정적“그 외 인스턴스 메서드(오버라이딩)” → 동적Constructor 관점A 클래스가 B 클래스를 상속한다고 쳤을때, 상속 받는 A 클래스는 어떻든 간에 B 클래스의 Constructor 를 실행시켜야 한다.B 가 아무 생성자가 없더라도 인자가 없는 Constructor 를 컴파일러가 자동으로 생성해주는 이유도 그 때문이다.밑의 예시를 보자.class Parent {    public String name = \"부모\";}class Child extends Parent {    public String name = \"자식\";}Parent 는 아무런 생성자가 없지만 자동으로 빈 생성자가 생성될 것이다. Child 도 마찬가지로 빈 생성자가 생성되지만, 그 비어져 있는 생성자에 super() 라는 부모의 생성자가 생략된 것이다.따라서 부모의 생성자가 먼저 실행이 되고, 그 실행된 것을 토대로 Child 가 한 번 더 수정을 해준다고 보면 되겠다.  만약 Parent 에 인자가 있는 생성자를 직접 명시했다면, 비어져 있는 생성자(default constructor) 가 자동 생성이 되지 않으므로 이때 Child 는 부모의 생성자 super() 를 이용하여 초기화 해주어야 한다.이는 이 전 강의에서도 무조건 super 가 있어야 한다고 했었다.Field 관점class Parent {    public String name = \"부모\";}class Child extends Parent {    public String name = \"자식\";}Parent pc = new Child();System.out.println(pc.name)위 코드를 출력해보면 pc.name 은 자식이 아니라 부모가 출력됨을 볼 수 있다.실제로 pc 라는 변수는 Parent 필드와 Child 필드 둘 다 가지고 있다. 하지만 자바는 특정 변수를 볼 때 이 변수의 선언된 클래스 명을 우선으로 따라간다. 즉, Parent pc 이기 때문에 멤버 변수로는 Parent 것이 따라가게 된다.이는 컴파일 시점에 결정되는 것이며, 필드는 정적 바인딩이 되는 것이기에 참조변수 타입을 따르는게 맞다.Method 관점위와 비슷한 예시로 다음을 또 보자.class Parent {    public String name = \"부모\";    public void print() {        System.out.println(\"부모: 안녕하세요\");    }}class Child extends Parent {    public String name = \"자식\";    public void print() {        System.out.println(\"자식: 안녕하세요\");    }}class Main {    public static void main(String[] args) {        Parent pc = new Child();        pc.print();    }}위는 자식의 메서드가 실행되는 것을 볼 수 있다.이는 메서드가 동적 바인딩이 되기 때문이다.상속 주의점class Parent {    Parent() { print(); }      // 위험: 오버라이딩 가능 메서드 호출    void print(){ System.out.println(\"Parent\"); }}class Child extends Parent {    int x = 42;    Child() {}    @Override void print(){ System.out.println(x); }}new Child(); // 출력: 0   (x가 아직 기본값 0일 때 Child.print()가 불림)상속 요약  필드: 참조 타입(정적)  static/ private / final / super/ 오버로딩: 정적  오버라이딩된 인스턴스 메서드: 동적  생성자 내부에서 오버라이딩 메서드 호출 지양Polymorphism범용 메소드 이름을 정의하여 형태에 따라 각각 적절한 변환 방식을 정의해두어 타입 간의 변환이 자유성을 가지는 성질을 말한다.정적/컴파일에서의 다형성주로 오버로딩이 해당되며, 같은 이름을 가진 메서드가 매개변수 유형이나 개수에 따라 다르게 정의되어 컴파일러가 호출 시점에서 어떤 메서드인지 결정하게 된다.class Calculator {    int add(int a, int b) { return a + b; }    double add(double a, double b) { return a + b; }}동적/런타임에서의 다형성오버 라이딩 기반으로 부모 클래스를 참조 타입으로 사용하더라도, 실제 객체가 자식이라면 자식 클래스의 메서드가 호출됨.class Animal {    void speak() { System.out.println(\"Animal speaks\"); }}class Dog extends Animal {    @Override    void speak() { System.out.println(\"Dog barks\"); }}Animal a = new Dog();a.speak();  // \"Dog barks\"  위 다형성 외에도 제너릭, 인터페이스 기반 등의 다양한 형태의 다형성이 존재함Servletjava 에서 서블릿은 자바 기반의 웹 어플리케이션에서 동적 웹페이지를 생성하고 클라이언트의 요청을 처리하는 서버 컴포넌트이다.주로 HTTP 요청을 받고, 동적인 응답을 반환하는 애다.  javax.servlet  javax.servlet.http등을 보면 좋을 것이다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 6일차 Effective Java 맛보기",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/22/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-6%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-22",
      "content": "📂 목차  Effective Java          생성 관련                  Static Factory Method          Builder Pattern          인스턴스가 불필요한 클래스          try-with-resources를 활용                    Class &amp; Interface                  클래스와 멤버의 접근 권한을 최소화          변경 가능성을 최소화          상속보다는 조합을 사용          상속을 고려하여 설계 및 문서화하기          추상 클래스보다는 인터페이스를          태그 달린 클래스보다는 계층 구조 이용          Nested Class 는 Static 으로                    Generic                  Raw 타입 사용하지 말기          Array 보다는 List          한정적 와일드 카드를 사용해 API 유연성 높이기                    Enumerate      Lambda &amp; Stream      Method      일반적 프로그래밍 원칙      예외      직렬화        기타 가져갈 것들참고: 망나니 개발자📚 본문이번에는 자바의 코드를 좋게 만드는 과정을 보려고 한다.Effective Java생성 관련Static Factory Method장점  이름을 가지며 의도 표현 가능  호출 시 항상 새 인스턴스를 만들 필요가 없음  하위 클래스 반환 가능  매개변수에 따라 다른 클래스 객체 반환 가능  클래스가 존재하지 않아도 작성 가능단점  하위 클래스로 상속하려면 public/protected 생성자가 필요  직관적이지 않아서 찾기가 어려움예시public class Person {    private String name;    private int age;    private Person(String name, int age){        this.name = name;        this.age = age;    }        // Static Factory Method    public static Person of(String name, int age) {        return new Person(name, age);    }}심화 예시public abstract class Shape {    public abstract void draw();    // Static Factory Method    public static Shape create(String type) {        return switch (type.toLowerCase()) {            case \"circle\": return new Circle();            case \"square\": return new Square();            default: throw new IllegalArgumentException(\"Unknown Type\");        };    }}class Circle extends Shape {    @Override    public void draw() {        System.out.println(\"Drawing a circle\");    }}class Square extends Shape {    @Override    public void draw() {        System.out.println(\"Drawing a square\");    }}Builder Pattern생성자의 매개변수가 많아짐에 따라 코드 이해가 힘들고, Setter 를 사용하면 객체 일관성이 깨지며 Open-Closed 원칙 위배이다.이때 Builder 패턴을 사용하면 이 문제를 쉽게 해결할 수 있다.예시public class Person {    private final String name;    private final int age;    private final String email;    private final String phone;    // private 생성자    private Person(Builder builder) {        this.name = builder.name;        this.age = builder.age;        this.email = builder.email;        this.phone = builder.phone;    }    // Builder 클래스    public static class Builder {        private final String name; // 필수        private int age = 0;       // 선택, 기본값 0        private String email = \"\"; // 선택, 기본값 \"\"        private String phone = \"\"; // 선택, 기본값 \"\"        public Builder(String name) {            this.name = name;        }        public Builder age(int age) {            this.age = age;            return this;        }        public Builder email(String email) {            this.email = email;            return this;        }        public Builder phone(String phone) {            this.phone = phone;            return this;        }        public Person build() {            return new Person(this);        }    }}이를 Static Factory Method 와 함께하면 다음과 같이 짤 수도 있다.public class Person {    private final String name;    private final int age;    private final String email;    private final String phone;    private Person(Builder builder) {        this.name = builder.name;        this.age = builder.age;        this.email = builder.email;        this.phone = builder.phone;    }    // Static Factory Method    public static Person builder(String name) {        return new Builder(name).build();    }    public static class Builder {        private final String name;        private int age = 0;        private String email = \"\";        private String phone = \"\";        public Builder(String name) {            this.name = name;        }        public Builder age(int age) {            this.age = age;            return this;        }        public Builder email(String email) {            this.email = email;            return this;        }        public Builder phone(String phone) {            this.phone = phone;            return this;        }        public Person build() {            return new Person(this);        }    }}final 이라 값을 변경할 수 없지만 다음과 같이 새로 생성하는 것은 쉽게 된다:Person p1 = new Person.Builder(\"Alice\").age(30).build();Person p2 = new Person.Builder(p1.getName())                 .age(35) // 새 나이로 새 객체 생성                 .build();인스턴스가 불필요한 클래스  유틸성 클래스  Validator 관련  Exception 관련  …전부 생성자를 private 로 명시해버린다.try-with-resources를 활용try 안에 특정 변수를 선언하여서 해당 블럭이 종료되면 그 변수를 자동 메모리 할당 해제해주는즉, AutoClosable 인터페이스가 구현이 되어 있다면, try 블록이 종료되면 자동으로 메모리를 회수해준다.try (ResourceType resource = new ResourceType()) {    // 리소스 사용} catch (Exception e) {    e.printStackTrace();}  AutoClosable 인터페이스는 따로 구현하지 않아도 자바에서 거의 다 지원해준다.실제 예시를 보자.public class BufferedReaderExample {    public static void main(String[] args) {        String filePath = \"example.txt\"; // 읽을 파일 경로        // try-with-resources 사용        try (BufferedReader br = new BufferedReader(new FileReader(filePath))) {            String line;            while ((line = br.readLine()) != null) { // 한 줄씩 읽기                System.out.println(line);            }        } catch (IOException e) {            e.printStackTrace(); // 예외 발생 시 출력        }    }}public class ConsoleInputExample {    public static void main(String[] args) {        System.out.println(\"이름을 입력하세요: \");        // try-with-resources로 BufferedReader 사용        try (BufferedReader br = new BufferedReader(new InputStreamReader(System.in))) {            String name = br.readLine(); // 한 줄 입력 받기            System.out.println(\"입력한 이름: \" + name);            System.out.println(\"나이를 입력하세요: \");            String ageInput = br.readLine();            int age = Integer.parseInt(ageInput); // 문자열을 정수로 변환            System.out.println(\"입력한 나이: \" + age);        } catch (IOException e) {            e.printStackTrace();        } catch (NumberFormatException e) {            System.out.println(\"나이는 숫자로 입력해야 합니다.\");        }    }}Class &amp; Interface클래스와 멤버의 접근 권한을 최소화접근 제한자 활용 및 은닉화 잘되어 있게 설계를 해야한다.예시를 보자.public class Person {    // public 필드: 외부에서 직접 접근 가능    public String name;    public int age;}public class Main {    public static void main(String[] args) {        Person p = new Person();        p.name = \"\";  // 잘못된 이름 넣을 수 있음        p.age = -5;   // 말이 안 되는 나이 넣을 수 있음    }}위처럼 해버리면 아무 변수나 막 넣을 수 있고,그 값이 정말 신뢰할 수 있는지도 모른다.public class Person {    // private 필드: 외부에서 직접 접근 불가    private String name;    private int age;    // public getter/setter 제공: 필요한 경우만    public String getName() {        return name;    }    public void setName(String name) {        // 간단한 검증 가능        if (name != null &amp;&amp; !name.isEmpty()) {            this.name = name;        }    }    public int getAge() {        return age;    }    public void setAge(int age) {        if (age &gt; 0) { // 유효성 체크            this.age = age;        }    }}이렇게 작성하면 함수 내에서 유효성 검증도 가능하게 되며 직접 멤버 변수로 접근을 못하게 할 수 있다.변경 가능성을 최소화불변의 객체(위에서 봤던 Builder 패턴 처럼)를 생성하여, 생성된 시점에 파괴되는 시점까지 동일한 값을 유지하도록 하게 최종적인, 가장 구체적인 클래스는 final 로 선언하거나, 정적 팩토리 메서드를 사용하여 더욱 유연하게 불변 객체를 생성 가능하다.모르겠다면 위에 쓴 Builder 패턴을 보고 오자.상속보다는 조합을 사용상속은 좋지만, 상위 클래스의 구현이 하위 클래스로 노출되어 캡슐화를 깨뜨림.  상속은 is-a 의 관계의 경우에만 사용하도록  그 외에는 강하게 결합(strictly coupling) 되는 상속은 되도록 X// 상위 클래스 구현이 그대로 하위로 노출됨public class Vehicle {    public int speed;    public void accelerate() {        speed += 10;    }}public class Car extends Vehicle {    public void turboBoost() {        // 상위 클래스 필드 직접 접근        speed += 50; // 하위 클래스가 상위 구현에 강하게 의존    }}public class Main {    public static void main(String[] args) {        Car car = new Car();        car.accelerate(); // Vehicle 메서드 사용        car.turboBoost(); // Vehicle 내부 구현 직접 활용    }}위는 하위 클래스가 상위 클래스의 직접 멤버 변수를 참조하는 것을 볼 수 있다.이렇게 되면 캡슐화가 제대로 된게 아니며, 강한 결합이 생긴다.// Vehicle은 내부 상태를 은닉public class Vehicle {    private int speed;    public void accelerate() {        speed += 10;    }    public int getSpeed() {        return speed;    }}// Car는 Vehicle을 필드로 가지고 조합 사용public class Car {    private final Vehicle vehicle = new Vehicle();    public void accelerate() {        vehicle.accelerate();    }    public void turboBoost() {        // vehicle 내부 구현에 직접 접근하지 않고, 메서드만 사용        for (int i = 0; i &lt; 5; i++) {            vehicle.accelerate();        }    }    public int getSpeed() {        return vehicle.getSpeed();    }}public class Main {    public static void main(String[] args) {        Car car = new Car();        car.accelerate();        car.turboBoost();        System.out.println(car.getSpeed());    }}위와 같이 가지는, 조합하는 형태로 바꾼다.상속을 고려하여 설계 및 문서화하기  상속된 메서드는 공개  hook 을 이용했다면 그 hook 도 protected 로 공개public class Vehicle {    public int speed;    private void accelerate() {         speed += 10;    }}public class Car extends Vehicle {    public void turboBoost() {        speed += 50;    }}위는 얼핏 보면 잘 설계한 것 같지만, 상속된 메서드에 대해 private 때문에 공개를 하지 않고 있다. 밑과 같이 바꾸자.public class Vehicle {    private int speed;    // 상속된 메서드는 공개    public void accelerate() {        speed += 10;    }    // Hook 제공, 하위 클래스에서 필요 시 오버라이드 가능    protected void onSpeedChange() {        // 기본 동작은 아무것도 하지 않음    }    public int getSpeed() {        return speed;    }    public void changeSpeed(int delta) {        speed += delta;        onSpeedChange(); // Hook 호출    }}public class Car extends Vehicle {    @Override    protected void onSpeedChange() {        System.out.println(\"차의 속도가 변경되었습니다: \" + getSpeed());    }    public void turboBoost() {        changeSpeed(50); // 내부 구현에 직접 접근하지 않고 메서드 사용    }}public class Main {    public static void main(String[] args) {        Car car = new Car();        car.accelerate();     // 상속된 메서드 사용        car.turboBoost();     // Hook 활용    }}추상 클래스보다는 인터페이스를  추상 클래스는 최상단의 조상 클래스이다. 이는 계층 구조에 혼란을 줄 수 있음  하지만 인터페이스는 유연하고 mix-in도 가능함  Java8 부터는 default 메서드도 있어서 인터페이스 구현이 명확한 부분은 개발하여 제공 가능// 최상위 조상으로만 사용되어 계층 구조가 복잡public abstract class Animal {    public abstract void makeSound();}public class Dog extends Animal {    @Override    public void makeSound() {        System.out.println(\"멍멍\");    }}public class Cat extends Animal {    @Override    public void makeSound() {        System.out.println(\"야옹\");    }}추상 클래스가 계층 구조의 최상위에 위치하여 확장성에 제한을 시킨다.코드의 유연성을 해치며, 다중 상속이 불가능 하도록 한다. 인터페이스로 바꾸자.// 인터페이스 정의public interface Soundable {    void makeSound();    // Java8 부터 default 메서드 제공 가능    default void greet() {        System.out.println(\"안녕하세요!\");    }}// 개 클래스public class Dog implements Soundable {    @Override    public void makeSound() {        System.out.println(\"멍멍\");    }}// 고양이 클래스public class Cat implements Soundable {    @Override    public void makeSound() {        System.out.println(\"야옹\");    }}// mix-in 예시: Flying 기능 추가public interface Flyable {    void fly();}public class Bird implements Soundable, Flyable {    @Override    public void makeSound() {        System.out.println(\"짹짹\");    }    @Override    public void fly() {        System.out.println(\"날아간다!\");    }}태그 달린 클래스보다는 계층 구조 이용  어떤 객체가 동일 클래스 안에서 여러 타입을 구분하기 위해 추가 필드를 사용하는 것, 그 필드를 Tag 라고 함.  이는 새 class 추가 시 기존 클래스 수정이 필요하게 됨  이보다는 계층 extends 와 같은 걸 이용해 구조화를 함.public class Shape {    public static final int CIRCLE = 1;    public static final int SQUARE = 2;    private int type; // Tag 필드    private int size;    public Shape(int type, int size) {        this.type = type;        this.size = size;    }    public void draw() {        if (type == CIRCLE) {            System.out.println(\"Drawing a circle of size \" + size);        } else if (type == SQUARE) {            System.out.println(\"Drawing a square of size \" + size);        }    }}멤버 변수에 type 이라는 태그를 만들었다. 이는 새로운 Shape 가 추가될 때마다 확장성에 굉장히 예민하게 동작하며, 기존 클래스를 수정해야 한다.또한 타입 별 동작이 조건문으로 분기하여 코드가 복잡하고, 유지보수가 어렵다.// 상위 추상 클래스public abstract class Shape {    protected int size;    public Shape(int size) {        this.size = size;    }    public abstract void draw();}// 하위 클래스별 구현public class Circle extends Shape {    public Circle(int size) {        super(size);    }    @Override    public void draw() {        System.out.println(\"Drawing a circle of size \" + size);    }}public class Square extends Shape {    public Square(int size) {        super(size);    }    @Override    public void draw() {        System.out.println(\"Drawing a square of size \" + size);    }}이를 계층으로 해결한다.Nested Class 는 Static 으로이는 이전에 살펴보았다.GenericRaw 타입 사용하지 말기다시 말해서 Generic 타입을 생략하지 않아야 한다.Object 는 Raw Type 과 마찬가지로 모든 타입을 포용할 수 있지만, 컴파일러에게 모든 타입을 허용하겠다는 의사를 전달했다는 것과 Raw 타입과는 다르다.import java.util.ArrayList;import java.util.List;public class Main {    public static void main(String[] args) {        List list = new ArrayList(); // Raw 타입        list.add(\"Hello\");        list.add(123); // 다른 타입도 추가 가능        for (Object obj : list) {            System.out.println(obj);        }    }}제너릭 타입을 지정하지 않으면 모든 타입이 추가 가능하여값의 다양성이 높아져 ClassCastException 에러가 발생할 우려가 있다.import java.util.ArrayList;import java.util.List;public class Main {    public static void main(String[] args) {        List&lt;String&gt; list = new ArrayList&lt;&gt;(); // 제네릭 타입 지정        list.add(\"Hello\");        // list.add(123); // 컴파일 단계에서 오류 발생        for (String str : list) {            System.out.println(str);        }    }}제너릭 타입을 명시하여 타입 안정성을 확보하고, 컴파일러가 타입을 체크하도록 한다.Array 보다는 List  배열은 공변이지만, 제너릭인 리스트는 불공변임만약 A 가 B 의 하위 타입이면 A[] 역시 B[] 의 하위타입이 되는걸 공변 관계에 있다고 한다.하지만 List 는 Generic 을 쓰기에 Generic 에서는 이러한 공변관계가 성립하지 않아 이를 컴파일 시점에서 잡아낼 수 있다.  배열은 실체화 됨.class Animal {}class Dog extends Animal {}public class Main {    public static void main(String[] args) {        Dog[] dogs = new Dog[2];        Animal[] animals = dogs; // 배열은 공변        animals[0] = new Animal(); // 런타임 오류 발생 (ArrayStoreException)    }}이는 컴파일 시 오류가 없지만, 런타임에 ArrayStoreException 이 발생할 수 있다. 타입 안전성도 보장되지 않으므로 다음과 같이 변경한다.import java.util.ArrayList;import java.util.List;class Animal {}class Dog extends Animal {}public class Main {    public static void main(String[] args) {        List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;();        // List&lt;Animal&gt; animals = dogs; // 컴파일 오류 발생, 불공변        dogs.add(new Dog());        // dogs.add(new Animal()); // 컴파일 오류, 타입 안전성 확보    }}한정적 와일드 카드를 사용해 API 유연성 높이기  ? extends E, ? super E 등을 사용  Pecs(Producer-extends, Consumer-super) 공식:매개변수화 타입이 생산자 = extends매개변수화 타입이 소비자 = super  (한 번만 나오면 그냥 super 쓰자)// static 와 void 사이의 &lt;E&gt; 는 이 제너릭 타입을 쓰겠다 라는 의미public static &lt;E&gt; void swap(List&lt;E&gt; list, int i, int j);public static void swap(List&lt;?&gt; list, int i, int j);한 번만 제너릭이 나오면 두번째(와일드카드)가 좋음Enumerate  필요한 원소가 컴파일 시점때 다 알 수 있으면 열거가 좋음  switch 문에서는 좀 길어져서 유지보수가 힘든데,이때는 중첩 열거 타입이나 내부 메소드를 추가하여 해결할 수 있다.public class Direction {    public static final int NORTH = 0;    public static final int SOUTH = 1;    public static final int EAST  = 2;    public static final int WEST  = 3;}public class Main {    public static void main(String[] args) {        int dir = Direction.NORTH;        switch (dir) {            case 0: System.out.println(\"북쪽\"); break;            case 1: System.out.println(\"남쪽\"); break;            case 2: System.out.println(\"동쪽\"); break;            case 3: System.out.println(\"서쪽\"); break;        }    }}이는 상수값으로 방향을 표현하며 의미가 불분명하다. 새로운 방향을 추가하면 또 기존 코드를 수정해야 한다.public enum Direction {    NORTH(\"북쪽\"),    SOUTH(\"남쪽\"),    EAST(\"동쪽\"),    WEST(\"서쪽\");    private final String label;    Direction(String label) {        this.label = label;    }    public String getLabel() {        return label;    }    // 내부 메서드 활용 가능    public void printDirection() {        System.out.println(\"방향: \" + label);    }}public class Main {    public static void main(String[] args) {        Direction dir = Direction.NORTH;        // switch 대신 내부 메서드 사용        dir.printDirection();        // switch 사용 시에도 enum 사용 가능        switch (dir) {            case NORTH -&gt; System.out.println(\"북쪽으로 이동\");            case SOUTH -&gt; System.out.println(\"남쪽으로 이동\");            case EAST  -&gt; System.out.println(\"동쪽으로 이동\");            case WEST  -&gt; System.out.println(\"서쪽으로 이동\");        }    }}Lambda &amp; Stream  익명 클래스보다는 람다 사용을 하되 남용하진 말고 코드 줄도 길어지지 않는 선에서 사용한다.  람다보다는 메소드 참조를 이용하여 코드를 더 간결하게 작성한다.  Stream 은 주의해서 사용해야 한다. 장점도 많지만, 과용하면 유지보수가 힘들며, 메소드 이름을 잘 지어주어야 한다.  Stream 에서는 부작용(Side Effect)이 없는 함수를 이용한다.ex) forEach 내에서 값을 set 하는 건 부작용 우려가 있음. 순회하는 동안 데이터를 변경했기 때문에 다른 스레드에 영향을 줌  병렬 스트림은 주의!!!          int, long 형 범위가 병렬화 효과가 가장 좋음(데이터가 연속적이고 손쉽게 나눌 수 있기 때문)      int, long 이 참조 지역성이 뛰어남      collect 메서드는 합치는 비용 때문에 병렬화에 적합하지 않음      Stream 은 처리할 데이터가 수십만은 되어야 성능 향상이 됨      잘못된 예시import java.util.*;public class Main {    public static void main(String[] args) {        List&lt;String&gt; names = new ArrayList&lt;&gt;(Arrays.asList(\"Alice\", \"Bob\", \"Charlie\"));        // 불필요하게 긴 람다        names.forEach(name -&gt; {            if (name.startsWith(\"A\")) {                System.out.println(name.toUpperCase());            } else {                System.out.println(name.toLowerCase());            }        });        // forEach 내에서 외부 상태 변경 (부작용 발생)        int[] count = {0};        names.forEach(n -&gt; count[0]++); // 공유 변수 변경 → 동시성 문제 발생 가능    }}잘된 예시import java.util.*;import java.util.stream.*;public class Main {    public static void main(String[] args) {        List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");        // 간단한 경우 메서드 참조 활용        names.forEach(System.out::println);        // Stream 연산에서 부작용 없는 함수 사용        List&lt;String&gt; upperNames = names.stream()                                       .filter(n -&gt; n.startsWith(\"A\"))                                       .map(String::toUpperCase) // 순수 함수                                       .toList();        System.out.println(upperNames);        // 병렬 스트림은 신중히        long count = IntStream.rangeClosed(1, 1_000_000)                              .parallel()                              .filter(i -&gt; i % 2 == 0)                              .count();        System.out.println(\"짝수 개수: \" + count);    }}Method  메서드 시그니처를 신중히 설계          편의 메서드 많이 만들지 말기      이름 신중히 짓기      매개변수가 boolean 이 있다면 Enum 을 사용하는 것을 고려      빌더 패턴을 메서드 호출에 응용        Overloading 은 신중히 사용          Overloading 은 가변 인수를 쓰면서 오버로딩하면 컴파일러가 헷갈릴 수 있으며, 특히 매개변수 수가 같다면 어떤 메서드가 선택될 지 혼란을 줄 수 있음        가변인수는 신중히 사용          Overriding 할 때 컴파일러에게 혼동을 줄 수 있음        Optional 반환은 신중히 반환          Optional 은 null 일 수도 있기 때문에 API 사용자에게 명확히 알려주어야 한다.      특히 이를 받은 사용자는 다음 행동을 할 수 있다.                  기본값 정함          예외 던짐          항상 값이 있다고 가정하고 꺼냄          값의 여부를 boolean 으로 받음(isPresent 활용)                    잘못된 예시// boolean 매개변수 → 의미 불명확public void setMode(boolean flag) {    if (flag) {        System.out.println(\"Dark mode ON\");    } else {        System.out.println(\"Dark mode OFF\");    }}// 오버로딩이 헷갈림public void print(String s) {}public void print(Object o) {} // String도 Object라 애매// Optional 반환을 남용public Optional&lt;String&gt; findName() {    return Optional.ofNullable(null); // 무의미한 Optional}잘된 예시// Enum 활용 → 의미 명확public enum Mode { DARK, LIGHT }public void setMode(Mode mode) {    switch (mode) {        case DARK -&gt; System.out.println(\"Dark mode ON\");        case LIGHT -&gt; System.out.println(\"Light mode OFF\");    }}// 오버로딩 대신 명확한 메서드명public void printString(String s) {}public void printObject(Object o) {}// Optional은 null 가능성이 있을 때만public Optional&lt;String&gt; findNameById(int id) {    if (id == 1) return Optional.of(\"Alice\");    else return Optional.empty();}public static void main(String[] args) {    // Optional 활용 예시    String name = new Main().findNameById(1)                            .orElse(\"기본 이름\");    System.out.println(name);}일반적 프로그래밍 원칙  라이브러리 익히고 사용: 특히 java.lang, java.util, java.io 와 그 하위 패키지, Collection, Stream 패키지에 대해서 눈여겨 보기  정확한 계산을 위해서는 float 나 double 을 피하기.          정확한 계산을 하고 싶다면, 소수점 추적이 필요하다면  BigDecimal 을 사용하는 것이 더 좋다.        박싱된 기본 타입 보다는 기본 타입을 사용하기  다른 타입이 적절하다면 문자열 사용을 피하기  문자열 연결은 느리니 주의하기 =&gt; StringBuilder 를 사용  객체는 인터페이스를 사용해 참조(Open-Closed Principle)  최적화는 신중하게 하기예외  예외는 진짜 예외 상황에만 적용  복구 가능한 상황에는 검사 예외 사용  프로그래밍 오류에는 런타임 예외 사용  메소드가 던지는 모든 예외를 문서화 하기  예외의 상세 메시지에 실패 관련 정보를 담기  가능한 실패를 Atomic 하게 만들기public class Calculator {    // 단순 조건에도 예외를 던짐 (남용)    public int divide(int a, int b) throws Exception {        if (b == 0) {            throw new Exception(\"0으로 나눌 수 없음\");        }        return a / b;    }}public class Main {    public static void main(String[] args) {        Calculator calc = new Calculator();        try {            int result = calc.divide(10, 0);        } catch (Exception e) { // 광범위한 Exception            e.printStackTrace();        }    }}// 복구 가능한 상황 → 검사 예외class FileFormatException extends Exception {    public FileFormatException(String message) {        super(message);    }}// 프로그래밍 오류 → 런타임 예외class NegativeNumberException extends RuntimeException {    public NegativeNumberException(String message) {        super(message);    }}public class Calculator {    /**     * @throws FileFormatException 잘못된 입력 형식일 경우     * @throws NegativeNumberException 음수 입력 시     */    public int parseAndAdd(String input) throws FileFormatException {        try {            int num = Integer.parseInt(input);            if (num &lt; 0) {                throw new NegativeNumberException(\"음수는 허용되지 않음: \" + num);            }            return num + 10;        } catch (NumberFormatException e) {            throw new FileFormatException(\"잘못된 숫자 형식: \" + input);        }    }}public class Main {    public static void main(String[] args) {        Calculator calc = new Calculator();        try {            int result = calc.parseAndAdd(\"abc\");        } catch (FileFormatException e) {            System.err.println(\"입력 오류 → \" + e.getMessage());        }    }}직렬화  직렬화 대안을 찾기: 직렬화는 상당히 우험함. Json 이나 프로토콜 버퍼와 같은 대안을 사용하는 것이 좋음.신뢰할 수 없는 데이터는 역직렬화 하지 않으며, 필터를 통해 먼저 검사하기  Serializable 을 구현할지는 신중히 결정하기          버그와 보안 구멍이 생길 우려      Serializable 을 구현 시 릴리즈 한 뒤 수정이 힘듦      해당 클래스의 신 버전을 릴리즈할 때 테스트 할 것들이 늘어남      기타 가져갈 것들  import 문에 와일드 카드 생략하지 않기  패키지명은 도메인 역순 사용  모든 생성자는 첫 줄에 super() 또는 this()를 호출해야 함  명시하지 않으면 자동으로 super() 호출  인터페이스의 메서드에도 default, static 이 올 수 있다.과제하며 배운점다음을 java docs 의 Marker 와 함께 써넣으면 좋다.  DRY – Don’t Repeat Yourself  YAGNI – You Aren’t Gonna Need It  KISS – Keep It Simple, Stupid  SRP - Single Responsibility Principle  OCP - Open-Closed Principle  LSP - Liskov Substitution Principle  ISP - Interfaced Segregation Principle  DIP - Dependency Inversion Principle  POJO - Plain Old Java Object  VO - Value Object  DTO - Data Transfer Object  DAO - Data Access Object"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 5일차 JVM 메모리 공간",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/21/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-5%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-21",
      "content": "📂 목차  Parameter          Pass-by-value      가변 길이 매개변수 받기        Static          Static Field      Static Method      static 초기화 블록      Nested Class                  Static Nested Class          Inner Class                      ⭐️ JVM 의 메모리 공간          Method Area                  역어셈블러를 통한 class 파일 살펴보기          헤더 부분 해석          Attributes 구성요소          Constant Pool 해석          클래스의 필드 정의 해석          생성자 및 메서드 바이트코드 부분 해석          LineNumberTable 해석          결론                    Heap                  Heap Area 의 Generational Collection Theory          Heap 에서의 GC                    Thread                  Stack          PC Register          Native Method Stack                      ClassLoader          Loading                  Bootstrap ClassLoader          Platform ClassLoader          System ClassLoader          User-defined ClassLoader          클래스 로더의 원칙                    Linking      Initialize      📚 본문참고: JVM 밑바닥까지 파헤치기참고: Dev Uni 블로그Parameterparameter 는 메서드 선언부에 정의된 변수이며, 그 매개 변수 내의 값을 argument 라고 한다.Pass-by-value모든 매개변수 전달 시 값에 의한 전달 방식을 사용한다. 매개체에 따라 두 가지 전달 유형이 있는데      Primitive type 을 전달할 때에는 값 자체가 복사되어 메서드로 전달하며, 메서드 내부에서 변경해도 원본에 영향이 없다.        Reference type 을 전달할 때에는 주소가 복사되어 전달되므로 객체 내부 상태는 수정 가능하며, 참조 자체를 다르게 바꾸면 원본에는 영향이 없게 된다.  가변 길이 매개변수 받기자바에서 메서드의 파라미터에는 매개변수를 가변길이로 받을 수 있도록 … 기능을 넣어주셨는데, 다음 규칙을 따라야 한다:  String… args 형태로 선언할 수 있다. 이는 내부적으로 String Array 와 동일하여 컴파일러가 자동으로 처리해준다.  한 메서드에서 가변 매개변수는 매개변수들 맨 뒤에 선언해주어야 한다.  한 메서드에서 가변 매개변수는 오로지 하나만 가능하다.  null 값이 들어갈 수 있으므로 NPE 예외처리를 해주어야 한다.  성능을 고려하여 빈번한 호출 시 성능에 부담을 줄 수 있으므로 가급적 primitive 변수를 넘겨주는게 좋다.  만약 같은 타입의 가변 길이 메서드와 그냥 여러 개 매개변수 받는 메서드가 있다면, 개수에 따라 여러 개 매개변수를 우선으로 한다.  초보자는 가변 길이 매개변수를 쓰지 말자. [] 로도 충분히 인자를 받을 수 있다.Staticstatic 은 특별한 키워드이다. 정적의 의미를 가지며, 정적 이라는 소리는 동적과는 반대되는 의미이다. 동적이라는 것은 움직이는, 변하는의 의미를 가진다. 정적은 그 메모리 그대로 변하지 않는 이라는 의미를 가진다 바뀔 수 있지만 가르키는 곳은 변화하지 않는다.따라서 정적이라는 것은 동적과는 다르게 변하지 않을 것이며, 항상 메모리에서 유일하게 하나로 존재할 것이다. 그것이 JVM 이 loading 될 때의 그 세상에 하나 메모리에 하나의 의미를 지니게 될 것이다.  더 깊이있게 나아가자면, static 변수 정의 정보가 Method Area에 올라가며, JVM 이 올라가고 나서 Heap 에 로딩된다.Static Field필드는 클래스가 가지는 변수이다. 이 변수가 유일하다는 것이다.이런 변수들은 class 가 public 하고 field 가 public static 이면 다른 객체가 변경을 할 수 있게 된다.이미 메모리에 올라와져 있는 이 static 키워드가 붙은 field 값을 굳이 instance initializing 을 하지 않아도 접근이 가능하다.public class C { public static final int N = 42; }// C.N 접근 가능  주의! 공유 상태이기 때문에 volatile / Atomic / Lock 으로 가시성, 원자성 보장이 필요하다.Static Method이 또한 마찬가지이다. static 이 붙었기에 메모리에 미리 올라와 있으며, 굳이 instance 를 선언해주지 않아도 유틸 기능을 가지는 함수들을 이렇게 정의하여 사용할 수 있도록 한다.다만 extends 할 때를 보자. 이때는 오버라이딩을 하면 선언된 변수의 타입에 맞춰서 함수를 실행하게 된다. 이해가 안되면 밑을 보자.class P { static void hi(){ System.out.println(\"P\"); } }class C extends P { static void hi(){ System.out.println(\"C\"); } }P p = new C();p.hi();      // 컴파일타임 타입 P 기준으로 \"P\" 출력C.hi();      // \"C\"  즉, 오버라이딩이 아닌 메서드 숨김(hiding) 이 일어나게 된다. 이 또한 공유이기 때문에 만약 해당 객체의 데이터를 수정한다, 삭제한다 등의 변경 사항이 일어날 때 synchronized static 을 붙여줘야 한다.static 초기화 블록클래스 초기화 시에 딱 한 번만 시행한다(JVM 이 올라갈 때 말하는 것).클래스에 대해 딱 한 번 실행하고 싶은 코드가 있다면 이를 사용할 수 있다. 이 코드 스코프에서 던져지는 예외는 ExceptionalInInitializerError 로 래핑되어 던져지며, 이 이후에 클래스를 다시 쓰면 NoClassDefFoundError 가 일어나게 된다. 이 상황을 만들어보자.class Bed {    static {        if (true) {            throw new RuntimeException(\"boom\");        }    }}클래스는 무조건 Exception 을 띄운다. 이때 JVM 이 Bed 클래스를 처음 로드 &amp; 초기화를 할 때 static 블록이 실행되는데,public class Main{    public static void main(String[] args) {        Bed bed = new Bed(); // Exception 발생    }}여기서 처음 ExceptionInIntializerError 가 발생되며 이는 초기화가 제대로 수행되지 않았다는 소리가 된다. 당연히 Exception 이 발생하여 트랩을 발생시키면 제어권을 OS가 가져가게 되고, 이는 명령을 그때부터 더이상 수행할 수 없게 되는 것이다.이제 이 클래스는 초기화 실패한 클래스로 JVM에 표시되어 있고, 이를 new Bed() 를 하거나 Bed.(static 메서드)() 를 하면 ExceptionInInitializerError 가 발생하게 된다.public class Main{    public static void main(String[] args) {        Bed bed = new Bed(); // Exception 발생    }}Nested ClassNested(중복) 클래스는 클래스 안에 클래스를 넣는 설계이다. 보통은 두 종류가 있다(함수 내부에서 선언하는 class 도 있음):      static 키워드가 붙은 Static Nested Class        Inner Class(static 없음)  Static Nested Classstatic 키워드가 붙은 중첩 클래스이며, 바깥 클래스의 인스턴스 멤버에는 접근이 불가한 형태이다. 바깥 클래스의 static 멤버에는 대신 접근이 가능하다.이것 또한 JVM 을 심도 있게 안다면 바로 알 수 있는 내용인데 static 자체는 JVM 이 올라가고 나서 인스턴스 및 변수가 Heap 영역에 로드, 위치하게 된다.따라서 Static Nested Class 는 바깥 클래스의 인스턴스에 종속된게 아니다. static 으로 되어진 변수나 함수가 어떻게 값이 들어가게 되는지는 나중에 나온다.어쨋든 바깥 클래스의 객체 상태(this)와는 독립적으로 존재하기 때문에(initializing 을 안하여도 존재하기 때문에), 바깥 클래스의 인스턴스 필드에 접근할 수 없고 오직 정적 멤버만 참조 가능하다는 것이다(아직 초기화하지 않았기 때문). &lt;- 이거는 public static void main 에서 static 이 아닌 method 를 불러올 때도 마찬가지로 에러가 뜸을 볼 수 있는 것과 동일한 원리다.만약 Static Nested Class 가 설계된 .class 파일을 javac 로 컴파일 하게 되면 Outer$StaticNestedClass.class 와 같은 별도의 클래스 파일이 생성됨을 볼 수 있을 것이다(중요).또한 이때 GC 가 이 Static Nested Class 에 대해서도 이미 컴파일된 파일 자체가 독립적으로 되었기 때문에 이는 바깥 클래스 인스턴스의 생명주기와 얽히지 않고 독립적으로 관리하는 것으로 유추해볼 수 있다.따라서 다음 특징으로 정리해볼 수 있겠다:  Memory Independence  역할과 책임의 분리Inner Classstatic 키워드가 없다. 이는 바깥 클래스의 모든 멤버에 접근이 가능하다는 것이며, 대신 바깥 클래스의 인스턴스가 반드시 존재할 때 이 또한 비로소 접근을 할 수 있을 터이다.  우선 초기화를 해야 메모리에 적재가 되기 때문하지만 이 Inner Class 는 많이 사용하지는 않는데, 숨은 참조가 발생하여 바깥 클래스를 암묵적으로 참조하여 GC 가 Outer 인스턴스를 수거해갈 수 없는 상황이 발생할 수 있기 때문에 메모리 누수가 발생할 수 있다. 진짜 그 클래스와 의미론적으로 강한 연관(Node 와 List 간의 관계)이 있는게 아닌 이상 굳이 사용하지 않는다.익명 Nested Class그때 딱 한 번만 사용할 경우 유용하다. 그것을 제외하고는 X// 4. 익명 내부 클래스 (anonymous inner class)public void createAnonymousClass() {    // 인터페이스를 구현하는 익명 클래스    Runnable runnable = new Runnable() {        @Override        public void run() {            System.out.println(\"익명 클래스 실행\");        }    };    // Java 8+ 람다 표현식으로 대체 가능    Runnable lambdaRunnable = () -&gt; System.out.println(\"람다 실행\");}⭐️ JVM 의 메모리 공간더 깊이 있게 들어가보자. JVM 은 프로그램을 실행할 때 OS 위에서 자바 프로세스만의 메모리 공간을 따로 확보해서 운영한다.  마크 서버를 운영해보면 알 수 있다.이 할당된 JVM 의 메모리 구조는 다음 영역으로 다시 구분되게 되는데:  Runtime 객체          JVM 머신                  ClassLoader          Runtime Data Areas(JVM Memory Areas)                          Method Area(Static Area)                                  Runtime Constant Pool                                            Heap Area              Thread                                  PC Register                  Stack Area                  Native Method Stack                                                                        Method Area클래스 로딩 정보(ClassLoader 가 읽어들인 바이트 코드) 들을 여기 메모리에 저장하게 된다. 모든 스레드가 다음을 공유하게 된다.저장 요소  Runtime Constant Pool: Java Compiler 에 의해 만들어지는 Symbol Table 을 사용하여 클래스나 인터페이스 별 Constant Pool 을 만들고, 만들어지는 상수풀은 아래 요소들을 가진다. 이런 상수 풀이 메모리에 올라갈 때 비로소 Runtime Constant Pool 이라고 한다.          Literal Constant: String literal 이나 숫자 리터럴 등등      Type Field(Local Variable, Class Variable): 필드에 선언된 변수 타입들      Class 및 Method 로의 모든 Symbolic Reference: 가져온 클래스나 메서드 들의 참조를 말한다.        Java 7 까지는 PermGen 이라는 명칭이었다.역어셈블러를 통한 class 파일 살펴보기위 Constant Pool 을 보기 위해 컴파일 된 Main.class 를 다시 역어셈블러(javap) 를 통해 살펴볼 수 있다.javap -v Main.class필자는 다음을 컴파일 후 역어셈블러를 통해 얻었다.public class Main {    static final int staticFinalInt = 100;    static final String staticFinalString = \"HELLO\";    int notStaticInt = 999;    String notStaticString = \"Bye\";    public static void main(String[] args) {        String str = \"new\";        int i = 100;        System.out.println(staticFinalInt);        System.out.println(staticFinalString);        System.out.println(\"HELLO\");        System.out.println(i);        System.out.println(str);    }}헤더 부분 해석...  Compiled from \"Main.java\"public class Main  minor version: 0  major version: 65  flags: (0x0021) ACC_PUBLIC, ACC_SUPER  this_class: #8                          // Main  super_class: #2                         // java/lang/Object  interfaces: 0, fields: 4, methods: 2, attributes: 1맨 위는 민감한 정보같아 가렸다. 구분이 잘되도록 줄바꿈을 좀 했다.맨 위의 public class Main 이 헤더 부분이다. 해석하자면 public 접근제어자를 가진 Main 클래스를 명시하고, major 65 는 JDK 21에서 컴파일 된 class 파일이라는 뜻이다. 즉 컴파일 컴포넌트의 버전을 암시하는 듯하다. flags 는 접근에 대한 플래그이며, ACC_PUBLIC 을 통해 public 클래스임을 나타내며, ACC_SUPER 를 통해 invokespecial 명령어 동작을 최신 방식(상위 메서드 호출 시 올바른 메서드 선택) 을 따르게 한다.  this_class: #8 // Main : Constant Pool 에서의 #8 항목이 현재 Main 클래스를 가르키는 것을 명시  super_class: #2 // java/lang/Object : 상위 클래스가 java.lang.Object 임을 의미  interfaces: 0 : 구현한 인터페이스 개수는 0개  field: 4: 클래스에 선언된 필드(변수) 개수가 총 4개, 이를 통해 static 도 포함되는 것을 볼 수 있다.  methods: 2: 클래스에 선언된 메서드 개수이며, 생성자 + main 메서드 로 총 2개이다.  attriubtes: 1: 이게 중요한 요소인데, 클래스 파일 수준에서 추가된 속성(attribute)의 개수이다. SourceFile 속성이 일반적으로 들어가며 어떤 소스 파일에서 컴파일 된 것인지 등을 나타낸다.Attributes 구성요소attribute 를 보자. 클래스 파일은 기본 구조가 다음과 같다(순서는 신경 안썼다).  magic number  version  constant pool  access flags  this_class / super_class  interface  fields  methods  attributes이때 attributes 는 추가 설명서 역할을 한다. 클래스, 필드, 메서드 모두에 붙을 수 있고, JVM 사양에 기본적으로 정의된 것도 있고 컴파일러가 자동으로 붙여주는 것도 있다. JVM 이 실행을 하는데 있어서 꼭 필요한 거는 아니지만 메타데이터로서 존재한다.이러한 메타데이터는  JVM 런타임  개발 도구(Compiler, Debugger, IDE, java.lang.reflect 등)에게 제공되게 된다.위 구성요소들을 분류해보면 다음과 같다.클래스 수준에서의 Attribute  SourceFile: 어떤 .java 소스 파일에서 컴파일되었는지  InnerClasses: 내부 클래스 정보들  BootstrapMethods: Lambda, invokedynamic  위 예제 코드에서는 안보이지만 역어셈블러 된 파일의 맨 아래 줄에 SourceFile: “Main.java” 라는 줄이 들어가 있고, 이는 SourceFile 한 개(Main.java) 가 컴파일 됐으므로 1이라는 값이 들어가게 되는 것이다.메서드 수준에서의 Attribute  Code: 실제 바이트 코드 명령어  LineNumberTable: 바이트 코드, 소스코드 줄 번호 매핑(디버깅 용)  LocalVariableTable: 지역 변수 이름과 슬롯 매핑 정보(디버깅 용)필드 수준에서의 Attribute  ConstantValue: 상수 풀에 고정된 값 저장Constant Pool 해석Constant pool:   #1 = Methodref          #2.#3          // java/lang/Object.\"&lt;init&gt;\":()V   #2 = Class              #4             // java/lang/Object   #3 = NameAndType        #5:#6          // \"&lt;init&gt;\":()V   #4 = Utf8               java/lang/Object   #5 = Utf8               &lt;init&gt;   #6 = Utf8               ()V   #7 = Fieldref           #8.#9          // Main.notStaticInt:I   #8 = Class              #10            // Main   #9 = NameAndType        #11:#12        // notStaticInt:I  #10 = Utf8               Main  #11 = Utf8               notStaticInt  #12 = Utf8               I  #13 = String             #14            // Bye  #14 = Utf8               Bye  #15 = Fieldref           #8.#16         // Main.notStaticString:Ljava/lang/String;  #16 = NameAndType        #17:#18        // notStaticString:Ljava/lang/String;  #17 = Utf8               notStaticString  #18 = Utf8               Ljava/lang/String;  #19 = String             #20            // new  #20 = Utf8               new  #21 = Fieldref           #22.#23        // java/lang/System.out:Ljava/io/PrintStream;  #22 = Class              #24            // java/lang/System  #23 = NameAndType        #25:#26        // out:Ljava/io/PrintStream;  #24 = Utf8               java/lang/System  #25 = Utf8               out  #26 = Utf8               Ljava/io/PrintStream;  #27 = Methodref          #28.#29        // java/io/PrintStream.println:(I)V  #28 = Class              #30            // java/io/PrintStream  #29 = NameAndType        #31:#32        // println:(I)V  #30 = Utf8               java/io/PrintStream  #31 = Utf8               println  #32 = Utf8               (I)V  #33 = String             #34            // HELLO  #34 = Utf8               HELLO  #35 = Methodref          #28.#36        // java/io/PrintStream.println:(Ljava/lang/String;)V  #36 = NameAndType        #31:#37        // println:(Ljava/lang/String;)V  #37 = Utf8               (Ljava/lang/String;)V  #38 = Utf8               staticFinalInt  #39 = Utf8               ConstantValue  #40 = Integer            100  #41 = Utf8               staticFinalString  #42 = Utf8               Code  #43 = Utf8               LineNumberTable  #44 = Utf8               main  #45 = Utf8               ([Ljava/lang/String;)V  #46 = Utf8               SourceFile  #47 = Utf8               Main.java해석  #1 = Methodref: 메서드 참조이며 참조 대상은 #2.#3(#2 클래스의 #3 메서드 시그니처)  java/lang/Object.()V  Object 클래스의 기본 생성자 호출  #2 = Class: 클래스 참조이며 #4 를 참조하고 있음. #4는 문자열 java/lang/Object 임  “java/lang/Object” 를 가르키는 중  #3 = NameAndType: 이름과 타입 묶음을 말하고 #5:#6 을 참조 중이다.  “\":()V 를 통해 보면 이름은 , 타입은 ()V 이고 이 타입의 의미는 파라미터가 없고, void 를 반환한다는 뜻이다.  #4 = Utf8    java/lang/Object  #5 = Utf8      #6 = Utf8    ()VUtf8 문자열 상수들을 말한다.  #7 = Fieldref    #8.#9   // Main.notStaticInt:I  #8 = Class       #10     // Main  #9 = NameAndType #11:#12 // notStaticInt:I위 7-9 는 우리가 선언한 notStaticInt 라는 변수명이 int 라는 타입을 가진다는 것을 메타데이터로 알려주고 있음을 볼 수 있다.나머지는 유사하기에 넘어간다. 이처럼 모든 변수와 메서드 호출과 클래스 명들을 참조 혹은 String 상수를 저장하고 있음을 볼 수 있다.클래스의 필드 정의 해석{  static final int staticFinalInt;    descriptor: I    flags: (0x0018) ACC_STATIC, ACC_FINAL    ConstantValue: int 100  static final java.lang.String staticFinalString;    descriptor: Ljava/lang/String;    flags: (0x0018) ACC_STATIC, ACC_FINAL    ConstantValue: String HELLO  int notStaticInt;    descriptor: I    flags: (0x0000)  java.lang.String notStaticString;    descriptor: Ljava/lang/String;    flags: (0x0000)하나만 가지고 와보자.클래스 변수  static final int staticFinalInt;    descriptor: I    flags: (0x0018) ACC_STATIC, ACC_FINAL    ConstantValue: int 100위는 static final int StaticFinalInt 가 선언한 것에 대한 메타데이터 들이 저장되어 있다.  descriptor: I 는 int 타입을 뜻하며,  ACC_STATIC, ACC_FINAL 은 플래그로 해당 변수는 static 과 final 레벨의 access 가 가능하다.  ConstantValue: int 100 컴파일 시점에 상수 풀에 박힌 값이다.클래스  static final java.lang.String staticFinalString;    descriptor: Ljava/lang/String;    flags: (0x0018) ACC_STATIC, ACC_FINAL    ConstantValue: String HELLOprimitive 와는 다르게 L이 붙여져있음을 볼 수 있다.인스턴스 변수  int notStaticInt;    descriptor: I    flags: (0x0000)생략생성자 및 메서드 바이트코드 부분 해석  public Main();    descriptor: ()V    flags: (0x0001) ACC_PUBLIC    Code:      stack=2, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.\"&lt;init&gt;\":()V         4: aload_0         5: sipush        999         8: putfield      #7                  // Field notStaticInt:I        11: aload_0        12: ldc           #13                 // String Bye        14: putfield      #15                 // Field notStaticString:Ljava/lang/String;        17: return      LineNumberTable:        line 2: 0        line 6: 4        line 7: 11여기서  public Main();    descriptor: ()V    flags: (0x0001) ACC_PUBLIC의 부분은 필드 정의와 똑같음을 알 수 있다. 즉, 클래스/인스턴스 멤버 변수들은 동작하는 것이 없기에 그리 길지 않다. 하지만 함수에 있어서는 아래와 같이 Code 블럭이 있다.    Code:      stack=2, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.\"&lt;init&gt;\":()V         4: aload_0         5: sipush        999         8: putfield      #7                  // Field notStaticInt:I        11: aload_0        12: ldc           #13                 // String Bye        14: putfield      #15                 // Field notStaticString:Ljava/lang/String;        17: return  stack=2: 이 메서드에서 사용하는 JVM 스택의 최대 깊이 = 2  locals=1: 로컬 변수 슬롯 개수 = 1 (this 만 있음)  args_size=1: 인자 개수 = 1 (this)그 이후는 함수형 언어로 어셈블리어와 유사한 형태로 흘러가게 된다. 이는 JVM 이 실행하는 가상 어셈블리 같은 것이다.LineNumberTable 해석      LineNumberTable:        line 2: 0        line 6: 4        line 7: 11}자바 바이트 코드는 줄 번호라는 개념이 없기에 소스코드 몇 번째 줄이 필요하다 라고 가정하면, 번호가 필요하게 된다. 이때 컴파일러가 LineNumberTable Attribute 를 넣어서 바이트코드와 원래 자바 소스코드의 줄 번호를 매핑시켜주는 메타데이터이다.결론Compile 상태에서의 Constant Pool 을 봤을 것이다. 이 Constant Pool 이 이제 메모리에 올라가게 된다면 Method Area 에 Runtime Constant Pool 개념으로 바뀌게 된다.이 말은 클래스 파일 하나하나 즉 인터페이스, 클래스 들 각각이 Constant Pool 을 가지며,자신의 클래스 내부에 선언되어 있는 소스 코드에 관여하는 모든 클래스, 필드와 심볼릭 링크 등이 모두 저장되어 있다.여기서는 Constant Pool 만이 Method Area 로 올라감 을 보았다.HeapHeap 도 Method Area 와 공통된 특징으로 모든 스레드가 공유하는 영역이며JVM 이 실행되고 생성되는 공간이며 저장 요소는 Runtime 에 생성된 인스턴스, 객체(object)를 저장한다.이때 Heap 영역은 객체가 생성되고 삭제되는 공간이며 이는 GC 가 이를 관리한다.저장 요소  static object  String  String Constant Pool위에서 볼 수 있듯이 String 들은 전부 String Pool 에 저장됨을 볼 수 있다. “Cat”, “Dog” 등등이 저장되고, s1, s2 의 변수는 참조에 대한 정보는 Meta Area 에 있고, 참조가 가르키는 곳이 String 이 있는 곳이 된다.여기서 Intern String 이라는 개념이 나오는데, String Constant Pool 에 리터럴 String 이 있다면, 그 리터럴 String 을 다시 만들기 보다 String Constant Pool 에서 참조하는 형식으로 메모리 양을 최적화하고 있다. 이렇게 Constant Pool 에 하나만 저장하여서 할당하는 것을 intern 이라고 하고 interned 된 String 을 Interned String 이라고 한다(실제로 String 쪽에 intern 메서드가 있다).다시 정리하자면,byte code 에서의 constant pool 이 class loader 에 의해 linking 이 될 때 여기서 heap 영역에 string constant pool 이 생성되고, method area 영역에 runtime constant pool 이 생성되게 된다.리터럴로 선언한 애들은 전부 string constant pool 에 의해 저장되어서 효율적으로 관리되게 되지만 new String() 으로 생성한 문자열은 heap 으로 따로 저장되는 메커니즘이며, 이는 new String() 자체가 함수이고 생성자이기 때문에 명시적으로 생성자를 지정해주는 것이 새로운 영역에 새로운 값을 할당하는 동적 할당의 개념과 같으므로 string constant pool 로의 정적 할당과는 다르게 string constant pool 영역은 아니지만 heap 영역에 저장되게 되는 것이다.   /**     * Returns a canonical representation for the string object.     * &lt;p&gt;     * A pool of strings, initially empty, is maintained privately by the     * class {@code String}.     * &lt;p&gt;     * When the intern method is invoked, if the pool already contains a     * string equal to this {@code String} object as determined by     * the {@link #equals(Object)} method, then the string from the pool is     * returned. Otherwise, this {@code String} object is added to the     * pool and a reference to this {@code String} object is returned.     * &lt;p&gt;     * It follows that for any two strings {@code s} and {@code t},     * {@code s.intern() == t.intern()} is {@code true}     * if and only if {@code s.equals(t)} is {@code true}.     * &lt;p&gt;     * All literal strings and string-valued constant expressions are     * interned. String literals are defined in section {@jls 3.10.5} of the     * &lt;cite&gt;The Java Language Specification&lt;/cite&gt;.     *     * @return  a string that has the same contents as this string, but is     *          guaranteed to be from a pool of unique strings.     */    public native String intern();JDK21 의 문서를 가져왔다. 이때 native 로 선언됨을 볼 수 있는데 intern 메서드는 Native Stack Area 에 생성됨을 볼 수 있다. 즉 이는 운영체제가 함수를 실행하게 만든다.이런 특징 때문에 String 은 + 연산이 메모리 적으로 안좋다. Heap 영역에 계속해서 새로운 객체로 저장되기 때문에 안좋으며 GC 가 관리해야 할 대상이 늘어나게 된다.  String: 문자열 연산 자체가 적고 멀티스레드일 경우  StringBuffer: 문자열 연산이 많고 멀티스레드의 경우  StringBuilder: 문자열 연산이 많고 단일스레드이며 동기화를 고려하지 않아도 되는 경우왠만해서는 StringBuffer 를 쓰자.  Uni Dev 참고 : Intern String 객체든 Static 객체든 메서드 영역에 있나 힙 영역에 있나는 그렇게 중요한 사실이 아니다. 어디에 있든 스레드가 공유하는 자원이고 여러 개 생성되지 않고 하나만 생성되고 여러 스레드가 이를 참조한다는 사실이 중요하다.Heap 에서의 GCHeap 에서 GC 가 활발하게 활동하는데 그 범위는 java 는 실행할 때 할당할 수 있는 메모리 영역으로 지정할 수 있으며 이 영역은 Heap Area 를 지정하는 옵션이다.-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError  -Xms, -Xmx 는 JVM 가용 힙 크기-XX 는 실험적/고급 옵션을 사용하고 싶을 때 사용(GC 방식, JIT 컴파일러, 내부 동작 등)메모리가 overflow 됐을 때 JVM이 예외 발생 시점의 힙 메모리 snapshot 을 파일러 저장(dump)해주는 옵션-XX:+UseG1GC      # G1 GC 사용-XX:-UseG1GC      # G1 GC 사용 안함-XX:MaxMetaspaceSize=256m   # Metaspace 최대 크기-XX:NewRatio=2              # New/Old 비율-XX:SurvivorRatio=8         # Survivor/Eden 비율반드시 쓰이지 않는 것은 null 로 바꾸어 해제시켜주자.Heap Area 의 Generational Collection Theory아직 이를 공부하기에는 굳이 인 느낌이 있지만, 적어놓고 나중에 다시 보려고 한다. 옛날 이론이라 지금이랑 또 다를 수 있다.통계학적으로 다음이 밝혀졌다:  대부분 객체는 얼마 지나지 않아 사용하지 않는다  오래된 객체에서 젊은 객체로의 참조는 아주 적게 존재한다.메모리 회수 관점에서 GC들이 이걸 참조한다고 한다.이 이론에 따르면 heap 을 다음과 같이 메모리 영역을 구분한다:  신세대(new generation)          에덴 영역(Eden): 가장 처음 객체가 메모리에 할당되는 공간, GC 가 1회 수행 후에는 Survivor 영역 중 하나로 이동      생존자 영역: from, to 두 부분으로 나뉘며, 둘 중 하나는 반드시 비어있다.  여러 번 생존에 성공 시 구세대로 승격한다.        구세대(old generation)          신세대에서 오래 살아남은 객체들의 정보가 복사되어 있는 공간임  GC는 적게 발생하고, 신세대에 비해 큰 메모리를 할당받게 된다.      Card Table: 구세대에서 신세대 영역으로의 참조 테이블을 말하며, 512 bytes chunk 로 구성된다고 한다(옛날 정보)        영구세대(permanent generation)          고정 메모리 크기 공간이며 -XX 옵션으로 지정한다.      위 세대 영역들과 아무런 관련이 없으며, GC 가 발생 여부도 독립적이다.      PermGen 이 이 영역이며, 이 이론을 토대로 설계를 했지만 지금은 삭제하고 없음을 볼 수 있다.Thread우리가 운영체제에서 생각하는 그 스레드 맞다.Stack각 스레드 마다 독립적으로 존재하는 메모리 영역이며, 각 스레드 마다 하나씩 존재한다.  메서드 호출 시마다 Stack Frame(가상 메모리 공간에서의 프로세스 하나 당 기본 단위와 유사한 개념) 이 쌓임  {Local Variable Array, Operand Stack, 현재 메서드의 Constant Pool 참조 등등}으로 구성          Local Variable Array: 0부터 시작하는 인덱스를 가지는 배열  0: this, 1부터는 전달된 파라미터들, 그 이후 메서드 지역 변수들 저장      Operand Stack: 메서드 하나하나 수행되는 공간      Reference to Constant Pool: 필요한 데이터 및 결과를 저장함        메서드 종료 시 Stack Frame 임이 제거됨  참조를 할 때 동적 linking 을 함PC Register각 스레드 마다 하나씩 존재(여기서 주의할 점은 실제 하드웨어 PC를 말하는게 아니다… 그냥 SW의 추상화된 형태로 PC를 제공한다 Java 가 독립적인 이유에 한 몫 하는 변수이다)  현재 실행 중인 JVM 명령어의 주소를 저장  스레드 전환 시, 다시 돌아왔을 때 실행 위치를 잃지 않도록 함Native Method StackJava 가 아닌 네이티브(C, C+) 코드 등의 JNI(Java Native Interface) 호출 을 실행할 때 사용하는 스택  일반 자바 스택과 유사하지만, 네이티브 라이브러리를 위한 공간임  ex. System.arraycopy(), Object.hashCode(), Object.clone() 등등 네이티브로 구현됨  왜 있냐? 모든 기능을 자바로 구현하기는 힘듦. OS/HW의 밀접하게 의존해야 할 때는 더 low-level 의 언어가 필요함. 이때 C, C++을 사용하지만, 언어 자체가 달라서 이를 호환시키도록 하는게 JNI  JNI 를 쓸 때는 그래서 그냥 Stack 이 아닌 Native Method Stack 이 사용된다. 이는 C 함수의 호출 처럼 동작하게 됨. 네이티브 코드 실행은 GC 의 관리영역 밖이기 때문에 사용에 주의해야 하며, 보안 검사 등도 유의해야 한다… 꼭 필요한 경우만 사용하자.┌──────────────────────────┐│        Method Area        │ ← 클래스 로딩 정보, Runtime Constant Pool│        (Metaspace)        │├──────────────────────────┤│           Heap            │ ← 객체 저장, GC 대상, String Constant Pool, static objects├──────────────────────────┤│      PC Register (T)      │ ← 각 스레드별 현재 실행 주소│        Java Stack (T)     │ ← 각 스레드별 메서드 실행│  Native Method Stack (T)  │ ← 각 스레드별 네이티브 코드 실행└──────────────────────────┘메모리 공간의 구조 파악은 끝났고 클래스가 어떻게 로딩되는지 보자.ClassLoader이제 JVM 의 메모리 개념을 이해했다면 ClassLoader 를 이해할 수 있게 되는데, 이름 그대로 자바에서 .class 바이트 코드를 JVM 메모리에 적재하는 역할을 한다.실행 시점에서 동적으로 클래스 로딩을 하기 때문에 자바는 한 번 컴파일을 하면 어디서든 실행된다는 특징을 가질 수 있다.Loading클래스 로딩은 클래스를 로드하라는 요청이 왔을 때 Loading 과정이 실행된다. 주된 작업은 다음과 같다.  .class 파일들 JVM 에 적재  ClassLoader 가 파일 읽음클래스 로더 주로 3가지가 있고, 각각의 수행 처리 순서는 Bootstrap ClassLoader -&gt; Platform ClassLoader -&gt; Application ClassLoader 순으로 진행되며  System  Platform  BootStrap순으로 클래스의 메모리 적재를 요청하게 되고(getClassLoader()),  BootStrap  Platform  System순으로 class 를 로딩해주게 된다. JVM 이 ByteCode 를 토대로 클래스, 인터페이스를 찾고 이를 생성하는 과정을 진행한다.위 순서로 진행되는 이유는 충돌을 방지하기 위해서이다.Bootstrap ClassLoaderJVM 자체에 내장되어 있고, JAVA_HOME/lib 안의 핵심 클래스(java.lang.*, java.util.*) 로딩제일 먼저 동작하고, 클래스로더 중에 유일하게 Native C 로 구현되어 있다.Platform ClassLoaderBootstrap 이 찾지 못한 클래스들을 로딩하며, JDK 확장 라이브러리(lib/ext 또는 모듈)을 로드한다. 예를들면 javax.* 가 있겠다(사실 잘 모른다 그런 추측이다. javax 는 java 에서 extension 이 붙어서 다양한 기능으로 서드 파티가 구현한게 자주 쓰여서 실제로 공식 java 라이브러리에도 등록되어서 쓰고 있는 것으로 안다).  Java 8까지는 Extension ClassLoader 였다.System ClassLoaderPlatform ClassLoader 가 못찾은 클래스만 로딩한다.우리가 설계한 어플리케이션 .class 파일이 최종적으로 적재되는 것(우리는 구현되어 있는걸 가져다 쓰기 때문에 가장 최후에 선언됨).  Java 8 까지는 Application ClassLoader 였다.User-defined ClassLoader사용자가 직접 정의해 사용하는 클래스 로더로, java.lang.ClassLoader 로 정의할 수 있다.이는 Spring 에서 이를 사용하는 메서드들을 자주 볼 수 있다.클래스 로더의 원칙클래스 로더는 다음을 따르도록 설계되어야 한다.위임-우선 모델  상위 클래스에서 찾고 싶은 클래스를 찾고  없으면 하위 클래스에서 다시 찾는 다이어그램  관련 Exception 은 ClassNotFoundException 을 내뱉는다. 이는 Checked Exception 이다.가시성 원칙  하위 클래스 로더가 로딩한 클래스는 상위 클래스 로더가 볼 수 없고  상위 클래스 로더가 로딩한 클래스는 하위 클래스 로더가 볼 수 있고유일성 속성  클래스는 오로지 “한 번” 만 로드한다.유일성 식별 기준은 위의 utf8 에서 java.lang.String 같은 클래스 명을 일컫는다.Unload 불가  클래스로더는 클래스를 로딩은 가능  클래스로더는 클래스를 언로딩은 불가이는 클래스 로더가 로드한 클래스는 보통 GC 의 수거대상이 되지 않기 때문이며, 대신 User-defined ClassLoader 는 클래스를 동적으로 로드하고 언로드 할 수 있다.Linking로딩 다음 거치는 링킹은 3단계에 걸쳐 진행된다.      Verify: 바이트코드가 JVM 규칙 위반하는지 안하는지가장 시간이 많이 걸리고 복잡하다.        Prepare: 클래스가 필요로 하는 메모리를 할당한다.이때 static variable은 defualt 값으로 설정(static variable 을 true 로 설정해도 default 로 설정됨)        Resolve: 심볼릭 참조 를 실제 참조로 변환  Initialize  static 변수에 값 할당  static 블록 실행  최초 클래스가 사용될 때 한 번만 실행됨  이 과정을 보면 알겠지만, static 이 여기서 올라감을 볼 수 있다.✒️ 용어Hotspot JVMJVM은 추상화된 개념이지 실제 있는건 아니다. 이 구현체가 바로 Hotspot JVM 이며, JVM 구현체 중 하나이다. 위 그림도 이 Hotspot JVM에서 나온 것이다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 4일차 자바 문법(3)",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/20/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-4%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-20",
      "content": "📂 목차  For 문 label  Collection          Collection 구현체 생성자 규칙        Stream API          BaseStream      Stream                  생성 관련 메서드          Functional Interface          Collectors          Intermediate Operation          Terminal Operation                    Java Stream 종류        기타 얻어갈 것들          Deep Copy &amp; Shallow Copy      다른 복사 유틸리티 함수      모든 함수는 IDE 에서 Ctrl + 클릭 이나 CMD + 좌클릭 으로 소스코드를 직접 볼 수 있기에 모든 함수의 동작 세부 사항은 생략하고 어떨때, 언제, 왜, 어디서 중요하고 쓰이는지를 설명하고 이론적인 내용을 본다.📚 본문배울 수 있는 내용만 적는 것이 도움이 될거 같아서 얻어갈 수 있는 것들을 요약 정리한다.나머지의 내용들은 타 블로그나 타 수강생들이 매우 많이 적기에 굳이 따로 적지 않고제공해준 책이나 영상으로도 충분히 독학이 가능하다.For 문 labelfor 문 안에는 continue 예약어를 써넣을 수 있다.중첩 for 문에 대해 continue 를 하게 되면 해당 scope 내에서만그 다음 iteration 으로 진행하게 된다.하지만 그 밖의 for 문에게로 가고 싶을때 해당 label 을 쓰게 된다.label 은 break 나 continue 와 함께 쓸 수 있고,반복문 바로 위에 label 을 붙여 해당 반복문으로 이동할 것이다 라는의미를 가지게 된다.continue 예시outer:for (int i = 0; i &lt; 3; i++) {    for (int j = 0; j &lt; 3; j++) {        if (j == 1) {            continue outer; // outer 반복문의 다음 iteration으로 이동        }        System.out.println(i + \", \" + j);    }}break 예시outer: // 라벨 이름for (int i = 0; i &lt; 3; i++) {    for (int j = 0; j &lt; 3; j++) {        if (i + j == 3) {            break outer; // outer 라벨이 붙은 반복문을 종료        }        System.out.println(i + \", \" + j);    }}Collection여러 객체(element)를 그룹화한 인터페이스 형태의 자료구조이다.가지는 element 의 규칙에는 두 특징을 가진다:  중복 요소를 허용하거나 안허용하거나  순서가 정의되거나 안되거나  정의된 컬렉션은 SequencedCollection 인터페이스의 하위 타입JDK는 이런 Collection 인터페이스를 직접 구현한 객체는 제공하지 않고,대신 Set, List 같은 구체적인 하위 인터페이스를 구현한 클래스를 제공한다.  Bag 이나 Multiset 은 이 인터페이스를 직접 구현하는 것이 좋다.Collection 구현체 생성자 규칙우선 표준 생성자 규칙을 먼저 보자.표준 생성자 규칙  인수가 없는 생성자(void constructor)          빈 컬렉션을 생성 ex) ArrayList list = new ArrayList&lt;&gt;();        단일 컬렉션 인자를 받는 생성자          인자로 전달된 컬렉션과 동일한 요소를 가진 새 컬렉션 생성 ex) ArrayList list2 = new ArrayList&lt;&gt;(list1);      어떤 컬렉션이든 복사를 하여 원하는 구현 타입으로 새 컬렉션을 만들 수 있다.  인터페이스 자체는 생성자를 가질 수 없기 때문에 이는 구현체에서 해주어야 한다.Optional Method컬렉션이 반드시 구현해야 하는 메서드는 아니고,필요에 따라 구현할 수 있는 메서드의 의미이다.만약, 특정 method 를 지원하지 않는 경우에는 해당 메서드를UnsupportedOperationException 가 발생시키도록 정의해야 하며,컬렉션 인터페이스의 메서드 명세에서 “optional operation”으로 표시된다.Element Constraints일부 구현체는 컬렉션에 들어갈 요소를 제한할 수 있다.  null 금지  특정 타입만 허용제약 위반 시에는 NullPointerException 혹은 ClassCastException과 같은 unchecked 예외가 발생한다.또한 제한 위반을 해도 조회 시에 단순히 false 를 반환하는 것도 가능하다.Synchronization컬렉션 자체 동기화 여부는 구현체가 결정한다.멀티 스레드 환경에서 다른 스레드가 컬렉션을 수정 중일 때,안전하지 않으면 정의되지 않은 동작이라는 예외(ConcurrentModificationException)발생이 된다.이런 제약의 적용 범위는 다음과 같다:  직접 메서드 호출:ex) 한 스레드가 list.add(x) 를 하는 중에 다른 스레드가 동시에 list.get(0) 을 실행  Collection을 다른 메서드에 전달:전달받은 메서드 안에서 또 다른 스레드가 수정하면 위험함  기존 Iterator 로 탐색:for (Objevt o : list) { // 탐색    list.remove(0);    // 탐색 동시에 수정 -&gt; ConcurrentModificationException}대부분의 컬렉션 반복자(iterator)는 fail-fast 특성을 가지고 있어,컬렉션이 구조적으로 수정되면 즉시 ConcurrentModificationException을 발생시킨다.이는 컬렉션이 예상치 못한 상태에서 변경되는 것을 방지하기 위한 메커니즘이다.  fail-fast는 컬렉션을 반복(iterate)하는 도중,컬렉션이 구조적으로 수정(add, remove 등 요소 개수가 변하는 변경)되면,즉시 예외(ConcurrentModificationException)를 던져서잘못된 상태에서 계속 실행되는 걸 막는 메커니즘따라서 이런 Thread-safety 가 필요할 때,Collections.synchronizedList() 등의 명시적 동기화가 필요하다.해결 방법  Collections.synchronizedXXXXXX():Collections.synchronizedList(new ArrayList&lt;&gt;()) &lt;- 내부적으로 모든 메서드에synchronized 블록 을 씌움, 단 반복문, 반복자 사용 시 외부에서 explicitly 하게 동기화 필요List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;());synchronized (list) {    for (String s : list) {        // Thread-safety    }}  java.util.concurrent 사용          ConcurrentHashMap - 동시 접근 안전      CopyOnWriteArrayList      …      Stream APIStream은 데이터 흐름을 다루기 위한 API 이며, Collection, Array, I/O 자원 등 다양한 데이터 소스로부터 시퀀스 데이터를 처리하게된다.  SQL 의 선언형 처리 방식 처럼, 데이터에 무엇을 할지 집중 가능  반복문을 직접 돌리는 대신 filter, map, reduce 등을 활용파이프-필터 패턴과 비슷하다고 보면 된다. 다음 특징을 가진다:  데이터 불변성: 원본 데이터는 변경 안됨  일회성: 한 번 소비하면 재서용이 불가하다 즉, 스트림 재생성 필요  내부 반복: 개발자가 아닌 Stream 이 내부에서 처리  lazy evaluation: 중간 연산(map, filter 등등)은 즉시 실행되지 않으며, 최종 연산(sum, collect, 집계 연산)등이 호출될 때 실행된다.  병렬 지원: .parallelStream() 으로 멀티코어 활용 가능BaseStreamInterface BaseStream&lt;T, S extends BaseStream&lt;T, S&gt;&gt;으로 선언되며, T는 스트림 요소 유형, S는 스트림 구현 유형이다.메서드  void close(): 스트림을 닫는 메서드다. 모든 handlers 를 닫게 된다.  boolean isParallel()  Iterator&lt;T&gt; iterator(): 이 스트림의 요소에 대한 iterator 를 반환  S parallel(): 병렬인 유형이 동등한 스트림을 반환  S sequential(): 순차적인 자료구조의 동등한 스트림을 반환  Spliterator&lt;T&gt; spliterator(): 스트림 요소에 대한 분할기 반환  S unorder(): 순서가 없는 동등한 스트림 반환여기서 parallel, sequential, unorder 을 먼저 보자.StreamStream 은 BaseStream 을 확장하는 인터페이스이다.깊은 이해는 했으니 활용만 잘하면 된다. 주요 메서드들을 보자.생성 관련 메서드  Arrays.stream(array): 배열을 Stream 으로 변환  Stream.of(): 가변인자들을 받아 Stream 을 생성Functional Interface@FunctionalInterface: 추상 메서드를 딱 하나만 가지는 인터페이스이며, 함수형 인터페이스의 규칙을 보장해준다.@FunctionalInterfaceinterface MyFunction {    void run(); // 추상 메서드 1개    // default 메서드 여러 개 있어도 됨    default void print() {        System.out.println(\"default method\");    }}public class Main {    public static void main(String[] args) {        // 람다로 구현        MyFunction f = () -&gt; System.out.println(\"Hello Lambda!\");        f.run(); // 실행    }}위 예제는 FunctionalInterface 를 이용하는 거고, 이 애너테이션인 Predicate 를 설명하기 위해 가져왔다. 함수를 구현할 때 추상 메서드를 넣어야 하며, 위는 run() 이라는 함수를 실행하기 위해 main 스코프에서 정의하는 것을 볼 수 있다.이 이후에 나오는 것들은 전부 Functional Interface 이다.Predicate여기서 Interface Predicate&lt;T&gt; 라는 것은 함수형 인터페이스이기 때문에 람다 표현식이나 메서드 참조에 대한 할당 대상으로 사용해도 된다.Predicate 인터페이스는 negate, and, or 등의 메서드를 통해서 다른 Predicate 와 and, or 의 논리 연산을 수행하거나, negate 를 통한 단일 논리 연산도 수행가능하다.이렇게 만들어진 Predicate 가 함수의 인자로 들어가게 되면 내부적으로 Predicate 마다 @FunctionalInterface의 구현 규칙에 따라 추상 메서드가 정의된 test 함수를 사용하여 맞는지, 틀린지를 보게 된다.FunctionInterface Function&lt;T,R&gt; 도 인터페이스이다. T는 들어가는 인자, R은 return 타입이 뭔지를 말한다.이 또한 @FunctionalInterface 이므로 R apply(T t) 라는 추상 메서드 하나를 받아야 한다.andThen(Function&lt;? super R, ? extends V&gt; after) 는 순차 실행을 하는 것이고 this 함수를 먼저 실행 후에 실행된 결과를 after 함수에 전달하게 된다. 반환되는 값도 &lt;V&gt; Function&lt;T,V&gt; 이다.  f.andThen(g) = g(f(x))compose(Function&lt;? super V, ? extends T&gt; before)는 before 함수를 먼저 실행하고 그 결과를 this 함수에 전달하게 된다. 반환되는 값도 &lt;V&gt; Function&lt;T,V&gt; 이다.  f.compose(g) = f(g(x))당연하겠지만 andThen에 들어가는 인자는 this의 들어가는 T 를 신경쓰지 않는 것을 볼 수 있다. 또한 compose 에는 인자로 들어가는 함수가 더 먼저 실행되기 때문에 이를 반환하기 위한 T 라는 인자가 안에 들어가는 것을 볼 수 있다.  ? 는 와일드카드로 어떤 타입인지 모르지만 제너릭타입을 넣을 자리를 채워야 할 때 쓰는 기호이다. 제한 없는 와일드 카드로 모든 타입이 올 수 있다는 것이다.매번 저렇게 Comparator, Function 을 구현하려면 시간 낭비이다. 이를 간소화하기 위해 anonymous function 인 lambda 를 사용하게 된다.BiFunction매번 인자를 하나만 받게 되기 보다는 두 개 받을 수 있는 BiFucntion 의 인터페이스까지 있다. 이는 위와 비슷하므로 넘어간다.Consumer단일 인수를 받고 결과를 반환하지 않는 함수형 인터페이스이다.그냥 void 와 같다.SupplierSupplier&lt;T&gt;간단하기에 설명은 생략한다. 공식 문서를 보자. get() 을 통해 특정 함수를 실행하여 그 결과를 get() 을 호출할 때 실행하여 반환한다.CollectorsInterface Collector&lt;T,A,R&gt;  T: 축소작업을 위한 입력 유형  A: 축소작업을 위한 가변적 누적 유형  R: 축소작업의 결과 유형Collector 는 입력 요소를 변경 가능한 결과 컨테이너에 누적하는 변경 가능한 축소 연산을 지원한다.연산이 끝난 놈들을 최종 변환하는 애라고 보면된다. 여기서 집계를 하는 함수나 형태를 변환하는 것도 될 수 있다.이제 그 연산들을 보자:주요 4가지 연산  새로운 결과 컨테이너 생성(supplier())  결과 컨테이너에 새 데이터 요소 통합(accumulator())  두 개의 결과 컨테이너를 하나로 결합(combiner())  컨테이너에 선택적 최종 변환 수행(finisher())위 4개를 토대로 언어를 다루기 쉽게 다음 메서드도 추가된다.  joining()  mapping() / flatMapping()  filtering()  counting()  minBy() / maxBy()  summingXXX() / averagingXXX()  reducing()  groupingBy() / groupingByConcurrent() / partitioningBy()  toList() / toMap() / toSet()  toUnmodifiableXXX(): List, Map, Set 등등위를 쉽게 다루는 것은 문제를 풀면서 다루면 되지만,그 핵심을 찌르는 위 4가지 연산을 더 보자.record CollectorImpl&lt;T, A, R&gt;(    Supplier&lt;A&gt; supplier,    BiConsumer&lt;A, T&gt; accumulator,    BinaryOperator&lt;A&gt; combiner,    Function&lt;A, R&gt; finisher,    Set&lt;Characteristics&gt; characteristics) implements Collector&lt;T, A, R&gt; {      supplier(): 이전에 봤던 함수를 통해 그 함수의 결과를 제공해주는 아이이다. 이는 result container 와 같은 생성하는 함수를 가지고 있고, 이를 토대로 여기에 하나하나 값들이 관리되게 된다.        accumulator(): 핵심적인 역할을 하며, 함수형 인터페이스로 두 개의 인자를 받아서 연산 수행 후 누적 컨테이너에 해당 요소를 통합하는 역할을 한다. 즉, supplier 에 accumulator.accept 의 정의된 메서드 대로의 처리 연산을 하여 차곡차곡 넣게 된다.그렇게 돠면 A 라는 컨테이너에 T 라는 유형의 데이터들이 차곡차곡 들어가게 것과 같다.        combiner(): 여러 개의 Publisher 에 대해 발생하는 이벤트를 결합하여 새로운 퍼블리셔를 생성하는 데 사용된다. 즉, 복잡한 비동기 이벤트 흐름을 관리하고 여러 데이터 소스를 하나의 흐름으로 통합하기 위해 존재한다.예시로 A라는 퍼블리셔와 B라는 퍼블리셔가 있다고 치자. 해당 A 와 B 는 어떤 이벤트를 통해 값을 생성해내서 우리에게 제공해준다고 치자. 그럼 이 제공하는 이벤트의 두 진행 상황이 항상 일정하지는 않고 A의 부산물이 없을 때, B 의 부산물이 있을 때도 있고, A 의 부산물이 있을 때, B 의 부산물이 없을 때가 있을 것이다.이때 퍼블리셔에서 새로운 값들을 방출할 때 다른 퍼블리셔의 값이 없게 된다면 이는 데이터 처리 과정에서 제대로 원하는 값이 처리가 안된 것이다. 따라서 이 비동기 흐름을 관리하기 위한 함수형 인터페이스이다.  좀 어려울 수 있지만 정리하면 다음과 같다:  combiner() 는 여러 Publisher 를 결합하여 새로운 Publisher 를 생성하는 연산자  이를 통해 복잡한 비동기 이벤트 흐름을 관리하고, 여러 데이터 소스를 하나의 흐름으로 통합 가능  CombineLatest 와 같은 연산자를 사용하여 여러 Publisher 의 값을 결합 가능  두 Publisher 중 하나가 값을 방출하지 않으면, 결합된 값을 방출하지 않으므로 다른 연산자를 고려할 수도 있음  zip, sink 등이 그 예이다.  finisher(): 수집된 결과에 적용할 추가적인 변환 함수로, 수집된 데이터를 원하는 형태로 가공하는 데 사용된다.  collect 가 그 예  이 모든 것들을 배우는 이유는 일급 함수를 이용한 Lazy Evaluation 과 Parallelism &amp; Concurrency 최적화, Immutability 를 통한 사이드 이펙트를 줄이며, Modularity 가 좋아진다.Intermediate Operation결과가 또 다른 Stream 을 반환하는즉, Chain 형태로 이어질 수 있는 연산  filter(Predicate): Predicate 에 맞는 요소 걸러냄  map(Function): 변환 (String -&gt; Integer)  flatMap(Function): 중첩 스트림을 평탄화함  sorted() / sorted(Comparator): 정렬  distinct(): 중복 제거  limit(n): 앞에서 n개만 가져옴  skip(n): 앞에서 n개를 건너뜀Terminal Operation결과를 값이나 컬렉션으로 반환하여,Stream 을 소비해 종료하는 연산  forEach()  sum(), max(), count(), min(), average()  collect(): 리스트/맵 등으로 변환  reduce(): 누적 연산Java Stream 종류  Object Stream타입: Stream&lt;T&gt;, Object 타입을 다룸예시로 Stream&lt;String&gt;, Stream&lt;Person&gt; 등이 있음  Primitive Stream기본형에 대한 Stream 이다.  IntStream  LongStream  DoubleStream특히 각 기본형 스트림은 summaryStatistics() 를 제공하여합계, 평균, 최댓값, 최솟값, 개수를 한 번에 구할 수 있다.int[] arr = {95, 87, 66, 73, 82};IntSummaryStatistics stats = Arrays.stream(arr).summaryStatistics();System.out.println(stats.getSum());   // 합계System.out.println(stats.getAverage()); // 평균System.out.println(stats.getMax());   // 최댓값System.out.println(stats.getMin());   // 최솟값System.out.println(stats.getCount()); // 개수기타 얻어갈 것들Deep Copy &amp; Shallow Copy얕은 복사는 객체 복사에서 객체 자체를 새로 만들긴 하지만 안의 참조 타입 필드들은 원본 객체와 동일한 참조를 공유하게 된다.즉, 객체 구조는 새로 만들어내도, 내부의 다른 객체들은 공유가 된다. 완벽하게 copy는 되지 않고 일차원적으로 복사가 된 것이다.깊은 복사는 객체를 복사할 때 객체 뿐 아니라 객체 내부의 참조 객체들 까지도 전부 새로 생성하여 복사가 된다.즉, 원본과 복사본이 완전히 독립적이게 된다.다른 복사 유틸리티 함수private static void copy_() {    int[] arr = {1, 2, 3, 4, 5};    int[] arr1 = new int[10];    System.arraycopy(arr, 0,arr1, 2, 3);    System.out.println(Arrays.toString(arr1));    arr1 = Arrays.copyOf(arr, 3);    System.out.println(Arrays.toString(arr1));    // 4 전까지 copy    arr1 = Arrays.copyOfRange(arr, 2, 4);    System.out.println(Arrays.toString(arr1));}"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 3일차 Java 문법(1)",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/19/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-3%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-19",
      "content": "📂 목차  Java 변수          정수 리터럴      기타 리터럴        Java 변수 유형          데이터 타입에 따른 분류      범위에 따른 분류                  Local Variable          Field          Parameter                    final 키워드        Java 변수 할당 방식          Constant Pool        Java 형 변환          Implicit Type Casting      Explicit Type Casting      Arithmetic Promotion        Java 공식 문서 파헤치기          Number      String      System      Runtime      Process      Object        Wrapper Variables          Auto Boxing      📚 본문Java = 강형 언어이며, 변수에 항상 데이터의 형태가 뭔지 알려줘야 변수 선언이 가능한타입에 엄격한 언어라는 말이다.Java 변수변수는 데이터를 쓸 수 있는 영역을 마련해주는 공간, 쓸 변수마다 그 공간이 달라진다.변수를 선언할 때 대입연산자(=)과 literal 을 통해 변수에 값을 할당해줄 수 있다.  literal: 데이터 그 자체, 실제 값// 10 은 리터럴 특히 정수형 리터럴이라고 함int a = 10;정수 리터럴  10진수: int x = 10  8진수: int y = 010  16진수: int z = 0xA  2진수: int b = 0b1010  10진수 리터럴은 _를 사용하여 숫자를 쉽게 보게 할 수 있다.기타 리터럴  long 리터럴: int a = 10000000000000L  실수 리터럴          3.193      10f      3.29F      3d - d 혹은 D 생략 가능      1.2e3 - 지수 표기법        논리 리터럴: true, false  null 리터럴: null  문자 리터럴:          ‘A’      ‘\\n’ - 이스케이프 문자(\\t, \", ', \\, \\r 등등)      ‘\\u0041’      “String”        char 은 한 문자를 의미, 여기는 숫자(유니코드 내의 숫자) 와 홑따옴표로 한 개의 문자가 들어가도록 리터럴을 넣어줄 수 있음Java 변수 유형자바 변수는 선언하는, 내용의 특징에 따라 혹은 선언하는 위치에 따라 수식어가 붙는다.데이터 타입에 따른 분류  기본형(Primitive): 실제 값 자체를 저장하며 byte, short, int, long, float, double, char, boolean 8가지가 있다.          Stack 이라는 메모리 영역에 저장        참조형(Reference): 그 이외에          Heap 이라는 영역에 저장      범위에 따른 분류클래스 범위와 함수 범위와 변수 할당의 차이public class Exam {    int intValue;    public static void main(String[] args) {        // 초기화하지 않으면 사용이 불가함        // 직접 리터럴을 대입해줘야 함        int intValue_;    }}  intValue: 클래스 변수, 필드 변수, 멤버 변수라고 하며 기본적으로 값이 초기화(0으로)된다.  intValue_: 지역 변수라고 하며 메서드 내에서 자동으로 초기화가 되지 않고, 초기화를 해줘야 한다.이를 더 자세히 보자.Local Variable메서드/생성자/블록 안에서 선언하는 변수이다.Field클래스 범위(스코프) 내에서 선언한 변수이다. 보통 클래스 범위의 맨 위에 선언한다.  Instance Variable: 객체가 생성될 때 함께 생성되며, 값이 자동 초기화되는 특징이 있다.  Static Variable: static 키워드로 선언하며, 클래스 로딩시 딱 한 번만 메모리에 올라가고, 모든 객체가 공유를 한다.Parameter메서드 호출 시 전달되는 값이며, 일종의 지역변수이지만 특별히 구분해서 부르게 된다.파라미터에서 선언된 변수명을 로컬 변수로 다시 선언할 수 없다.final 키워드재할당, 재정의 금지라는 뜻 이 이후에는 변수를 바꿀 수 없음final double PI = 3.141592dfinal의 primitive 는 대문자로 쓰는게 관례(Convention)이다. final의 String 도 마찬가지Java 변수 할당 방식위 변수들은 전부 JVM이 메모리에 할당하여 사용할 수 있게 된다.Java 프로그램이 실행되면 JVM은 크게 Heap, Stack, Method Area(=Metaspace) 세 부분을 사용하며, 각 영역마다 다음 특징이 있다.메모리 영역  Heap: new 키워드로 생성된 instance 들이 저장          ⭐️ 모든 스레드가 공유하는 메모리 영역      ⭐️ GC 의 대상이 된다.        Stack: 메서드 호출 시마다 Stack Frame이 생성된다.          지역 변수가 저장되며, 메서드가 끝나면 해당 Stack Frame 삭제        Method Area(Metaspace)          클래스 정보, static 변수, 상수 풀(Constant Pool) 저장      JVM 시작 시 로딩되는 영역이다(static 으로 선언된 변수가 포함됨)      Constant Pool  클래스 상수 풀(Class Constant Pool): 클래스 메타데이터, 상수 값, 필드, 메서드, 참조 등을 저장  문자열 상수 풀(String Constant Pool): 문자열 리터럴을 효율적으로 관리하기 위해 사용하는 특수 저장공간이며, 문자열 리터럴이 생성될 때마다 JVM 은 해당 문자열이 문자열 상수 풀에 존재하는지 확인하고, 존재하지 않으면 추가하여 메모리를 최적화 함Java 형 변환연산자들은 생략하고, 얻어갈 수 있는 형 변환에 대한 것들을 적는다.Implicit Type Casting자동 형변환은 작은 타입에서 큰 타입으로 변환이 필요할 때 컴파일러가 자동으로 해주는 것을 의미한다.  작은 타입 → 큰 타입 가능  정수형 → 실수형 가능  하지만 이때 long → float 의 경우에는 변환 시에 값 손실을 감안하고 형변환을 진행한다(소수점으로 표현하고 지수자리로 표현됨에 따라 2진법을 사용하는 컴퓨터는 손실이 됨).Explicit Type Casting큰 타입 → 작은 타입 으로 변환할 때 사용하며, 손실을 감안하고 변환한다.long l1 = 12345678910L;int i1 = (int) l1;System.out.println(i1);// 출력: -539222978Arithmetic Promotion숫자들을 다룰 때, byte, short, char 등으로 표현했다고 치자. 그러고 두 수를 더하고 싶을 때 일반적으로 덧셈 연산을 통해 수행을 한다. 하지만 여기서 short + short 는 short 로 나와버리면 short 로는 표현할 수 없는 값이 생기고, 이는 음수로 바뀔 것이다.이를 방지하고 값의 신뢰성을 높이기 위해 덧셈이나 곱셈 등과 같이 크기가 늘어나는 연산에 대해 산술 승격이 자동으로 이루어지게 된다.  byte, short, char는 연산 시 자동으로 int로 승격 → int  연산 중 더 큰 타입과 만나면 큰 타입으로 승격Java 공식 문서 파헤치기자주 사용되는 클래스들은 전부 java.lang 에 포함되어 있으며,import를 쓰지 않아도 java.lang의 모듈에 있는 기능들은전부 컴파일러가 알아서 추가해준다.자동 추가 클래스 목록  String  Math  Number  Object  System  …  여기서 주의할 점은 java.lang 에 있는 클래스들만이지, java.lang.reflect 와 같은 패키지는 자동 import 가 되지 않는다.더 많은 내용은 공식 문서를 참고하자.NumberNumber 추상 클래스는 byte, double, float, int, long 타입의 수퍼 클래스이다.주로 숫자 데이터를 다룰 수 있게하고, 정의한다.메서드  (primitive)Value(): Number 를 통해 위 primitive 타입 들로 변환할 수 있다.StringString 은 immutable 타입이고, reference 형태인 특이한 데이터타입이다.즉, 한 번 생성되면 변하지 않고 변하지 않으면 안전하게 공유를 할 수 있다는 뜻이 된다(이전의 String Constant Pool 참고).Field  static Comparator&lt;String&gt; CASE_INSENSITIVE_ORDER: 문자열을 정렬할 때에 대소문자를 구분하지 않고 정렬을 하고 싶을때 사용한다.  보통 Collections.sort, List.sort 등에 넘겨서 많이 쓰이며, 정렬을 하는 행위에서 두 값을 비교할 때 어떤 정책을 따라, 어떤 규칙을 따라 비교할지에 Comparator 를 넣어준다.함수들은 너무 많기에 코드 문제를 풀면서 익히는 것이 좋을 듯하다.System멤버 변수  err: 표준 에러 출력 스트림  in: 표준 입력 스트림  out: 표준 출력 스트림여기서 스트림이란 데이터를 문자나 바이트 형태로 전달하는 통로를 의미하며,  출력스트림: 데이터를 바이트 단위로 외부로 내보낼 수 있는 스트림  입력스트림: 데이터를 바이트 단위로 읽어오는 최상위 추상 클래스RuntimeJVM 환경을 나타내는 클래스이며 운영체제와 JVM 사이의 직접적인 시스템 작업을 수행할 수 있게 해주는 클래스이다.가장 핵심 클래스이며, Singleton 패턴으로 다른 클래스들에게 제공된다. 기본적으로 Runtime.getRuntime() 으로 접근하면 된다.주요 메서드  exec(String command): 지정된 환경과 작업 디렉토리에서 별도의 프로세스로 지정된 문자열 명령을 실행(ex. notepad, ls 등등)Deprecated 되어서 이젠 쓰이지 않고 ProcessBuilder 를 통해 Process 를 만들어 사용하게 된다.  gc(): 가비지 컬렉션 요청  totalMemory() / freeMemory(): JVM 이 가용한 메모리 상태 확인  exit(int status): JVM status code 의 상태로 종료  addShutdownHook(Thread hook): JVM 종료 시 실행할 코드 등록(이런걸 훅이라고 한다)  훅: 특정 이벤트나 시점에서 사용자가 원하는 코드를 끼워 넣을 수 있는 지점Process위 Runtime 으로 exec 을 할 수 있지만, 이는 들어갈 수 있는 인자의 제어를 효과적으로 못하여 Process 라는 실행 가능한 클래스를 통해 실행하게 된다.ProcessBuilder pb = new ProcessBuilder(\"echo\", \"Hello\");Process process = pb.start();  // 프로세스 실행위 코드 처럼 ProcessBuilder 는 네이티브 프로세스(운영체제의 개념)를 Builder 패턴으로 어떤 프로세스를 만들지 정의를 해주고 프로세스를 만들 수 있다(재사용성 증가).이를 Runtime 에게 주어서 exec()으로 실행하게 된다.주요 메서드  InputStream getInputStream(): 프로세스가 표준 출력에 쓴 데이터 읽기  InputStream getErrorStream(): 프로세스가 표준 에러에 쓴 데이터 읽기  OutputStream getOutputStream(): 프로세스가 표준 입력에 쓰기  void destroy(): 하위 프로세스 종료  getRuntime(): 현재 Java Application 과 연결된 런타임 객체 반환  …Object모든 클래스가 상속받는 최상위 클래스이다.보통 오버라이드하여 객체 동작을 커스터마이징한다.메서드  toString(): 객체를 문자로 표현하는 법 정의  equals(Object obj): 객체 비교 방법 정의  hashCode(): 객체 해시코드 반환  getClass(): 객체의 Runtime 클래스 정보 반환  clone(): 객체 복제 방법 정의(깊은/얕은 복사 가능)  finalize(): GC가 객체를 수거하기 전에 호출  wait(), notify(), notifyAll(): 스레드 동기화에 사용Object에 스레드 관련 메서드가 있는 이유는,자바에서 모든 객체를 Monitor로 사용할 수 있기 때문이다.synchronized 키워드를 사용하면 객체 단위로 Monitor Lock이 걸리며,synchronized는 이 추상적 클래스 모니터의 구현체인 동기화 Monitor를 기준으로 이루어진다.모니터란 한 번에 하나의 Thread만이모니터 내의 임계 구역(critical section)에 들어올 수 있도록 보장하는 장치이다.따라서 공유 자원에 대한 접근은 반드시 Monitor Lock을 획득한 스레드만 가능하다.즉, 객체가 모니터 락을 얻어서 동기화된 코드 블록(또는 메서드)을 실행할 수 있게 되는 것이synchronized (모니터 락을 획득할 대상) 구문이다.보통 this 자체가 모니터 락 대상이 되는 경우가 많지만,별도의 Object 멤버 변수를 선언해서 락으로 쓰기도 한다.또는 메서드에 synchronized를 직접 선언할 수도 있다.class Counter {    private static int count = 0;    public static synchronized void increment() {        count++;        // 이 시점에 Counter.class 모니터 락을 보유 중이므로        // wait() / notify() 호출 가능    }}이는 운영체제에서 더 다루겠다. 또한 더 많은 기능들과 기본적인 자바 문법들은 전부 타 블로그에 정보가 매우 많기에 생략한다.Wrapper Variables자바의 기본형 타입을 객체로 다룰 수 있게 해주는 클래스이며 reference 타입으로 감싸는 역할을 한다.  Integer, Short, Byte, Boolean, Float, Double …다음 이점을 위해 사용한다:  객체만 다룰 수 있는 API 사용          Collection 은 기본형을 직접 담을 수 없기 때문에 다양한 유틸 기능을 가지는 Collection 을 사용하기 위해 형변환을 수행한다.        편리한 형 변환 유틸 기능을 public static 함수로 제공          Integer.parseInt(), Double.toString 등 편리한 기능 제공        nullable          아무 값도 존재하지 않는 그런 값을 표현할 수 있다.      Auto BoxingJava 5 이후에 오토 박싱이라는 것으로 primitive 변수를 Integer 선언한 변수에 담을 때 자동으로 컴파일러가 형변환을 시행하여 들어가게 되는게 Auto Boxing 이다.int n = 10;// BoxingInteger obj1 = Integer.valueOf(n);// Unboxingint m = obj1.intValue();// 오토 박싱 &amp; 언박싱Integer obj2 = n;     // int → Integer (자동 박싱)int k = obj2;         // Integer → int (자동 언박싱)"
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 2일차 Java 개발 환경 세팅",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/java/2025/08/18/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-2%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-18",
      "content": "📂 목차  Java 준비          Java 버전별 주요 기능 정리                  JDK 8          JDK 11          JDK 17          JDK 21                    Java 환경변수 설정      Java 컴파일 및 실행하기        문서화를 위한 Java Docs          Java Docs Tag      Class 주석 달기      Method 주석 달기      Marker 사용하기      📚 본문자바는 다음 특징을 가진다  플랫폼 독립성: “Write Once, Run Anywhere” - 한 번 작성하면 어디서든 실행  객체지향 프로그래밍: 코드 재사용성과 유지보수성이 뛰어남  자동 메모리 관리: 가비지 컬렉션으로 메모리 누수 방지  모던 자바: 최신 버전에서 다른 언어의 장점을 흡수  람다 표현식: 함수형 프로그래밍 지원 (Java 8+)  Stream API: 데이터 처리를 선언적으로 작성 가능  병렬 프로그래밍: 멀티코어 CPU 효율적 활용  멀티 스레딩 지원  JIT 컴파일러등등의 장점들을 이용할 수 있다.Java 준비자바를 설치하기 위해 JVM, JRE, JDK 를 먼저 살펴보자.  JVM: Java Virtual Machine 이며, 실제로 자바 프로그램이 실행되는 환경이다. 자바 바이트 코드(.class) 를 해석해서 운영체제에 맞게 실행하는 곳이다.  JRE: Java Runtime Environment 의 약자이고, JVM + 자바 표준 라이브러리(거의 필수적인 기능들을 담는 모듈)를 담고 있고, 자바 프로그램을 실행할 수 있다.  JDK: Java Development Kit 이라고 불리고, JRE + 개발도구 이다. 개발 도구라고 함은 javac, jdb, javadoc 등 개발에 필요한 다양한 기능들을 넣어놓았다.Java 버전별 주요 기능 정리JDK 8가장 많이 사용되었던 버전, 람다 표현식 도입람다 표현식: 함수형 프로그래밍 스타일 도입을 위해 람다라는 익명 함수 기능 도입기존 방식Runnable run = new Runnable() {    @Override    public void run() {        System.out.println(\"Hello, World!\");    }}run.run();람다 표현식// 두 줄 이상의 코드가 되면 중괄호로Runnable run = () -&gt; System.out.println(\"Hello, World!\");run.run()이를 통해 forEach 문의 가독성이 상승하고 함수형 프로그래밍이 가능해짐.JDK 11모듈 시스템 안정화, HTTP Client API기존 방식import java.net.URI;import java.net.http.HttpClient;import java.net.http.HttpRequest;import java.net.http.HttpResponse;public class HttpExample {    public static void main(String[] args) throws Exception {        // HttpClient 생성        HttpClient client = HttpClient.newHttpClient();        // GET 요청 builder 패턴으로 생성        HttpRequest request = HttpRequest.newBuilder()                .uri(new URI(\"https://jsonplaceholder.typicode.com/posts/1\"))                .GET()                .build();        // 동기 요청 (send)        HttpResponse&lt;String&gt; response = client.send(request, HttpResponse.BodyHandlers.ofString());        // 결과 출력        System.out.println(\"Status code: \" + response.statusCode());        System.out.println(\"Body: \" + response.body());    }}비동기 요청// 불변 객체 request 를 보내는 주체 HttpClient 인스턴스를 생성함HttpClient client = HttpClient.newHttpClient();// \"https://jsonplaceholder.typicode.com/posts/1\" 에 요청하는 http 방식의 request 생성HttpRequest request = HttpRequest.newBuilder()        // 인터넷 자원 URI 생성        .uri(URI.create(\"https://jsonplaceholder.typicode.com/posts/1\"))        // 인스턴스 생성        .build();// 요청을 전송하는 client 가 Async(비동기) 방식으로 요청을 보냄, 응답바디를 String 으로 읽음client.sendAsync(request, HttpResponse.BodyHandlers.ofString())        // 앞단계가 완료되면 HttpResponse::body() 메서드 호출        .thenApply(HttpResponse::body)        // 앞단계가 완료되면 body를 받아서 표준 출력에 찍음        .thenAccept(System.out::println)        // 스레드를 join시키고 블록해서 위 명령이 끝날 때까지 기다림        .join();  HttpClient 는 불변 객체로 재사용이 되며, 동기와 비동기 전부 지원이 가능해졌고, HTTP/2 지원 및 요청과 응답을 BodyHandler 로 처리가 가능(String, File, InputStream)해졌다JDK 17패턴 매칭, 텍스트 블록, 레코드 클래스기존 방식public class Person {    private final String name;    private final int age;    public Person(String name, int age) {        this.name = name;        this.age = age;    }    public String name() { return name; }    public int age() { return age; }    @Override    public String toString() {        return \"Person[name=\" + name + \", age=\" + age + \"]\";    }    @Override    public boolean equals(Object o) { ... }    @Override    public int hashCode() { ... }}레코드 클래스public record Person(String name, int age) {}불변의 특징을 지니고 있고, 위와 동일한 코드를 제공한다. 자주 사용하는데 핵심 로직과는 관련이 없고 코드가 긴 보일러플레이트 코드들을 간략히 할 수 있다. 보통 record는 DTO를 만들 때 쓰인다.JDK 21가상 스레드, 패턴 매칭 강화Java 환경변수 설정자바를 설치하고 간혹 실행이 안되는 경우가 있을 수 있는데 Window와 Mac 은 다음 환경 변수가 세팅이 되어있는지 확인해야 한다.Windows:: JAVA_HOME 확인echo %JAVA_HOME%:: Path에 JAVA_HOME/bin 포함 여부 확인echo %PATH%Mac / Linux# JAVA_HOME 확인echo $JAVA_HOME# Path에 JAVA_HOME/bin 포함 여부 확인echo $PATH두 변수가 제대로 설정되어 있지 않다면, java.exe 가 위치한 폴더를 찾아서 환경변수로 세팅해주자.Windows:: 설치된 JDK 확인 (Program Files 폴더 확인)dir \"C:\\Program Files\\Java\\\":: 또는 64비트 시스템은 Program Files (x86) 도 확인dir \"C:\\Program Files (x86)\\Java\\\"위 명령어를 통해 설치된 JDK 폴더를 확인할 수 있고, 예를 들어 C:\\Program Files\\Java\\(jdk) 이 설치되어 있다면,JAVA_HOME 환경변수를 해당 경로로 설정해주면 된다.:: 환경변수 설정 예시 (명령 프롬프트)setx JAVA_HOME \"C:\\Program Files\\Java\\(jdk)\"setx PATH \"%JAVA_HOME%\\bin;%PATH%\"Mac# 설치된 JDK 확인ls -al /Library/Java/JavaVirtualMachines/위 명령어를 통해 깔려있는 JDK 버전을 확인할 수 있고, /Library/Java/JavaVirtualMachines/(jdk)/Content/Home 을 JAVA_HOME 으로 환경변수 세팅해주면 된다. 세팅해줄때는 ~/.zshrc 혹은 ~/.bashrc 를 편집하면 된다.nano ~/.zshrc# mac os 에서 /usr/libexec/java_home 이라는 JDK 경로를 찾을 수 있도록# 제공되는 실행파일임 -v 를 통해 버전을 입력할 수 있다.export JAVA_HOME=$(/usr/libexec/java_home -v 21)export PATH=$PATH:$JAVA_HOME/binsource ~/.zshrc위 JAVA_HOME 에서는 ls로 검색해서 찾았던 /Library/Java/JavaVirtualMachines/(jdk)/Content/Home 이 절대경로를 직접 입력해주어도 된다.Java 컴파일 및 실행하기Java는 컴파일러와 인터프리터 성격을 모두 가지고 코드를 실행한다.첫 단계에서는 소스코드를 전체 컴파일하여 JVM이 읽을 수 있는 바이트코드(.class 파일)로 변환한다.이후 JVM은 이 바이트코드를 읽어 실행하게 된다.  소스코드 → 바이트코드 → JVM 실행바이트코드 실행 방식에는 두 가지가 있다:  인터프리터 방식: 바이트코드를 한 줄씩 읽어 실행  JIT(Just-In-Time) 컴파일러 방식: 자주 실행되는 코드 블록을 감지하여 기계어로 변환 후 실행JIT 덕분에 순수 인터프리터보다 속도가 훨씬 빠르며, 반복 실행되는 코드의 성능이 크게 향상된다. 이제 이를 수행해보자.# byte 코드 생성javac (컴파일 할 java 파일 이름).javajava (컴파일 할 java 파일 이름)자바는 컴파일 + 인터프리터 방식을 통해 플랫폼에 독립적으로 동작할 수 있게 된다.문서화를 위한 Java Docs자바의 문법은 추후에 다루고 Java 코드를 상대방에게 알려주기 위한 주석을 달 때 어떻게 다는지 살펴본다./** * 여기는 docs 주석 입니다. *//** 로 시작하며 줄바꿈 Enter 를 치면 알아서 자동으로 넣어야할 것들과 설명을 쓸 수 있도록 폼을 IDE에서 만들어준다.만약 안만들어준다면 다음 참고를 보고 작성하면 되겠다. 주석을 달 때는 다음 물음에 답할 수 있어야 한다.  Why, 코드를 왜 그렇게 작성했는지  How, 비즈니스 로직이 복잡하다면 어떻게 동작하는지주석을 다는 것을 보기 전에 태그를 먼저 보자.Java Docs TagJavaDoc 태그는 주석 안에서만 의미가 있는 메타 정보이다. 메타 정보는 정보를 설명하는 정보라고 보면 되겠다.이를 문서 생성 도구(Javadoc)가 읽어서 HTML 문서, PDF, 마크다운 등으로 변환할 때 의미를 지니게 되며문서를 찾을 때 쉽게 찾을 수 있게 된다.JavaDoc에서 자주 사용하는 태그와 용도를 한눈에 정리하고, 코드에서 어떻게 쓰이는지 예시를 포함했다.            태그      용도 / 기능      사용 위치 / 설명                  @author      클래스/인터페이스 작성자 표시      클래스/인터페이스 상단              @version      클래스/인터페이스 버전 정보      클래스/인터페이스 상단              @since      기능이 추가된 Java/API 버전      클래스, 메서드              @see      관련 클래스, 메서드, 문서를 참조      클래스, 메서드              @param      메서드 매개변수 설명      메서드 주석, 매개변수 하나당 작성              @return      메서드 반환값 설명      메서드 주석 (void는 사용 X)              @throws / @exception      메서드에서 발생 가능한 예외 설명      메서드 주석, 예외마다 작성              @deprecated      더 이상 사용되지 않는 기능 표시      클래스, 메서드, 필드              @link      다른 클래스/메서드 하이퍼링크 생성      설명 문장 내              @code      코드 조각 강조      설명 문장 내              @literal      HTML 태그를 그대로 표시      설명 문장 내        클래스/인터페이스: @author, @version, @since, @see, @deprecated  메서드: @param, @return, @throws, @see, @deprecated  문장 내 강조/링크: @link, @code, @literal베스트 프랙티스는 아니지만 클래스, 메서드 등등의 주석에서 다음 폼을 따르면 좋을거 같아서 써보았다.Class 주석 달기클래스를 선언하는 곳 바로 위에 Java docs 주석을 위치시키고 다음 내용을 표현하면 좋다./** * 간단한 클래스/메서드 설명 * * &lt;p&gt;상세 설명을 추가할 수 있음. * 여러 줄로 작성 가능하며, HTML 태그 일부도 사용 가능&lt;/p&gt; * * &lt;pre&gt;예시 코드도 넣을 수 있음. * 여러 줄 작성 가능&lt;/pre&gt; * * @author 작성자 * @version 버전 * @see 관련 클래스/메서드 (ex. String#equals, java.lang.reflect 등등) */Method 주석 달기함수 선언 바로 위에 주석을 달면 되고, 클래스와는 다르게함수는 특히 오류를 내뱉을 수 있으므로 던져지는 오류가 어떤 형태인지도 알려준다.만약 오류가 여러 개면 throws 태그를 여러개 작성한다./** * 한 줄 요약 * * &lt;p&gt;상세 설명 (여러 줄 가능)&lt;/p&gt; * * @param param1 설명 * @param param2 설명 * @return 반환값 설명 * @throws 예외설명 * * &lt;pre&gt; * // 예시 코드 * ClassName obj = new ClassName(); * obj.method(param1, param2); * &lt;/pre&gt; */  필드나 변수에 대한 주석은 한-두 줄로 충분하다.Marker 사용하기주석이 너무 많으면 사람들은 회색 글들중에 특별히 참고해야 할 만한 내용을 놓칠 수 있다.이때 쓰는 것이 Marker 인데, 해당 코드 바로 위 혹은 옆에 한 줄로 작성하여 IDE 에서 색상이나 강조로 다른 주석보다 더 잘보이게 되는 주석이다.다음 마커들이 있다:  TODO: 나중에 해야 할 일, 미완성 기능을 표시하는 용도이다.  FIXME: 버그나 문제가 있는 코드를 표시하게 된다.  XXX: 위험하거나 주의가 필요한 코드이다. 보안상에 문제가 있다면 사용할 수 있다.  HACK: 임시 방편 코드의 의미를 가진다.  NOTE: 참고용 설명이다."
    },
  
    {
      "title": "[멋사 백엔드 19기] TIL 1일차 Git 설정",
      "url": "/seonghun120614/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC/%EB%A9%8B%EC%82%AC/%EB%B0%B1%EC%97%94%EB%93%9C/til/git/2025/08/13/%EB%A9%8B%EC%82%AC-%EB%B0%B1%EC%97%94%EB%93%9C-19%EA%B8%B0-til-1%EC%9D%BC%EC%B0%A8.html",
      "date": "2025-08-13",
      "content": "📂 목차  Git 개요          Git 설치      Git 초기 설정      Git 기본 워크플로우      Git Repository 생성                  로컬 디렉토리를 Git 저장소로 하기          Git 저장소를 Clone                    파일의 다양한 상태      git diff 를 통한 변경 내용 확인      git log      파일 되돌리기                  git commit –amend          파일 Unstaged 로 바꾸기          Modified 파일을 되돌리기          git revert                    Remote 저장소        Git Branch          Git Main                  Git HEAD                    git push &amp; pull                  Personal Access Token                    조퇴를 하여 따로 독학하여 글을 쓴다.참고: Git 공식 홈 메뉴얼Git 개요분산 버전 관리 시스템이며, 리누스 토발즈가 만들었고, 리눅스 커널(운영체제의 핵심)을 개발하기 위해서 수천 명의 개발자들의 소스코드 공유와 협력을 위해 코드를 효율적으로 관리하기 위해 만들어졌다.이전에 BitKeeper 분산 버전 관리 시스템을 사용해 왔던 리눅스 커널팀은 무료로 사용해왔지만, 개발사 측과 틀어져 BitKeeper를 무료로 사용할 수 없게 되어 팀 내에서 Git 이라는 분산 버전 관리 시스템을 직접 만들어 사용하게 되었다.Git 설치Linux Fedora 계열sudo dnf install git-allLinux Debian 계열sudo apt install git-allMacOS# homebrew 설치/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"# homebrew 를 통한 Git 설치brew install gitWindow웹사이트 검색 후 설치Git 초기 설정Git 설치가 끝났다면 초기 설정이 필요하다.git config 명령어를 통해 설정을 만질 수 있고, 밑의 파일 내용들을 수정한다.      /etc/gitconfig 파일: 시스템의 모든 사용자와 모든 저장소에 적용되는 설정이다. git config --system 옵션으로 이 파일을 읽고 쓸 수 있다. (이 파일은 시스템 전체 설정파일이기 때문에 수정하려면 시스템의 관리자 권한이 필요하다.)        ~/.gitconfig, ~/.config/git/config 파일: 특정 사용자(즉 현재 사용자)에게만 적용되는 설정이다. git config --global 옵션으로 이 파일을 읽고 쓸 수 있다. 특정 사용자의 모든 저장소 설정에 적용된다.        .git/config : 이 파일은 Git 디렉토리에 있고 특정 저장소(혹은 현재 작업 중인 프로젝트)에만 적용된다. –local 옵션을 사용하면 이 파일을 사용하도록 지정할 수 있다. 하지만 기본적으로 이 옵션이 적용되어 있다. (당연히, 이 옵션을 적용하려면 Git 저장소인 디렉토리로 이동 한 후 적용할 수 있다.)  역순으로 우선순위가 높기 때문에 .git/config 의 변경이 위 내용들을 전부 덮어씌운다. Window 는 $HOME 환경 변수로 cmd 를 통해 cd $HOME 으로 들어가보면 된다. Git을 설치함과 동시에 우리는 공유 저장소를 사용할 수 있는 기능들을 갖추게 된 것이고, 우리들의 파일을 전송 가능하게 된다.전송할 때 해당 파일이 누구의 것인지를 명시해주어야 하기에 이 또한 세팅해줘야 한다.git config --global user.name \"John Doe\"git config --global user.email johndoe@example.com# 윈도우 사용자 권장git config --global core.autocrlf true위와 같이 설정해주면 /etc/gitconfig 파일에 해당 내용이 저장되었음을 볼 수 있다. Git 은 커밋이라는 동작을 할 때마다 이 정보를 사용하게 되는데, 만약 설치 후에 커밋을 이미 한 번 하였다면, 이 후에는 이 정보를 변경할 수 없게 된다(딱 한 번 수정가능).마지막 설정은 윈도우 사용자에서는 줄바꿈 문자 때문에 파일 전체가 변경되는 상황이 있는데 이를 방지하기 위해 넣어준다고 한다.  만약 프로젝트마다 자신의 이름과 이메일을 다르게 하고 싶다면, –global 옵션을 빼고 사용하면 된다.제대로 변경이 되었는지 보려면 다음 명령어를 입력하면 된다.git config --list이제 Git 레포지토리를 만들기 전에 어떻게 동작하는지 전체적인 흐름을 본다.Git 기본 워크플로우  작업 디렉토리(Work Directory)에서 파일을 수정한다. 이때 이 디렉토리는 로컬 영역이다.  스테이징 영역(Staging Area)으로 수정된 내용들, 변경 사항들을 넣어준다(로컬 영역).git add 명령어를 사용한다.  로컬 저장소(Local Repository)로 프로젝트의 로컬 버전을 스테이징 영역에 올린 변경 내용들을 토대로 업데이트 해준다.git commit 명령어를 사용한다.  원격 저장소(Remote Repository)로 로컬 저장소에 반영된 내용을 모든 개발자가 접근 가능한 서버로 전송시켜준다. 이는 공유 저장소로 각 개발자들이 서로 변경된 사항을 공유할 수 있게 해준다.git push 명령어를 사용한다.Git Repository 생성레포지토리라는 저장 공간은 Git 이 다루는 기본적인 단위가 된다. 레포지토리를 생성하려면 다음 2가지 방법이 있다.  아직 버전관리를 하지 않는 로컬 디렉토리 하나를 선택해서 Git 저장소를 적용하는 방법  다른 어딘가에서 Git 저장소를 Clone 하는 방법로컬 디렉토리를 Git 저장소로 하기터미널에서 다음을 입력한다.git init해당 폴더에 .git 디렉토리가 생성됨을 볼 수 있을 것이다. 이는 폴더 자체가 Repository 라는 개념이 되기 위한 뼈대(필수) 파일이 들어있다. 이제 해당 디렉토리에서 다양한 파일을 생성 후에 git commit -m \"First Commit\" 을 쳐보면 Local Repsitory 에 변경 내용을 저장하게 된다.Git 저장소를 Clone가져오고 싶은 Shared Repository 를 GitHub 에서 찾아서 이 디렉토리를 생성할 곳에서 터미널로 다음을 입력한다.git clone (복사할 레포지토리 URL).git파일의 다양한 상태상태  Tracked: Work Directory 에서 관리되어야 할 대상 파일들          Modified: Tracked 중 수정된 파일들을 일컫는다      Unmodified: Modified 가 아닌 Tracked 파일을 말한다      Staged: commit 으로 저장소에 기록할 파일들        Untracked: Work Directory 에서 관리에 제외되어야 할 대상 파일들상태들은 repository 에서 다음 명령어를 통해 모든 파일의 상태를 확인할 수 있다.git statusgit status -s특히 특정 파일을 Untracked 로 바꾸고 싶을 때는 .gitignore 이라는 파일에 해당 파일의 경로를 써넣어주면 된다. gitignore.io 사이트에서 프로젝트 별로 불필요한 파일들의 목록을 쉽게 얻을 수 있다..gitignore 파일에 입력된 내용은 다음 패턴을 따른다.  #로 시작하면 주석 라인이다(무시, 설명란임)  Globs 패턴을 사용하여 다양하고 많은 파일들을 써넣을 수 있다  /(슬래시)로 시작하면 하위 디렉토리에 적용시키지 않는다.git diff 를 통한 변경 내용 확인  git diff: Work Directory 와 Staging Area 의 차이  git diff --staged: Staging Area 와 Local Repository(커밋한거) 의 차이git log옵션  –patch: 커밋 별로 git diff 를 출력  –stat: 얼마나 많은 파일이 변경됐는지 얼마나 많은 라인을 추가하거나 삭제했는지 보여준다  –pretty=oneline: 커밋을 한 라인으로 보여준다  –pretty=format: 예시를 보는 것이 빠르다.git log --pretty=format:\"%h - %an, %ar : %s\"ca82a6d - Scott Chacon, 6 years ago : changed the version number085bb3b - Scott Chacon, 6 years ago : removed unnecessary testa11bef0 - Scott Chacon, 6 years ago : first commit  –pretty 옵션과 –graph 옵션을 같이 사용하면 굉장히 이쁜 형태로 출력이 가능하다.파일 되돌리기특정 상태의 파일을 다른 상태로 변환하여 되돌리고 싶을 때가 생길 수 있다. 다음 명령어들을 보자:git commit –amend너무 일찍 커밋했거나 어떤 파일을 빼먹었을 때 혹은 커밋 메시지를 잘못 적었을 때는 커밋된 파일을 다시 되돌릴 수 있는데, 이때 git commit --amend 를 사용할 수 있다.  메시지를 수정해야 할 때, git commit --amend  커밋에 빠진 파일을 추가할 때, git add 후에 git commit --amend, 이는 하나의 커밋으로 쳐짐파일 Unstaged 로 바꾸기Committed -&gt; Staged, Modified 로 돌리고 싶을 때,staged 된 파일(commit 이전 파일, 즉 add 된 파일)을 되돌리려면 다음을 입력해준다.git reset HEAD &lt;file_name&gt;commit 을 하기 전에 add 단계에서 잘못 add를 했을 경우 사용한다.  명령어 자체가 커밋 기록을 변경하는 것이기 때문에 이는 상당히 위험한 작업이다.–hard 옵션을 사용하면 더 위험하지만, 옵션 없이 사용하면 워킹 디렉토리의 파일은 건드리지 않게 된다.기본적으로 –mixed 옵션이며, 이는 커밋을 되돌리고 modified 들을 전부 work directory 로 옮기게 된다.–soft 옵션은 커밋만 되돌리고 modified 들은 전부 staging area 에 놔둔다.되도록 한 파일에 대상으로 명령어를 사용하자.Modified 파일을 되돌리기Modified -&gt; Unmodified 로 돌리고 싶을 때,워킹 디렉토리에서 수정을 가하고, 수정이 너무 에러가 많고 이전의 상태가 더 나았을 때, 이전의 즉 마지막 커밋이 일어난 그 시점으로 해당 파일을 돌리고 싶을 때 사용하는 명령어이다:git checkout -- &lt;file_name&gt;  원래 파일로 덮어썼기 때문에 수정한 내용은 전부 사라지기 때문에 쓰는 것을 신중히 고려해야 한다git revert특정 커밋을 취소하는 커밋을 생성하여서 취소는 그대로 두어서 다른 협업자와 커밋 히스토리는 그대로 가져가되 새로운 커밋을 추가하는 형태로 하여 변경은 없이 확장에 열려있어 적용이 용이하다.우선 오류가 심하거나 보안에 심각한 타격을 주는 코드의 커밋을 추적해야 한다. 다음 명령어로 추적할 수 있을 것이다:git log --oneline위에서 받은 commit ID 를 통해 다음을 입력하면:git revert (해당 commit ID)Revert \"커밋 메시지\" 의 제목의 새로운 커밋 메시지 창이 뜨며, 이는 취소된 상태로 되돌리는 커밋이 되겠다.Remote 저장소리모트 저장소는 인터넷이나 네트워크 어딘가에 있는 저장소를 말하며, 저장소는 여러 개가 있을 수 있다. 어떤 저장소는 읽고 쓰기 모두 할 수 있고 어떤 저장소는 읽기만 가능할 수 있는 권한이 필요할 수 있다. 이 저장소들을 관리하는 것이 협업의 핵심이다.보통 git remote 를 통해 현재 레포지토리의 등록된 리모트 저장소를 확인할 수 있다. 여러 사람과 함께 작업하는 리모트 저장소가 여러개라면 다음 명령어를 통해 여러개의 remote 주소를 얻을 수 있다.git remote -v출력  bakkdoor  https://github.com/bakkdoor/grit (fetch)bakkdoor  https://github.com/bakkdoor/grit (push)cho45     https://github.com/cho45/grit (fetch)cho45     https://github.com/cho45/grit (push)defunkt   https://github.com/defunkt/grit (fetch)defunkt   https://github.com/defunkt/grit (push)koke      git://github.com/koke/grit.git (fetch)koke      git://github.com/koke/grit.git (push)origin    git@github.com:mojombo/grit.git (fetch)origin    git@github.com:mojombo/grit.git (push)그러면 해당 소스 코드의 리모트 저장소를 출력해보고 위 들을 remote add 명령어로 url 을 추가할 수 있다.# git remote add (alias) (URL)git remote add pb https://github.com/paulboone/ticgit이제 해당 URL의 소스코드를 가져오고 싶다면 다음 명령어를 입력해주면 된다.git fetch pbfetch 는 리모트 -&gt; 로컬 로의 데이터를 가져오는 과정이다. 이때, 로컬로 데이터를 가져만 오고 로컬 레포지토리의 로컬 브랜치에 병합(Merge)되지는 않는다. 이때 git merge 명령어를 통해 merge 시킬 수 있다. 이 두 명령어를 한꺼번에 수행하고 싶다면 git pull 을 수행하면 된다.데이터를 가져오는 것뿐 아니라 내보내는 것도 가능한데, git push (리모트) (브랜치) 를 통해 해당 브랜치의 내용을 내보낼 수 있다. 리모트 주소는 git remote rename, git remote remove 등을 통해 삭제, 이름 변경 등을 할 수 있다.이제 원격 레포지토리랑 현재 로컬 레포지토리의 URL 등록이 되었는지 다음을 통해 확인하면 된다: git remote -vGit Branch브랜치는 Snapshot Series 이며, Snapshot 이라는 것은 직관적으로는 특정 시각의 프로젝트 내의 Tracked 파일들의 그 당시 소스코드를 의미한다. 이런 기록들을 토대로 하나하나 스냅샷이 쌓이다 보면 하나의 일련된 과정처럼 볼 수 있다. 더 자세히는 스냅샷은 커밋을 할 때 Staging Area 에 있는 Tracked 파일들, 포인터, 저자, 커밋 메시지 같은 메타데이터, 이전 커밋에 대한 포인터 등을 포함하는 커밋 개체(커밋 Object)를 같이 저장하게 되고 이를 통틀어 스냅샷이라고 볼 수 있다. 스냅샷 하나하나를 커밋 포인터라고 부르기도 한다.여기서 우리가 실제로 프로젝트에서 보고 있는 것은 Commit Pointer 가 가르키고 있는 스냅샷을 보게 되는 것이다. 이런 여러 개의 커밋 포인터들이 모여서 하나의 브랜치를 이루고, 브랜치는 커밋 사이를 가볍게 이동할 수 있는 어떤 포인터와도 같다.Git Main가장 초기에 생성되는 레포지토리에는 초기 스냅샷(아무 파일도 없는) 이 있다. 이때 이 스냅샷을 포함하는 브랜치를 main 브랜치라고 보통 부른다(예전에는 master 가 쓰였다).main 브랜치에서 계속해서 커밋을 할 시 일련의 스냅샷들이 완성되고, 이것들이 하나의 뿌리를 이루게 된다고 해서 브랜치라고 하기도 한다. 만약 특정 과거의 스냅샷에서 다음 스냅샷으로 넘어가지 않고 또 다른 변경 사항을 넣고 싶다면 해당 브랜치에서 또 다른 브랜치를 만들어 다른 경로로 들어가도록 하면 된다.Branch 생성하기  git switch -c &lt;branch 명&gt;: 새 브랜치를 생성 후에 그 브랜치로 이동한다(git checkout은 옛방식이다).  git branch &lt;branch 명&gt;: 새 브랜치를 생성만 한다.물론 git switch &lt;branch 명&gt; 은 해당 브랜치로 이동하는 명령이다. 브랜치가 자꾸 나누어지면 복잡해지고 어떤 코드로 가야할지 헤맬 수 있다. 이때 다음 명령어를 사용하여 branch가 어디서 파생되었는지 알 수 있다:# log를 1개 줄에 꾸며서 graph(tree) 형태로 전부 띄워줘 git log --oneline --decorate --graph --all브랜치를 삭제하고 싶을 수 있는데 다음 명령어를 사용한다:  git branch -d &lt;branch&gt;: 해당 브랜치가 현재 선택된 브랜치에 완전히 병합된 후에만 삭제를 허용하게 되고, 머지된 브랜치를 삭제한다  git branch -D &lt;branch&gt;: 병합됐는지 안됐는지 상관 없이 그냥 강제로 삭제하며, --force --delete 와 같은 옵션이다.병합되지 않은 브랜치를 삭제하려 하면, Git이 오류를 띄우며 삭제를 거부한다.Git HEAD이제 브랜치에서 우리가 작업할 어떤 스냅샷이 특정되어야 한다(작업 할 스냅샷). 항상 우리는 어떤 브랜치에 상주하게 되는데, 이 브랜치의 가장 최신 버전의 커밋 포인터로 코드를 보게 된다. 그리고 이런 현재 스냅샷을 가르키는 커밋 포인터가 있는 브랜치를 HEAD 라고 칭한다(현재 가르키는 브랜치라고 생각하자).git merge이런 브랜치들이 자꾸 나눠지고 합쳐지는게 없다면 협업이 아닐 것이다. 이번에는 브랜치들의 최종 작업물들을 합치는 것을 본다.현재 A라는 브랜치에서 작업중이고, 작업을 완료하고 main 으로 checkout 했다고 하자. 이제 A의 변경사항을 main 에 적용시키고 싶을때는 다음과 같이 입력한다.git merge AGit merge 가 될 때는 다음 merge 유형들이 있다.Fast-forward merge가장 단순한 형태의 merge 이며, 브랜치 A 와 main 에서 A 라는 브랜치가 main 브랜치 최신 커밋 이후에만 커밋이 이루어졌고 이를 main 에 merge 시킬 경우 main 브랜치의 포인터 HEAD 를 A 브랜치의 최신 커밋 포인터로 이동시키게 된다. 이를 Fast-forward merge 라고 한다.Three-way merge복잡한 merge 방식이며 두 브랜치 A, main 가 서로 다른 변경 이력을 가지고 있을 때, 다음 3개의 스냅샷을 비교하게 된다.  A의 최신 커밋  main의 최신 커밋  이들의 공통 조상 커밋이 세 커밋을 비교하여 새로운 커밋을 만들어내는데 새로운 커밋은 두 브랜치의 모든 변경 사항을 통합한 결과를 담고 있고, 이 방식은 복잡한 병합 상황에서 변경 이력을 다룰 때 유리하다.Merge Conflict병합을 하는 도중에는 두 브랜치가 변경 이력이 서로 충돌하는 상황이 발생할 수 있다. 가령 A 브랜치는 a 파일을 수정하고, B 브랜치도 a 파일을 수정할 수도 있다. 이때 두 브랜치를 merge 할 때는 충돌이 생긴다.이때 Git은 자동으로 충돌을 해결할 수 없으므로, 개발자가 직접 파일을 수정하여 어떤 변경 사항을 최종적으로 반영할지 결정해야 한다. 충돌이 발생하면 Git은 충돌이 난 부분을 표시하고 개발자는 이를 보고 어떤 변경 이력을 새 커밋에 넣어줄지를 반영하게 된다.git push &amp; pull이제 원격 레포지토리와 로컬 레포지토리 간의 상호작용을 본다.  git push origin &lt;branch&gt;: 로컬 레포지토리에서 작업한 브랜치를 원격 레포지토리로 옮기기 위한 작업  git pull origin &lt;branch&gt;: 원격 레포지토리에서 갱신된 브랜치를 로컬 레포지토리로 옮기기 위한 작업  git push -u 옵션을 사용하면 원격 레포지토리에 해당 브랜치가 없을 경우 자동 추적을 하여 어떤 snapshot 에 브랜치가 가지치기로 들어갈지를 알아서 판단하에 브랜치를 생성해주고 갱신해준다. 이는 이후에도 push 명령에서 원격 저장소와 브랜치를 기본값으로 설정되어 git push 를 할 수 있게 된다.push 하는 것은 결국에는 내가 쓴 코드를 공유, 원격 레포지토리로 옮기는 것이므로 사람들에게 내 코드를 알리는 것이다. 이를 토대로 사람들이 이 코드를 보고 이를 main 브랜치에 포함시킬지 안시킬지를 검토하는 Pull Request 작업을 수행할 수 있다.Personal Access TokenGithub 는 public repo 이더라도 권한이 없는 사람은 직접 push가 불가능하다.이때 fork + PR 방식으로 기여하게 되는데, 이때 이중 인증 혹은 CI/CD파이프 라인이 있거나, Github API 를 사용하여 레포지토리에 접근할 때 등등이 PAT을 필요로 하게 된다.따라서 Github 에 push를 하기 위해서는 인증 이 필요하다. ID/Password 로도유저가 push/pull 을 할 수 있었지만, 추후에 더 보안에 좋은 PAT 또는 SSH 를 사용하여접근할 수 있도록 바꿨다.PAT 은 다음을 통해 발급 가능하다.  Settings → Developer settings → Personal access tokens → Tokens  만료 기간과 권한 선택          권한은 보통 repo 접근 권한만 주면 된다.      필요에 따라 workflow, admin:org, gist 등 선택이 가능        토큰 생성이 토큰을 clone 한 시점에 사용할 수 있고 비밀번호 대신에 이걸 사용하면 된다.발급한 Token 을 Git Credential Helper 이용해 등록우선 Git Credential Helper 를 확인한다git config --global credential.helper만약 아무 출력도 나오지 않는다면 아직 이게 설정이 안되어 있는 상태이다.이제 이를 설정해주자.Git Credential Helper 를 설정한다.Macgit config --global credential.helper osxkeychain  mac 은 Keychain(osxkeychain) 에 PAT을 저장해서 매번 입력할 필요가 없다.Windowgit config --global credential.helper manager  Window 는 Windows Credential Manager 에 PAT을 저장한다.위처럼 실행하면 PAT을 이제 사용할 수 있게 된다.git clone 을 이제 수행하면 username, password 입력을 한 번만 수행하면그 다음부터는 입력하지 않아도 되게 된다.이제 사용하려면 아래의 user, password 입력이 생략된다.git clone https://github.com/username/repo.git# Username: GitHub 계정명# Password: 여기에 PAT 입력✒️ 용어Globs 패턴Regex 와 비슷하다.  ?: 어떤 한 문자를 뜻함  *: 한 개 이상의 문자를 뜻함(ex. a*는 a.mp3, abc.txt, apple 을 전부 포함, 슬래시는 제외)  **: 0 개 이상의 하위 디렉토리를 뜻함  {}: 안의 원소 중 하나를 뜻함 (ex. *.{txt,md} 는 txt와 md의 확장자를 가지는 파일들 전부를 뜻함)  []: 한 개의 문자들 중 하나를 뜻함 !를 사용하면 해당 문자는 제외                              (): 문자의 반복을 의미 (ex. *(ab          cd) 1개 이상의 ab, cd 의 조합을 말함, abab, cdab 등등)                    "
    },
  
    {
      "title": "9. Spring Boot Devtools",
      "url": "/seonghun120614/computerscience/java/spring/2025/08/10/9.-spring-boot-devtools.html",
      "date": "2025-08-10",
      "content": "📂 목차  Devtools 의 웹기반 HTML 템플릿 엔진 캐싱 기능  Devtools 의 Live Reload📚 본문스프링 부트 개발자 도구라고 불리는 이 컴포넌트는 어플리케이션을 개발할 때 개발자들이 필요로 하는 기능들을 담은 도구 세트들을 제공한다. 여기는 편리한 기능들이 많아서 이용하면 좋을 것이다.// Spring Boot devtoolsdevelopmentOnly 'org.springframework.boot:spring-boot-devtools'위 의존관계를 추가해주자.Devtools 의 웹기반 HTML 템플릿 엔진 캐싱 기능스프링 부트와 스프링 부트를 구성하는 라이브러리 중 일부는 성능 향상을 위해 캐시를 지원하는데, 한 번 호출되고 사라지는 휘발성 데이터들에 대해 다음 실행에서 또 그 데이터들을 불러와야 하는 상황일 때, 우리는 이것들을 계속 저장시켜서 이미 저장되어 있는 것들을 불러오게 할 수 있다.실제로 Thymeleaf 템플릿 엔진에서 HTML 을 캐싱하고 이후 호출될 때는 템플릿을 다시 parsing 하지 않고, 미리 파싱해놓은 HTML 을 다시 쓰게 하면 된다. 하지만 변경 내용이 바로 반영되지 않을 수 있기 때문에 개발 단계에서는 끄고 진행해야 한다(org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor 클래스를 사용해서 기본적으로 캐싱을 모두 비활성화 할 수 있음).다음 properties 값들이 기본적으로 설정된다.spring.thymeleaf.cache=falsespring.freemarker.cache=falsespring.groovy.template.cache=falsespring.mustache.cache=falsespring.web.resources.cache.period=3600spring.web.resources.chain.cache=true위부터 차례대로 설명하면 다음과 같다:  템플릿 파일(HTML)을 파싱한 결과를 메모리에 캐시할지 여부  FreeMarker 템플릿 엔진 캐시 여부  Groovy 기반 템플릿 캐시 여부  Mustache 템플릿 캐시 여부  정적 리소스(이미지, CSS, JS)의 캐시 지속 시간(초 단위)  정적 리소스 처리 체인(Static Resource Chain)의 캐시 여부Devtools 의 Live Reload개발 환경을 구성했을때, 소스 코드를 변경하고 변경 내용을 확인하려면 어플리케이션을 재시작 해야하는 번거로움이 있는데, Devtools를 사용하면 클래스패스에 변경 사항이 있을 때마다 자동으로 재시작을 해준다.리로드를 해주는 역할을 하는 클래스는 두 종류인데 base classloader 와 restart classloader 이다. base loader는 변경되는 일이 별로 없는 클래스를 로딩하며, 다른 하나는 변경이 잦은 클래스를 로딩하는 역할을 한다.일반적으로 설정할 수 있는 프로퍼티는 다음과 같다:spring.devtools.livereload.enabled=truespring.devtools.restart.enabled=true  LiveReload 서버 활성화  코드 변경 시 자동 재시작✒️ 용어Static Resource Chain기본적으로 웹 서비스를 제공하려면 웹사이트에 대한 HTML 문서를 제공해야 하는데, 우리가 만드는 HTML 웹사이트는 전부 HTML 을 만드는 엔진에 의해서 만들어지고, 여기서 src/main/resources/static, public, resources 와 같은 정적 리소스들을 활용하게 된다.이 파일들을 단순히 내려주는게 아니라 템플릿 엔진에서는 이를 여러 단계(Chain)로 필터링, 변환, 가공, 최적화를 진행하고 내려주게 된다. 이 처리 단계를 연결시켜 Static Resource Chain 이라고 부른다."
    },
  
    {
      "title": "10. Spring Boot Custom Failure Analyzer",
      "url": "/seonghun120614/computerscience/java/spring/2025/08/10/10.-spring-boot-custom-failure-analyzer.html",
      "date": "2025-08-10",
      "content": "🚧 작성중🪛 한계점어플리케이션의 다수의 컴포넌트에 대한 실패(Trap) 확률이 어플리케이션이 복잡해지고 규모가 커지면 예외 상황이 발생할 확률이 늘어난다. 이에 따라 오류들을 잡을 수 있도록 정확한 logging 이 필요하며, 개발 생산성과 신속한 개선을 도모할 수 있다.📂 목차    📚 본문예외를 감지하고, 해당 이슈에 대한 정보를 띄울 수 있는 무언가가 필요할 것이다. HTTP 포트를 여러개 띄우다가 포트간의 충돌이나 외부 API 요청이 필요한데, 해당 외부 API 서비스가 불가용할 경우에도 메시지를 띄워주어야 하고(DB 서버에서 자주 발생), 내부적인 로직에서 어떤 코드에서 어떤 오류가 났는지도 필요할 것이다.이때 실패 분석기를 사용한다. 목표는 다음과 같다.  발생한 트랩에 대한 상세 메시지를 제공하여 문제의 근본 원인과 해결책을 제시한다.  어플리케이션 시작 시점에서 검증을 수행하여 추측 가능한 에러를 일찍 파악하여 어플리케이션을 아예 동작하지 않게 할 수 있다.Custom Spring Boot Failure Analyzer예제로 의존하는 외부 REST 서비스를 사용할 수 있는지를 어플리케이션 시작 지점에서 확인해야 하는 상황이다. 여기서는 Postgres Server 에 대해 검증을 수행해보자.예외를 따로 처리하기 위해 다음을 작성한다.public class UrlNotAccessibleException extends RuntimeException {    private String url;    public UrlNotAccessibleException(String url) {        this(url, null);    }    public UrlNotAccessibleException(String url, Throwable cause) {        super(\"URL \" + url + \" is not accessible\", cause);        this.url = url;    }}url 의 연결에 실패하면 발생하는 런타임 예외이다.✒️ 용어######🔗 관련 출처  "
    },
  
    {
      "title": "8. Spring Boot Auto Configuration",
      "url": "/seonghun120614/computerscience/java/spring/2025/08/08/8.-spring-boot-auto-configuration.html",
      "date": "2025-08-08",
      "content": "📂 목차  Common Context Configuration 설정  Conditional 을 통한 특정 Bean 제외하고 Import 하기  @Condition 동작 방식  spring.factories  Auto Configuration 구성하기  Auto Configure 되는 DataSource 클래스 우회하기📚 본문스프링 부트는 개발에 필요한 컴포넌트를 자동으로 설정해주는 기능이 있는데 이를 Auto Configuration 이라고 한다. 만약 spring-boot-starter-web 을 추가한다면, Spring Boot는 웹 어플리케이션 구동에 필요한 웹 서버가 필요할 것이라고 추론하고 아파치 톰캣(기본값임) 웹서버를 기본 웹 서버로 추가해준다. 톰캣 말고도 Jetty를 사용해도 무관하다. 그때는 dependencies를 Jetty를 사용하도록 수정해주면 된다(spring-boot-starter-jetty).하지만 이게 모든 상황에 편리할 수는 없다. 예를 들어 개발팀1 에서 스프링 프레임워크를 사용해서 여러가지 프로젝트를 진행하고 있는데 spring bean 설정이 모든 팀(개발팀2, 개발팀3)에서 복사해서 사용하고 있으면 중복되는 bean 들을 여러 개 생성하는 것은 매우 비효율적일 것이다. 따라서 공통 구성 설정 이 필요할 수 있다.Common Context Configuration 설정@Configuration 애너테이션을 통해 이 클래스를 스프링 설정으로 담당하는데, 따로 CommonApplicationContextConfiguration 이라는 클래스를 만들어서 이 클래스를 포함하는 프로젝트는 메이븐이나 그레이들 컴포넌트로 배포되고 개발 팀에서는 이 프로젝트를 의존 관로 추가해서 설정 클래스를 사용할 수 있을 터이다(중복된 설정 작업 막기).@Configurationpublic class CommonApplicationContextConfiguration {    @Bean    public RelationalDataSourceConfiguration dataSourceConfiguration() {        return new RelationalDataSourceConfiguration    }}위는 RelationalDataSourceConfiguration 의 다른 모든 팀에서 자주 사용할 법한 그런 클래스들을 빈으로 정의하고 있다. 이렇게 정의해두면 다른 팀에서 이를 사용할 때 설정 파일 내용을 수정하는 수고를 덜 수 있다. 이제 이를 함의하는 다른 Application Context(IoC 컨테이너)를 정의하자. 영업팀은 다음을 사용할 수 있을 것이다.package com.example.study.config;import org.springframework.context.annotation.*;@Configuration@Import(CommonApplicationContextConfiguration.class)public class CommonBusinessApplicationContextConfiguration {    // 영업팀의 Common ApplicationContext}Conditional 을 통한 특정 Bean 제외하고 Import 하기스프링 프레임워크는 스프링이 관리하는 컴포넌트의 생성을 제어할 수 있도록 @Bean, @Component, @Configuration 애너테이션과 함께 사용할 수 있는 @Conditional 애너테이션을 제공한다.@Configurationpublic class CommonApplicationContextConfiguration {    @Bean    @Conditional(RelationalDatabaseCondition.class)    public RelationalDataSourceConfiguration dataSourceConfiguration() {        return new RelationalDataSourceConfiguration();    }}Conditional 을 붙여 조건을 걸 수 있고, 조건에 해당하는 Context들에만 해당 Bean이 들어가게 된다. RelationalDatabaseCondition 은 Condition 인터페이스를 구현하는 클래스이고, boolean matches() 을 구현하도록 한다.package com.example.study.config;import org.springframework.context.annotation.*;import org.springframework.core.type.*;public class RelationalDatabaseCondition implements Condition {    @Override    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {        return isMySqlDatabase();    }    private boolean isMySqlDatabase() {        try {            Class.forName(\"com.mysql.jdbc.Driver\");            return true;        } catch (ClassNotFoundException e) {            return false;        }    }}위에서는 reflect API를 활용하여 JVM에 jdbc.Driver 가 올라가 있는지를 살피는 로직이다. 안에 얼마든지 복잡한 로직을 사용하여 Application Context 를 유연하게 활용할 수 있다.@Condition 동작 방식애너테이션만으로 조건부 빈 생성이 가능하지만, 스프링에서는 다양한 조건을 쉽게 사용할 수 있게 해주는 다양한 고수준의 애너테이션을 따로 제공한다. 몇 개만 외우자.            애너테이션      예시      예시 설명                  @ConditionalOnBean      @Conditional(DataSource.class)      설정에서 DataSource 빈이 명시돼 있으면 true 반환              @ConditionalOnClass      @ConditionalOnClass(DataSource.class)      클래스 패스에 DataSource 클래스가 있으면 true 반환              @ConditionalOnProperty      @ConditionalOnClass(“some.property”)      some.property 가 정의되어 있으면 true 반환              @ConditionalOnCloud      @ConditionalOnCloud(CloudPlatform.KUBERNETES)      CloudPlatform 이 KUBERNETES로 설정돼있으면 true 반환              @ConditionalOnJava      @ConditionalOnJava(JavaVersion.EIGHT)      Java 버전이 8을 지원하면 반환              @ConditionalOnMissingBean      @ConditionalOnMissingBean(DataSource.class)      DataSource 빈이 설정돼 있지 않으면 true 반환              @ConditionalOnMissingClass      @ConditionalOnMissingClass(DataSource.class)      클래스 패스에 DataSource 빈이 설정돼 있지 않으면 true 반환              @ConditionalOnNotWebApplication      @ConditionalOnNotWebApplication      웹 어플이 아니면 true 반환              @ConditionalOnSingleCandidate      @ConditionalOnSingleCandidate(DataSource.class)      DataSource 빈이 하나만 정의돼 있으면 true      spring.factories모든 스프링 프로젝트는 spring-boot-autoconfigure 의 의존관계를 포함하고 있다.이 모듈의 JAR 파일의 META-INF 폴더를 파헤치면...# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnBeanCondition,\\org.springframework.boot.autoconfigure.condition.OnClassCondition,\\org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition...위와 같은 properties 가 보이며, Auto Configuration 으로 표시된 부분이 스프링 부트 컴포넌트, 서드 파티 라이브러리 등에 대한 자동 구성 정보가 포함돼 있는 곳이다.위 Condition 들 순서대로  OnBeanCondition  OnClassCondition  OnWebApplicationCondition을 통해 걸러지고 남은 Configuration 들만 @Configuration 으로 처리된다.Auto Configuration 구성하기모든 팀들이 공통적으로 사용할 데이터 소스의 자동 설정을 건드려보자.  dev 환경: mysql, postgresql 사용  test 환경: H2 사용  prod 환경: mysql, postgresql 사용각 환경마다 저렇게 구성하고 싶다고 해보자. properties 를 우선 설정하여 profiles 만 바꾸는 것만으로 DataSource 를 자동 변경을 시키도록 하고 싶을 것이다.test 환경에서는 spring.active.profiles 라는 spring에서 지정된 key 에 의해 application-{spring.active.profiles}.properties 의 설정 정보를 읽어 들여 실행하게 된다. 이 값을 통해 Condition 을 짜보자.public class InMemoryDatabaseCondition implements Condition {    @Override    public boolean matches(            ConditionContext context,            AnnotatedTypeMetadata metadata) {        Environment env = context.getEnvironment();        String activeProfile = env.getProperty(\"spring.profiles.active\");        return // activeProfile == null ||                activeProfile.equals(\"test\");    }}InMemory는 내장 RAM 을 통한 db source 를 구성하는 방식이다. context 를 통해서 들고 와도 되고, javax.lang.reflect를 통해 JVM에 올라간 driver class 의 name 을 검사해도 무방하다. 왠만해서는 Spring을 쓰자.@Configuration@Conditional(InMemoryDatabaseCondition.class)public class InMemoryDataSourceConfiguration {    private final DataSourceProperties dsp;    @Autowired    public InMemoryDataSourceConfiguration(DataSourceProperties dataSourceProperties) {        this.dsp = dataSourceProperties;    }    @Bean    public DataSource dataSource() {        HikariDataSource ds = new HikariDataSource();        ds.setJdbcUrl(dsp.getUrl());        ds.setUsername(dsp.getUsername());        ds.setPassword(dsp.getPassword());        return ds;    }}공통 DB Configuration 을 선언하여 inner class 를 통해 다수의 class 를 들고 오게 할 수 있다. 이를 통해 각 DB에 대한 property 를 다르게 설정하여 들고 올 수 있고, NoSQL 을 사용하는 DB에 대해서도 추가적으로 확장할 수 있을 터이다. 여기서 DataSource 는 HikariDataSource 를 사용한다(경랑, 성능 좋음)(Spring 2.x 에서는 커넥션 풀이 Hikari 를 사용하기 때문에 따로 설정해줄 필요가 없다).Auto Configure 되는 DataSource 클래스 우회하기Spring Boot는 DataSource 를 spring.datasource prefix 의 key-value 프로퍼티를 읽어들여서 DataSource를 구성하게 된다. 이때, 자신의 project 에 DataSource 타입의 Bean 이 존재하게 되면 내부의@ConditionalOnMissingBean(DataSource.class) 의 조건 때문에 원래의 Auto Configure 에 의한 DataSource 의존성 주입을 우회하게 된다. 이를 사용하면 다음을 구성할 수 있다.@Configuration@Conditional(InMemoryDatabaseCondition.class)public class InMemoryDataSourceConfiguration {    private final DataSourceProperties dsp;    @Autowired    public InMemoryDataSourceConfiguration(DataSourceProperties dataSourceProperties) {        this.dsp = dataSourceProperties;    }    @Bean    public DataSource dataSource() {        HikariDataSource ds = new HikariDataSource();        ds.setJdbcUrl(dsp.getUrl());        ds.setUsername(dsp.getUsername());        ds.setPassword(dsp.getPassword());        return ds;    }}여기서 DataSource thread 개수들을 서버의 성능에 따라 달리 사용하여서 조정할 수도 있고 Pool을 달리 설정할 수도 있다."
    },
  
    {
      "title": "Project. User Function MVP",
      "url": "/seonghun120614/computerscience/java/spring/2025/07/30/project.-user-function-mvp.html",
      "date": "2025-07-30",
      "content": "v0.1📂 목차  핵심 기능 도출          최소 기능 정의      User Flow 설계                  UF Registration                      요구사항 정의(Requirement Specification)          핵심 기능에 대한 요구 수집                  RQ Registration                    시나리오/유스케이스 작성                  SC Registration                      기획 협업(생략)  기술 설계(Design Specification)          API 스펙 초안 작성                  API Registration                            DB 테이블/엔티티 구조 정의            서비스 계층의 로직 흐름 정리                  SD Registration                      개발 Sprint          핵심 기능 우선순위 설정 및 분할      TDD 기반 소스코드 작성        Sprint Review &amp; Retrospective          v0.1      📚 본문User 관련 기능을 RESTful 하게 구현하고 재사용하기 위해 User Component 혹은 패키지를 구현한다. 필요에 따라 서브 프로세스는 생략한다.핵심 기능 도출대부분의 서비스에 대한 User 관리 기능을 총체적으로 관리하는 컴포넌트를 개발하기 위해 핵심 기능을 도출한다.최소 기능 정의서비스가 존재할 수 있는 가장 작은 단위를 다음 기능을 포함하는 서비스로 정의  회원가입 (Registration)  목표: 새로운 사용자가 서비스에 계정을 생성하고 접속 가능  핵심 기능:          사용자로부터 이메일 주소, 비밀번호, 사용자 이름을 입력      이메일 주소의 유일성 및 유효성을 검증      비밀번호는 보안을 위해 해싱하여 저장      성공적으로 계정이 생성되면 사용자에게 확인 응답      User Flow 설계UF Registrationgraph TD    A[클라이언트] --&gt; B{POST /api/v1-beta/users/register};    B --&gt; C[백엔드: 요청 수신];    C --&gt; D{요청 바디 유효성 검증};    D -- 실패 (400 Bad Request) --&gt; E[응답: 에러 메시지];    D -- 성공 --&gt; F{이메일 중복 확인};    F -- 중복 (409 Conflict) --&gt; E;    F -- 고유함 --&gt; G[비밀번호 해싱];    G --&gt; H[사용자 정보 DB 저장];    H --&gt; I{DB 저장 성공?};    I -- 실패 (500 Internal Server Error) --&gt; E;    I -- 성공 --&gt; J[응답: 201 Created, 생성된 사용자 ID/Email];    J --&gt; A;    E --&gt; A;##### Login```mermaidgraph TD    A[클라이언트] --&gt; B{POST /api/v1/users/login};    B --&gt; C[백엔드: 요청 수신];    C --&gt; D{요청 바디 유효성 검증};    D -- 실패 (400 Bad Request) --&gt; E[응답: 에러 메시지];    D -- 성공 --&gt; F[DB에서 Email 기준 사용자 정보 조회];    F --&gt; G{사용자 존재 여부 및 비밀번호 일치 확인};    G -- 사용자 없음/비밀번호 불일치 (401 Unauthorized) --&gt; E;    G -- 일치 --&gt; H[JWT Access Token &amp; Refresh Token 생성];    H --&gt; I[응답: 200 OK, AccessToken, RefreshToken, 사용자 기본 정보];    I --&gt; A;    E --&gt; A;```##### Authentication &amp; Authorization```mermaidgraph TD    A[클라이언트] --&gt; B{GET /api/v1/users/me Authorization 헤더에 AccessToken 포함};    B --&gt; C[백엔드: 요청 수신];    C --&gt; D{Authorization 헤더를 통한 AccessToken 존재 여부 확인};    D -- 없음 (401 Unauthorized) --&gt; E[응답: 에러 메시지];    D -- 있음 --&gt; F{서명, 만료 시간을 통한 AccessToken 유효성 검증};    F -- 유효하지 않음/만료 (401 Unauthorized) --&gt; E;    F -- 유효함 --&gt; G[토큰에서 사용자 ID 추출];    G --&gt; H[DB에서 ID 기준 사용자 정보 조회];    H --&gt; I{사용자 존재 여부};    I -- 없음 (404 Not Found) --&gt; E;    I -- 있음 --&gt; J[Authorization를 통한 요청된 자원에 대한 사용자 권한 확인 인가];    J -- 권한 없음 (403 Forbidden) --&gt; E;    J -- 권한 있음 --&gt; K[사용자 정보 응답 데이터 구성];    K --&gt; L[응답: 200 OK, 사용자 상세 정보];    L --&gt; A;    E --&gt; A;```##### Deletion```mermaidgraph TD    A[클라이언트] --&gt; B{DELETE /api/v1/users/me Authorization 헤더에 AccessToken 포함};    B --&gt; C[백엔드: 요청 수신];    C --&gt; D{AccessToken 유효성 검증 및 사용자 ID 추출};    D -- 실패 (401 Unauthorized) --&gt; E[응답: 에러 메시지];    D -- 성공 --&gt; F[DB에서 해당 사용자 정보 조회 및 삭제/비활성화];    F --&gt; G{DB 처리 성공?};    G -- 실패 (500 Internal Server Error) --&gt; E;    G -- 성공 --&gt; H[연관된 세션/토큰 무효화];    H --&gt; I[응답: 204 No Content 또는 200 OK];    I --&gt; A;    E --&gt; A;```요구사항 정의앞서 다뤘던 MVP 와 User Flow Chart 를 통한 기능에 대한 구체적인 요구사항을 수집한다. 개발자들이 기능을 구현할 때 참고할 수 있는 구체적인 설계 가이드라인이 되기에 상세히 작성할수록 좋다.핵심 기능에 대한 요구 수집RQ Registration새로운 사용자가 서비스에 계정을 생성  API 엔드포인트: POST /api/v1/users/register  요청 (Request Body): JSON 형식          email (문자열, 필수): 사용자의 이메일 주소                  제약사항: 유효한 이메일 형식 (예: user@example.com).          제약사항: 시스템 내에서 고유해야 함          길이 제한: 최대 255자                    password (문자열, 필수): 사용자가 설정할 비밀번호                  제약사항: 최소 8자 이상, 대문자/소문자/숫자/특수문자 중 3가지 이상 포함          길이 제한: 최소 8자, 최대 64자                    username (문자열, 필수): 사용자 이름 (닉네임)                  제약사항: 중복 허용 (필요에 따라 고유성 제약 추가 가능)          길이 제한: 최소 2자, 최대 30자                      성공 응답 (Response - 201 Created): JSON 형식          id (정수/UUID): 생성된 사용자의 고유 ID      email (문자열): 등록된 이메일 주소      username (문자열): 등록된 사용자 이름      message (문자열): “회원가입이 성공적으로 완료되었습니다.”        오류 응답 (Response): JSON 형식          status (정수):                  400 Bad Request (유효성 검증 실패)          409 Conflict (이메일 중복)          500 Internal Server Error (서버 내부 오류)                    code (문자열): 특정 오류를 식별하는 내부 코드                  INVALID_EMAIL_FORMAT          PASSWORD_POLICY_VIOLATION          EMAIL_ALREADY_EXISTS                    message (문자열): 사용자에게 표시할 오류 메시지                  “이메일 형식이 올바르지 않습니다.”          “비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.”          “이름은 최소 2자 이상이며, 최대 30자 입니다.”          “이미 등록된 이메일 주소입니다.”          “서버 오류가 발생했습니다. 사용자 정보를 저장하는 데 실패했습니다. 잠시 후 다시 시도해 주세요.”                      백엔드 처리 로직:          요청 데이터 유효성 검증      이메일 중복 확인      비밀번호 해싱 (예: bcrypt)      사용자 정보를 데이터베이스에 저장        (선택 사항) 회원가입 시점에 기본 역할(Role) 부여 (예: USER)시나리오/유스케이스 작성작성하기 전 유스케이스 다이어그램graph LR    Actor(사용자) --&gt; UC1(회원가입);SC Registration공통 전처리  요청 바디에서 email, password, username을 추출한다.  각 필드에 대해 유효성 검증을 수행한다.          email: 문자열 여부 및 이메일 형식 검증      password: 길이 및 보안 정책(대소문자, 숫자, 특수문자 포함) 검증      username: 최소/최대 길이 확인      성공 흐름  이메일이 중복인지 확인한다.  비밀번호를 해싱 처리한다.  해싱된 비밀번호와 함께 사용자 정보를 DB에 저장한다.  저장이 성공하면 다음 정보를 포함한 201 Created 응답을 반환한다.          id: 생성된 사용자 ID      email: 등록된 이메일 주소      username: 등록된 사용자명      message: “회원가입이 성공적으로 완료되었습니다.”      실패 흐름 입력 무효  검증에 실패한 경우 400 Bad Request 응답과 함께 적절한 오류 메시지를 반환한다.          “이메일 형식이 올바르지 않습니다.”      “비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.”      “이름은 최소 2자 이상이며, 최대 30자 입니다.”      실패 흐름 이메일 중복  이메일이 중복인지 확인한다.  이메일이 중복인 경우 409 Conflict 응답과 함께 적절한 오류 메시지를 반환한다.          “이미 등록된 이메일 주소입니다.”      실패 흐름 DB 서버 통신 실패  이메일이 중복인지 확인한다.  비밀번호를 해싱 처리한다.  해싱된 비밀번호와 함께 사용자 정보를 DB에 저장한다.  DB에 반영되지 않은 경우 500 Internal Server Error 와 함께 적절한 오류 메시지를 반환한다.          “서버 오류가 발생했습니다. 사용자 정보를 저장하는 데 실패했습니다. 잠시 후 다시 시도해 주세요.”      기술 설계API 스펙 초안 작성API Registration새로운 사용자가 서비스에 가입하기 위해 필요한 정보를 제출하는 API입니다.  HTTP Method: POST  URL: /api/v1-beta/users/register요청 바디 (Request Body)            필드명      데이터 타입      설명                  email      string      사용자 이메일 주소              password      string      사용자 비밀번호              username      string      사용자 이름        요청 바디 예시{  \"email\": \"user@example.com\",  \"password\": \"Password123!\",  \"username\": \"홍길동\"}응답 (Response)            상태      코드      설명                  201      Created      회원가입이 성공적으로 완료되었을 때 반환하는 응답              400      Bad Request      요청 바디의 유효성 검증에 실패했을 때 반환하는 응답              409      Conflict      이메일이 이미 사용 중이어서 회원가입이 불가능할 때 반환하는 응답              500      Internal Server Error      서버 내부에서 예기치 않은 오류가 발생했을 때 반환하는 응답        응답 바디 예시 헤더는 생략:{  \"id\": \"uuid-1234-5678-90ab\",  \"email\": \"user@example.com\",  \"username\": \"홍길동\",  \"message\": \"회원가입이 성공적으로 완료되었습니다.\"}{  \"error\": \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\"}{  \"error\": \"이미 등록된 이메일 주소입니다.\"}{  \"error\": \"서버 오류가 발생했습니다. 잠시 후 다시 시도해 주세요.\"}DB 테이블/엔티티 구조 정의erDiagram    users {        UUID id PK \"사용자 고유 ID\"        VARCHAR email \"이메일 주소\"        VARCHAR password \"해싱된 비밀번호\"        VARCHAR username \"사용자 이름\"    }서비스 계층의 로직 흐름 정리SD RegistrationsequenceDiagram    participant User as 사용자    participant Client as 클라이언트(웹/앱)    participant APIServer as API 서버    participant Service as 서비스 계층    participant Database as 데이터베이스    Title: 사용자 회원가입 시퀀스 다이어그램    %% 성공 흐름    User-&gt;&gt;Client: 회원가입 정보 입력    Client-&gt;&gt;APIServer: 회원가입 요청&lt;br/&gt;(POST /api/v1-beta/users/register)    APIServer-&gt;&gt;Service: 요청 처리 위임    Service-&gt;&gt;Service: 1. 유효성 검증&lt;br/&gt;(email, password, username)    Service-&gt;&gt;Database: 2. 이메일 중복 확인    Database--&gt;&gt;Service: 중복 없음    Service-&gt;&gt;Service: 3. 비밀번호 해싱    Service-&gt;&gt;Database: 4. 사용자 정보 저장    Database--&gt;&gt;Service: 저장 성공    Service--&gt;&gt;APIServer: 201 Created 응답 반환    APIServer--&gt;&gt;Client: 201 Created 응답    Client--&gt;&gt;User: \"회원가입 성공\" 메시지 표시    %% 입력 무효 실패 흐름    alt 입력 무효        User-&gt;&gt;Client: 잘못된 정보 입력        Client-&gt;&gt;APIServer: 회원가입 요청&lt;br/&gt;(POST /api/v1-beta/users/register)        APIServer-&gt;&gt;Service: 요청 처리 위임        Service-&gt;&gt;Service: 1. 유효성 검증&lt;br/&gt;(실패)        Service--&gt;&gt;APIServer: 400 Bad Request 반환        APIServer--&gt;&gt;Client: 400 Bad Request 응답        Client--&gt;&gt;User: \"잘못된 입력입니다\" 메시지 표시    end    %% 이메일 중복 실패 흐름    alt 이메일 중복        User-&gt;&gt;Client: 중복 이메일 입력        Client-&gt;&gt;APIServer: 회원가입 요청&lt;br/&gt;(POST //api/v1-beta/users/register)        APIServer-&gt;&gt;Service: 요청 처리 위임        Service-&gt;&gt;Service: 1. 유효성 검증&lt;br/&gt;(성공)        Service-&gt;&gt;Database: 2. 이메일 중복 확인        Database--&gt;&gt;Service: 중복된 이메일 존재        Service--&gt;&gt;APIServer: 409 Conflict 반환        APIServer--&gt;&gt;Client: 409 Conflict 응답        Client--&gt;&gt;User: \"이미 등록된 이메일입니다\" 메시지 표시    end개발 Sprint여기서는 구현하기 전 사용할 공통 라이브러리들을 전부 불러오고, 서버의 구동 profile 에 맞춰 configuration 들을 미리 작성해준다.핵심 기능 우선순위 설정 및 분할빈 class 파일들을 생성하고 Data Access, Presentation, Business Logic Layer 을 중점으로 작성해준다.      엔드포인트(UserController) 구현 (/api/v1-beta/users)        register(POST /api/v1-beta/users/register)          User Entity 구현      비즈니스 엔티티 유효성 검증을 위한 커스텀 인터페이스들 정의                  @Password          @Email - jakarta.validation.constraints 참고                    비즈니스 엔티티 유효성 검증을 위한 빈 밸리데이터 정의                  PasswordRuleValidator 클래스 구현                    User JPA 변환 및 DAO 클래스(UserRepository) 구현                  이메일 중복 검증을 위한 existsByEmail 함수 정의          유저 데이터 저장하는 createUser 함수 정의                    User 관련 최종 서비스를 제공하는 클래스(UserService) 구현                  register 함수 구현                    UserController의 register 함수 구현      classDiagram    direction LR    subgraph Presentation_Layer        class UserController {            + register(String email, String password, String username) : ResponseEntity&lt;User&gt;        }    end    subgraph Business_Logic_Layer        class IUserService {          &lt;&lt;interface&gt;&gt;          ~ register(String email, String password, String username) : Optional&lt;User&gt;        }    end    subgraph Data_Access_Layer        class IUserRepository {          &lt;&lt;interface&gt;&gt;          ~ existsByEmail(email) : boolean          ~ save(user) : User        }    end    subgraph Domain_and_Validation        class User {          &lt;&lt;Entity&gt;&gt;          - @Email String email          - @Password String password          - String username        }        class IPassword {          &lt;&lt;interface&gt;&gt;        }        class PasswordRuleValidator {          + @Override isValid(Object value, ConstraintValidatorContext context)        }        class ConstraintValidator {          &lt;&lt;interface&gt;&gt;          + isValid(value, context)        }    end    UserController --|&gt; IUserService: use    IUserService --|&gt; IUserRepository: use    IUserRepository --|&gt; User: CRUD    User ..|&gt; IPassword    ConstraintValidator &lt;|.. PasswordRuleValidator: implements        ConstraintValidator ..&gt; IPassword: generic typeTDD 기반 소스코드 작성위의 class diagram을 바탕으로 Test class 들을 작성해주어야 한다.@DataJpaTest@ActiveProfiles(\"test\")class UserRepositoryTest {    @Autowired    UserRepository userRepository;    @BeforeEach    void setup() {        userRepository.save(                new User(\"1@email.com\", \"name\", \"1234!@\")        );    }    @AfterEach    void init() {        userRepository.deleteAll();    }    @ParameterizedTest    @CsvSource({\"1@gmail.com, name, 1234!@\"})    void givenTheData_whenCreatingSameUser_thenThrowsException(String email, String username, String password) {        User user = new User(email, username, password);        assertThrows(                DataIntegrityViolationException.class,                () -&gt; userRepository.save(user)        );    }    @ParameterizedTest    @CsvSource({\"user@email.com, user, 12329212@@!hdH\"})    void givenCreatedUser_whenExistingUser_thenExpectedResult(String email, String username, String password) {        userRepository.save(new User(email, username, password));        assertTrue(userRepository.existsByEmail(email));        assertTrue(userRepository.existsByEmail(\"1@email.com\"));    }}@SpringBootTest@ActiveProfiles(\"test\")public class UserServiceTest {    @Autowired    private UserService userService;    private static final BCryptPasswordEncoder PASSWORD_ENCODER = new BCryptPasswordEncoder();    // AI 생성 테스트케이스    // --- 테스트 데이터 제공 메서드 ---    // @MethodSource 가 참조하는 정적 메서드입니다.    // 각 Arguments 는 User 객체와 예상 결과를 담고 있습니다.    private static Stream&lt;Arguments&gt; wrongUserTestCases() {        return Stream.of(                // 이메일 형식이 유효하지 않은 경우                Arguments.of(\"invalid_email.com\", \"user\", \"Valid-Password-123!\",                        \"이메일 형식이 올바르지 않습니다.\"),                // 사용자 이름이 너무 짧은 경우 (최소 2자)                Arguments.of(\"valid@email.com\", \"a\", \"Valid-Password-123!\",                        \"이름은 최소 2자 이상이며, 최대 30자 입니다.\"),                // 비밀번호가 너무 짧은 경우 (최소 8자)                Arguments.of(\"valid@email.com\", \"user\", \"short1!\",                        \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\"),                // 비밀번호가 복잡성 조건을 만족하지 못하는 경우 (3가지 이상 포함)                Arguments.of(\"valid@email.com\", \"user\", \"lowercaseonly\",                        \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\"), // 소문자만                Arguments.of(\"valid@email.com\", \"user\", \"UPPERCASEONLY\",                        \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\"), // 대문자만                Arguments.of(\"valid@email.com\", \"user\", \"1234567890\",                        \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\"), // 숫자만                Arguments.of(\"valid@email.com\", \"user\", \"only!@#$\",                        \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\"), // 특수문자만                Arguments.of(\"valid@email.com\", \"user\", \"Abcdefg1\",                        \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\"), // 대문자, 소문자, 숫자 (3가지) -&gt; 통과해야 하지만, 예시를 위해 실패로 가정                Arguments.of(\"valid@email.com\", \"user\", \"Abcdefg!\",                        \"비밀번호는 최소 8자 이상, 64자 이하이며, 영문 대소문자, 숫자, 특수문자 중 3가지 이상을 포함해야 합니다.\")// 대문자, 소문자, 특수문자 (3가지) -&gt; 통과해야 하지만, 예시를 위해 실패로 가정        );    }    private static Stream&lt;Arguments&gt; rightUserTestCases() {        return Stream.of(                Arguments.of(\"valid@email.com\", \"user\", \"Abcdefg!\",                        new User(\"valid@email.com\", \"user\", PASSWORD_ENCODER.encode(\"Abcdefg!\"))),                        Arguments.of(\"valid@gmail.com\", \"user\", \"12341234\",                        new User(\"valid@gmail.com\", \"user\", PASSWORD_ENCODER.encode(\"12341234\")))        );    }    @ParameterizedTest    @MethodSource(\"wrongUserTestCases\")    void givenWrongUser_whenRegister_thenExpectedResult(            String email, String username, String password, String expected) {        ValidationException exception = assertThrows(                ValidationException.class,                () -&gt; userService.register(email, username, password)        );        assertTrue(\"예상한 메시지가 아닙니다.\", expected.contains(exception.getMessage()));    }    @Test    void givenSameUser_whenRegister_thenExpectedException() {        userService.register(\"email@email.com\", \"username\", \"Password123!\");        assertThrows(                Exception.class,                () -&gt; userService.register(\"email@email.com\", \"hi\", \"Password123!\")        );    }    @ParameterizedTest    @MethodSource(\"rightUserTestCases\")    void givenValidUser_whenRegister_thenExpectedResult(String email, String username, String password, User expected) {        Optional&lt;User&gt; user = userService.register(email, username, password);        assertTrue(\"등록 실패\", user.isPresent());        User validUser = user.get();        assertEquals(\"이메일 불일치\",  expected.getEmail(), validUser.getEmail());        assertEquals(\"이름 불일치\",  expected.getUsername(), validUser.getUsername());        assertTrue(\"패스워드 불일치\", PASSWORD_ENCODER.matches(password, validUser.getPassword()));    }}컨트롤러 수준은 더 공부하고 작성Sprint Review &amp; Retrospectivev0.1"
    },
  
    {
      "title": "7. Spring Data",
      "url": "/seonghun120614/computerscience/java/spring/2025/07/27/7.-spring-data.html",
      "date": "2025-07-27",
      "content": "🪛 한계점다양한 데이터 소스를 관리하려면 DAO 를 수행하는 객체들을 여러개 정의해야 한다.📂 목차  개요          Java Persistence API (JPA)      Spring Template      Repository      Spring Data Modules        Spring Boot RDBMS 연동하기          Spring Boot Database 스키마 정의 및 초기 데이터 설정      Spring Boot MySQL Database                  properties 설정하기          Testing                    Spring Boot PostgreSQL Database 로 변경해보기                  properties 분리하기          Postgre SQL 작성          Testing                      Spring Data JPA 사용하기          CrudRepository      @Entity 와 @Table      CrudRepository를 활용한 User Table Schema 구현      JPA 와 sql 사이의 DB 초기화 고찰                  Case 1: JPA가 테이블을 만들고, SQL은 초기 데이터만 삽입          Case 2: SQL로 테이블을 정의하고, JPA는 건들지 않음          Case 3: 둘 다 사용했지만 충돌 발생 가능          Case 4: 테스트 환경에서만 초기화                    Testing      PagingAndSortingRepository 를 활용한 페이징                  CrudRepository 와 PagingAndSortingRepository 를 통한 포스트 조회          @DataJpaTest와 @AutoConfigureTestDatabase 를 활용한 테스팅          @DataJpaTest 와 @ActiveProfiles 를 활용한 테스팅                      Spring Custom Repository          @NoRepositoryBean 애너테이션      Spring Data Query      Query Methods                  Query Pattern(Prefix)          Attribute(Entity Field)          조건 키워드          연결자          정렬 조건                    @Query 애너테이션        Criteria API          EntityManager      EntityManager 참조 및 CriteriaBuilder 선언        Spring Data JPA &amp; QueryDSL          QueryDSL 의존성 추가      QuerydslPredicateExecutor 인터페이스        Projection          인터페이스 기반 프로젝션      클래스 기반 프로젝션      📚 본문데이터 소스를 접근하기 위해 자주 쓰는 보일러 플레이트 코드들을 안쓰도록 하고, 다양한 데이터 소스에 대한 접근을 일관된 코드로 가져가서 개발자에게 편의성을 제공함과 동시에 다양한 메서드를 제공하기 위한 DAO 생성 템플릿을 지원한다.이를 위해 JDBC(Java Database Connectivity) 를 활용해 DB에 연결, 쿼리를 만들기 위한 PreparedStatement를 정의만 하면 내부적인 로직을 자동으로 짜주어서 DB 에 접근하는 세부 로직들을 다 안짜주어도 된다. 결과적으로 생산성이 비약적으로 늘어난다.우선 개념부터 보고 가자.개요Java Persistence API (JPA)JPA는 자바 객체(Entity)를 데이터베이스에 매핑하기 위한 ORM(Object-Relational Mapping) 표준 인터페이스이다.기본 구조는 다음과 같다:  Entity (자바 객체) → Persistence Provider (예: Hibernate, EclipseLink) → Database우리는 JPA가 정의한 인터페이스(API 명세)를 사용하고, 실제 동작은 Hibernate 등의 퍼시스턴스 제공자가 구현한다.즉, JPA는 표준을 정의하고, 구현체는 이를 따르는 방식으로 동작한다.Spring TemplateJDBC, JMS(Java Message Service), JNDI 등 공통적으로 사용하는 저수준 API에서는 DB 연결, 예외 처리, 자원 해제 등의 보일러플레이트 코드가 반복적으로 발생한다.Spring은 이러한 반복 작업을 줄이기 위해 Template 기반의 추상화 클래스를 제공한다.예를 들어 JdbcTemplate은 JDBC API를 사용할 때 필요한 연결, 쿼리 실행, 예외 처리, 자원 정리 등을 자동으로 처리해준다.  즉, 복잡한 try-catch 패턴 없이도 DB 작업을 간단하게 수행할 수 있다.JdbcTemplate의 역할  DB 연결 및 자원 해제 자동 처리  SQLException → DataAccessException (스프링 공통 예외로 변환)  SQL 실행 및 결과 매핑 지원 (query, update 등)RepositorySpring에서 Repository는 전통적인 DAO(Data Access Object)의 역할을 수행하는 개념이다. @Repository 어노테이션을 사용해 데이터 접근 계층을 정의하며, 이는 Spring Data Commons에 포함된 여러 인터페이스들을 통해 기능이 확장된다.Spring Data JPA나 JdbcTemplate 기반 Repository를 사용하면,  CRUD 메서드가 자동 생성되며  쿼리 메서드(findByName, countByStatus 등)도 자동 구현된다  DB 연결, 트랜잭션 처리, 예외(DataAccessExcpetion으로 일관된 처리) 변환 등은 모두 스프링이 자동으로 처리한다  Bean으로 등록  즉, 인터페이스만 정의하면 구현 없이도 기본적인 데이터 접근 로직을 자동으로 생성해준다.Spring Data Modules  Spring Data Commons  Spring Data JDBC  Spring Data JPA  Spring Data MongoDB  Spring Data Redis  Spring Data REST  Spring Data Apache Casandra  …데이터 소스들마다 모듈들이 있어 굉장히 많은 모듈이 있다. 모듈들을 이해하기 위해 모듈을 계층적으로 나눌 수 있다.  Spring Data Commons: Repository, CrudRepository, PagingAndSortingRepository  Spring Data Sub-modules: JDBC, JPA, MongoDB, Casandra  DB Layer: JDBC-MySQL, JPA-PostgreSQL, MongoDB-MongoDB, …Spring Data Commons는 Data 서브 모듈들을 사용하기 위한 일관된 인터페이스를 개발자에게 제공하고, 서브 모듈은 각각의 다양한 DB에 연결되어 데이터 소스마다 코드 차이를 개발자가 굳이 몰라도 사용할 수 있도록 한다.Spring Boot RDBMS 연동하기우선 JPA를 사용하기 위해 다음 의존성을 추가한다.implementation('org.springframework.boot:spring-boot-starter-data-jpa') {    exclude group: 'com.zaxxer', module: 'HikariCP'}여기서 HikariCP 말고 Connection Pool 로 다음을 설정한다.implementation 'org.apache.tomcat:tomcat-jdbc:10.1.20' // 커넥션 풀 tomcat jdbc 사용커넥션 풀은 서비스마다 알맞은걸 사용하면 된다.Spring Boot Database 스키마 정의 및 초기 데이터 설정데이터베이스 스키마를 정의하는 부분은 resources/schema.sql, resources/data.sql 에서 할 수 있다. 그 전에 *.sql을 사용하도록 하기 위해 spring 에서 다음 프로퍼티를 설정해주어야 한다.# application.properties# always 내장DB, 외장DB든 상관 없이 항상 SQL 파일 실행# embedded(기본값) H2, HSQL 등의 내장 DB 에서만 SQL 파일 실행# never SQL 초기화 파일 실행 안함spring.sql.init.mode=always# schema.sql + data.sql 사용을 명시spring.sql.init.schema-locations=classpath:schema.sqlspring.sql.init.data-locations=classpath:data.sql# Hibernate가 테이블 만들지 않도록 설정spring.jpa.hibernate.ddl-auto=none# JPA SQL 쿼리를 콘솔에 출력하도록 함spring.jpa.show-sql=true스키마를 설정한다.// schema.sqlCREATE TABLE IF NOT EXISTS USERS (  id INT AUTO_INCREMENT PRIMARY KEY,  name VARCHAR(100),  email VARCHAR(100));기본적으로 핸들링 할 데이터를 추가해준다.// data.sqlINSERT INTO USERS(id, name, email)SELECT 1, 'Alice', 'alice@example.com'WHERE NOT EXISTS (SELECT 1 FROM USERS WHERE id = 1);데이터는 그냥 GPT 가 주는 예시로 했다.Spring Boot MySQL Database우선 mysql을 연결하기 위해 다음 의존성을 추가해줘야 한다.runtimeOnly 'mysql:mysql-connector-java:8.0.33'dev 환경에서 MySql server를 내부적으로 사용하기 위해 다음을 입력한다. 포트는 3306이다.docker run --name mysql-dev \\  -e MYSQL_ROOT_PASSWORD={password} \\  -e MYSQL_DATABASE={DB 이름} \\  -p 3306:3306 \\  -d mysql:8properties 설정하기자주 사용되는 url과 password 등을 properties에 저장한다.# mysql.propertiesspring.datasource.url=jdbc:mysql://localhost:3306/{DB 이름}spring.datasource.username=rootspring.datasource.password=1234spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver필자는 mysql.properties 를 만들어, application.properties에spring.config.import=classpath:mysql.properties를 추가해줬다.다양한 방법으로 import 해준다. Spring Data 에서 자체적으로 DataSource 라는 싱글톤 객체에 우리가 정의한 spring.datasource 프로퍼티들을 토대로 자동으로 connection 을 생성해준다. 이를 log 찍어보자.Testing@Testpublic void givenDatasourceAvailableWhenAccessDetailsThenExpectDetails()        throws SQLException {    assertThat(dataSource.getClass().getName())            .isEqualTo(\"org.apache.tomcat.jdbc.pool.DataSource\");    assertThat(dataSource.getConnection().getMetaData().getDatabaseProductName())            .isEqualTo(\"MySQL\");}기본적으로 예외 처리 또한 일관성 있게 지원해주기 때문에 메서드에 throws SQLException 만 넣어주면 exception 을 받을 수 있다. 이제 데이터 또한 들어갔는지를 살펴보자.@Testpublic void givenUserWhenGetUserNameByIdThenGetUser() throws Exception {    try(            Connection cn = dataSource.getConnection();            PreparedStatement ps = cn.prepareStatement(\"SELECT name FROM USERS WHERE id=1\");            ResultSet rs = ps.executeQuery();    ) {        if (rs.next())            assertThat(\"Alice\").isEqualTo(rs.getString(\"name\"));        else            fail(\"No user found with id=1\");    }}현재 JPA Repository를 따로 정의하지 않았기 때문에, Spring Data JPA의 기능은 사용하지 않고 순수 JDBC 방식으로 테스트를 진행했다.Spring Boot PostgreSQL Database 로 변경해보기Postgre 전용 db 를 사용하기 위한 임시 서버를 연다. 포트는 5432 이다.docker run --name postgres-dev \\  -e POSTGRES_USER={username} \\  -e POSTGRES_PASSWORD={password} \\  -e POSTGRES_DB={DB 이름} \\  -p 5432:5432 \\  -d postgres:15의존성을 추가해준다.runtimeOnly 'org.postgresql:postgresql'properties 분리하기postgre 를 사용할 때는 세팅 값이 바뀌어야 하므로 postgres, mysql 별로 properties 를 따로 만들어준다.# application-postgres.properties# DB Initializespring.sql.init.schema-locations=classpath:db/postgres/schema.sqlspring.sql.init.data-locations=classpath:db/postgres/data.sql# DataSourcespring.datasource.url=jdbc:postgresql://localhost:5432/{DB 이름}spring.datasource.username={username}spring.datasource.password={password}spring.datasource.driver-class-name=org.postgresql.Driver위를 만들어준다고 해서 자동으로 참조하지는 않는다. application.properties에서 다음을 넣어주면 된다.# application.propertiesspring.profiles.active=postgres이렇게 되면 db server 가 바뀔 때마다 이 property 만 바꿔주면 될 터이다.Postgre SQL 작성-- shema.sqlCREATE TABLE IF NOT EXISTS USERS (  id INT GENERATED ALWAYS AS IDENTITY PRIMARY KEY,  name VARCHAR(100),  email VARCHAR(100));-- data.sqlINSERT INTO USERS(id, name, email)OVERRIDING SYSTEM VALUEVALUES (1, 'Alice', 'alice@example.com')ON CONFLICT (id) DO NOTHING;Testing@Testpublic void givenDatasourceAvailableWhenAccessDetailsThenExpectDetails()        throws SQLException {    assertThat(dataSource.getClass().getName())            .isEqualTo(\"org.apache.tomcat.jdbc.pool.DataSource\");//\t\tassertThat(dataSource.getConnection().getMetaData().getDatabaseProductName())//\t\t\t\t.isEqualTo(\"MySQL\");    assertThat(dataSource.getConnection().getMetaData().getDatabaseProductName())            .isEqualTo(\"PostgreSQL\");}@Testpublic void givenUserWhenGetUserNameByIdThenGetUser() throws Exception {    try(            Connection cn = dataSource.getConnection();            PreparedStatement ps = cn.prepareStatement(\"SELECT name FROM USERS WHERE id=1\");            ResultSet rs = ps.executeQuery();    ) {        if (rs.next())            assertThat(\"Alice\").isEqualTo(rs.getString(\"name\"));        else            fail(\"No user found with id=1\");    }}테스트에서 수정할 부분은 한가지 뿐이다(찾아보아라).Spring Data JPA 사용하기코드에서도 데이터베이스에 대한 명령을 수행할 수 있고, 이를 JPA를 통해 한다고 사전에 보았을 것이다. 여기서는 이 JPA의 가장 기본적인 Persistence Provider 의 Repository 를 본다.@Indexedpublic interface Repository&lt;T, ID&gt; { }Repository 인터페이스를 파보면 제너릭 타입 T, ID 가 있음을 볼 수 있다. ID 는 행을 구분하는 즉, 레코드를 구분하는 컬럼 명 혹은 필드 명이다. T는 이 ID 의 타입을 선언한다.하지만 내부는 비어있는걸 볼 수 있는데 이를 Marker Interface 라고 한다.CrudRepositoryRepository를 상속 받는 CrudRepository를 보자. 자주 사용하는 놈이다.@NoRepositoryBeanpublic interface CrudRepository&lt;T, ID&gt; extends Repository&lt;T, ID&gt; {\t&lt;S extends T&gt; S save(S entity);\t&lt;S extends T&gt; Iterable&lt;S&gt; saveAll(Iterable&lt;S&gt; entities);\tOptional&lt;T&gt; findById(ID id);\tboolean existsById(ID id);\tIterable&lt;T&gt; findAll();\tIterable&lt;T&gt; findAllById(Iterable&lt;ID&gt; ids);\tlong count();\tvoid deleteById(ID id);\tvoid delete(T entity);\tvoid deleteAllById(Iterable&lt;? extends ID&gt; ids);\tvoid deleteAll(Iterable&lt;? extends T&gt; entities);\tvoid deleteAll();}메서드 명은 설명 안해도 될 정도로 직관적이고 명확하다. 위 메서드를 다 지원하며, 굳이 이를 상속하는 구현체에 위 메서드를 다 구현해야 하는 수고를 덜 수 있다.이제 이를 사용해야 하는데, JVM은 DB 쪽 서버에서 정의된 스키마를 모르기에 Java 내에서 해당 레코드와 맞먹는 클래스를 구현해야 한다. 다음을 정의하자.@Entity 와 @Table엔티티는 DB의 한 테이블에 매핑되는 도메인 객체(비즈니스 모델)이며, 스키마와 1:1로 대응될 수 있도록 정의된다. USERS 테이블에 대응되는 비즈니스 엔티티를 만들어보자.import jakarta.persistence.*;import lombok.*;@Entity@Table(name = \"USERS\")@Datapublic class User {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Integer id;    @Column(length = 100)    private String name;    @Column(length = 100, nullable = false)    private String email;    public User() {}    public User(@NonNull String name, @NonNull String email) {        this.name = name;        this.email = email;    }}  NonNull 과 Data 어노테이션은 필자의 Lombok 글을 보자.@NonNull과 @Data는 Lombok 애노테이션이며, @NonNull은 생성자 인자에 null이 들어오지 않도록 런타임 검사를 수행한다.@Data를 사용하더라도 Spring Data JPA는 생성자 기반 객체 생성을 하지 않을 수도 있기 때문에, 명시적 생성자를 선언해주는 것이 안정적이다.MySQL 기준으로 Java 의 타입과 DB 스키마의 필드 타입 매핑은 다음과 같다.  INT - Integer, int  BIGINT - Long  VARCHAR(n) - String  CHAR(n) - String  TEXT, LONGTEXT - String  BOOLEAN, TINYINT(1) - Boolean / boolean  DATE - java.time.LocalDate  DATETIME, TIMESTAMP - javatime.LocalDateTime  DECIMAL, NUMERIC, FLOAT, DOUBLE - java.math.BigDecimal  이진 관련 데이터 - byte[]주의할 점  int 는 null 을 허용하지 않기 때문에 자동으로 생성되는 ID의 값과 충돌 가능성이 있다Integer이나 Long을 사용하여 null을 허용하고 DB 자체에 접근이 될때 미지정 상태로 넣어주면 DB에서 알아서 정의해줄 것이다.따라서, Long은 BIGINT AUTO_INCREMENT 와도 같고, Integer은 INT AUTO_INCREMENT와 같다. int 의 사용은 되도록 일반적인 필드에서만 사용하도록 하자. 그리고 이를 java 에서 사용하고 싶다면 @GeneratedValue(strategy = GenerationType.IDENTITY)를 추가하여 해당 필드가 AUTO_INCREMENT 임을 타 프로그래머와 제 3자에게 알려주자.또한, PK, FK, 누적값에 대한 필드에 대해서는 Long을 쓰는 것이 더 바람직하다.  TEXT 계열은 인덱싱 제한이 있기 때문에 검색 필드로는 사용 주의가 필요하다.GenerationValue  GeneratedType.Table: DB의 AUTO_INCREMENT를 사용하지 않고 JPA 구현체가 ID를 직접 증가시키기 위해 직접 키 생성 전용 테이블을 만들어서 사용, schema 에서 AUTO_INCREMENT를 빼야 함.  GeneratedType.Identity: DB에서 생성된 식별자 컬럼에서 생성된 값을 기본키로 사용  GeneratedType.Sequence: 이름 그대로 JPA 구현체가 데이터베이스의 시퀀스를 사용하여 키를 생성하고 이를 기본키로 사용  GeneratedType.Auto: JPA 구현체가 기본 키 생ㅅ어 방식을 스스로 결정TIP  어노테이션 @Column 에 자체적으로 length 라는 인자를 받을 수 있는데 이를 설정해주는 걸로 VARCHAR 의 길이와 매핑이 된다.Java에는 String이 null 값을 가질 수도 있는데, 이를 제어하기 위해 @Column(nullable = false) 를 해주면 무조건 입력하도록 하게 할 수 있다(unique 인자도 있음).이제 정의된 Entity 를 Table Schema와 연결시키자.@Data@Table(name = \"USERS\")public class User {이제 JPA 를 사용하기 위한 준비가 끝났다(Repository 사용 준비 끝).CrudRepository를 활용한 User Table Schema 구현import com.example.study.dao.entity.*;import org.springframework.stereotype.Repository;import org.springframework.data.repository.CrudRepository;@Repositorypublic interface UserRepository extends CrudRepository&lt;User, Long&gt; { }이제 JPA 에서 제공하는 CRUD, 쿼리 메서드들을 사용할 수 있게 된다. 나머지 필요한 메서드는 서비스가 요구하는 상황에 맞춰 그때그때 추가해주는게 바람직하다.JPA 와 sql 사이의 DB 초기화 고찰이제 프로퍼티에 관해서 보자. 앞서 봤듯이 우리는 sql 문을 통해 초기 데이터들을 정의하고 테스트를 수행했는데 그렇다면, 단순 SQL 파일이 아닌 JPA 자체를 통해서도 초기 데이터를 설정할 수 있지 않을까 하는 의문이 생긴다.sql로 수행할 때, 다음 properties 들을 썼다:  spring.jpa.hibernate.ddl-auto: JPA가 ddl을 어떻게 처리할 지에 대해 명시          create-drop 은 엔티티를 기반으로 테이블 생성      create 는 엔터티를 기반으로 새 테이블 생성(기존 테이블 모두 삭제)      update 는 엔터티를 기반으로 스키마를 업데이트하며 기존 테이블이 있다면 수정하고 없으면 생성      validate 는 프로덕션 환경에서 스키마가 올바른지 확인      none 은 Hibernate 가 전혀 스키마를 관리하지 않는다.        spring.sql.init.mode: schema.sql/data.sql 실행 여부 제어이제 이를 조금 바꿔가면서 케이스마다 어떤 프로퍼티 값을 가지게 해야할지 정리해보자.Case 1: JPA가 테이블을 만들고, SQL은 초기 데이터만 삽입spring.jpa.hibernate.ddl-auto=createspring.sql.init.mode=alwayscreate는 애플리케이션 시작 시 테이블을 모두 드롭 후 재생성하는 설정이다.즉, 기존 데이터는 매번 삭제되며, 테스트나 개발 초기에만 사용하기 적합하다.이 설정에서는 JPA가 직접 스키마를 생성하므로, schema.sql은 무시되고 실행되지 않는다.다만 data.sql은 JPA가 테이블 생성을 완료한 후에 실행되기 때문에 초기 데이터 삽입 용도로는 유효하다.Case 2: SQL로 테이블을 정의하고, JPA는 건들지 않음spring.jpa.hibernate.ddl-auto=nonespring.sql.init.mode=alwaysSQL 파일에 모든 테이블과 초기 데이터를 명시적으로 관리한다. 보통 실무에서 많이 사용한다.Case 3: 둘 다 사용했지만 충돌 발생 가능update는 JPA 기준으로 테이블을 수정하려고 시도하며, 동시에 schema.sql이 적용되면서로의 구조가 충돌할 수 있다. 특히 컬럼 중복, 타입 불일치 시 오류 발생 가능하다.spring.jpa.hibernate.ddl-auto=updatespring.sql.init.mode=always유지보수가 어렵고 예측이 불가능하다. 비추천Case 4: 테스트 환경에서만 초기화내장 DB 전용이다.spring.jpa.hibernate.ddl-auto=createspring.sql.init.mode=embedded내장 DB일 때만, schema.sql, data.sql이 실행되고,실제 MySQL이나 PostgreSQL에서는 schema.sql, data.sql이 무시된다.서버를 올리고 나서는 JPA를 기준으로 돌아가게 된다.Testing테스트를 하기 전에 위의 경우들에 맞춰 프로퍼티를 설정해주길 바란다.import com.example.study.dao.entity.*;import org.junit.jupiter.api.*;import org.springframework.beans.factory.annotation.*;import org.springframework.boot.test.context.*;import static org.junit.jupiter.api.Assertions.*;@SpringBootTestpublic class UserRepositoryTest {    @Autowired    UserRepository userRepository;    @Test    public void givenCreateUserWhenLoadTheUserThenExpectExistedUser() {        User user = new User(\"IU\", \"1234\");        userRepository.save(user);        assertEquals(\"IU\", userRepository.findById(1L).orElseThrow(                () -&gt; new AssertionError(\"User not found\")        ).getName());    }    @Test    public void givenCreateUserWhenLoadTheUserThenExpectSameUser() {        User user = new User(\"Alice\", \"alice@alice.co.kr\"); // 여기선 user id 가 null 이지만        User savedUser = userRepository.save(user); // 여기서는 user id가 자동 설정됨        assertEquals(user, savedUser);    }    @Test    public void givenUpdateUserWhenLoadTheUserThenExpectUpdatedUser() {        User user = userRepository.findById(1L)                .orElseThrow(() -&gt; new AssertionError(\"User not found\"));        user.setName(\"Bob\");        userRepository.save(user);        User foundUser = userRepository.findById(1L).get();        assertNotEquals(\"IU\", foundUser.getName());        assertEquals(\"Bob\", foundUser.getName());    }    @Test    public void givenDeleteUserWhenLoadTheUserThenExpectNoUser() {        long total = userRepository.count();        User user = userRepository.findById(1L)                .orElseThrow(() -&gt; new AssertionError(\"User not found\"));        userRepository.delete(user);        assertEquals(total-1,userRepository.count());        userRepository.deleteAll();        assertEquals(0L, userRepository.count());    }}전부 통과해야 한다.PagingAndSortingRepository 를 활용한 페이징어떤 쇼핑몰이든 게시물들이던 1000만 개의 포스트나 글들을 불러오는 것은 굉장히 무거운 작업이다. 따라서 많은 양의 데이터를 여러 페이지로 잘게 나눠서 조회한다면 page 만큼의 양만 조회하기 때문에 효율적이게 된다. 이런 기술을 Paging 이라고 한다.스프링 데이터에서는 PagingAndSoringRepository 인터페이스를 지원하며, Repository 를 상속 받는 클래스이다.CrudRepository 와 PagingAndSortingRepository 를 통한 포스트 조회하기 전에 새로운 엔티티를 다루자. Paging 기능을 극한으로 활용할 수 있는 곳은 게시글, 상품 글들 보기 등등 일 것이다. 필자는 게시글로 Post 엔티티를 정의한다. 정의하기 전에 low-level의 DB 단에서 schema 를 정의한다.DROP TABLE IF EXISTS USERS;DROP TABLE IF EXISTS POSTS;CREATE TABLE USERS (  id BIGINT AUTO_INCREMENT PRIMARY KEY,  name VARCHAR(100),  email VARCHAR(100));CREATE TABLE POSTS (  id BIGINT AUTO_INCREMENT PRIMARY KEY,  created_at DATETIME NOT NULL,  title VARCHAR(50),  content TEXT);초기 데이터도 삽입해준다(물론 필자는 init.mode 가 never 이지만 넣어줬다).INSERT INTO USERS (name, email)SELECT 'Alice', 'alice@example.com';INSERT INTO POSTS (time, title, content)VALUES (NOW(), 'Spring Boot Intro', 'This is the content of the post.');포스트를 선언하자.package com.example.study.dao.entity;import jakarta.persistence.*;import lombok.*;import java.time.*;@Entity@Table(name = \"POSTS\")@Datapublic class Post {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Long id;    @Lob    @Column(nullable = false)    private LocalDateTime createdAt;    @Column(length = 50, nullable = false)    private String title;    @Column(nullable = false)    private String content;    public Post() {}    public Post(@NonNull LocalDateTime createdAt, @NonNull String title, @NonNull String content) {        this.createdAt = createdAt;        this.title = title;        this.content = content;    }}이제 Repository를 선언해준다.import com.example.study.dao.entity.*;import org.springframework.data.repository.*;import org.springframework.stereotype.Repository;@Repositoryimport com.example.study.dao.entity.*;import org.springframework.data.repository.*;import org.springframework.stereotype.Repository;@Repositorypublic interface PostRepository extends PagingAndSortingRepository&lt;Post, Long&gt;, CrudRepository&lt;Post, Long&gt; { }테스트를 작성하자.import com.example.study.dao.entity.*;import org.junit.jupiter.api.*;import org.springframework.beans.factory.annotation.*;import org.springframework.boot.test.context.*;import org.springframework.data.domain.*;import java.time.*;import java.util.*;import static org.junit.jupiter.api.Assertions.*;@SpringBootTestclass PostRepositoryTest {    @Autowired    PostRepository postRepository;    @Test    void readPostWhenLoadThePostThenExpectExistedPost() {        // given        Post post1 = new Post(                LocalDateTime.of(2025, 7, 3, 10, 0),                \"Spring Boot Intro\", \"Introduction to Spring Boot\"        );        Post post2 = new Post(                LocalDateTime.of(2025, 7, 3, 11, 0),                \"JPA Basics\", \"Learn JPA with Spring\"        );        Post post3 = new Post(                LocalDateTime.of(2025, 7, 3, 12, 0),                \"Testing with JUnit\", \"Unit testing guide\"        );        Post post4 = new Post(                LocalDateTime.of(2025, 7, 3, 13, 0),                \"REST API\", \"Building REST APIs\"        );        Post post5 = new Post(                LocalDateTime.of(2025, 7, 3, 14, 0),                \"Spring Security\", \"Securing applications\"        );        Post post6 = new Post(                LocalDateTime.of(2025, 7, 3, 15, 0),                \"Advanced JPA\", \"Advanced JPA techniques\"        );        postRepository.saveAll(List.of(post1, post2, post3, post4, post5, post6));        Pageable pageable = PageRequest.of(0, 5);        // when        Page&lt;Post&gt; page = postRepository.findAll(pageable);        assertEquals(0, page.getNumber());        assertEquals(5, page.getSize());        assertEquals(5, page.getNumberOfElements());        assertEquals(6, page.getTotalElements());        // then        List&lt;Post&gt; posts = page.getContent();        assertTrue(posts.stream().anyMatch(post -&gt;                        post.getId().equals(1L) &amp;&amp; post.getTitle().equals(\"Spring Boot Intro\")),                \"ID가 1이고 제목이 'Spring Boot Intro'인 Post가 존재해야 한다.\");    }}@DataJpaTest와 @AutoConfigureTestDatabase 를 활용한 테스팅우리는 테스트를 할 때 항상 IoC 에 Bean 을 전부 등록하고, 다 등록된 후에야 테스트를 수행하게 된다. 단위 테스트에 대해서는 테스트 할 컴포넌트와 의존적인 컴포넌트만 올리면ㄷ 되지만, 다른 컴포넌트까지 올려버리기 때문에 굉장히 비효율적이다. 따라서 이를 방지하기 위해 Spring 에서는 Data 에 대한 컴포넌트 끼리의 테스트 컨텍스트를 구분시켜주는 어노테이션을 지원해준다.DataJpaTest 를 사용하려면 다음과 같이 어노테이션을 테스트 클래스 레벨에 붙여준다.@DataJpaTest@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)여기서 AutoConfigureTestDatabase 의 역할은 기본적으로 테스트 수준에서의 DB는 In-memory 를 사용하여 데이터를 관리하기 때문에 이걸 참조하는 프로퍼티를 비활성화 해주어야 한다. 이는 AutoConfigureTestDataBase 를 통해 해당 인메모리 DB 로의 대체를 비활성화해주는 프로퍼티를 넣어주면 application.properties 의 DB 구성 설정을 따르게 된다.@DataJpaTest 와 @ActiveProfiles 를 활용한 테스팅스프링 데이터에서 자동으로 설정해주는 테스트 환경으로 하기가 싫을 때, properties 가 이미 test 환경에 대한 구성 설정 properties 파일이 있을 때는 다음 어노테이션 @ActiveProfiles 을 사용하여 우리가 db properties 를 설정만으로 바꾸 듯이 여기서도 사용할 수 있게 된다.import ...@DataJpaTest@ActiveProfiles(\"test\") // application-test.properties 로드public class PostRepositoryTest {    ...}이제 application-test.properties 를 설정해주도록 하자.Spring Custom Repository실무에서는 CRUD 기능들 중에 front에게 굳이 노출하지 않아도 되는 API는 숨겨야 한다. 스프링 데이터의 레포지토리는 인터페이스를 사용하여 어플리케이션 도메인 객체를 관리하지만, 이 인터페이스들을 요구사항에 맞게 구현시키도록 한다.이는 근본적인 Repository 를 먼저 상속하는 인터페이스를 구현하여, 이를 해결할 수 있다. 예를들어 create, read 만 구현하고 싶다면 다음과 같이 근본 repository 를 정의할 수 있다.import org.springframework.data.repository.*;public interface BaseRepository&lt;T, ID&gt; extends Repository&lt;T, ID&gt; {    &lt;S extends T&gt; S save(S entity);    Iterable&lt;T&gt; findAll();}@NoRepositoryBean 애너테이션여기서 위처럼 interface를 선언하고 서비스를 구동하면 BaseRepository 라는 빈이 생성될 것이다. 즉 구현체가 만들어진다. 이를 방지하기 위해 @NoRepositoryBean 애너테이션을 사용하여서 이를 내려주자.package com.example.study.dao;import org.springframework.data.repository.*;public interface BaseRepository&lt;T, ID&gt; extends Repository&lt;T, ID&gt; {    &lt;S extends T&gt; S save(S entity);    Iterable&lt;T&gt; findAll();}Spring Data Query스프링 데이터에서는 Repository 인터페이스를 통해 다양한 기본 CRUD 쿼리를 제공해주지만, 이보다 더 많고 다양한 쿼리들을 정의하고 싶을 수 있다. 엔티티의 프로퍼티에 조건을 걸어서 조회하거나 하나 이상의 프로퍼티를 기준으로 정렬 조회 같은 것도 하고 싶을 수 있다. 스프링 데이터는 다음 두 가지 방법을 지원한다.  Query Method: 인터페이스에 메서드의 이름을 패턴에 맞게 작성하면 스프링 데이터가 알아서 파싱하여 맞는 쿼리 만들어냄  선언적 Query: 필요한 쿼리문을 직접 작성해서 전달해주면 스프링 데이터가 이 쿼리를 실행Query MethodsQuery Methods 는 스프링 데이터에서 주는 패턴만 잘 따르도록 메서드를 정의하면 알아서 쿼리를 실행한다.  [쿼리 패턴][속성 이름][조회 키워드][연결자][조건]다음 규칙을 가지며, 보통 맨 앞의 쿼리 패턴에는 다음이 올 수 있다.Query Pattern(Prefix)            쿼리 패턴(Prefix)      설명                  findBy      조건에 맞는 데이터를 조회함 (가장 일반적)              getBy      findBy와 유사하지만, 반드시 결과가 있어야 함을 암시              readBy      findBy와 유사, 읽기 동작 강조              queryBy      쿼리 수행의 의도를 강조하는 표현              countBy      조건에 맞는 데이터의 개수를 반환              existsBy      조건에 맞는 데이터의 존재 여부를 반환 (boolean)              deleteBy      조건에 맞는 데이터를 삭제              removeBy      deleteBy와 동일하게 작동, 표현의 차이만 있음        반환 타입에 따라 여러 개 인지 하나인지 알 수 있지만, 보통은 findAll 처럼 여러개가 반환되면 시그니처에 All 을 붙여 제 3자의 프로그래머에게 알려주는 것이 좋다.또한 Optional을 반환으로 썼다는 것은 해당 타입이 0개 혹은 1개 인지를 말해준다. 존재하지 않다면 .empty() 메서드가 true 일터이다.Attribute(Entity Field)  CamelCase 로 작성  대소문자 구분 없음조건 키워드            조건 키워드      설명                  Is, Equals      값이 일치함 (=)              Between      두 값 사이의 범위              LessThan, LessThanEqual      미만, 이하 조건 (&lt;, &lt;=)              GreaterThan, GreaterThanEqual      초과, 이상 조건 (&gt;, &gt;=)              IsNull, IsNotNull      null 여부 판단              Like, NotLike      SQL LIKE 문 (부분 일치)              StartingWith, EndingWith, Containing      문자열 시작, 끝, 포함 여부 (LIKE 기반)              In, NotIn      포함/제외된 값들 집합 (IN 조건)              True, False      boolean 값 조건      연결자설명 생략  And  Or정렬 조건설명 생략  Asc  Desc  쿼리메서드는 반환되는 게 여러 개라면 Iterable, Stream 으로 반환되지만, Stream 을 쓸 때는 Transactional 사용을 유의해야 한다. 따로 다룰 수도 있다.Stream은 map-reduce-filter 를 사용하여 대용량 데이터를 다룰 수 있다.Query 애너테이션을 활용한 커스텀 쿼리 선언두 번째 방법이며, 다양한 쿼리문 자체를 넣어 다음 장점을 가져갈 수 있다.  특정 DB에 특화된 기능을 사용하여 최적화된 쿼리를 활용하기 위함  두 개 이상의 테이블을 조인하기 위함NamedQuery, Query, QueryDSL 을 사용해 쿼리문을 직접 지정할 수 있다.@NamedQuery 애너테이션자카르타 퍼시스턴스 쿼리 언어(Jakarta Persistence Query Lang., JPQL) 을 사용하여 쿼리를 정의한다. NamedQuery는 엔티티 클래스, 엔티티 클래스의 super 클래스에 정의하기 때문에 실제 repository 클래스가 행해야 하는 일을 이 애너테이션을 통해 엔티티에 클래스에 붙여버리면 책임분리가 안되며 프로그래머가 찾지도 못할 수 있다. 하지만 다양한 방법 중에 하나이므로 이것도 살펴본다.NamedQuery 는 인자로 다음을 가지고 있다:  name: 보통 엔티티명.쿼리명 형식을 따르도록 넣는다.  query: JPQL 로 작성된 문자열이며, SQL 과 유사하지만, 테이블과 컬럼 ㅐ신 엔티티 클래스와 그 속성을 참조한다. ?1, ?2와 같은 문자열은 :paramName 같은 이름 기반의 파라미터를 사용한다. 예를들어 ?email을 사용한다면 repository 에서 API 선언으로 @Param(“email”) 로 매핑할 수 있다.  lockMode(선택)  hints(선택)NamedQuery를 여러개 쓰고 싶다면 @NamedQueries를 사용하면 된다.@Query 애너테이션위 NamedQuery를 사용하면 비즈니스 도메인 클래스가 데이터 저장/조회와 strictly coupling 이 발생한다. 따라서 해당 애너테이션의 위치를 옮겨야 한다. 이때 query를 통해 작성한다.@Repositorypublic interface PostRepository extends PagingAndSortingRepository&lt;Post, Long&gt;, CrudRepository&lt;Post, Long&gt; {    @Query(\"SELECT p FROM      p WHERE :keyword IN p.content\")    Iterable&lt;Post&gt; search(@Param(\"keyword\") String keyword);}위와 같이 작성한다면 비즈니스 엔티티는 정의에 대한 책임, 레포지토리는 엔티티 관리와 생성, 삭제에 대한 책임으로 분리가 되며, 가독성 측면에서도 엔티티와 레포지토리 둘 다 안보아도 된다. 만약 native query를 사용하고 싶다면 다음과 같이 입력하면 된다.@Repositorypublic interface PostRepository extends PagingAndSortingRepository&lt;Post, Long&gt;, CrudRepository&lt;Post, Long&gt; {    @Query(\"SELECT p FROM POSTS p WHERE p.content LIKE %:keyword%\")    Iterable&lt;Post&gt; search(@Param(\"keyword\") String keyword);}⭐️수정과 삭제에 대한 데이터 일관성 가져오기@Modifying@Transactional@Query(\"UPDATE POSTS p set p.content=:content WHERE p.id=:id\")int updateCourseRatingByName(@Param(\"id\") Long id, @Param(\"content\") String content);      @Modifying 애너테이션: @Query 애너테이션과 같이 쓰며, 정의된 쿼리가 조회가 아닌 수정 작업을 한다는 것을 알려준다. Modifying 애너테이션을 붙이지 않은 데이터의 변경이 수반되는 쿼리를 사용하면 InvalidDataAccessApiUsageException의 예외가 발생한다.        @Transactional 애너테이션: 데이터 변경(예: INSERT, UPDATE, DELETE)과 같은 작업을 트랜잭션 단위로 관리하는 데 사용되며, 원자성을 보존하게 되어 작업이 모두 완료되거나(COMMIT) 취소(ROLLBACK) 단위로 사용하게 된다.  중요하다. 다음 글을 읽기 전에는 Java 의 persistence 패키지를 보고 오자(Spring 섹션에서 안다룸).Criteria API위에서 사용된 애너테이션 내에서 사용되는 쿼리를 JPQL 쿼리라고 한다. JPQL을 컴파일 타입에서 검증할 수 없기 때문에 잘못 작성한 쿼리에 대한 문제는 런타임 에러로만 발견할 수 있다.이런 문제점을 방지하기 위해서 Criteria API를 사용하여 쿼리문을 문자열이 아닌 프로그램 소스처럼 작성하도록 하여 타입 안전성을 확보할 수 있다.EntityManagerJPA 를 관리하는 객체인 EntityManager는 엔티티의 생명주기를 관리하는 애다. javax.persistence.EntityManager 의 인터페이스를 따라야 하며, Spring은 이를 참고하여 편리하게 사용할 수 있도록 할 뿐이다. Spring의 EntityManager 의 관리 범위는 다음과 같다.  Managing Persistence Context: 영속성 컨텍스트라는 개념이 나오는데 DB에 실제로 저장하기 전에 1차적으로 저장하는 캐시와 유사하다. 여기서 미리 처리를 다 하고 이를 올리게 된다. git 에서 local 의 작업이 끝나고 최종 결과를 root 에 올리는 것과 유사하다.  Persisting Entity: 영속성 컨텍스트(Persist Context)가 있는데 여기에 저장되는 엔티티들은 보통 DB에 저장되기 직전 준비를 하고 있는 데이터들이다.  Transaction Context: EntityManager는 EntityTransaction 인터페이스를 통해 데이터베이스 트랜잭션을 시작하고 커밋하며 롤백하는 기능을 제공한다. 하지만 스프링 같은 프레임워크에서는 보통 선언적 트랜잭션(@Transactional) 관리를 통해 자동으로 처리되게 된다.  Query Creation and Excution: createQuery(), createNamedQuery(), createNativeQuery(), getCriteriaBuilder() 등을 통해 다양한 쿼리를 생성하고 실행하여 데이터를 조회하거나 조작할 수 있다.밑은 기본적으로 있어야 할 기능이기에 따로 뺐다.  Finding Entity: find() 메서드를 통해 PK 로 조회를 할 수 있다. 보통 find 보다는 createQuery(), createNamedQuery() 를 사용하여 조회를 하는 경우가 대부분이다.  Updating Entity: Persistence Context 의 entity 상태가 변경되면 트랜잭션이 commit 될 때 자동으로 변경 사항을 저장하게 된다.  Removing Entity: remove() 메서드는 영속성 컨텍스트에서 엔티티를 제거하며, 트랜잭션 commit 시 데이터베이스에서도 해당 엔티티가 삭제되도록 한다.이제 위를 참고하여 Criteria Query 를 작성해보자.EntityManager 참조 및 CriteriaBuilder 선언쿼리를 만들기 위해서, 엔티티를 관리하기 위해서 EntityManager 를 들고 와야 한다. Spring 의 Bean 에 자동으로 등록되는 EntityManager 를 테스트던 Repository 클래스 컨텍스트 쪽에서 자동주입으로 들고오자.@Autowiredprivate EntityManager em;엔티티를 관리하기 위한, JPA를 사용하기 위한 준비가 끝났다. 이제 쿼리를 검증하기 위한 클래스를 가져오자. CriteriaBuilder 는 검증하기 위한 쿼리를 생성하기에 앞서 부분 부분 각 쿼리의 절(SELECT 절, WHERE 절 등등) 의 절과 Query의 뼈대를 만들기 위한 빌더 패턴이다.당연히 EntityManager 의 getCriteriaBuilder() 메서드를 통해 들고 올 수 있다(EntityManager 가 보통 다 가지고 있다).CriteriaBuilder cb = em.getCriteriaBuilder();쿼리의 뼈대를 생성하고 살을 채워넣자.// 쿼리 뼈대 생성CriteriaQuery&lt;Post&gt; criteriaQuery = cb.createQuery(Post.class);이제 살을 채워주자. 채워주기 전에 참조를 쉽게쉽게 코딩하기 위해 참조를 저장하는 것을 생성한다. 여기서 참조의 명세는 Root로 되어있다.// SELECT * FROM Post 와 같은 격Root&lt;Post&gt; root = criteriaQuery.from(Post.class);쿼리 작성// SELECT * FROM Post as root WHERE root.title = \"HA HA HA Example\"criteriaQuery.select(root)        // root.get(\"컬럼명\") 으로 database 구성요소를 들고 올 수 있다.        .where(cb.equal(root.get(\"title\"), \"HA HA HA Example\"));여기서 에러 처리를 위해 더 구분하고 싶다면 where 절의 Predicate 인스턴스를 넣는 곳을 분리시켜주면 된다. 위를 지우고 다음처럼 써보자.Predicate condition = cb.equal(root.get(\"title\"), \"HA HA HA Example\");만든걸 종합하면 다음과 같다.    @Test    void givenSelectWhenLoadedTheDataThenExpectedResult() {        // Take CriteriaBuilder for handling Entity        CriteriaBuilder cb = entityManager.getCriteriaBuilder();        // Define Blueprint for Post CriteriaQuery        CriteriaQuery&lt;Post&gt; cq = cb.createQuery(Post.class);        // Write Statement        Root&lt;Post&gt; p = cq.from(Post.class);        Predicate condition = cb.equal(p.get(\"title\"), \"Hello World\");        // Merge        cq.select(p)                .where(condition);    }여기서는 타입 검사가 자동으로 일어나고 JPQL 쿼리를 직접 날 것으로 작성하지 않아도 쿼리를 날릴 수 있는 것을 볼 수 있다.이제 검증 쿼리가 아닌 실제 쿼리로 바꾸어서 결과를 fetch 해오자.    @Test    void givenSelectWhenLoadedTheDataThenExpectedResult() {        // Take CriteriaBuilder for handling Entity        CriteriaBuilder cb = entityManager.getCriteriaBuilder();        // Define Blueprint for Post CriteriaQuery        CriteriaQuery&lt;Post&gt; cq = cb.createQuery(Post.class);        // Write Statement        Root&lt;Post&gt; p = cq.from(Post.class);        Predicate condition = cb.equal(p.get(\"title\"), \"Hello World\");        // Merge        cq.select(p)                .where(condition);        // Actual Query Created        TypedQuery&lt;Post&gt; query = entityManager.createQuery(cq);        // Fetch        assertEquals(query.getResultList().size(), 0);    }위와 살짝 다르긴 한데, 그래도 흐름은 동일하다.Spring Data JPA &amp; QueryDSL위에서는 Criteria API 와 스프링 데이터 JPA를 사용하여 데이터를 활용하는 방법을 봤는데, 위를 짜면서 느낀 것은 코드가 굉장히 긴 것을 볼 수 있다. 단순한 조회 쿼리를 작성하기 위해 저렇게나 많은 양의 코드가 필요하다. 여기서 대체재로 QueryDSL을 사용하는 것을 검토할 수 있다. 코드 작성량을 줄임과 동시에 검증 또한 컴파일 타임중에 할 수 있다.서드 파티 라이브러리인 QueryDSL은 다음 검증을 지원한다:  엔티티 타입이 실제로 존재하고 해당 엔티티를 DB에 저장 가능한가?  모든 프로퍼티가 엔티티에 실제로 존재하고 해당 프로퍼티를 DB에 저장 가능한가?  모든 SQL 연산자에는 적합한 타입이 사용되었나?  최종 쿼리가 문법적으로 올바른가?Spring Data는 QueryDSL을 사용할 수 있도록 QuerydslPredicateExecutor 인터페이스를 제공한다. 이를 보자. 하기 전에 위에 썼던 Criteria API 사용한 코드들은 다 지워버리자 :)QueryDSL 의존성 추가우선 의존성 추가를 해주자.plugins {    ...\t// 이 플러그인이 Q-클래스 생성 작업을 간편하게 해줌\tid \"com.ewerk.gradle.plugins.querydsl\" version \"1.0.10\"}dependencies {    ...    // querydsl Spring Boot 3.x 이상과 호환하려면 :jakarta classifier 를 사용\timplementation \"com.querydsl:querydsl-jpa:5.0.0:jakarta\"\t// querydsl Q-class 생성을 위한 어노테이션 프로세서\tannotationProcessor 'com.querydsl:querydsl-apt:5.0.0:jakarta'}// Q 클래스들이 생성될 디렉토리 지정def querydslDir = \"$buildDir/generated/querydsl\"// QueryDSL Q-클래스 생성 설정// 이 플러그인은 Q-클래스가 생성될 경로를 지정하고 클린 작업을 자동으로 설정querydsl {\tjpa = true // JPA를 사용할 경우 true로 설정\tquerydslSourcesDir = querydslDir // Q-클래스 생성 경로}  com.querydsl:querydsl-apt: 엔티티 클래스 바탕으로 Q-타입 클래스를 생성하기 위한 애너테이션 처리 도구, 만약 Course 클래스에 애너테이션을 넣어주면 QCourse 가 생성  com.querydsl:querydsl-jpa: JPA를 사용하는 어플리케이션에서 QueryDSL 을 사용 가능. 만약 MongoDB 를 사용하면 querydsl-mongodb로 바꿔주면 된다.  com.ewerk.gradle.plugins.querydsl: querydsl 블럭을 사용하여 querydsl의 q-class 생성 위치나 설정을 간편하게 해준다.  Q-class 라는 것은 QueryDSL을 사용할 때 데이터베이스 쿼리를 타입-세이프(Type-Safe)하게 작성할 수 있도록 도와주는 특별한 static 클래스여기서 생성된 Q-class는 어플리케이션 소스코드로도 사용되기 때문에 outputDirectory 프로퍼티로 지정된 디렉터리는 프로젝트의 소스 디렉터리로도 지정되어야 한다.QuerydslPredicateExecutor 인터페이스보통 Repository 에 상속하여 QueryDSL 기능을 사용할 수 있게 한다.@Repositorypublic interface UserRepository extends CrudRepository&lt;User, Long&gt;, QuerydslPredicateExecutor&lt;User&gt; { }이제 Q-class 를 생성하기 위해 터미널에서 다음을 입력한다../gradlew clean build  build 후에 querydslDir 의 저장소에 Q-class 가 생성된 것을 볼 수 있다.여기서는 우리가 정의했던 Entity 들의 Q-class 들이 있다.위처럼 쓰며, 다음 메서드를 기본적으로 지원해준다.  findOne  findAll  count  exists  findByCrudRepository 도 findAll이 있지만, 이를 오버로딩한 메서드를 제공한다. 들어가는 인자가 Q-class 관련 변수들이며, 이는 동적이고 타입-세이프한 쿼리 기능을 제공하게 된다(QPE 사용 이유).    @Test    public void givenQueryDSLWhenLoadedTheDataThenExpectedResults() {        QUser user = QUser.user;        JPAQuery query1 = new JPAQuery(em);        query1.from(user).where(user.name.eq(\"IU\"));        assertEquals(query1.fetch().size(), 0);        JPAQuery query2 = new JPAQuery(em);        query2.from(user).where(user.email.eq(\"ssss@gmail.com\").and(user.id.gt(3)));        assertEquals(query2.fetch().size(), 0);        assertFalse(userRepository.exists(user.name.eq(\"IU\")));        OrderSpecifier&lt;Integer&gt; descOrderSpecifier = user.id.desc();        assertEquals((new ArrayList&lt;&gt; (                (Collection&lt;User&gt;) userRepository.findAll(descOrderSpecifier)                )).size(), 0);    }Projection엔티티를 조회할 때마다 테이블의 모든 컬럼은 조회할 필요가 없다. 이때, DB에는 프로젝션이라는 기능을 사용하는데 여기서도 사용할 수 있다.기본적으로 인터페이스 기반 프로젝션, 클래스 기반 프로젝션이 있다.인터페이스 기반 프로젝션인터페이스 기반 프로젝션은 Repository 의 반환값을 임의로 설정한 인터페이스로 두고, 안에 관심있는 Column 들만 Getter 로 선언하여 Projection을 하도록 할 수 있다.public interface PostInfo {    // 엔티티의 'id' 필드에 직접 매핑    Long getId();    // 엔티티의 'title' 필드에 직접 매핑    String getTitle();    // 엔티티의 'createdAt' 필드에 직접 매핑    LocalDateTime getCreatedAt();}위는 인터페이스 기반 프로젝션에서 closed projection 이다. open projection은 SpEL을 사용하여 하는데, 이는 나중에 공부해도 무방하다.레포지토리에 이를 써보자.@Repositorypublic interface UserRepository extends CrudRepository&lt;User, Long&gt;, QuerydslPredicateExecutor&lt;User&gt; {    // 필요한 column, 관심있는 column 만 반환    Iterable&lt;UserInfo&gt; findByName(String name);}테스트@Testpublic void givenFindUserDTOWhenLoadTheUserThenExpectedResult() {    User user = new User(\"seonghun\", \"seonghun@gmail.com\");    userRepository.save(user);    Optional&lt;UserInfo&gt; userInfo = userRepository.findByName(\"seonghun\");    userInfo.ifPresent(info -&gt; assertThrows(            NoSuchMethodException.class,            () -&gt; {                Class&lt;?&gt; clazz = info.getClass();                clazz.getMethod(\"getId\");            },            \"UserDTO는 id를 인자로 가지지 않습니다.\"    ));}java.lang.reflect 를 써서 테스트 가능하다.클래스 기반 프로젝션인터페이스 대신 데이터 전송 객체라고 불리는 DTO 개념이 도입되고, 이는 자바 POJO 기반의 구현체로 DAO 계층과 서비스 계층 사이에서 데이터를 담당하게 된다(Bridge 패턴이다).DTO를 사용하려면 보통 @Query 가 동반된다. 메서드 마다 쿼리를 사용하여 새로 정의해줘야 하게 되고, 또한 DTO 클래스에 멤버 변수가 많아지면 많아진 만큼 생성자가 거대해진다. 이 예시는 바로 밑에서 다룬다.도메인 객체 관계 관리하나의 테이블에서 데이터를 조회하는 것은 상대적으로 쉽지만 회사의 크기가 커질수록 하나의 테이블에서만 데이터를 조회하진 않는다.엔티티 간에는 1:1 관계, 1:n 관계, n:1 관계, n:m 관계 등이 있다. 이를 DTO를 사용하여 구현해보자.다대다 관계 관리Post 와 Comment 의 관계는 다대다 관계로 볼 수 있다. 새로운 entity 인 Comment 를 정의하자@Data@Entity@Table(name=\"COMMENTS\")public class Comment {    @Id    @GeneratedValue(strategy=GenerationType.IDENTITY)    private long id;    @Column(nullable=false)    private String name;    @Column(nullable=false)    private String description;}Post 와 Comment 는 서로 다대다 이기 때문에 이를 구현해주려면 두 도메인을 식별할 수 있는 데이터를 담은 조인 테이블이 따로 필요하다. 그러기 위해 POSTS_COMMENTS 라는 조인테이블을 만들어서 두 값의 pk 들을 모으면 된다.erDiagram    POSTS ||--o{ POST_COMMENT : \"\"    COMMENTS ||--o{ POST_COMMENT : \"\"    POST_COMMENT {        long post_id FK \"Post's ID\"        long comment_id FK \"Comment's ID\"    }    POSTS {        Long id PK        String title        String content        DATETIME createdAt    }    COMMENTS {        long id PK        String name        String description    }스키마를 위처럼 수정해주고 더 기준이 되는 주체의 엔티티 정의를 수정해주자.@ManyToManyJPA 에서 지원해주는 애너테이션이고 두 테이블 간의 연관성을 표시해줄 수 있다. DB 자체에서는 다대다 관계를 지정해줄 수 없고, 이를 JPA가 자동으로 관리하도록 하게 해준다.public class Post {    ...    @ManyToMany    private Set&lt;Comment&gt; comments = new HashSet&lt;&gt;();}멤버 변수로 위와 같이 지정해주면 된다. 매핑이 되는 엔티티에서는 다음과 같이 정의해준다.public class Comment {    ...    @ManyToMany(mappedBy=\"comments\") // 소유자의 멤버 변수명을 넣어줘야 함    private Set&lt;Post&gt; posts = new HashSet&lt;&gt;();}다대다의 관계에서는 항상 소유자와 비소유자가 존재하여서 소유자는 관계를 소유하는 입장이고, 비소유자는 참조되는 입장이다. 반면에 일대다에서는 다 쪽이 소유자이어야 하고, 일 쪽이 소유자가 된다면 다 쪽을 가르키는 참조 여러 개를 관리해야 하기 때문에 복잡해진다.다대다에서는 엔티티의 의미를 파악하여서 어떤 쪽을 소유자로 할지를 정해주어야 한다.@JoinTable관계의 소유자 쪽에 매핑 테이블 정보를 지정해서 조인 테이블을 정의할 수 있다. 만약 JoinTable이 지정되어지지 않으면 기본적으로 소유자 쪽 테이블 이름과 비소유자 쪽 테이블 이름을 _로 연결한 테이블이 자동적으로 생성된다.public class Post {    ...    @ManyToMany    @JoinTable(            name=\"POSTS_COMMENTS\",            joinColumns = {@JoinColumn(name=\"post_id\", referencedColumnName=\"id\", nullable = false, updatable = false)},            inverseJoinColumns = {@JoinColumn(name=\"comment_id\", referencedColumnName=\"id\", nullable = false, updatable = false)}    )    private Set&lt;Comment&gt; comments = new HashSet&lt;&gt;();joinColumns 속성과 inverseJoinColumns 속성을 통해 조인 테이블의 소유자 쪽인 POSTS 테이블의 식별자 컬럼을 가리키는 외래 키를 지정할 수 있고, inverseJoinColumns 는 조인 테이블의 비소유자 쪽의 COMMENTS 테이블의 외래 키를 참조하게 만들 수 있다. 여기서 updatable 이나 nullable 을 통해 어플리케이션이 해당 값을 변경하거나 null 값을 만들지 않도록 할 수 있다.이제 DTO 를 정의하여 해당 JoinTable 에 대한 필요한 필드만 조회하도록 해보자.DTO 클래스를 사용한 Projection우선 주고 받게 될 불변 클래스 DTO 를 선언해주자. 불변이기 때문에 최신 문법인 record 를 써서 선언해주자.public record PostInfo(        long id,        String postTitle,        String postContent,        String commentName,        String commentDescription) {}이제 이를 활용하여 데이터를 가져오기 위해 repository 에 다음을 추가해준다.    @Query(\"SELECT new com.example.study.dao.dto.PostInfo(p.id, p.title, p.content, c.name, c.description) \" +            \"FROM Post p JOIN p.comments c\")    Iterable&lt;PostInfo&gt; getPostInfo();p에서 썼던 comments 를 통해 HQL 를 Join 과 함께 쓸 수 있고, Join이 들어감과 동시에 정의했던 JoinTable을 참고하여 맞는 record에 대해서 전부 값들을 들고오게 된다.테스트    @BeforeEach    void setup() {        Post post1 = new Post(LocalDateTime.of(2000, 12, 1, 12, 59), \"title\", \"content\");        Post post2 = new Post(LocalDateTime.now(), \"NOW\", \"THIS IS NOW\");        Comment comment1 = new Comment(\"HI\", \"WORLD\");        Comment comment2 = new Comment(\"Hello\", \"World!\");        post1.getComments().add(comment1);        post1.getComments().add(comment2);        postRepository.saveAll(List.of(post1, post2));        commentRepository.saveAll(List.of(comment1, comment2));    }    @Test    void test() {        Iterable&lt;PostInfo&gt; list = postRepository.getPostInfo();        System.out.println(\"\\n\\n\\n\\n\");        list.forEach(postInfo -&gt; System.out.println(postInfo.toString()));        System.out.println(\"\\n\\n\\n\\n\");    }✒️ 용어ORM객체와 DB 테이블을 매핑하여 객체 지향적으로 데이터베이스를 다룰 수 있도록 해주는 기술이다. SQL을 직접 작성하지 않아도 객체를 통해 데이터 조작이 가능하다.  예) 자바 클래스의 Member 정의와 DB의 member 테이블이 자동으로 매핑됨Member member = entityManager.find(Member.class, 1L);Java Database Connectivity (JDBC)관계형 데이터베이스(RDBMS)에 접근할 수 있도록 해주는 자바 표준 API이다.자바 코드에서 SQL을 실행하고 결과를 가져오는 기능을 제공하는 저수준의 DB 연결 도구이다.String sql = \"SELECT * FROM member WHERE id = ?\";PreparedStatement pstmt = conn.prepareStatement(sql);pstmt.setLong(1, 1L);ResultSet rs = pstmt.executeQuery();JPA(ORM)를 사용한 코드와 비교해 보면, JDBC는 SQL과 연결 코드(보일러플레이트)를 직접 명시해야 하는 반면, JPA는 미리 정의된 메서드(find, persist, remove 등)를 통해 간결하고 추상화된 코드로 DB를 다룰 수 있다.PreparedStatementJDBC에서 SQL 구문을 미리 컴파일하여 실행하는 객체이다.SQL Injection 방지, 성능 향상 등의 장점이 있으며,동적 파라미터를 안전하게 바인딩할 수 있다.Connection PoolDB를 연결할 때는 네트워크 연결, 사용자 인증, 세션 설정 등 많은 작업이 필요하다. 매 요청마다 이를 새로하게 되면 속도 저하, 리소스 낭비가 된다.한 번만 만들어놓고 재사용하는 방식으로 커넥션 풀을 생성하면, 스레드를 여러 개 사용하여 사용자들이 여러명 있어도 새로 생성하지 않고, 스레드를 하나 꺼내서 사용하고 다 사용하면 풀에 반납하는 방식으로 작동한다.이렇게 하면 DB 연결 속도가 향상되며, 리소스 절약이 된다. Spring Boot에서는 HikariCP 라는 커넥션 풀을 기본적으로 사용하는데, tomcat-jdbc의 커넥션 풀을 사용해도 된다. 취향 차이이다.  예: maximum-pool-size 프로퍼티가 10, 유저가 동시 접근이 11명, 1명은 스레드(자원)이 반환될 때까지 기다려야 함.Marker Interface말 그대로 ‘표식’ 인터페이스이다. 아무 메서드도 수행하지 않고 이런 인터페이스이다 라는 메타 데이터만 주기 위해서 사용한다. 보통 java 를 뜯어내다 보면 다음을 볼 수 있는데 다음도 마커 인터페이스이다.  Serializable  Cloneable  Remote해당 interface를 통해 JVM 혹은 프레임워크 단에서 조건 분기 처리가 가능해지므로 가독성과 동작 제어가 뛰어나다."
    },
  
    {
      "title": "Elementary Logic",
      "url": "/seonghun120614/math/settheory/2025/07/25/elementary-logic.html",
      "date": "2025-07-25",
      "content": "🚧 작업중📂 목차  명제 Statement          Simple Statement &amp; Compound Statement        Truth Table  Logically Equivalent  Conditional Truth Table  Biconditional Truth Table  Tautology          Implication                  Theorem                    Equivalence      📚 본문Statement논리는 타당하지 않은 논증으로부터 타당한 논증을 구별하는 데 쓰이는 원리와 방법을 익히는 것이다. 논리를 논하기 위해서는 참, 거짓으로 구분 할 수 있는 문장인 Statement 부터 보아야 한다.Simple Statement &amp; Compound Statement일반적으로 참, 거짓의 분기가 1회로 끝나는 문장을 Simple Statement 라고 하며, 단순 명제가 결합된 것을 Compound Statement 라고 한다.단순 명제는 보통 영소문자로 두어 명제를 정의하고, 이 단순 명제들을 결합자를 통해 결합하면 영대문자로 나타내는 복합명제가 되는데 결합자는 다음과 같다:Connectives  $\\lnot$ : not, 부정, 아니다의 의미  $\\land$: and, 그리고  $\\lor$: or, 또는  $\\rightarrow$: if…then, 이면, 라면  $\\leftrightarrow$: if…and only if…, 이면 그리고 그때에만복합 명제에서 부분 부분의 명제들을 보통 Component 라고 부르며, 이러한 복합 명제에 대한 참, 거짓 여부를 판단하고 싶을 때 Truth Table(진리표)를 사용하면 쉽게 검토할 수 있다.Truth Table각각의 결합자들을 사용한 복합 명제에 대해 진리표를 그려보자.$\\lnot p$| p | ¬p ||—|—-|| T | F  || F | T  |$p\\land q$| p | q | p ∧ q ||—|—|——–|| T | T |   T    || T | F |   F    || F | T |   F    || F | F |   F    |$p\\lor q$| p | q | p ∨ q ||—|—|——–|| T | T |   T    || T | F |   T    || F | T |   T    || F | F |   F    |여기서 각각의 가능한 경우, 성분들의 가능한 참, 거짓의 조합을 Logical Possibilities(논리적 가능성) 라고 하며, and, or 에 대한 논리적 가능성은 4가지, not 에 대한 논리적 가능성은 2가지 이다.Logically Equivalent단순 명제 p, q 이거나 합성명제인 P, Q에 대한 모든 논리적 가능성의 경우 진리값이 같으면 P, Q는 Logically Equivalent(논리적 동치) 또는 그냥 동치라고 한다. $P\\equiv Q$ 로 나타내게 된다.예를 들어 다음 복합 명제끼리 equivalent 임을 볼 수 있다.\\[p\\lor q \\equiv \\lnot(\\lnot p\\land \\lnot q)\\]  진리표를 그려보면 각각의 logical possibilities 에 대해 모든 결과 값이 동일함을 볼 수 있다.Conditional Truth Table‘이면’ 을 나타내는 $\\rightarrow$ 기호는 Conditional(조건부) 기호라고 부르며, $p\\rightarrow q$ 의 진리표는 다음과 같다.            p      q      ¬q      p ∧ ¬q      p → q := ¬(p ∧ ¬q)                  T      T      F      F      T              T      F      T      T      F              F      T      F      F      T              F      F      T      F      T      여기서 p 이면 q 이다. 라는 것은 전자의 명제가 참일 경우에만 따지는데, p가 거짓인 경우에는 그런 경우를 관심으로 두지 않기 때문에 논하는 것은 무의미하다. 따라서 생각조차 하지 않는데, 이를테면 다음과 같은 명제이다:  저 사람이 태양이면 나는 바람이다.사람이 태양일리 없으므로 이런 명제는 생각조차하지 않는다. 하지만 이 두 논리적 가능성은 결과적으로 참이라고 둔다(정의다).Biconditional Truth Table쌍화살표 라고 보통 많이 보았을텐데, Biconditional(쌍조건부)라고 읽고, 기호로 $p\\leftrightarrow q$ 로 쓸 수 있다. $(p \\rightarrow q) \\land (p \\leftarrow q)$ 와도 같다. 진리표는:            p      q      p → q      p ← q      p ↔ q                  T      T      T      T      T              T      F      F      T      F              F      T      T      F      F              F      F      T      T      T      Tautology모든 논리적 가능성에 대해 참인 것을 Tautology(항진)이라고 한다.다음은 다 항진일 것이다.  $p \\lor ~p$  $p \\leftrightarrow p$항진은 기호로 보통 소문자 t로 둔다.Implication$P \\rightarrow Q$ 가 t일 때, $P \\implies Q$ 라고 하고, P 는 Q를 함의한다. 라고 읽는다. 여기서 화살표 기호의 결합력이 or, and 의 결합력보다 더 느슨하므로 보통 $p \\rightarrow (p\\lor q)$ 을 $p \\rightarrow p\\lor q$ 로 쓴다. 또한 $\\lnot$ 은 $\\lor, \\land$ 보다 쎄다.  결합력 순위 $\\lnot &gt; \\land, \\lor &gt; \\rightarrow, \\leftarrow, \\leftrightarrow$위와 같이 진리표를 그려나가야 한다.어쨋든 함의가 나왔다는 것은 그 복합 명제가 무조건 항진임을 뜻한다.Theorem  Law of Addition(Add.): $p \\implies p \\lor q$  Laws of Simplification(Simp.): $p\\land q \\implies p$, $p\\land q \\implies q$  Disjunctive Syllogism(D.S.): $(p\\lor q) \\land \\lnot p \\implies q$Equivalence✒️ 용어######🔗 관련 출처  "
    },
  
    {
      "title": "National Number",
      "url": "/seonghun120614/math/analysis/2025/07/25/national-number.html",
      "date": "2025-07-25",
      "content": "📂 목차  페아노 공리계(PA)          정의      Axiom      귀납적 정의        덧셈 정의          Lemma 1      Lemma 2      Prop. Commutative Rule      Prop. Associative Rule      Prop. Cancellation Law      양수 정의                  Prop. 1          Corollary 1          Lemma 1                    자연수의 순서 정의                  Prop. 1          Props.          Prop. Trichotomy                    Prop. Strong Principle of Induction      Prop. Principle of Backwards Induction        곱셈 정의          Lemma 1      Lemma 2      Prop. Distributive Law      Prop. Associative Law      Prop. Order-preserving      Corollary. Cancellation Law      Prop. Euclid’s Division Lemma      자연수의 거듭제곱 정의        Practice📚 본문선행 학습으로 집합론과 수리논리학이 필요 할 수 있다.페아노 공리계정의  National Number $:= \\mathbb{N}$  Successor Operation $:= ++$Axiom      시작 수 정의$0 \\in \\mathbb{N}$        0에서 시작하는 ‘셈(Succession / Counting)’을 정의$\\forall n \\in \\mathbb{N}, n++ \\in \\mathbb{N}$즉, 모든 자연수는 Successor 를 갖는다.        공리 1, 2 만으로는 컴퓨터의 overflow 가 되는 수 체계에서는 0으로 되돌아가는 것이 맞지 않음, Wrap-around 를 방지$\\nexists n \\in \\text{s.t. }n++ = 0$        공리 1, 2, 3 만으로는 0, 1 에서의 1++ 가 다시 1이 되는 수체계가 있을 수 있다. 1 = 2 = 3 = … 의 문제 발생을 방지$\\forall n, m \\in \\mathbb{N}, n++=m++ \\implies n=m$이는 수가 그 자체로 자기 자신임을 함축하는 공리이며 유일성이 무너지지 않게 보장한다.        Principle of Mathematical Induction$0 \\in A \\land \\forall n \\in \\mathbb{N}, (n \\in A \\implies n++ \\in A) \\implies \\forall n \\in \\mathbb{N}, n \\in A$즉, 어떤 집합이 0을 포함하고 그 후속자를 포함한다면, 해당 집합은 자연수 집합이다.    0이 자연수라고 보는 것은 관점의 차이이다.위 공리 1 ~ 5 를 만족하는 수체계 $\\mathbb{N}$ 이 존재하고, $\\mathbb{N}$ 의 원소를 자연수라고 한다.귀납적 정의페아노의 공리계 안에서 정의 가능한 논리 구조로 재귀적인 수열을 정의할 때도 이를 쓴다.각 자연수 $n$ 에 대해 $f_n: \\mathbb{N} \\rightarrow \\mathbb{N}$ 의 함수가 존재하고, $c \\in \\mathbb{N}$ 일 때,  $a_0 := c$  $a_{n++} := f_n(a_n)$을 만족하게 할 수 있다. 즉, 귀납적으로 수열을 정의할 수 있고, 그 수열의 원소 $a_n$는 ‘유일’하게 결정이 된다.덧셈 정의$+:= \\mathbb{N}\\times\\mathbb{N}\\mapsto\\mathbb{N}$  $0+a = a$  $(a++)+b = (a+b)++$Lemma 1\\(\\begin{align*}&amp;\\forall n \\in \\mathbb{N},\\ n + 0 = n \\\\&amp;\\text{p.f)} \\\\\\end{align*}\\)\\[\\begin{align*}0 + 0 &amp;= 0 &amp;(\\because\\ 0 \\in \\mathbb{N}) \\\\\\text{Assume } k + 0 &amp;= k &amp;\\text{ (Inductive Hypothesis)} \\\\(k++) + 0 &amp;= (k + 0)++ \\\\&amp;= k++ \\\\\\\\\\therefore (k++) + 0 &amp;= k++ &amp;&amp;\\blacksquare\\end{align*}\\]Lemma 2\\(\\begin{align*}&amp;\\forall n, m \\in \\mathbb{N},\\ n + (m++) = (n + m)++ \\\\&amp;\\text{p.f)} \\\\\\end{align*}\\)\\[\\begin{align*}0 + (m++) &amp;= m++ = (0 + m)++  &amp;(\\because 0 + m := m) \\\\\\text{Assume } k + (m++) &amp;= (k + m)++ &amp;\\text{ (Inductive Hypothesis)} \\\\(k++) + (m++) &amp;= (k + (m++))++ &amp;\\\\&amp;= ((k + m)++)++ &amp;\\\\\\\\\\therefore \\forall n, m \\in \\mathbb{N},\\ n + (m++) &amp;= (n + m)++ &amp;\\blacksquare\\\\\\end{align*}\\]Prop. Commutative Rule\\(\\begin{align*}&amp;\\forall n, m \\in \\mathbb{N}, n + m = m + n \\\\&amp;\\text{p.f)} \\\\\\end{align*}\\)\\[\\begin{align*}0 + m &amp;= m + 0 \\\\\\text{Assume } k + m &amp;= m + k \\\\(k++) + m &amp;= m + (k++) \\\\&amp;=(k + m)++ \\\\&amp;=(m + k)++ \\\\&amp;=m + (k++) \\\\\\\\\\therefore \\forall n, m \\in \\mathbb{N}, n + m &amp;= m + n &amp;\\blacksquare\\end{align*}\\]Prop. Associative Rule\\(\\begin{align*}&amp;\\forall a, b, c \\in \\mathbb{N}, (a+b)+c = a+(b+c) \\\\&amp;\\text{p.f)} \\\\\\end{align*}\\)\\[\\begin{align*}(0 + b) + c &amp;= b + c = 0 + (b + c) \\\\\\text{Assume } (k + b) + c &amp;= k + (b + c) \\\\((k++) + b) + c &amp;= ((k + b)++) + c \\\\&amp;=((k + b) + c)++ \\\\&amp;=(k + (b + c))++ \\\\&amp;=(k++) + (b + c) \\\\\\\\\\therefore \\forall a, b, c \\in \\mathbb{N}, (a+b)+c &amp;= a+(b+c) &amp;\\blacksquare\\end{align*}\\]Prop. Cancellation Law\\(\\begin{align*}&amp;\\forall a, b, c \\in \\mathbb{N}, a + b = a + c \\implies b = c \\\\&amp;\\text{p.f)} \\\\\\end{align*}\\)\\[\\begin{align*}b \\neq c \\rightarrow a + b &amp;\\neq a + c &amp;(\\text{Reductio ad Absurdum}) \\\\0 + b = b &amp;\\neq c = 0 + c \\\\\\text{Assume } k + b &amp;\\neq k + c \\\\(k++) + b = (k + b)++ &amp;\\neq (k + c)++ = (k++) + c \\\\\\\\\\therefore \\forall a, b, c \\in \\mathbb{N}, a + b = a + c &amp;\\implies b = c &amp;\\blacksquare\\end{align*}\\]양수 정의자연수 n 이 양수(positive) 일 필요충분조건은 n이 0이 아닐때이다. 편의 상 양수를 $\\mathbb{Z}^+$ 라고 하자.Prop. 1\\(\\begin{align*}&amp;a\\in\\mathbb{\\mathbb{Z}^+} \\land b\\in\\mathbb{N} \\implies a+b \\in \\mathbb{Z}^+ \\\\&amp;\\text{p.f)} \\\\\\end{align*}\\)\\[\\begin{align*}a+0 = a &amp;\\in \\mathbb{Z}^+ \\\\\\text{Assume } a + k &amp;\\in \\mathbb{Z}^+ \\\\a + (k++) = (a + k)++ &amp;\\in \\mathbb{Z}^+ &amp;(\\because \\text{Axiom 3}) \\\\\\\\\\therefore a\\in\\mathbb{\\mathbb{Z}^+} \\land b\\in\\mathbb{N} &amp;\\implies a+b \\in \\mathbb{Z}^+ &amp;\\blacksquare\\\\\\end{align*}\\]Corollary 1\\(\\begin{align*}&amp;\\forall a, b \\in \\mathbb{N}, a + b = 0 \\implies a = 0 \\land b = 0 \\\\&amp;\\text{p.f)} \\\\\\end{align*}\\)\\[\\begin{align*}a \\neq 0 \\lor b \\neq 0 &amp;\\rightarrow a + b \\neq 0 &amp;(\\text{Reductio ad Absurdum}) \\\\a \\neq 0 \\lor b \\neq 0 &amp;\\rightarrow a \\in \\mathbb{Z}^+ \\lor b \\in \\mathbb{Z}^+ \\\\&amp;\\rightarrow a + b \\in \\mathbb{Z}^++ &amp;(\\because \\text{Prop. 1}) \\\\&amp;\\rightarrow a + b \\neq 0 \\\\\\\\\\therefore \\forall a, b \\in \\mathbb{N}, a + b = 0 &amp;\\implies a = 0 \\land b = 0 &amp;\\blacksquare\\end{align*}\\]Lemma 1\\(\\begin{align*}&amp;\\forall a \\in \\mathbb{Z}^+ \\implies \\exists! b \\in \\mathbb{N}, b++ = a \\\\&amp;\\text{p.f)}\\end{align*}\\)\\[\\begin{align*}\\textbf{Existence:} \\\\\\forall a \\in \\mathbb{Z}^+ , &amp;\\exists b \\in \\mathbb{N} \\\\&amp;\\exists 0 \\in \\mathbb{N}, 0++ = 1 \\\\\\text{Assume for k}\\quad &amp;\\exists c \\in \\mathbb{N}, c++ = k \\\\&amp;\\exists c++ \\in \\mathbb{N}, (c++)++ = k++ \\\\\\\\\\textbf{Uniqueness:} \\\\&amp;\\text{Take } b_1, b_2 \\in \\mathbb{N}, b_1++ = a \\land b_2++ = a \\\\&amp;\\text{Then } b_1 = b_2 &amp;(\\text{Axiom 4}) \\\\\\\\\\therefore \\forall a \\in \\mathbb{Z}^+ &amp;\\implies \\exists! b \\in \\mathbb{N}, b++ = a &amp;\\blacksquare\\\\\\end{align*}\\]자연수의 순서 정의자연수 n, m에 대해 순서를 정의하자:  $n \\ge m := a \\in \\mathbb{N}, n = m + a$n 이 m 이상(greater than or equal to) 또는 n 이 m보다 크거나 같다 라고 한다.  $n &gt; m := n \\ge m \\land n \\neq m$n 이 m 보다 크다 또는 n 이 m 초과 라고 한다.Prop. 1\\(\\begin{align*}&amp;\\forall n \\in \\mathbb{N}, n++ &gt; n \\\\&amp;\\text{p.f)}\\end{align*}\\)\\[\\begin{align*}0++ = (0 + 0)++ = 0 + 0++ &amp;&gt; 0 \\\\\\text{Assume } k++ &amp;&gt; k \\\\(k++)++ = (k+a)++ = k++ + a &amp;&gt; k++ \\\\\\\\\\therefore \\forall n \\in \\mathbb{N}, n++ &gt; n\\end{align*}\\]Props.\\(\\begin{align*}&amp;\\text{Reflexive }&amp; a \\geq a\\\\&amp;\\text{Transitive }&amp; a \\geq b \\land b \\geq c &amp;\\implies a\\geq c \\\\&amp;\\text{Anti-symmetric }&amp; a \\geq b \\land b \\geq a &amp;\\implies a=b\\\\&amp;\\text{Order-preserving }&amp; a \\geq b &amp;\\iff a + c \\geq b + c\\\\&amp;\\text{Prop. 2 }&amp; a &lt; b &amp;\\iff a++ \\leq b\\\\&amp;\\text{Prop. 3 }&amp; a &lt; b &amp;\\iff \\exists d \\in \\mathbb{Z}^+, b = a + d\\\\\\end{align*}\\)\\[\\begin{align*}&amp;\\text{p.f)}\\\\&amp;\\textbf{Reflexive} \\\\&amp;a = a + 0 \\geq a &amp;\\blacksquare \\\\\\\\&amp;\\textbf{Transitive} \\\\&amp;(a = b + d) \\land (b = c + e) \\\\&amp;\\implies a = c + e + d \\\\&amp;\\implies a \\geq c &amp;\\blacksquare \\\\\\\\&amp;\\textbf{Anti-symmetric} \\\\&amp;\\iff a = b + d \\land b = a + e \\\\&amp;\\iff a = a + e + d \\land b = b + d + e\\\\&amp;\\iff a \\geq a + d \\\\&amp;\\iff a = b &amp;\\blacksquare\\\\\\\\&amp;\\textbf{Order-preserving} \\\\&amp;\\iff a = b + d \\land b \\geq a \\\\&amp;\\iff b \\geq b + d &amp; \\tag{i}\\\\&amp;\\iff ((d \\neq 0) \\lor (d = 0)) \\land (b \\geq b + d) \\\\&amp;\\iff ((d \\neq 0) \\land (b \\geq b + d)) \\lor ((d = 0) \\land (b \\geq b + d))\\\\&amp;\\iff \\bot \\lor ((d = 0) \\land (d = 0) \\land (b \\geq b + d)) \\\\&amp;\\iff (d = 0) \\land t \\\\&amp;\\iff d = 0 \\\\&amp;\\iff a = b &amp;\\blacksquare \\\\\\\\&amp;\\textbf{Prop. 2, Prop. 3} \\\\&amp;\\iff (b = a + d) \\land (b \\neq a) \\\\&amp;\\iff (b = a + d) \\land (b = a + d \\neq a)\\\\\\\\&amp;\\because d \\neq 0 \\text{ By, Positive Number Lemma 1, we can take }\\\\&amp;\\exists! c \\in \\mathbb{N},\\quad s.t.\\quad c++ = d\\\\&amp;\\text{Also, Prop. 3 is naturally proved by above right proposition. }\\quad \\blacksquare\\\\\\\\&amp;\\iff (b = a + (c++) = (a+c)++ = (a++) + c) \\land (b \\neq a \\equiv t) \\\\&amp;\\iff b = (a++) + c = a + (c++) \\\\&amp;\\iff a++ \\leq b &amp; \\blacksquare \\\\\\end{align*}\\]이제 $a &gt; b$ 를 $a = b + p\\quad (p \\in \\mathbb{Z}^+)$ 로 둘 수 있다.Prop. Trichotomy삼분법이라고 한다. 하나가 참이면 다른 명제 두 개가 참이 아니며 어떤 상황에서든 하나만 참이 되는 명제다. xor의 확장 버전이지만 조금 다른 버전이다.\\(\\begin{align*}&amp;\\forall a, b \\in \\mathbb{N}, \\\\&amp;\\text{Let } P_1 := a &gt; b, P_2 := a = b, P_3 := a &lt; b\\\\&amp;\\text{then }\\bigvee_{i=1}^3 \\left( P_i \\land \\bigwedge_{j \\neq i} \\lnot P_j \\right)\\end{align*}\\)셋 중 하나만 참을 요약해서 표현한 것이다.\\[\\begin{align*}p.f) \\\\&amp;\\text{i) } P_1 \\equiv t, \\\\&amp;a = b + p &gt; b&amp;(P_2 \\equiv \\bot)\\\\&amp;\\text{prove by Reductio ad Absurdum}\\\\&amp;P_3 := a &lt; b := b = a + q = b + (p + q) \\implies \\bot &amp;(p+q \\neq 0)\\\\\\\\&amp;\\text{ii) } P_2 \\equiv t, \\\\&amp;a = b \\implies \\lnot P_1 \\land \\lnot P_2 &amp;(\\because \\text{Definition of Positive Number Order})\\\\\\\\&amp;\\text{iii) } P_3 \\equiv t, \\textbf{(trivial)} \\\\&amp;&amp;\\blacksquare\\\\\\end{align*}\\]Prop. Strong Principle of Induction\\(\\begin{align*}&amp;m_0 \\in \\mathbb{N}, P \\text{ is proposition function.}\\\\&amp;\\begin{cases}&amp; P(m_0) \\equiv t \\\\&amp;\\forall m(\\geq m_0) \\in \\mathbb{N}, \\bigwedge_{m_0 \\leq m' &lt; m} P(m') \\implies P(m) \\\\\\end{cases}\\\\&amp;\\forall n(\\geq m_0), P(n) \\equiv t\\end{align*}\\)위가 참이면 모든 자연수 $m(\\geq m_0)$에 대한 $P(n)$이 참이다. $m_0$은 보통 0 또는 1로 두고, $P_{m_0}$이 참이라고 해야 의미가 있게 된다. 증명하자.\\[\\begin{align*}p.f) \\\\&amp;\\text{i) } m = m_0,\\;P(m_0) \\equiv P(m) \\equiv t\\\\&amp;\\text{ii) } m = k, \\bigwedge_{m_0 \\leq m' &lt; k} P(m') \\implies P(k)\\\\&amp;\\implies \\bigwedge_{m_0 \\leq m' &lt; k} P(m') \\land t\\\\&amp;\\iff \\bigwedge_{m_0 \\leq m' &lt; k} P(m') \\land P(k)\\\\&amp;\\iff \\bigwedge_{m_0 \\leq m' &lt; k++} P(m') \\implies P(k++)\\\\&amp;\\therefore P(k) \\implies P(k++)\\\\\\therefore \\forall m(\\geq m_0)\\in\\mathbb{N}, P(m)\\equiv t\\\\&amp;&amp;\\blacksquare\\\\\\end{align*}\\]Prop. Principle of Backwards Induction\\(\\begin{align*}&amp;n \\in \\mathbb{N},\\text{P(m) is proposition function}\\\\&amp;\\begin{cases}&amp; P(n) \\equiv t \\\\&amp; P(m++) \\implies P(m)\\end{cases}\\\\&amp;\\forall m(\\leq n) \\in \\mathbb{N}, P(m) \\equiv t\\end{align*}\\)두 조건을 만족 시 n 이하의 자연수 전부에 대해 참임을 볼 수 있다. 여기서는 n에 대한 귀납법을 사용하면 된다.\\(\\begin{align*}&amp;\\text{i) }n = 0,\\;P(0) \\equiv t\\\\&amp;\\implies \\forall m(\\leq 0) \\in \\mathbb{N}, P(m) \\equiv t\\\\&amp;\\text{ii) }n = k,\\;\\forall m(\\leq k) \\in \\mathbb{N}, P(m) \\equiv t\\\\&amp;\\implies P(m) \\land P(k++)\\quad(\\because n=k+1)\\\\&amp;\\implies \\forall m(\\leq k++) \\in \\mathbb{N}, P(m) \\equiv t\\\\\\\\&amp;\\therefore \\begin{cases}&amp; P(n) \\equiv t \\\\&amp; P(m++) \\implies P(m)\\end{cases}\\implies \\forall m(\\leq n) \\in \\mathbb{N}, P(m) \\equiv t&amp;&amp;\\blacksquare\\end{align*}\\\\\\)곱셈 정의$\\times := \\mathbb{N}\\times\\mathbb{N}\\mapsto\\mathbb{N}$  $0\\times m:=0$  $(n++)\\times m:= (n\\times m) + m$로 정의한다. 여기서 귀납법을 사용하면 두 자연수의 곱이 자연수임을 쉽게 확인 할 수 있다.  두 자연수 $n, m$ 에 대해 $n\\times m$ 이 자연수 임을 보이자.n = 0 일 때는 자명하다.n = k 일 때 $k\\times m$이 자연수라고 하자.그러면 $(k++) \\times m = k \\times m + m$ 이므로 $k\\times m$ 이 자연수고, $m$이 자연수이기 때문에 전체도 자연수가 된다.Lemma 1곱셈의 교환법칙부터 증명하자. 사실 덧셈의 교환법칙 안에 포함되어 있다.\\[\\begin{align*}&amp;\\forall n, m \\in \\mathbb{N}, n \\times m = m \\times n\\\\&amp;p.f)\\\\&amp;\\text{i) } n = 0,\\\\&amp;\\quad \\text{1) } m = 0,\\;0\\times 0=0\\times 0\\\\&amp;\\quad \\text{2) } m = k,\\;0\\times k=k\\times 0=0\\\\&amp;\\quad \\implies (k++) \\times 0=k\\times 0+0=0\\times k = 0\\\\&amp;\\text{ii) } n = i,\\\\&amp;\\quad i \\times m = m \\times i\\\\&amp;\\quad \\implies i++ \\times m = i \\times m + m = m \\times i + m = m \\times i++\\\\\\\\&amp;\\therefore \\forall n, m \\in \\mathbb{N}, n \\times m = m \\times n&amp;&amp;\\blacksquare\\end{align*}\\]Lemma 2\\(\\forall n, m \\in \\mathbb{N},\\;n\\times m = 0 \\iff n=0 \\lor m=0\\)귀류법을 사용해 증명하자. 그러면 n, m 은 0이 아니고, 양의 자연수이다.\\(\\begin{align*}&amp;p.f)\\\\&amp;\\exists!\\;n_{-} \\in \\mathbb{N},\\;s.t.\\;n_{-}++ = n\\quad(\\because \\text{Positive Number Lemma 1})\\\\&amp;n\\times m = n_{-} \\times m + m = 0 \\implies m = 0 \\equiv c\\\\&amp;\\text{By commutativity of multiplication, the other case is contradiction}\\\\&amp;\\therefore \\forall n, m \\in \\mathbb{N},\\;n\\times m = 0 \\implies n=0 \\lor m=0\\\\&amp;\\text{The other arrow is trivial.}&amp;\\blacksquare\\end{align*}\\)Prop. Distributive Law\\[\\forall a, b, c \\in \\mathbb{N},\\; a(b+c) = ab + ac \\land (b+c)a = ba + ca\\]\\[\\begin{align*}&amp;\\text{i) } c = 0,\\\\&amp;a(b+0) = ab = ab + 0 = ab + a0 \\\\&amp;\\text{ii) } a(b+c) = ab + ac \\\\&amp;\\implies a(b+(c++)) = a((b+c)++) = a(b+c) + a = ab + ac + a = ab + a(c++)\\\\&amp;\\blacksquare\\end{align*}\\]Prop. Associative Law\\[\\forall a, b, c \\in \\mathbb{N},\\;(a\\times b)\\times c = a\\times (b\\times c)\\]\\[\\begin{align*}&amp;\\text{i) } b = 0, (a\\times 0) \\times c = 0 = 0 \\times c = a\\times (0\\times c)\\\\&amp;\\text{ii) } b = k, (a\\times k) \\times c = a\\times(k\\times c)\\\\&amp;\\implies (a\\times(k++))\\times c = (a\\times k + a) \\times c = (a\\times k)\\times c + a \\times c = a \\times (k \\times c) + a \\times c = a\\times(k++ \\times c)\\\\\\blacksquare\\end{align*}\\]Prop. Order-preserving\\[\\forall a, b \\in \\mathbb{N}, \\forall c \\in \\mathbb{Z^+}\\;a &lt; b \\implies ac &lt; bc\\]\\[\\begin{align*}a &lt; b&amp;\\implies \\exists k \\in \\mathbb{Z^+},\\; a + k = b\\quad(\\because\\text{Positive Number Prop.3})\\\\&amp;\\implies (a+k)c = bc\\\\&amp;\\implies \\exists kc \\in \\mathbb{Z^+},\\;ac + kc = bc\\\\&amp;\\implies ac &lt; bc\\\\\\blacksquare\\end{align*}\\]Corollary. Cancellation Law\\[\\forall a, b, c \\in \\mathbb{N}, ac = bc \\land c \\neq 0 \\implies a = b\\]\\[\\begin{align*}&amp;\\text{p.f)}\\\\&amp;\\text{i) }c = 0++, a(0++) = b(0++) \\implies a = b\\\\&amp;\\text{ii) }c = k, ak = bk \\implies a = b\\\\&amp;\\implies a(k++) = b(k++) \\implies ak + a = bk + a = bk + b = b(k++)\\\\\\blacksquare\\end{align*}\\]  앞으로 n++ = n + 1 임을 이용한다.Prop. Euclid’s Division Lemma\\(\\forall n\\in\\mathbb{N}, q\\in\\mathbb{Z^+},\\;\\exists m, r \\in \\mathbb{N},\\;(0\\leq r &lt; q) \\land (n = mq + r)\\)n에 대한 귀납법을 사용하자.\\[\\begin{align*}&amp;\\text{p.f)}\\\\&amp;\\text{i) } n = 0,\\;0 = 0q + 0\\\\&amp;\\text{ii) } n = k,\\;k = m_0q + r_0\\quad(0\\leq r_0 &lt; q)\\\\&amp;\\implies k+1 = m_0q + r_0 + 1 = m_0q + r_1\\quad(\\because 0 \\leq r_1 = r_0 + 1 &lt; q+1)\\\\&amp;\\begin{cases}&amp; r_1 = q \\implies k+1 = (m_0+1)q + 0\\\\&amp; r_1 &lt; q \\implies k+1 = m_0q + r_1\\end{cases}\\\\\\blacksquare\\end{align*}\\]자연수의 거듭제곱 정의\\(\\begin{align*}&amp;\\forall m \\in \\mathbb{N}\\\\&amp;m^0 := 1,\\;0^0 = 1 \\\\&amp;m^{n++} := m^n \\times m\\end{align*}\\)거듭제곱을 귀납적으로 정의한다.Practice  $\\forall a, b \\in \\mathbb{N}, (a+b)^2 = a^2 + 2ab = b^2$Distributive law를 사용하자.\\(\\begin{align*}(a+b)^2 = a(a+b) + b(a+b) = a^2 + ab + ba + b^2 = a^2 + 2ab + b^2\\end{align*}\\)다음은 집합론인데 따로 분야를 나눠서 다루므로 넘어간다. 이제 자연수에서 기본적인 곱셈과 덧셈에 대한 연산은 증명없이 전부 자연스럽게 넘어간다.🔗 관련 출처  Tao 해석학 I"
    },
  
    {
      "title": "정보처리기사 실기 응용 SW 기초 기술 활용 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/11/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%9D%91%EC%9A%A9-sw-%EA%B8%B0%EC%B4%88-%EA%B8%B0%EC%88%A0-%ED%99%9C%EC%9A%A9-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-11",
      "content": "📂 목차  운영체제 커널의 기능  메모리 관리 기본  메모리 관리 기법  LFU(Least Frequently Used) 알고리즘📚 본문운영체제 커널의 기능  쉘: 명령어 라인을 읽어 필요한 시스템 기능을 실행  커널: 운영체제의 핵심 기능들이 모여있는 프로그램메모리 관리 기본  가상 메모리: 실제 메모리 주소가 아닌 가상 메모리주 소를 부여하여 가상 주소 범위를 가상 주소 공간, 물리 주소 범위를 물리 주소 공간이라고 한다.  메모리 관리 장치(MMU): CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어(가상 주소 -&gt; 실제 주소 매핑)  메모리 관리자: 기억 장치의 어느 부분이 사용 중인지 아닌지 여부 판단메모리 관리 기법  반입 기법: When 을 결정, 요구 반입 기법, 예상 반입 기법(예측하여 미리 적재)  배치 기법: Where 을 결정, 최초 적합, 최적 접합(가장 크기가 비슷), 최악 적합  할당 기법: How 를 결정, 연속 할당, 분산 할당          연속 할당                  단일 분할 할당: 오버레이, 스와핑          다중 분할 할당: 고정 분할 할당, 동적 분할 할당                    분산 할당                  페이징          세그멘테이션          페이징/세그멘테이션                      교체 기법: Who 를 결정, Swap In/Out, FIFO, LRU, LFU⭐️ 페이징정해진 페이지의 크기에 따라 프로세스를 ‘일정하게’ 분할하여 주기억 장치에 분산된 공간에 적재하여 실행하는 방법이며, 프레임은 실제 물리 주소 공간에서 사용할 분산된 공간 각각을 말한다. 페이지 수와 일치해야 한다.논리 주소는 페이지 번호(p) 와 변위(d) 로 구성되어 있고, 페이지 테이블에서 실제 메모리 기준 주소를 찾고 변위를 더해 물리 메모리 주소(프레임의 시작 주소)를 결정하게 된다.  페이지 크기가 작을 경우: 많은 페이지의 사상 테이블 공간 필요, 내부 단편화가 줄지만 매핑 속도가 늦어짐, 디스크 접근 횟수가 많아져 I/O Bound Time 증가  페이지 크기가 클 경우: 테이블 크기가 작아져 주기억 장치의 공간이 절약, 매핑 속도가 빨라지지만 페이지 단편화가 증가하게 된다.⭐️ 세그멘테이션프로세스를 가변적인 크기의 블록으로 나누고, 메모리를 할당하는 기법이고, 필요한 만큼의 크기를 메모리에 배치하기 때문에 내부 단편화가 낮아지지만 외부 단편화가 증가한다.주소 변환 과정은 다음과 같다.  논리 주소 s(세그먼트 번호), d(변위)가 주어짐  s를 통해 segment table 에서의 limit, base 를 확인  base는 기준 주소이고 이는 물리 주소 공간에서 0에서의 offset이다.  읽을 base + d 의 값이 유효한지를 보아야 하기 때문에 d &lt; limit 인지 확인한다.  참이라면 base + d 로 물리 메모리에 접근한다.페이징/세그멘테이션하나의 세그멘트를 정수 배의 부분 페이지로 다시 분할하는 방식, 세그멘트 안에 페이징이 있음LFU(Least Frequently Used) 알고리즘  FIFO, LRU 생략사용된 횟수를 확인해 참조 횟수가 가장 적은 페이지를 선택예시참조 스트링: 2 3 1 3 1 2 4 5| 참조 스트링 | 2 | 3 | 1 | 3 | 1 | 2 | 4 | 5 ||—–|—–|—–|—–|—–|—–|—–|—–|—–||  페이지 프레임 1  |  2   |  2  |  2  |  2  |  2  |  2  |  2  |  2  ||  페이지 프레임 2  |     |  3  |  3  |  3  |  3  |  3  |  3  |  3  ||  페이지 프레임 3  |     |     |  1  |  1  |  1  |  1  |  1  |  1  ||  페이지 프레임 4  |     |     |     |     |     |     |  4  |  5  ||  페이지 부재   |  f  |  f  |  f  |     |     |     |  f  |  f  |메모리 단편화 해결하기  내부 단편화: 고정된 분할 영역 외에 남는 공간이 즉, 프로세스를 적재 후 남은 공간을 말한다.          Slab Allocator: 페이지 프레임을 할당받아서 공간을 작은 크기로 분할하고 메모리 요청 시 작은 크기로 메모리를 할당/해제하는 동적 메모리 관리 기법      집약(Coalescing): 인접한 단편화 영역을 찾아서 하나로 통합하는 기법      압축(Compaction): 메모리의 모든 단편화 영역을 하나로 압축하는 기법        외부 단편화: 할당된 크기가 프로세스 크기보다 작아서 사용하지 못하는 공간          버디 메모리 할당(Buddy Memory Allocation): 가장 알맞은 크기를 할당하기 위해 메모리를 $2^n$ 의 크기로 분할하여 메모리를 할당하는 기법      집약: 인접한 단편화 영역을 찾아 하나로 통합하는 기법      압축: 모든 단편화 영역을 하나로 압축하는 기법        위는 OS 에서 더 자세히 볼 수 있습니다.Thrashing어떤 프로세스가 지속적으로 페이지 부재가 발생하여서 실제 처리 시간 보다 페이지 교체 시간이 더 많아지는 현상Thrasing 해결 방안  워킹 세트(Working Set): 각 프로세스가 많이 참조한는 페이지들의 집합을 공간에 계속 상주시킴          워킹 세트를 달성하려면 Locality 를 알아야 한다.        페이지 부재 빈도(PFF; Page-Fault Frequency): 페이지 부재율의 상한, 하한을 통해 페이지 부재율을 예측하고 조절함Locality지역성(국부성, 구역성, 국소성)은 프로세스가 실행되는 동안 일부 페이지만 집중적으로 참조하는 특성이며, 참조 지역성 이라고도 불리며, 3가지 유형이 존재한다.  Temporal Locality(시간 지역성): 최근 사용한 기억장소들이 집중적으로 액세스하는 현상  Spatial Locality(공간 지역성): 일정 위치의 페이지를 집중적으로 액세스하는 현상  Sequential Locality(순차 지역성): 데이터가 순차적으로 액세스 되는 현상세 개념은 상호배타적인 개념이 아니다. 시간 지역성, 순차 지역성이 동시에 발생할 수도 있고, 다양하다.메모리 교체 기법 - 프로세스 스케줄링우선 프로세스 상태 다이어그램을 먼저 보아야 한다.  준비에서 실행으로 가는 이벤트를 Dispatch  실행에서 준비로 가는 이벤트를 할당 시간 초과  실행에서 대기로 가는 것을 입출력 발생  대기에서 준비로 가는 이벤트를 wake-up프로세스 구성 요소  사용자 작성 코드  사용자 사용 데이터  스택: 함수 호출 및 인자 값 전송에 사용  프로세스 제어 블록: PCB라고 불리고, 프로세스 생성 시 만들어지는 한 프로세스의 전체를 정의한 객체이다. PID, 프로세스 상태, 프로그램 카운터ㅡ 레지스터 저장 영역, 프로세서 스케줄링 정보, 계정 정보, 입출력 상태 정보, 메모리 관리 정보로 구성된다.  IPC: 모듈 간 통신 방식을 구현하기 위해 사용되는 인텊에ㅣ스 집합으로 복수의 프로세스를 수행해서 이뤄지는 프로세스 간 통신을 지원한다.Thread프로세스보다 가볍고, 독립적으로 수행되는 순차적인 제어의 흐름이며 실행 단위이다. 프로세스에서 실행 제어만 분리한 실행 단위로 한 개의 프로세스는 여러 개의 스레드를 가질 수 있다.  커널 수준 스레드          커널이 주체고 커널이 각 스레드를 개별적으로 관리할 수 있고      다른 스레드가 입출력 작업이 끝날 때까지 다른 스레드를 사용하여 다른 작업을 진행할 수 있다.      단점으로는 오버헤드가 많고, 생성 및 관리하는 것이 느리다.        사용자 수준 스레드          커널 모드로 전환하지 않기 때문에 인터럽트가 발생할 때 오버헤드가 적고      사용자 영역에서 행동하기 때문에 OS 스케줄러의 컨텍스트 스위칭이 없다. 하지만 경량화된 컨텍스트 스위칭을 사용하긴 한다.      여러 개의 사용자 스레드 중 하나의 스레드가 시스템 호출 등으로 블록이 걸리면 나머지 모든 스레드 역시 블록됨      사용자 수준 스레드는 프로세스 1개당 커널 스레드 1개가 할당됨      프로세스 스케쥴링 기준  서비스 시간 = 프로세스가 실행해야 할 총 시간, 프로세스가 CPU에서 실행되는 시간  응답 시간 = 프로세스가 처음 CPU를 할당받아 반응하는 시간 - 도착 시간  대기시간 = 프로세서에 할당되기 까지 프로세스가 대기 큐에 대기하는 시간  반환 시간 = 대기 시간 + 서비스 시간  평균 대기시간 = 모든 프로세스의 대기 시간 합을 프로세스 수로 나눈 값(대기시간이 0 인 애도 포함)  종료 시간 = 도착 시간 + 반환 시간  시간 할당량 = 각 프로세스가 한 번에 CPU를 사용할 수 있는 최대 시간, 주어짐  응답률 = $\\frac{(대기시간 + 서비스시간)}{서비스 시간}$, HRN 에서 사용프로세스 스케줄링 유형  선점형 스케줄링: CPU 반환시 까지 다른 프로세스 선점 가능  비선점형 스케줄링: CPU 반환시 까지 다른 프로세스가 선점 불가선점형 스케줄링 알고리즘  SRT(Shortest Remaining Time First): 가장 짧은 시간이 소요되는 프로세스를 먼저 수행  MLQ(Multi Level Queue): 여러 개의 큐를 이용하여 각 큐는 순위가 있고, 각자 독자적인 스케쥴링을 가짐  MLFQ(Multi Level Feedback Queue): FCFS 와 RR(Round Robin) 스케줄링 기법을 혼합하여 새로운 프로세스는 높은 우선순위 큐로, 프로세스 실행 시간이 길어질 수록 낮은 우선순위 큐로 이동하며, 마지막은 라운드 로빈 방식을 적용  RR(Round Robin): 균등한 CPU 점유 시간으로 시분할 시스템에서 활용비선점형 스케줄링 알고리즘  Priority  Deadline  FCFS(First Come First Served)  SJF(Shortest Job First)  HRN(Highest Response Ratio Next)Deadlock다중 프로세싱 환경에서 두 개 이상의 프로세스가 특정 자원할당을 무한정 대기하는 상태발생 조건  상호 배제: 자원을 배타적으로 점유하여 다른 프로세스가 그 자원을 사용할 수 없는 상태  점유와 대기: 자원을 점유하고 있으면서 또 다른 자원을 요청하여 대기하고 있는 상태  비선점: 점유한 자원에 대해 다른 프로세스가 선점할 수 없고 오직 점유한 프로세스만이 해제 가능  환형 대기: 두 프로세스가 서로서로 점유와 대기중해결 방안  예방(Prevention): 점유 자원 해제 후 새 자원 요청  회피(Avoidance): 안전한 상태를 유지할 수 있는 요구만 수락          은행가 알고리즘: 자원 Max - 자원 Allocation = Need 값을 통해 Request $&lt;=$ Need 가 아니면 에러, Request $&lt;=$ Available 가 아니면 대기 상태로 전환, Safe State 인지 확인 후 Unsafe State 면 자원 회수하고 대기를 한다.      Wound-Wait: 트랜잭션마다 타임스탬프가 있어서  $T_i 의 나이 &lt; T_j 의 나이$ 라면 $T_i$가 $T_j$ 를 Wound 하고($T_j$ 강제 종료 후 Rollback), $T_i$는 자원 획득하여 계속 진행  $T_i 의 나이 &gt; T_j 의 나이$ 라면 $T_i$는 대기한다.      Wait-Die: Wound-Wait 와 같지만 그냥 조건만 반대다.        발견(Detection): 시스템의 상태를 감시 알고리즘을 통해 교착 상태 검사          자원할당 그래프      Wait for Graph        복구(Recovery): 교착상태가 없어질 때까지 프로세스를 순차적으로 Kill하여 제거          프로세스 Kill      자원 선점      디스크 스케줄링  FCFS: FIFO랑 같음  SSTF: 현재 위치에서 탐색 거리가 짧은 트랙에 대한 요청  SCAN: 진행 방향이 결정되면 탐색 거리가 짧은 순서에 따라 그 방향의 끝까지 가면서 요청 처리 후 역방향도 그렇게 진행  C-SCAN: 바깥쪽에서 안쪽으로 움직이면서 가장 짧은 탐색 거리를 갖는 요청을 서비스  LOOK: SCAN을 기초로 끝까지 안가고 요청까지만 간 후 바꿈  N-STEP: 대기 중이던 요청들만 서비스, 진행 중 도착한 요청은 한꺼번에 모아서 다음의 반대 진행방향으로 진행할 때 서비스  SLTF: 섹터 큐잉이라고도 하며, 특정 실린더의 여러 트랙에 대한 요청들을 검사하고 회전지연시간이 가장 짧은 요청부터 처리전송 매체 접속 제어(MAC; Media Access Control)통신망에서 공유 매체에 대한 다중 접근 제어가 필요  CSMA/CD: IEEE802.3 유선 LAN의 반이중 방식(Half Duplex)에서 사용하며, 현재 채널이 사용 중인지 체크하여 사용하지 않을 때 전송하는 매체에 접속하여 단말이 신호 전송함  CSMA/CA: IEEE802.11 무선 LAN의 반이중 방식(Half Duplex)에서 사용하며, 매체가 비어있음을 확인하고, 충돌을 피하기 위해 임의 시간을 기다린 후 데이터를 전송함프로토콜 기본요소  구문: 데이터 형식, 코딩, 신호 레벨 구성  의미: 제어 정보, 에러 처리 등  타이밍: 속도 조절, 순서 관리를 위한 요소OSI 7계층물데네전세표응프로토콜| 계층           | Protocol Data Unit | 대표 Protocol              | 대표 장비               ||—————-|———————|—————————–|————————–|| 응용 계층       | Data                | HTTP, FTP, SMTP, POP3, IMAP, TELNET, SSH, SNMP | - (소프트웨어 계층)      || 표현 계층       | Data                | JPEG, MPEG, SSL/TLS         | - (소프트웨어 계층)      || 세션 계층       | Data                | RPC, NetBIOS, PPTP               | - (소프트웨어 계층)      || 전송 계층       | Segment             | TCP, UDP                    | - L4 Switch    || 네트워크 계층    | Packet              | IP, ICMP, IGMP, ARP, RARP, IPsec        | 라우터(Router), L3 스위치  || 데이터링크 계층 | Frame               | HDLC, Ethernet, PPP, 프레임 릴레이, ATM, MAC          | 스위치(Switch), 브리지(Bridge)   || 물리 계층       | Bit                 | RS-232, DSL, IEEE 802.3     | 허브(Hub), 리피터, 케이블 |데이터링크 계층주요 기술  VLAN: 물리적 배치와 상관없이 논리적으로 LAN을 구성하여 Broadcast Domain을 구분할 수 있게 해서 성능향상, 보안성 증대를 이룸  STP(Spanning Tree Protocol): 2개 이상의 스위치가 여러 경로로 연결될 때, 무한 루프를 막기 위해 우선순위에 따라 1개의 경로로만 통신하도록 하는 프로토콜오류 제어  전진 오류 수정(FEC; Forward Error Correction): 오류 검출 및 오류 재전송 요구 없이 스스로 수정          해밍 코드 방식: 1비트 오류 검출용이며, 특정 위치에 XOR 연산으로 오류 감지      상승 코드 방식: 각 비트가 이전 비트보다 크거나 같게 하여 신호의 순차성으로 오류 감지, 흐름 체크용        후진 오류 수정(BEC; Backward Error Correction): 전송 과정에서 오류 발생 시 송신 측에 재전송 요청          검출                  패리티 검사: 1비트 오류 검출용이며, 1의 개수가 홀수가 되도록 추가          CRC: 다수 비트 오류 검출용이며, 데이터를 이진 다항식으로 보고, 특정 다항식으로 나눈 뒤, 나머지를 코드에 추가          블록합 검사: 데이터 블록의 간단한 오류를 검사하며, 일정 크기로 나눈 후에 합계를 계산하여 비교한다.                    제어: 자동 반복 요청(ARQ; Automatic Repeat reQuest)이 대표적이고 다음과 같은 방식이 있다.                  Stop-and-Wait ARQ: ACK를 받으면 다음 프레임을 전송, NAK을 받으면 재전송          Go-Back-N ARQ: NAK를 받으면 오류가 발생한 프레임 이후에 전송된 모든 데이터 프레임을 재전송, 즉 NAK로 돌아감          Selective Repeat ARQ: 연속적으로 데이터를 재전송하고 에러가 발생한 데이터 프레임만 재전송                    ✒️ 용어DispatchReady Queue 중에서 실행할 프로세스를 선정하여 현재의 실행 중인 프로세스와 교체하는 과정을 디스패치라고 한다.할당 시간 초과시간 초과 시 스케쥴러에 의해 프로세스가 PCB에 저장되고 이를 Ready Queue에 저장한다. 해당 프로세스를 다시 ready state 상태로 보내고 대기시키는 과정이다.입출력 발생(Block)지정된 시간을 초과하기 전에 입출력이나 기타 사건이 발생하면 CPU를 스스로 반납하고 입출력이 될 때까지 대기 상태로 전이된다.깨움(wake-up)입출력 종료 시 대기 상태의 프로세스에게 입출력 사실을 wait &amp; signal 등에 의해 알려주고, 준비 상태로 전이됨.RS-232PC와 음향 커플러, 모뎀 등을 접속하는 직렬 방식의 인터페이스HDLCHigh-level Data Link Protocol, 다중 방식의 통신에서 동기식 비트 중심의 데이터 링크 프로토콜PPPPoint-to-Point Protocol, 두 통신 노드 간의 직접적인 연결을 위해 일반적으로 사용되는 데이터 링크 프로토콜프레임 릴레이데이터 프레임들의 중계 기능과, 다중화 기능만 수행하여 처리 속도와 전송 지연을 향상 시킴ATM정보 전달의 기본단위를 53 바이트 ‘셀 단위’로 전달하는 비동기식 시분할 다중화 방식의 패킷형 전송기술Switch허브의 단점을 개선하여, 출발지로 들어온 frame을 목적지 MAC 주소 기반으로 빠르게 전송, 전송방식은:  cut-through  store-and-forward  Fragment Free가 있다.Bridge두 개의 근거리 통신망(LAN)을 연결해주는 통신망IP데이터를 패킷 단위로 분할하여, 목적지 주소(IP 주소)를 기반으로 전송 경로를 결정하는 프로토콜ARPIP 네트워크 상에서 IP 주소를 MAC 주소로 변환하는 프로토콜RARPIP 호스트가 자신의 물리 네트워크 주소(MAC)은 알지만 IP를 모를때 서버로부터 IP주소를 요청하기 위해 사용ICMPIP에서 전송 오류 발생 시, 오류 정보를 전송하는 목적으로 사용되는 프로토콜이며 메시지 형식은 8 byte 헤더와 가변 길이의 데이터 영역으로 분리한다. ping 명령어가 대표적으로 ICMP 가 사용됨IGMP인터넷 그룹 관리 프로토콜로 멀티캐스팅 그룹을 구성할 때 사용, IGMP 에는 그룹가입, 멤버십감시, 멤버십응답, 멤버십탈퇴가 있어서 그룹을 관리하고 구성하는데 용이하다. 화상회의나 IPTV에서 사용Router서로 다른 네트워크 대역에 있는 호스트들 상호 간에 통신이 가능하도록 패킷 위치를 추출해 최적의 경로를 계산하여(라우팅 프로토콜 사용) 경로를 따라 데이터 패킷을 다음 라우터로 전송L3 SwitchIP 레이어에서 스위칭을 통해 외부로 전송, L2 기능 + 경로 제어 기능 + 고속 라우팅 기능 수행TCP데이터나 패킷을 세그먼트로 분리시켜 근거리 통신망에서 인트라넷, 인터넷에 연결된 단말에서 옥텟(1byte)을 안정적으로, 순서대로, 에러 없이 교환할 수 있게 해주는 프로토콜UDP비연결성이며 순서화되지 않은 데이터 그램(UDP에서 PDU만 이렇게 유독 부름)을 제공L4 Switch4계층에서 네트워크 단위들을 연결하는 통신 장비이며, TCP/UDP 등 스위칭을 수행한다. TCP 에도 여러 프로토콜, UDP 에도 여러 프로토콜이 있는데, FTP, HTTP 등의 프로토콜을 구분하여 스위칭을 하는 Load Balancing 이 가능하다.NetBIOS7계층에게 API를 제공하여 통신수행⭐️RPC원격 프로시저라고 불리고, 다른 주소 공간에서 함수나 프로시저를 실행할 수 있는 프로세스 간의 통신HTTP80번 포트 사용, 하이퍼 텍스트를 빠르게 교환FTP21번 포트 사용, TCP/IP 프로토콜을 가지고 서버와 클라이언트 사이의 파일 전송 담당SMTPTCP 포트번호 25를 사용해서 이메일을 보내기 위해 사용POP3110번 포트를 사용, 원격 서버로 부터 이메일을 가져오는 데 사용IMAP143번 포트 사용, TCP/IP 연결을 통해 이메일을 가져오는데 사용Telnet인터넷이나 로컬 영역에서 네트워크 연결에 사용되는 네트워크 프로토콜SSH22번의 포트를 사용하여 인증, 암호화, 무결성을 제공하여 클라이언트 공개키를 서버에 등록만 하면, 데이터를 암호화하여 컴퓨터 간의 원격 명령 실행, 쉘 서비스를 수앻할 수 있음SNMP161번의 포트를 사용하고, TCP/IP 네트워크 관리 프로토콜이다. 라우터나 허브에서 정보를 수집하고 관리하는 프로토콜이다."
    },
  
    {
      "title": "정보처리기사 실기 SQL 응용 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/11/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-sql-%EC%9D%91%EC%9A%A9-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-11",
      "content": "📂 목차    📚 본문  ⭐️ 스키마: 구조, 제약조건 등의 정보 담음          외부: 사용자 뷰      개념: 전체 뷰      내부: 물리적 저장장치 정의, 레코드 형식 정의, 내부 레코드의 물리적 순서, 저장 데이터 항목의 표현법        테이블  뷰  인덱스트랜잭션 특징  Atomicity: 연산을 나누는 단위, Commit/Rollback, 회복성 보장  Consistency: 트랜잭션 수행 전과 후의 시스템의 고정 요소가 같아야 함, 무결성, 동시성 제어  Isolation: 동시에 실행되는 트랜잭션이 서로 영향을 미치지 않아야 함, Read Uncommitted, Read Committed, Repeatable Read, Serializable  Durability: 성공이 완료된 트랜잭션의 결과는 영속적으로 데이터베이스에 저장, 회복 기법병행제어 기법  로킹: 하나의 자원에 대한 두 트랜잭션이 동시에 접근 X, 상호 배제 기능 구현  2PC: 2단계에 걸쳐 분산 데이터베이스 시스템에서 트랜잭션의 일관성을 유지관계 데이터 언어 - 관계 대수  합집합  교집합  차집합  카티션 프로덕트설명 생략관계 데이터 언어 - 순수 관계 연산자  Select: $\\sigma_{조건}(R)$, 조건을 만족하는 튜플s  Project: $\\pi_{속성리스트}(R)$  Join: ${R_1}⋈{R_2}$, 공통 속성을 활용해 튜플을 연결하여 만듦  Division: $R\\divide S$ Relation S에 맞는 것들로만 R에서 분리하여 프로젝션개체-관계 다이어그램구성 요소  개체: ☐  관계: ♢  속성: ○  다중 값 속성: ◎  관계-속성 연결: -Anomaly  삽입 이상: 데이터 삽입 시 다른 값들도 함께 삽입  삭제 이상: 데이터 삭제 시 다른 값들도 삭제  갱신 이상: 속성값 갱신 시 일부 튜플의 정보만 갱신(연동된 튜플이 갱신이 안됨)⭐️ 데이터 정규화  1NF: 원자값 구성  2NF: 1NF 에서 Partial Functional Dependency(비기본키가 기본키의 일부에만 의존하는 경우) 삭제즉, Full Functional Dependency을 가져야 하는데 기본키의 진부분집합의 키에 의존되어 비기본키가 정해지는 경우를 없애야 한다는 것  3NF: 2NF 에서 속성에 관한 종속성이 추이율(transitivity) 를 만족하면 안됨, 즉 이행 종속이면 안됨  BCNF(3.5NF): 3NF 에서 모든 함수 종속에서 결정자가 무조건 후보키여야 함  4NF: 3.5NF를 만족하는 릴레이션에서 다치 종속(Multi-Valued Dependency MVD, A -&gt;-&gt; B)를 제거  5NF: 4NF 에서 조인 종속성(Join Dependency, 모든 조인 종속이 후보키에 의해서만 발생해야 함) 제거, 조인으로 원래 릴레이션 정확히 복원 가능해야 함스토리지 구성  DAS: 케이블로 연결  NAS: LAN으로 연결  SAN: 광섬유 연결접근제어불법적인 데이터의 접근으로부터 DB를 보호하는 기법DAC, 신원기반 접근제어 정책정책  IBP(Individual-Based Policy): 1:1 의 사용자:객체 로 허가를 부여 받음  GBP(Group-Based Policy): n:1 의 그룹:객체 로 허가를 부여 받음MAC, 규칙기반 접근제어 정책정책  MLP(Multi-Level Policy): 사용자 및 객체가 각각 부여된 기밀 분류에 따른 정책  CBP(Compartment-Based Policy): 조직 내 ‘특정 집단별’로 구분된 기밀 허가에 따른 정책RBAC, 역할기반 접근제어 정책메커니즘  ACL(Access Control List): 주체가 디렉토리나 파일과 같은 특정 시스템 객체에 접근할 수 있는 허가 받은 접근 종류들이 기록된 목록  CL(Capability List): 주체에게 허가된 자원 및 권한의 목록  SL(Security Label): 객체에 부여된 보안 속성 정보의 집합데이터베이스 무결성 종류  개체 무결성: 개체의 기본키는 존재하고 유일해야 함  참조 무결성: 외래 키가 참조하는 다른 개체의 기본 키에 해당하는 값은 기본키 값이거나 NULL 이어야 함  속성 무결성: 속성의 값은 기본값, NULL 여부, 도메인이 지정된 규칙을 준수해야 하는 제약조건  사용자 무결성: 의미적 요구사항을 준수해야 하는 제약조건  키 무결성: 한 릴레이션에 같은 키 값을 가진 튜플들을 허용할 수 없다는 제약조건키 특성  유일성: 모든 엔티티가 식별자에 의해 유일함  최소성: 최소한의 속성으로 식별자 구성Denormalization개발의 성능 최적화, 단순화를 위해 선택한 데이터 정규화의 역방향 작업으로 통합, 중복, 분리하는 과정이다."
    },
  
    {
      "title": "정보처리기사 실기 어플리케이션 테스트 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/11/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%96%B4%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-11",
      "content": "📂 목차  테스트 레벨  테스트 종류          블랙박스 테스트      화이트박스 테스트        테스트 목적에 따른 분류  소프트웨어 테스트 원리  테스트 장치 구성요소📚 본문테스트 레벨  단위 테스트: 인터페이스, 자료 구조, 실행 경로, 오류 처리 테스트          블랙박스 테스트      화이트박스 테스트        통합 테스트: 빅뱅, 상향식/하향식 테스트  시스템 테스트: 기능/비기능 요구사항 테스트          기능적 요구사항 테스트: 요구사항 명세서, 비즈니스 절차, 유스케이스 등 명세서 기반의 블랙박스 테스트      비기능적 요구사항 테스트: 성능 테스트, 회복 테스트, 내부 시스템의 메뉴 구조, 웹 페이지의 내비게이션 등 구조적 요소에 대한 화이트 박스 테스트        인수 테스트: 알파/베타 테스트          알파테스트: 사용자가 개발자 환경에서 수행하는 인수 테스트      베타테스트: 실제 환경에서 소프트웨어를 사용하게 하고 피드백 받는 인수테스트      테스트 종류  정적 테스트: 동료 검토, 정적 분석, 워크스루, 인스펙션  동적 테스트: 블랙박스 테스트(명세 기반 테스트), 화이트박스 테스트(구조 기반 테스트)블랙박스 테스트사용자의 요구사항 명세를 보면서 수행  동등 분할 테스트(Equivalence Partitioning Testing): 유사한 도메인 별로 유효값/무효값으로 그룹핑 후 대푯값으로 테스트  경곗값 분석 테스트(Boundary Value Analysis Testing): 경계값 부근의 값을 테스트 케이스로 설계, 입력값의 극한 한계를 테스트  결정 테이블 테스트(Decision Table Testing): 요구사항의 논리와 발생조건을 테이블 형태로 나열하여, 조건과 행위를 모두 조합하여 테스트  상태전이 테스트(State Transition Testing): 테스트 대상 상태를 구분하고, 이벤트에 의해 어느 한 상태에서 다른 상태로 전이되는 경우의 수를 테스트  유스케이스 테스트(Use Case Testing): 유스케이스 다이어그램을 기반으로 테스트 케이스를 명세화하여 수행하는 테스트  분류 트리 테스트(Classification Tree Method Testing): SW의 일부 또는 전체를 트리 구조로 분석하여 테스트  페어와이즈 테스트(Pairwise Testing): 모든 조합에 비해 상대적으로 적은 양의 테스트 세트를 구성하기 위한 테스트  원인-결과 테스트(Cause-Effect Graph Testing): 그래프를 활용해 효용성이 높은 테스트 케이스를 선정하여 테스트  비교 테스트(Comparison Testing): 같은 입력 값을 넣어서 동일한 결과가 나오는지 비교하는 테스트  오류 추정 테스트(Error Guessing Testing): 개발자가 범할 수 있는 실수를 추정 후 그에 따른 케이스를 테스트화이트박스 테스트  구문 커버리지(Statement Coverage): 모든 명령문을 적어도 한 번 수행하는 테스트  결정 커버리지(Decision Coverage): 각 분기의 결정 포인트 내의 ‘전체 조건식’이 적어도 한 번은 참, 거짓이 되도록  조건 커버리지(Condition Coverage): 각 분기의 결정 포인트 내의 ‘개별 조건식’이 적어도 한 번은 참, 거짓이 되도록  조건-결정 커버리지(Condition/Decision Coverage): 결정 + 조건      변경 조건-결정 커버리지(Modified Condition/Decision Coverage): 각 개별 조건식들이 독립적으로 전체 조건식에 영향을 주도록 해서 보완    다중 조건 커버리지(Multiple Condition Coverage): 모든 개별 조건식의 모든 가능한 조합을 100% 보장하는 커버리지  기본 경로 커버리지(Base Path Coverage): 수행 가능한 모든 경로를 테스트  제어 흐름 테스트(Control Flow Testing): 그래프 형태로 나타내어 내부 로직을 테스트  데이터 흐름 테스트(Data Flow Testing): 제어 흐름 그래프에서 데이터 사용현황을 추가한 그래프를 통해 테스트  루프 테스트(Loop Testing): 반복 구조에 초점을 맞춰 실시하는 테스트 기법테스트 목적에 따른 분류  회복 테스트: 고의로 실패를 유도 후 정상 복귀 여부를 테스트  안전 테스트: 불법 소프트웨어가 시스템을 파괴하지 못하도록 소스코드 내의 보안적인 결함을 미리 점검  성능 테스트: 사용자 이벤트에 시스템이 응답하는 시간, 특정 시간 내에 처리하는 업무량, 반응 속도 등을 측정  강도 테스트: 부하 임계점 이상의 부하를 가하여 비정상적인 상황에서의 처리 테스트  구조 테스트: 시스템의 내부 논리 경로, 소스 코드의 복잡도를 평가하는 테스트  회귀 테스트: 오류를 제거하거나 수정한 시스템에서 오류 제거와 수정에 의해 새로 유입된 오류가 없는지 확인  병행 테스트: 변경된 시스템과 기존 시스템에 동일한 데이터를 입력 후 결과를 비교소프트웨어 테스트 원리  결함 존재 증명: 결함이 없다는 것을 증명할 수 없다  완벽 테스팅은 불가능: 무한 경로, 무한 입력으로 인한 완벽한 테스트 어려움  초기 집중: SW 개발 초기에 체계적인 분석과 설계가 수행되지 않으면 프로젝트 후반에 영향을 미치게 되어 비용이 커지는 요르돈 법칙  결함 집중: 파레토의 법칙 적용  살충제 패러독스: 동일한 테스트 케이스에 의한 반복적 테스트는 새로운 버그를 찾지 못함  정황 의존성: 소프트웨어의 성격에 맞게 테스트 수행  오류-부재의 궤변: 요구사항을 충족시키지 못하면 결함이 없다고 해도 품질이 높다고 볼 수 없음테스트 장치 구성요소  테스트 드라이버: 하위 모듈을 호출하는 상위 모듈의 역할(임시적 상위 모듈)  테스트 스텁: 상위 모듈에 의해 호출되는 하위 모듈의 역할(임시적 하위 모듈)  테스트 슈트: 시나리오가 포함되지 않은 단순한 테스트 케이스의 모임  테스트 케이스: 입력, 실행 조건, 기대 결과 등의 집합  테스트 시나리오: 시나리오 : 케이스 = 1 : n  테스트 스크립트: 테스트 케이스의 실행 순서를 작성한 문서  Mock Object: 사용자의 행위를 조건부로 사전에 입력하여 그 상호아에 예정된 행위를 수행하는 객체"
    },
  
    {
      "title": "정보처리기사 실기 제품 소프트웨어 패키징 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/10/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%A0%9C%ED%92%88-%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%ED%8C%A8%ED%82%A4%EC%A7%95-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-10",
      "content": "📂 목차  어플리케이션 배포 도구 세부 기술  DRM  ISO/IEC 9126 소프트웨어 품질 특성  ISO/IEC 14598 소프트웨어 품질 특성  SQuaRE(ISO/IEC 25000)  소프트웨어 공학 관련 법칙  빌드 자동화 구성 요소📚 본문어플리케이션 배포 도구 세부 기술  공개키 기반 구조: (보안에서 다룸)  대칭 및 비대칭 암호화: (보안에서 다룸)  전자서명: 특정 전자문서에 첨부되거나 논리적으로 결합된 전자적 형태의 정보  DOI: 바코드 시스템  URI: 인터넷에 있는 자원의 유일한 주소  XrML: 콘텐츠/서비스의 권리 표현을 위한 XML 기반 마크업 언어  MPEG-21: 멀티미디어 관련  XML: W3C에서 개발한 특수한 목적의 마크업 언어를 만드는 데 사용하도록 만든 다목적 마크업 언어  CMS: 다양한 미디어 포맷을 생성, 수집, 관리, 배급 까지의 공급 전의 전 과정을 관리하는 시스템  코드 난독화: 역공학을 막기 위해 소스 코드 indent 와 띄어쓰기 다 생략 등등  Secure DB: 커널 암호화 방식으로 DB 파일을 직접 암호화  SSO: 한 번의 시스템 인증을 통해 여러 정보시스템에 재인증 절차 없이 접근 가능DRM디지털 콘텐츠의 권리정보를 지정 후 암호화 기술을 사용하여 허가된 사용자 만이 권한 범위 내에서 콘텐츠 이용이 가능ISO/IEC 9126 소프트웨어 품질 특성  기능성: 요구사항 만족하는지  신뢰성: 주어진 시간 동안 주어진 기능을 오류 없이 수행하는지  사용성: 사용자가 이해하고 학습하고 선호하는 소프트웨어인지  효율성: 자원의 양에 따라 요구된 성능을 제공하는지  유지보수성: 수정/개선/개작 을 통해 변경되는 능력  이식성: 하나 이상의 하드웨어에서 쉽게 수정될 수 있는 시스템 능력ISO/IEC 14598 소프트웨어 품질 특성  반복성: 특정 제품을 동일 평가자가 동일 사양으로 평가시 동일한 결과가 나와야 함  재현성: 특정 제품을 다른 평가자가 동일 사양을 평가하면 유사한 결과가 나와야 함  공정성: 평가가 특정 결과에 편항되면 안됨  객관성: 평가가 객관적 자료에 의해서 평가되어야 함SQuaRE(ISO/IEC 25000)소프트웨어 품질 특성 및 품질 평가 방법을 통합한 소프트웨어 품질 평가 모델소프트웨어 공학 관련 법칙  브룩스의 법칙: 지체되는 소프트웨어 개발에 인력을 추가하면 개발을 늦출 뿐이다(마비노기 모바일 - 내부 조직 구조 변경이 있었음 무려 8년의 개발이 걸림).  파레토 법칙: 결과의 80%가 전체 원인의 20%에서 일어나는 현상 다시 말해 오류로 결과가 나면 모듈의 20% 에서 80% 의 결함이 발견됨  롱테일 법칙: 80%의 다수가 20%의 소수 핵심 인력보다도 뛰어난 가치를 창출해낸다는 법칙, 파레토의 반대 법칙빌드 자동화 구성 요소  CI: Jenkins, Hudson, Git Actions, …  SCM: SVN, Git, …  Build Tool: Ant, Maven, Gradle, …  Test Tool: Junit, Selenium, PyTest, …  Test Coverage Tool: Emma, …  Inspection Tool: CheckStyle, Cppcheck, …"
    },
  
    {
      "title": "정보처리기사 실기 통합 구현 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/10/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%ED%86%B5%ED%95%A9-%EA%B5%AC%ED%98%84-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-10",
      "content": "📂 목차    📚 본문단위 모듈 구현의 원리  정보 은닉  분할과 정복  데이터 추상화  모듈 독립성재사용 기법재공학기존 소프트웨어를 버리지 않고 기능을 개선시키거나 기능을 새로운 소프트웨어로 재활용  분석  재구조  역공학  이식재개발기존 시스템 내용을 참조하여 완전히 새로운 시스템 개발단위 모듈 테스트 종류  블랙박스 테스트: 입력과 결과만 보는 것  화이트박스 테스트: 모듈 내부 소스를 보며 수행각종 기능 및 도구  JDBC: DB에 접속할 수 있도록 자바에서 인터페이스 제공  ODBC: MS에서 만든 데이터베이스에 접근하기 위한 소퍼트웨어의 표준 규격  JIRA: 프로젝트 이슈 트래킹 기반 협업 도구  CVS: 중앙 집중 서버 저장소를 두고 클라이언트가 접속하여 버전 관리  SVN: 클라이언트-서버 방식으로 CVS의 단점을 보완, 롤백 가능  Git: 설명 생략"
    },
  
    {
      "title": "정보처리기사 실기 인터페이스 구현 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/10/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4-%EA%B5%AC%ED%98%84-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-10",
      "content": "📂 목차  내/외부 인터페이스 요구사항의 분류  요구사항 개발 단계  요구사항 도출 기법  요구사항 명세 기법          비정형 명세 기법      정형 명세 기법        요구사항 확인 및 검증 기법          정형 기술 검토 기법        시스템 구성요소📚 본문내/외부 인터페이스 요구사항의 분류  기능 요구사항: 기능과 관련하여 소프트웨어가 가져야 하는 기능적 속성에 대한 요구사항  비기능 요구사항: 기능적 속성이 아닌 성능, 보안, 품질 등에 대한 요구사항요구사항 개발 단계  도출  분석  명세  확인 및 검증요구사항 도출 기법  인터뷰: 이해관계자 대화  브레인 스토밍: 편안한 분위기의 아이디어 회의  델파이 기법: 전문가의 지식  롤 플레잉: 각자 맡은 역을 연기  워크숍: 모든 핵심 인물이 참여하여 공유  설문조사: 설문, 여론조사요구사항 명세 기법비정형 명세 기법자연어 기반으로 서술  FSM  Decision Table  E-R Modeling  State Chart정형 명세 기법수학적 원리와 표기법을 이용하여 서술  VDM  Z-Schema  Petri-Nets  CSP요구사항 확인 및 검증 기법정형 기술 검토 기법  동료 검토: 동료 2-3 명이 진행하는 리뷰  워크 스루: 회의 전에 배포해서 사전검토한 후 짧은 시간 동안 회의를 진행  인스펙션: 계획 → 사전 교육 → 준비 → 인스펙션 회의 → 수정 → 후속 조치시스템 구성요소  Input: 데이터  Output: 결과  Process: 처리 방법, 조건  Control: 감독  Feedback: 반복 개선"
    },
  
    {
      "title": "정보처리기사 실기 어플리케이션 설계 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/09/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%96%B4%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%A4%EA%B3%84-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-09",
      "content": "📂 목차  재사용 유형  모듈  공통 모듈 원칙  모듈화 기법  모듈 개수-비용 간 상관관계  응집도  결합도  팬인 및 팬아웃  소프트웨어 아키텍쳐 비용 평가 모델 종류  소프트웨어 아키텍처 패턴 유형  객체 지향 기법  객체 지향 설계 원칙(SOLID)  객체 지향 방법론 종류  ⭐️ 디자인 패턴          생성 패턴      구조 패턴      행위 패턴      📚 본문재사용 유형  함수와 객체  컴포넌트  어플리케이션모듈자체적으로 컴파일 가능공통 모듈 원칙  정확성: 실제 시스템 구현 시 필요한지 아닌지를 알 수 있도록 정확하게 작성  명확성: 일관되게 이해되고 한 가지로 해석될 수 있게 작성  완전성: 필요하고 요구되는 모든 것을 기술  일관성: 상호 충돌이 없도록 작성  추적성: 공농 기능에 대한 요구사항 출처와 관련 시스템 등의 유기적 관계에 대한 식별 가능하도록 작성모듈화 기법  루틴: 특정 동작을 수행하는 일련의 코드로 기능을 가진 명령들의 모임  메인루틴: 전체적인 동작 절차를 표시하도록 만들어진 루틴  서브 루틴: 메인 루틴에 의해 호출되는 루틴모듈 개수-비용 간 상관관계  모듈 개수가 늘어나면, 모듈 통합 비용은 커지며, 개발 비용은 줄어듦  모듈 개수가 적어지면, 모듈 통합 비용은 줄지만, 개발 비용은 늘어남응집도모듈 내부 구성요소 간의 연관 정도외우기 - 우논시절통순기  우연적(Coincidental) 응집도 - 서로 간에 어떠한 의미 있는 연관이 없을때  논리적(Logical) 응집도 - 유사한 성격을 갖거나 특정 형태로 분류되는 처리요소들이 한 모듈에서 처리됨  시간적(Temporal) 응집도 - 특정 시간에 처리되어야 하는 활동들을 한 모듈에서 처리  절차적(Procedural) 응집도 - 구성요소들이 순차적으로 수행  통신적(Communication) 응집도 - 동일한 입력과 출력을 사용하여 다른 기능을 수행하는 활동들이 모여 있음  순차적(Sequential) 응집도 - 한 활동으로부터 나온 출력값을 다른 활동이 사용할 경우  기능적(Functional) 응집도 - 모든 기능이 단일한 목적을 위해 수행  기준은 ‘한 모듈’결합도모듈과 모듈간의 상호의존성을 나타냄외우기 - 내공외제스자  내용(Content) 결합도 - 다른 모듈의 변수나 기능을 다른 모듈에서 사용하는 경우  공통(Common) 결합도 - 모듈 밖의 전역 변수를 참조하고 갱신하는 식의 상호작용  외부(External) 결합도 - 데이터 포맷, 통신 프로토콜/디바이스 인터페이스를 공유할 경우  제어(Control) 결합도 - 내부 논리 조직을 제어하기 위한 목적으로 제어 신호 이용  스탬프(Stamp) 결합도 - 모듈 간 인터페이스로 객체, 구조 등이 전달되는 경우  자료(Data) 결합도 - 전달되는 파라미터를 통해서만 모듈 간의 상호작용이 일어남팬인 및 팬아웃팬인: 어떤 모듈을 제어하는 모듈 수팬아웃: 어떤 모듈에 의해 제어되는 모듈 수소프트웨어 아키텍쳐 비용 평가 모델 종류  SAAM: 변경 용이성과 기능성에 집주, 평가가 용이  ATAM: 아키텍처 품질 속성 판단  CBAM: 비용 평가 모델  ADR: 응집도 평가 모델  ARID: 특정 부분에 대한 품질요소의 비용 평가소프트웨어 아키텍처 패턴 유형  계층화 패턴: 하위 모듈이 상위 모듈에게 서비스 제공  클라이언트-서버 패턴  파이프-필터 패턴: 데이터 스트림 생성, 처리하는 단반향 패턴, 필터 컴포넌트는 재사용성이 좋음  브로커 패턴: 브로커가 통신 조정하는 역할  모델-뷰-컨트롤러 패턴: 모델(핵심 기능과 데이터 보관), 뷰(정보 표시), 컨트롤러(입력 처리)  마스터-슬레이브 패턴: 실시간 시스템에서 사용객체 지향 기법  Encapsulation: 인터페이스 단순화  Inheritance: re-define 없이 물려받아 사용하는 기법  Polymorphism: 오버로딩(여러 생성자를 정의), 오버라이딩(메서드 재정의)  Abstraction: 공통 성질을 추출하여 추상 클래스를 정의  Information Hiding: 공개 인터페이스만을 통해서만 접근, Side-effect 최소화, 모듈 간 독립성 유지  Relationship: 두 개 이상의 엔티티 형에서 데이터를 참조하는 관계를 나타내는 기법          연관화: is-member-of, 객체 참조      집단화: part-whole, 모여서 하나의 상위 객체를 만듦      분류화: is-instance-of, 포함관계이자 상속      일반화: is-a, 상위 특성을 상속      특수화: is-a, 상위 특성을 상속 후 그 특성을 수정      객체 지향 설계 원칙(SOLID)  Single Responsibility: 하나의 클래스는 하나의 목적을 위해서  Open Close Principle: 확장에는 열려있고, 변경에는 닫혀있고  Liskov Substitution Principle: “서브 타입은 어디서나 그 상위 타입으로 교체할 수 있어야 한다.”  Interface Segregation Principle: 필요한 최소한의 인터페이스만 구현  ⭐️ Dependency Inversion(Injection) Principle: 실제 사용 관계는 바뀌지 않고 추상을 매개로 메시지를 주고받아 관계를 최대한 느슨하게 만드는 원칙객체 지향 방법론 종류  OOSE: 분석-설계-구현, 기능 요구사항 중심  OMT: 객체-동적-기능, 모델링 중심          Object Modeling: 객체 다이어그램      Dynamic Modeling: 상태 다이어그램      Functional Modeling: 자료 흐름도        OOD: 분석과 설계의 분리 불가능  Coad-Yourdon: E-R 다이어그램  Wirfs-Brock: 분석/설계 간의 구분이 없고 고객 명세서를 평가하여 설계 작업까지 연속적으로 수행⭐️ 디자인 패턴생성 패턴생빌 프로 팩앱싱  Builder: 복합 객체를 생성하는 방법, 객체를 구현하는 방법을 분리, 보통 클래스 내부에 Builder nested class 를 작성  Prototype: 일반적인 원형을 만든 후 해당 객체를 복제  Factory Method: 객체를 생성하는 인터페이스를 정의 → 하위에서 객체를 생성하는 인터페이스 구현  Abstract Factory: Composite Structure 를 가지는 인스턴스에 대한 팩토리를 만드는 객체  Singleton: 전역 변수를 사용하지 않고 객체 하나만 생성구조 패턴구 브데 퍼플 프록 컴 어  Bridge: ‘분리된’ 기능과 구현을 ‘연결시켜’ 추상화된 부분과 실제 구현 부분을 독립적으로 확장, 구현 뿐 아니라 추상화 부분 까지 건드려야 하는 경우 유용  Decorator: 필요한 기능을 추가해 확장이 필요할 때 객체 간의 결합을 통해 기능을 유연하게 확장, 여러 곳에 기능을 쉽게 넣을 때 개발의 편의성을 위한 목적  Facade: 사용자와 시스템, 시스템과 시스템 간의 통합된 단순한 인터페이스를 제공, 느슨한 결합도 목적  Flyweight: 다수 객체로 생성될 때, 공유 요소를 클래스 화하여 가상 인스턴스 공유로 메모리를 절약, 클래스 경량화 목적  Proxy: 실제 객체에 대한 대리 객체, 특정 객체로 접근을 제어하기 위해 사용  Composite: 객체들의 관계를 트리 구조로 구성, 복합 객체와 단일 객체를 동일시  Adapter: 기존 생성된 클래스를 재사용할 수 있도록 인터페이스 역할을 함, 인터페이스가 호환되지 않는 클래스들을 함께 이용하도록 할때 유용행위 패턴메인아이템 옵스 비컴 스메체  Mediator: 객체의 수가 많아짐에 따라 서로 간의 통신이 복잡하여 통신을 위한 중재자(mediator)를 둠  Interpreter: 구문을 나누고, 분리된 구문의 해석을 맡는 클래스를 ‘각각 작성’ 후 여러 형태의 언어 구문을 해석  Iterator: 컬렉션 구현 방법을 노출시키지 않고, 순회자(반복자) 클래스를 사용하여 접근  Template: 추상 클래스에는 추상 메서드를 통해 기능의 골격을 제공, 메서드는 세부 처리를 구체화하는 방식으로 사용  Observer: 한 객체의 상태가 바뀔 시 의존하는 다른 객체들에게 연락이 가는 구조, 일대 다의 의존성을 가짐  State: 객체 상태를 캡슐화하여, 참조하게 만드는 방식, 상태에 따라 다른 처리를 해야할 때 유용  Visitor: 각 객체가 구조가 자주 변경되지 않고, 새로운 연산을 자주 추가해야 할 때 사용, 보통 for 문으로 visitor를 매개변수로 넣는식으로 동작하며 그림 그리기 서비스에 유용하다.  Command: 재사용성이 높은 클래스를 설계, 하나의 추상 클래스에 메서드를 만들어 각 명령이 들어오면 그에 맞는 서브 클래스가 선택되어 실행  Strategy: 알고리즘 군을 정의(추상 클래스)하고, 같은 알고리즘을 각각 하나의 클래스로 캡슐화 후 필요할 때 서로 교환해서 사용  Memento: 객체의 정보를 저장할 필요가 있을 때 적용하는 디자인 패턴, Undo 기능을 개발할 때 사용  Chain of Responsibility: 정적으로 하드코딩 되어 있을 때 기능 처리의 연결 변경이 불가능, 동적으로 연결되어 있는 경우 다르게 처리될 수 있도록 연결한 디자인 패턴, 한 요청을 2개 이상의 객체에서 처리"
    },
  
    {
      "title": "정보처리기사 실기 화면 설계 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/09/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%ED%99%94%EB%A9%B4-%EC%84%A4%EA%B3%84-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-09",
      "content": "📂 목차  UI 유형  UI 화면 구성요소  UI 제스쳐  UI 설계 원칙  UI 설계 프로세스📚 본문UI 유형  CLI  GUI  NUI: 신체를 기반으로 상호작용  OUI: 입력장치가 곧 출력장치UI 화면 구성요소  그리드  콤보 박스: 드롭 다운 메뉴가 뜸  토글 버튼: Boolean  텍스트 박스  라디오 버튼: 택일  체크 박스: 다중 선택  Page 요소  팝업 요소  Alert 요소UI 제스쳐  탭: 짧고 가볍게 터치  더블 탭: 빠르게 두 번  프레스: 길게 꾹 누름  플릭: 수평/수직으로 빠르게 밈  스와이프: 드래그랑 같음  팬  드래그: 끌다가 손을 뗌  핀치: 두 손가락 확대, 축소 제스쳐  로테이트: 두 손가락 회전 제스쳐UI 설계 원칙  직관성: 누구나 쉽게 이해하고, 쉽게 사용  유효성: 정확하고 완벽하게 사용자의 목표가 달성되도록  학습성: 쉽게 배우고 사용  유연성: 상용자의 인터랙션 포용UI 설계 프로세스  문제 정의  사용자 모델 정의  작업 분석  컴퓨터 오브젝트 및 기능 정의  사용자 인터페이스 정의  디자인 평가"
    },
  
    {
      "title": "정보처리기사 실기 요구사항 확인 정리",
      "url": "/seonghun120614/computerscience/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/2025/07/09/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD-%ED%99%95%EC%9D%B8-%EC%A0%95%EB%A6%AC.html",
      "date": "2025-07-09",
      "content": "📂 목차  요구사항 분석 단계 절차  UML          UML 구성요소      구조적 다이어그램                  클래스 다이어그램          객체 다이어그램          컴포넌트 다이어그램          배치 다이어그램          복합체 구조 다이어그램          패키지 다이어그램                    동적 다이어그램                  유스케이스 다이어그램          시퀀스 다이어그램          커뮤니케이션 다이어그램          상태 다이어그램          활동 다이어그램          타이밍 다이어그램                    UML 관계      UML Stereotype        Agile 개발 방법론          XP      SCRUM      Lean        분석 자동화 도구📚 본문Ctrl + P 인쇄 가능합니다.요구사항 분석 단계 절차  요구사항 분류: 기능 요구사항, 비기능 요구사항을 구분하는 단계          기능 요구사항: 기능과 관련하여 소프트웨어가 가져야 하는 기능적 속성에 대한 요구사항      비기능 요구사항: 기능적 속성이 아닌 성능, 보안, 품질 등에 대한 요구사항        개념 모델링 생성 및 분석: 현실 세계의 상황을 단순화, 개념적으로 표현하는 것을 모델링이라고 한다.          DFD: 데이터 흐름을 처리기(◯), 데이터 흐름(→), 데이터 저장소(=), 단말(□) 로 표현함. 시간의 흐름 ❌, 제어 흐름 ❌                                                  DD: 시스템에 사용하는 모든 데이터에 대한 정의와 설명을 체계적으로 정리한 문서로 =(is composed of), +(연결), (생략), { , , }(반복), [              ](택일), **(주석) 을 통해 표현함.                                          UML      E-R        요구사항 할당  요구사항 협상  정형 분석UML객체 지향 소프트웨어 개발 과정에서 산출물을 명세화, 시각화, 문서화 할 때 사용되는 모델링 기술과 방법론을 통합해서 만든 표준화된 범용 모델링 언어UML 구성요소  사물(Things): 주제를 나타내는 추상적 개념으로 명사, 동사 의미  관계(Relationships): 사물-사물 연결로 형용사, 부사 의미  다이어그램(Diagrams): 사물과 관계를 모아 그림으로 표현, 9가지로 정의구조적 다이어그램외우기 - 클객 컴배 복패클래스 다이어그램  시스탬 내 클래스의 정적 구조 표현  속성과 동작으로 구성  클래스와 클래스, 클래스와 속성 사이 관계 표현  접근 제어자: public +, default ~, protected #, private -  UML에서 클래스는 보통 직사각형으로 표현됨객체 다이어그램  ‘특정 시점’의 인스턴스와 인스턴스 사이의 관계를 표현  객체 인스턴스를 나타내는 대신 실제 클래스를 사용  연관된 모든 인스턴스를 표현  객체가 인스턴스이다.컴포넌트 다이어그램  컴포넌트(Executable 단위) 기반의 물리적 구조 표현  실질적 프로그래밍 작업에 사용배치 다이어그램  컴포넌트 사이의 종속성을 표현  소프트웨어가 실제 시스템에 어떻게 배포되는지를 시각화할 때 사용  결과물, 프로세스, 컴포넌트 등 물리적 요소들의 위치를 표현  아키텍처 설계나 배포 구조 문서화, 운영 인수인계 할 때 사용복합체 구조 다이어그램  클래스나 컴포넌트가 복합 구조를 갖는 경우 그 내부 구조를 표현  일반적인 클래스 다이어그램은 이런 속성과 메서드를 가진다는 외형적인 관계만을 보여주지만, 이 클래스 내부에 어떤 역할과 부품이 있고, 어떻게 동작 객체를 통해 연결되는가 까지 설명하려면 이를 사용  내부 구조를 정밀하게 모델링패키지 다이어그램  유스케이스나 클래스 등의 모델 요소들을 그룹화한 패키지들의 관계를 표현동적 다이어그램외우기 - 유시커 상황타유스케이스 다이어그램  사용자 관점에서 시스템의 활동을 표현  유스케이스는 시스템의 기능적 요구 정의에 활용  구성요소          유스케이스: ◯      액터      시스템: □        관계 표현          연관관계 (유스케이스)-(액터)      포함 관계 (포함하는) - « include » - &gt; (포함되는)      확장 관계 (확장 기능) - « extend » -&gt; (확장 대상, 더 넓은 개념)  ex) (비밀번호 재설정) - « extend » -&gt; (로그인)      일반화 관계 (추상화) ◁- (구현체)      시퀀스 다이어그램  객체 간 상호 작용을 메시지 흐름으로 표현  객체 사이 메시지를 보내는 시간을 표현  교류 다이어그램의 한 종류로 볼 수 있음  구성 요소          객체: □      생명선: 객체 아래로 이어진 ┆      실행: 생명선 위의 □      메시지: -▶      회귀 메시지: Lifeline 에서 자신의 Activation 에 메시지로 연결      커뮤니케이션 다이어그램  시퀀스 다이어그램과 같이 동작에 참여하는 ‘객체’들이 주고 받는 메시지를 표현  메시지 뿐만 아니라 객체 간의 연관까지 표현상태 다이어그램  하나의 객체가 자신의 속한 클래스의 상태 변화 표현  다른 객체와의 상호작용에 따라 상태가 어떻게 변화하는지 표현  모든 가능한 상태와 전이를 표현  진입 조건, 탈출 조건, 상태 전이 등을 기술  구성요소          상태: 객체가 존재할 조건, 둥근 사각형으로 표현      시작 상태: ●      종료 상태: ⦿      전이: -▶                  이벤트: -이벤트-▶          전이 조건: -[전이조건]-&gt;                    활동 다이어그램  시스템이 어떤 기능을 수행하는지 객체의 처리 로직이나 조건에 따른 처리의 흐름을 순서대로 표현  활동의 순서대로 흐름을 표현타이밍 다이어그램  객체 상태 변화와 시간 제약을 명시적으로 표현UML 관계연의 일실 포집  연관 관계: -&gt;  의존 관계: - - -&gt;  일반화 관계: (Child Class) -▶ (Parent Class)  실체화 관계: (Class) - - -▶ (Interface)  포함 관계: (Class) ◆-&gt; (Several Class)  집합 관계: (Class) ◇-&gt; (Several Class)  포함은 강한 결합, 집합은 느슨한 결합UML Stereotype  « include »: Usecase  « extend »: Usecase  « interface »: Class Diag.  « entity »: Usecase  « boundary »: 외부 액터와의 상호작용을 담당하는 클래스 Sequence  « control »: 로직 및 제어를 담당하는 클래스 SequenceAgile 개발 방법론반복적이고 점진적인 개발을 통해 변화하는 요구사항에 빠르게 대응XP의사소통 개선과 즉각적 피드백으로 소프트웨어 품질을 높이기 위한 방법론  1~3주의 반복 개발 주기  5가지의 가치와 12개의 실천SCRUM매일 정해진 시간, 장소에서 짧은 시간의 개발을 하는 팀을 위한 프로젝트 관리 중심 방법론  제품 책임자(Product Owner)  제품 백로그  스프린트: 2~4주의 짧은 개발 기간 반복 수행  스크럼 미팅: 매일 15분 정도의 미팅으로 To-Do List 수립  스크럼 마스터: 스크럼 수행 시 문제를 인지하는 사람  스프린트 회고: 스프린트 주기를 되돌아봄  번 다운 차트: 백로그 대비 시간을 그래프로 나타냄LeanJIT, 칸반 보드 이용분석 자동화 도구  상위 CASE(문서 기반): 계획 수립, 요구 분석, 기본 설계 단계를 다이어그램으로 표현, 자료흐름도 프로토타이핑 작성 지원 및 UI 설계 지원  하위 CASE(코드 기반): 구문 중심 편집 및 정적, 동적 테스트 지원"
    },
  
    {
      "title": "1. Exercises",
      "url": "/seonghun120614/computerscience/os/2025/07/07/1.-exercises.html",
      "date": "2025-07-07",
      "content": "🚧 작업중  운영체제의 세 가지 주요 목적  운영 체제의 자원 관리 적시성  실시간 시스템에서의 운영체제 문제 해결점  운영 체제의 다양한 관점에서 본 사용자 프로그램  보안 관점에서 커널 모드와 사용자 모드의 구분  명령어의 처리 우선권 나열  수정 불가능한 메모리 파티션에 운영체제를 저장 시 문제점  사용자 모드와 커널 모드의 용도  타이머의 시간 계산 및 구현  캐시가 유용한 이유  클러스터링 시스템과 다중 프로세서 시스템의 차이 및 두 시스템 간의 고가용성  데이터베이스 관점에서 보는 스토리지 저장과 액세스 방식  인터럽트의 목적과 인터럽트와 트랩의 차이  Hz 와 Jiffies  고속 I/O 장치의 직접 메모리 액세스📚 본문다양한 LLM 을 사용하여 답변을 집계하였다.운영체제의 세 가지 주요 목적은 무엇입니까?  컴퓨터 자원(하드웨어) 관리  사용자 어플리케이션이 구동 될 수 있는 환경 조성  시스템 오류 및 오용 방지우리는 컴퓨팅 하드웨어를 효율적으로 사용하기 위한 운영 체제의 필요성을 강조해 왔습니다. 운영 체제가 이 원칙을 저버리고 자원을 “낭비”하는 것이 적절한 때는 언제일까요? 그러한 시스템이 실제로 낭비적이지 않은 이유는 무엇일까요?When? - 사용자 경험 개선이나 시스템 반응성 향상을 위해 리소스 낭비가 발생할 때Why? - 시스템을 더욱 안정적이고 반응성 있게 만드는 이점이 있기 때문에 낭비가 아니다.실시간 환경을 위한 운영 체제를 작성할 때 프로그래머가 극복해야 하는 주요 어려움은 무엇입니까?Strict timing constraints 충족운영 체제의 다양한 정의를 염두에 두고, 웹 브라우저나 메일 프로그램과 같은 애플리케이션을 운영 체제에 포함해야 하는지 고려해 보세요. 포함해야 한다는 주장과 포함해서는 안 된다는 주장을 모두 펼치고, 자신의 주장을 뒷받침하세요.운영 체제를 사용자 편의성을 포함하는 광범위한 개념으로 본다면 웹 브라우저나 메일 프로그램과 같은 애플리케이션은 포함될 수 있지만,운영 체제를 커널 중심 시스템 소프트웨어로 정의한다면 이러한 애플리케이션은 포함되어서는 안된다.특히 웹 브라우저를 운영체제에 통합하는 것은 운영체제의 핵심 역할과 무관할 뿐만 아니라, 특정 애플리케이션에 대한 독점 우려를 야기하기 때문에 시스템이 사용자 편의성에 중점을 둔 통합 환경으로 설계되지 않는 한, 이러한 애플리케이션은 운영체제에 포함되어서는 안된다.커널 모드와 사용자 모드의 구분은 기본적인 보호(보안) 형태로 어떻게 기능합니까?커널 모드와 유저 모드의 구분은 하드웨어와 운영체제로 구현되어 진다. 모드 비트, 권한 분리, 시스템 호출, 예외처리 등으로 시스템 자원을 보호하고 악의적인 행위나 오류로부터 시스템의 안전성과 보안을 유지한다:      모드 비트: CPU의 상태를 나타내는 flag 로써, 커널 모드(0), 유저 모드(1) 로 구분되어진다. 사용자 모드에서 특권 명령어를 수행하려하면, 예외를 발생시켜 커널에게 제어권이 넘어가게 된다.        권한 분리: 사용자 모드에서 실행되는 프로그램은 메모리의 특정 영역(커널 공간)에 접근할 수 없으며, 이를 통해 커널 데이터와 다른 프로세스의 데이터를 보호한다.        시스템 호출: 사용자 프로세스가 파일 입출력, 네트워크 통신 등 시스템 자원에 접근하거나 저수준의 명령을 처리하려면 커널이 제공하는 안전한 인터페이스(시스템 호출)를 사용해야 하며, 커널은 요청의 유효성을 검사하여 보안을 강화한다.        예외 처리: 사용자 모드에서 잘못된 메모리 접근이나 금지된 명령을 시도하면 운영 체제가 이를 감지하고 프로세스를 종료하거나 오류를 처리하여 시스템 안정성을 유지한다.  이런 구분을 통해 악의적인 코드나 버그가 있는 프로그램이 시스템 전체를 손상시키는 것을 방지한다. 예를 들어, 사용자 모드에서 실행되는 애플리케이션이 커널 메모리에 접근하려고 하면 운영 체제가 이를 차단하여 데이터 유출이나 시스템 충돌을 방지한다.다음 중 어떤 지시사항에 우선권을 주어야 합니까?a. Set value of timer.b. Read the clock.c. Clear memory.d. Issue a trap instruction.e. Turn off interrupts.f. Modify entries in device-status table.g. Switch from user to kernel mode.h. Access I/O device.a, c, e, f, g, hCRUD의 CUD 에 해당하는 동작은 다 특권이 필요하다. 여기서 d는 그저 요청만 보내는 것(발행하는 것)이지 실제 trap instruction 을 실행한다는 의미는 아니다.일부 초기 컴퓨터는 운영 체제를 사용자 작업이나 운영 체제 자체가 수정할 수 없는 메모리 파티션에 배치하여 보호했습니다. 이러한 방식으로 인해 발생할 수 있는 두 가지 어려움을 설명하십시오.우선, 첫 번째로 운영체제의 노후화 이다. 이는 유지보수가 보급된 운영체제에 대해서 유지보수가 어렵다는 것이며, 사용자 입장에서는 OS가 들어있는 하드웨어를 아예 사야하는 비용이 큰 작업이며, 시스템 입장에서는 업데이트가 유연하지 못한 운영체제로 인해 보안 위협, 크로스 하드웨어 지원의 어려움 등을 꼽을 수 있을 것이다.두 번째로 자원 할당의 어려움, 부족성 이다. 새로운 하드웨어에 대한 드라이버가 필요할 때는 이를 지원하기 위한 OS 영역의 메모리 파티션을 늘려서 할당하는게 힘들 것이며, 주메모리 내에서도 가지고 있는 장치 디바이스 테이블의 크기를 늘리기 힘들 것이다.일부 CPU는 두 가지 이상의 작동 모드를 제공합니다. 이러한 여러 모드를 어떤 용도로 사용할 수 있을까요?CPU의 여러 작동 모드는 시스템의 보안, 자원 관리, 성능 최적화를 위해 사용된다. 첫째, 보안과 권한 분리를 위해 커널 모드와 사용자 모드를 구분하여, 특권 명령(예: I/O 접근, 인터럽트 제어)을 커널 모드에서만 실행 가능하게 한다. 이를 통해 사용자 프로그램이 시스템 자원(메모리, 디바이스)에 무단 접근하는 것을 방지하고, 다중 사용자 환경에서 프로세스 간 격리를 보장한다. 예를 들어, 사용자 모드에서 실행되는 응용 프로그램은 시스템 호출을 통해 커널 모드에 요청해야 하드웨어에 접근할 수 있다.둘째, 효율적인 자원 관리와 인터럽트 처리를 위해 사용된다. 커널 모드는 디바이스 드라이버를 통해 하드웨어 자원을 관리하고, 인터럽트를 처리하여 시스템의 응답성을 높인다. 예를 들어, 인터럽트 서비스 루틴(ISR)은 커널 모드에서 실행되어 디바이스 이벤트를 신속히 처리할 수 있다.셋째, 가상화와 시스템 확장성을 지원한다. 일부 CPU는 하이퍼바이저 모드를 제공하여 가상 머신(VM)을 실행할 수 있게 하며, 이는 클라우드 컴퓨팅이나 서버 환경에서 여러 운영 체제를 동시에 실행하는 데 사용된다. 이러한 모드 분리는 시스템 안정성을 높이고, 다양한 워크로드를 효율적으로 관리할 수 있게 한다.타이머를 사용하여 현재 시간을 계산할 수 있습니다. 이를 어떻게 구현할 수 있는지 간략하게 설명하세요.타이머는 CPU의 클럭 신호를 기반으로 현재 시간을 계산할 수 있다. CPU는 수정 진동기(쿼츠 크리스털)에서 생성된 고정 주파수의 클럭 틱을 카운트하고, 운영 체제는 하드웨어 타이머(예: 실시간 클록 또는 시스템 타이머)를 설정하여 이 클럭 틱을 주기적으로 기록하고, 이를 누적하여 초, 분, 시간 단위로 변환한다. 부팅 시 기준 시간(예: BIOS의 RTC)을 참조하여 현재 시간을 계산하고, 타이머 인터럽트를 통해 지속적으로 업데이트한다.캐시가 유용한 두 가지 이유를 제시하십시오. 캐시는 어떤 문제를 해결합니까? 어떤 문제를 발생시킵니까? 캐시 크기를 캐시 대상 장치(디스크 크기만큼 큰 캐시)만큼 크게 만들 수 있다면, 캐싱 대상 장치를 없애는 것이 어떻겠습니까?어떤 문제를 해결하냐 - 캐시는 주메모리의 자주 참조 및 접근하는 주소에 대한 데이터를 미리 저장하여, 메모리 접근 지연을 최소화하며, 코어 간의 데이터 공유 또한 가능하게 된다.어떤 문제를 발생시키냐 - 캐시를 사용하게 데이터 일관성이 깨질 우려가 있고, 이에 따라 동시성 문제를 해결해야 한다.캐시 메모리가 어떻게 되어 있는지 먼저 보자. SRAM 기반의 일반 메모리 배열로 주소를 참조하여 접근하게 되는데, 코어 내부의 레지스터들로 되어 있는게 아니다. 코어 내부의 레지스터들은 전부 1클럭 내에 접근 할 수 있는데, 레지스터 마다 특정 역할이 있고, 특정 연산에 특화되어 있다. 이런 레지스터들을 2클럭 이상으로 접근하도록 하는 SRAM 기반의 일반 메모리 배열 주소를 참조하여 그 데이터로 ALU 등을 통해 연산을 하는 것은 굉장히 비효율적이며, 초고속 메모리인 레지스터들을 완전히 대체할 수도 없을 것이다.RAM을 이걸로 대체한다고 쳐보자. RAM 은 기본적으로 수~수십 기가바이트인데, 이를 캐시로 전부 대체하려면 굉장히 큰 비용이 들어간다. 일반적인 사용자들이 이런 비싼 컴퓨터를 사지는 않을 터이다. 즉, 비용-효율성 측면에서 떨어진다(또한 전력소모도 심함).보조 메모리를 이걸로 대체한다고 했을때, 비용도 비용이지만 대용량의 처리를 캐시 메모리가 할 수 없을뿐더러 휘발성이기 때문에 영구 저장이 불가능하다.클러스터링 시스템은 다중 프로세서 시스템과 어떻게 다릅니까? 클러스터에 속한 두 머신이 협력하여 고가용성 서비스를 제공하려면 무엇이 필요합니까?클러스터링 시스템은 독립된 컴퓨팅 시스템이 노드라는 단위로 구분되어져 각각의 노드가 서로 다른 아키텍쳐를 구성할 수 있는 시스템이며, 네트워크로 서로 자원을 공유하는 형태이다.다중 프로세서 시스템은 한 시스템 내에 CPU의 각 코어가 2개 이상의 프로세서를 가지는 형태이다. 하나의 아키텍쳐만이 구동되어질 수 있다는 점이 클러스터링 시스템과는 다른 점이다.고가용성 서비스를 제공하려면 다중 프로세서 시스템 보다는 클러스터링 시스템을 사용하여 한 시스템이 장애가 나도 다른 시스템을 돌릴 수 있도록 할 수 있다.데이터베이스를 실행하는 두 개의 노드로 구성된 컴퓨팅 클러스터를 고려해 보세요. 클러스터 소프트웨어가 디스크의 데이터에 대한 액세스를 관리하는 두 가지 방법을 설명하세요. 각 방법의 장단점을 논하세요.두 클러스터가 서로 공유를 해야하기 때문에  공유 스토리지  비공유 스토리지방식으로 데이터를 관리할 수 있다.공유 스토리지는 NAS, SAN 등의 연결 방식으로 데이터를 공유하여 외장 스토리지는 하나이지만, CPU, 주메모리, 운영체제는 독립적인 방식으로 동작된다. 두 노드가 스토리지를 접근할 때는 캐시 일관성, 락킹 메커니즘을 사용하여 데이터 신뢰성을 지녀야 한다.장점  높은 가용성  데이터의 쉬운 확장성(데이터 형태와 저장 방식-파일시스템 이 하나라 확장 용이)단점  스토리지 병목 현상(모든 노드가 동일 스토리지에 접근하기에 요청에 대한 지연이 발생)  단일 실패 지점(Single Point of Failure, 공유 스토리지 자체가 장애가 발생하면 전체 클러스터가 다운될 수 있는 잠재적인 SPOF가 이를 방지하기 위해 스토리지 시스템 자체에 고가용성(HA) 구성이 필수적)  락킹 메커니즘의 복잡성(두 컴퓨팅 각각에 클러스터 소프트웨어에 분산 락 및 캐싱 프로토콜이 구현되어져야 한다)  노드의 제한적인 수평 확장성(노드가 늘어날수록 오버헤드 증가)비공유 스토리지(Shared-nothing Storage)는 위 개념에서 외장 스토리지를 노드가 각각 가지는 형태이다. 클러스터 내에 분산 저장되며, 필요한 경우 노드간에 데이터 복제/통신 접근이 가능하다.데이터의 일관성과 가용성은 보통 데이터 복제(replication), 분산 트랜잭션(Distributed Transaction)를 통해 보장된다.장점  뛰어난 수평적 확장  단일 실패 지점 없음  I/O 병목 없음  비용 효율성단점  데이터 관리 복잡성(복제, 샤딩, 분산 트랜잭션, 백업 및 복구가 힘듦)  데이터 일관성 유지 어려움(일관성 유지를 위해 복잡한 프로토콜이 필요하여 이는 성능 문제로 이어질 수 있음)  데이터 재분배 오버헤드(노드가 추가되거나 제거될 때 데이터 재분배가 필요함 이는 데이터 관리 복잡성의 연장선)인터럽트의 목적은 무엇인가요? 인터럽트는 트랩과 어떻게 다른가요? 사용자 프로그램에서 의도적으로 트랩을 생성할 수 있나요? 그렇다면 어떤 목적으로 생성되나요?인터럽트의 목적은 CPU가 현재 수행 중인 작업을 잠시 중단하고, 외부 또는 내부에서 발생한 중요한 사건을 처리하도록 하여 시스템의 효율성과 반응성을 높이는 것이며, 제어의 전환 목적이라고 봐도 무방하다.인터럽트가 없다면 CPU는 I/O 작업이 완료되기를 계속 확인(폴링, polling)하거나, 오류 발생 여부를 주기적으로 검사해야 하는데, 이는 CPU 시간을 낭비하고 시스템의 전반적인 성능을 저하시킨다. 따라서:  비동기적 사건 처리  시스템 효율성 증대  시분할 시스템 구현등이 목적이다.여기서 트랩은 인터럽트의 한 종류이며 현재 실행 중인 소프트웨어(사용자 프로그램)의 코드 실행 과정에서 ‘동기적으로’ 발생한다. 대표적으로 exception 발생, system call 의 호출로 발생되는게 전부 트랩이며 의도는 커널 모드 권한의 system call 명령어를 실행하기 위해서 그리고 비정상적인 처리 과정의 발생 중지를 위하여가 있다. 반면에 인터럽트는 이 개념들을 모두 포함하고 하드웨어 장치에 의해 발생되는 I/O 완료 및 요청의 비동기 처리 신호도 포함한다.Linux 커널 변수 HZ와 jiffies를 사용하여 시스템이 부팅된 이후 실행된 시간(초)을 확인하는 방법을 설명하세요.우선 Hz는 리눅스 커널의 타이머 인터럽트 주기를 나타내는 값이며, 1초 동안 타이머 인터럽트가 몇 번 발생하는지 나타낸다. 100 Hz 이면 1초 동안 100번의 인터럽트가 발생하게 된다. 보통 /usr/src/linux/include/asm/param.h 에 위치한 변수 CONFIG_HZ 또는 HZ 로 정의된다.jiffies 는 시스템이 부팅된 이후로 발생된 총 인터럽트 횟수이다. 보통 unsigned long 로 저장되며, 만약 값이 너무 커지면 커널이 자동으로 이 값을 처리하여 연속성을 유지한다.명령어는 다음과 같다:Hz 확인  grep \"CONFIG_HZ\" /boot/config-$(uname -r)  grep \"jiffies\" /proc/timer_listjiffies 확인  cat /proc/uptime - 첫 번째 숫자는 부팅 이후 경과된 시간, 두 번째는 유휴 시간고속 I/O 장치에서는 CPU 실행 부하 증가를 방지하기 위해 직접 메모리 액세스가 사용됩니다.  a. CPU는 전송을 조정하기 위해 장치와 어떤 방식으로 상호작용합니까?DMA 컨트롤러를 통해 CPU가 데이터 전송 초기 설정과 완료 처리에만 관여하고, 나머지는 전부 DMA 컨트롤러가 직접 메모리에 접근하여 데이터 전송을 한다.  CPU 가 DMA 전송 및 요청: I/O 장치(예: 네트워크 카드, 디스크 컨트롤러)를 통해 또는 직접 DMA 컨트롤러에 다음 정보들을 프로그래밍합니다.      b. CPU는 장치와 어떻게 상호 작용하여 전송을 조정합니까?        c. DMA 컨트롤러가 데이터를 전송하는 동안 CPU는 다른 프로그램을 실행할 수 있습니다. 이 프로세스가 사용자 프로그램 실행을 방해합니까? 그렇다면 어떤 유형의 방해가 발생하는지 설명하십시오.  일부 컴퓨터 시스템은 하드웨어에서 특권 작동 모드를 제공하지 않습니다. 이러한 컴퓨터 시스템에 안전한 운영 체제를 구축하는 것이 가능할까요? 가능하다는 주장과 불가능하다는 주장을 모두 제시하십시오.많은 SMP 시스템은 서로 다른 수준의 캐시를 가지고 있습니다. 한 수준은 각 처리 코어에 로컬이고, 다른 수준은 모든 처리 코어에서 공유됩니다. 캐싱 시스템이 이렇게 설계된 이유는 무엇일까요?다음 저장 시스템을 가장 느린 것부터 가장 빠른 것까지 순위를 매겨보세요:a. Hard-disk drivesb. Registersc. Optical diskd. Main memorye. Non-volatile memoryf. Magnetic tapesg. Cachef &gt; c &gt; a &gt; e &gt; d &gt; g &gt; b그림에 표시된 것과 유사한 SMP 시스템을 생각해 보세요. 예를 들어 메모리에 있는 데이터가 실제로 각 로컬 캐시에서 어떻게 다른 값을 가질 수 있는지 보여주세요.다음 처리 환경에서 캐시된 데이터 매니페스트의 일관성을 유지하는 문제가 어떻게 발생하는지 예를 들어 설명하십시오.a. Single-processor systemsb. Multi processor systemsc. Distributed systems프로그램이 다른 프로그램과 연결된 메모리를 수정하지 못하도록 메모리 보호를 적용하는 메커니즘을 설명하세요.다음 환경에 가장 적합한 네트워크 구성(LAN 또는 WAN)은 무엇입니까?a. A campus student unionb. Several campus locations across a state wide university systemc. A neighborhooda - LANb - WANc - LAN모바일 기기용 운영 체제를 설계할 때의 몇 가지 과제를 설명하십시오. 기존 PC용 운영 체제를 설계할 때와 비교하십시오.클라이언트-서버 시스템에 비해 P2P 시스템의 장점은 무엇입니까?P2P 시스템에 적합한 분산 애플리케이션을 몇 가지 설명하십시오.오픈 소스 운영 체제의 여러 가지 장단점을 파악하십시오. 각 측면을 장점으로 생각하는 사람과 단점으로 생각하는 사람의 유형을 파악하십시오."
    },
  
    {
      "title": "1.11 Free and Open-Source Operating Systems",
      "url": "/seonghun120614/computerscience/os/2025/07/06/1.11-free-and-open-source-operating-systems.html",
      "date": "2025-07-06",
      "content": "📂 목차  Overview  1.11.1 Free Operating System  1.11.2 GNU/Linux  1.11.3 BSD UNIX  1.11.4 Solaris📚 본문Overview많은 운영 체제는 free operating system 과 open-source operating system 들의 등장으로 인해 공부가 더 쉬워졌다. 이 두 형태의 os는 모두 컴파일 된 binary 가 아닌 소스 코드로 제공된다.  free operating system: 소스코드도 제공하며, 비용 없이 사용, 재배포, 2차 수정 가능한 라이선스를 제공  open-source operating system: 라이선스를 제공 안함, 또한 무료가 아닐 수도 있다.예시  GNU/Linux: 오픈 소스 운영체제고, 일부 배포판은 무료이다.Microsoft Window: 오픈 소스와 반대되는 폐쇄형 소스 방식, 코드를 철저히 보호한다.MacOS: 하이브리드 방식인데, 일부는 오픈, 일부는 폐쇄되어 있다.1.11.1 Free Operating SystemGNU는 소프트웨어의 재사용 및 재배포를 제한하는 움직임을 막기 위해 리처드 스톨만이 GNU 라는 이름으로 UNIX 호환 운영체제 개발을 시작했다. 무료 소프트웨어 운동은 사용자에게 다음 4가지 자유가 보장된다.GNU Manifesto  프로그램을 자유롭게 실행할 수 있는 자유  소스코드를 연구하고 변경할 수 있는 자유  변경 없이 프로그램을 복사해 주거나 팔 수 있는 자유  변경한 버전을 복사해 주거나 팔 수 있는 자유또한 스톨먼은 FSF 재단을 설립하여 라이선스 copyleft 를 구현하여 위 4가지를 필수적으로 지켜야 함을 명시한다. GNU 일반 공중 사용 허가서(GNU General Public License, GPL)는 자유 소프트웨어가 배포되는 일반적인 라이선스이며, GPL은 모든 바이너리와 소스가 함께 배포되어야 하며, 이를 수정한 2차 저작물 또한 GPL을 따라야 한다. 크리에이티브 커먼즈(Creative Commons)의 “저작자표시-동일조건변경허락(Attribution Sharealike)” 라이선스 또한 카피레프트 라이선스이며, “동일조건변경허락(sharealike)”은 카피레프트 아이디어를 표현하는 또 다른 방식이다.1.11.2 GNU/LinuxFree OS 인 GNU/Linux 는 운영체제이며 GNU 프로젝트에서 컴파일러, 에디터, 유틸리티, 라이브러리, 게임 등 가능한 모든 구성요소를 개발, 그리고 리누스 토발즈가 GNU 컴파일러와 도구들을 사용해 초기 수준의 유닉스 계열 커널 기능을 하는 마지막 구성 요소를 개발하여 완성된 운영체제이다.여기서 파생되어져 나온 운영체제는 수백개이며, Red Hat, SUSE, Fedora, Debian, Slackware, Ubuntu 등이 있다.1.11.3 BSD UNIX리눅스 보다 더 오래된 운영체제이며, AT&amp;T 의 UNIX를 기반으로 파생된 운영체제이다. 캘리포니아 대학교에서 소스코드, 바이너리를 배포했고, AT&amp;T 라이선스가 필요하여, 오픈소스는 아니다.리눅스처럼 다양한 형태 배포판이 존재하며, FreeBSD, NetBSD, OpenBSD, DragonflyBSD 가 있으며, 우리가 사용하는 MacOS의 핵심 컴포넌트인 커널도 BSD UNIX의 Darwin 커널을 기반하여 만들어졌다.1.11.4 SolarisSun Microsystems 사에서 개발한 상업용 UNIX 운영체제이며, 처음에는 BSD UNIX 기반이었지만, AT&amp;T의 System V UNIX 기반으로 바뀌었다. 대부분의 소스코드를 OpenSolaris 프로젝트에서 오픈 소스화했고, 2009년에 Oracle이 Sun을 인수하여 프로젝트가 애매모호해졌다.OpenSolaris를 계속 사용하는 여러 그룹들은 이 기능들을 확장시켜 개발했고, Project Illumos 라는 이름으로 오픈소스 운영체제로 자리잡았다."
    },
  
    {
      "title": "1.10 Computing Environments",
      "url": "/seonghun120614/computerscience/os/2025/07/05/1.10-computing-environments.html",
      "date": "2025-07-05",
      "content": "📂 목차  1.10.1 Traditional Computing          사무실 환경의 변화      가정 환경의 변화      컴퓨팅 자원 활용 방식의 변화        1.10.2 Mobile Computing          주요 변화      남아있는 한계      주요 운영체제        1.10.3 Client-Server Computing  1.10.4 Peer-to-Peer Computing          P2P 네트워크 참여 및 서비스 검색 방식        1.10.6 Real-Time Embedded Systems📚 본문10.3 이후로 보기를 권장한다.1.10.1 Traditional Computing과거의 컴퓨팅 환경은 PC, 서버, 제한적인 원격 접근, 노트북을 통한 휴대성 등으로 명확하게 구분되었지만 웹 기술의 발전과 WAN 대역폭의 증가는 이러한 전통적인 경계를 허물고 있다.사무실 환경의 변화  기업들은 내부 서버에 대한 웹 접근성을 제공하는 포털을 구축  보안 및 유지보수가 용이한 네트워크 컴퓨터(씬 클라이언트)가 전통적인 워크스테이션을 대체  모바일 컴퓨터와 장치들은 PC와 동기화되거나 무선/셀룰러 네트워크를 통해 회사 정보 및 웹 리소스에 접근하며 휴대성과 연결성을 극대화가정 환경의 변화  느린 모뎀으로 한정되었던 가정 내 인터넷 연결은 고속 광대역망이 보편화되면서 데이터 접근성이 크게 향상  웹 서버 혹은 프린터 및 클라이언트 PC를 포함하는 홈 네트워크 구축까지 가능하며, 방화벽을 통해 보안을 강화컴퓨팅 자원 활용 방식의 변화  20세기 후반에는 컴퓨팅 자원이 부족하여 배치(Batch) 시스템과 상호작용(Interactive) 시분할(Time-sharing) 시스템이 주를 이룸.  오늘날 전통적인 다중 사용자 시분할 시스템은 드물어졌지만, 시분할 스케줄링 기술 자체는 여전히 데스크톱, 노트북, 서버, 모바일 컴퓨터 등 다양한 장치에서 여전히 활용 됨.결론적으로, 컴퓨팅은 중앙 집중적이고 분리된 환경에서 벗어나, 웹 기술, 고속 네트워크, 모바일 장치를 통해 더욱 유연하고 상호 연결된 분산 환경으로 진화했으며, 과거의 자원 활용 기술은 현대에서 다중 작업 환경을 지원하는 방식으로 적용됨.1.10.2 Mobile Computing모바일 컴퓨팅은 스마트폰과 태블릿 같은 휴대용 기기를 중심으로 빠르게 발전했다. 과거에는 데스크톱이나 노트북에 비해 화면 크기, 메모리, 기능 면에서 제약이 있었지만, 이제는 그 차이가 거의 사라져 노트북과 태블릿의 기능 구분이 어려워졌다. 오히려 모바일 기기만이 제공할 수 있는 고유한 기능들도 생겨났다(다양한 하드웨어의 embedding).주요 변화  기능 확장 - 이메일, 웹 브라우징을 넘어 음악, 비디오 재생, 전자책 읽기, 사진 촬영, 고화질 비디오 편집 등 다양한 용도로 활용  고유 센서 활용 - GPS 칩, 가속도계, 자이로스코프 같은 내장 센서 덕분에 내비게이션, 증강 현실(AR), 모션 기반 게임 등 데스크톱/노트북에서는 구현하기 어렵거나 불가능한 애플리케이션이 등장  연결성 - 주로 Wi-Fi(802.11) 또는 셀룰러 데이터 네트워크를 통해 온라인 서비스에 접속남아있는 한계  하드웨어 제약: 여전히 데스크톱/노트북에 비해 메모리 용량과 처리 속도(더 작고 느린 프로세서, 적은 코어)는 제한적이며 이는 전력 소비를 최소화하기 위한 설계 때문이다.주요 운영체제  현재 모바일 컴퓨팅 시장은 Apple iOS와 Google Android 두 운영체제가 주축모바일 컴퓨팅은 단순히 휴대 가능한 기기를 넘어, 독자적인 기능과 생태계를 구축되었다.1.10.3 Client-Server Computing클라이언트-서버 시스템은 주로 두 가지가 사용된다:      Compute-server system: 서버는 클라이언트가 작업을 수행하도록 요청(예: 데이터 읽기)을 보낼 수 있는 인터페이스를 제공한다. 이에 응답하여 서버는 해당 작업을 실행하고 그 결과를 클라이언트에게 전송한다.        File-server system: 클라이언트가 파일을 CRUD 할 수 있는 파일 시스템 인터페이스를 제공한다. 파일의 실제 내용은 전통적인 웹 페이지부터 고화질 비디오와 같은 풍부한 멀티미디어 콘텐츠에 이르기까지 매우 다양하다.  1.10.4 Peer-to-Peer Computing시스템 내의 모든 노드(피어)가 동등하게 여겨지며, 각 피어는 서비스를 요청하는지 제공하는지에 따라 클라이언트 또는 서버 역할을 모두 수행할 수 있다(분산 시스템임). 전통적인 클라이언트-서버 시스템에서 서버가 병목 현상을 일으킬 수 있는 반면, P2P 시스템에서는 서비스가 네트워크 전체에 분산된 여러 노드에 의해 제공될 수 있다는 장점이 있다.P2P 네트워크 참여 및 서비스 검색 방식P2P 시스템에 참여하려면 노드는 먼저 피어 네트워크에 합류해야 하며, 네트워크에 합류한 노드는 다른 노드에 서비스를 제공하고 요청할 수 있다. 서비스 가용성을 확인하는 방법은 크게 두 가지가 있다:      중앙 집중식 조회 서비스 이용 - 노드가 네트워크에 참여할 때 자신의 서비스를 중앙 집중식 조회 서비스에 등록한다. 특정 서비스를 원하는 노드는 먼저 이 중앙 조회 서비스에 접속하여 해당 서비스를 제공하는 노드를 확인하고, 클라이언트와 서비스 제공자 간의 통신이 직접 이루어진다.        분산된 서비스 검색(브로드캐스팅) - 중앙 집중식 조회 서비스 없이, 클라이언트 역할을 하는 피어가 원하는 서비스를 제공하는 노드를 찾기 위해 네트워크의 다른 모든 노드에 요청을 브로드캐스팅 후 해당 서비스를 제공하는 노드(들)는 요청을 보낸 피어에게 직접 응답한다. 이러한 접근 방식을 지원하기 위해 피어들이 네트워크 내의 다른 피어가 제공하는 서비스를 발견할 수 있도록 발견 프로토콜(Discovery Protocol)이 필요하다.  1.10.5 Cloud Computing클라우드 컴퓨팅은 컴퓨팅 자원, 저장 공간, 심지어 애플리케이션까지도 네트워크를 통해 서비스 형태로 제공하는 방식이다. 이는 가상화 기술을 기반으로 하며, Amazon EC2와 같이 수많은 서버와 방대한 저장 공간을 인터넷을 통해 제공하고 사용량에 따라 요금을 부과하는 것이 대표적인 예시다.클라우드 컴퓨팅의 주요 유형클라우드 컴퓨팅은 여러 가지 형태로 분류할 수 있으며, 복합적으로 활용될 수 있다:  퍼블릭 클라우드(Public Cloud) - 인터넷을 통해 누구나 비용을 지불하고 사용할 수 있는 클라우드  프라이빗 클라우드(Private Cloud) - 특정 기업이 자체적인 용도로 운영하는 클라우드  하이브리드 클라우드(Hybrid Cloud) - 퍼블릭 클라우드와 프라이빗 클라우드 구성 요소를 모두 포함하는 형태  SaaS(Software as a Service) - 워드 프로세서나 스프레드시트 같은 하나 이상의 애플리케이션을 인터넷을 통해 서비스로 제공  PaaS(Platform as a Service) - 애플리케이션 사용을 위한 소프트웨어 스택(예: 데이터베이스 서버)을 인터넷을 통해 즉시 사용할 수 있도록 제공  IaaS(Infrastructure as a Service) - 서버나 저장 공간(예: 백업 데이터 저장 공간)과 같은 컴퓨팅 인프라를 인터넷을 통해 제공클라우드 인프라의 관리클라우드 인프라 내부에는 전통적인 운영체제들이 존재하며, 그 위에는 가상 머신(VM)을 관리하는 VMM(Virtual Machine Monitor)이 있다. 더 나아가, VMM 자체는 VMware vCloud Director나 오픈 소스 Eucalyptus와 같은 클라우드 관리 도구에 의해 관리되며, 이 도구들은 클라우드 내의 자원을 관리하고 클라우드 구성 요소에 대한 인터페이스를 제공하여, 사실상 새로운 유형의 운영체제로 간주될 수 있다.  참고로 퍼블릭 클라우드에서 IaaS를 제공하는 경우, 클라우드 서비스와 사용자 인터페이스는 방화벽으로 보호된다.1.10.6 Real-Time Embedded Systems임베디드 컴퓨터(Embedded computers)는 매우 특정하고 제한적인 작업을 수행하기 위해 만들어진 시스템이며, 주로 하드웨어 장치를 모니터링하고 관리하는 데 시간을 보낸다(주로 상호작용하는 사용자의 비중이 상대적으로 없음). 따라서 사용자 인터페이스가 거의 없는 경우가 많고, 실행되는 시스템과 운영체제도 제한된 기능을 제공하는 원시적인 형태이다.임베디드 시스템의 다양한 형태와 확장성임베디드 시스템은 매우 다양하게 존재:  주로 리눅스와 같은 표준 운영체제에서 특정 목적의 애플리케이션을 실행하는 범용 컴퓨터  다른 일부는 특정 목적의 임베디드 운영체제를 탑재한 하드웨어 장치  운영체제 없이 태스크를 수행하는 ASIC(Application-Specific Integrated Circuits)으로 구현된 하드웨어 장치로 나눌 수 있다.실시간 운영체제(Real-time Operating Systems)의 중요성임베디드 시스템은 거의 항상 실시간 운영체제(Real-time Operating Systems, RTOS)를 사용하며, 실시간 시스템은 프로세서 작동이나 데이터 흐름에 엄격한 시간 제약 조건(strictly time constraints)이 부여될 때 사용되어 전용 애플리케이션에서 제어 장치로 자주 활용된다. 일반화 된 예시로 센서가 데이터를 컴퓨터에 전달하면, 데이터를 분석하고 센서 입력을 수정하기 위해 제어 장치를 조정해야 할 때 사용한다.실시간 시스템은 정확한 결과뿐만 아니라 정해진 시간 제약 조건 내에서 결과를 반환해야만 한다.  예시과학 실험 제어 시스템, 의료 영상 시스템, 산업 제어 시스템, 특정 디스플레이 시스템, 자동차 엔진 연료 분사 시스템, 가전제품 컨트롤러, 무기 시스템✒️ 용어발견 프로토콜발견 프로토콜은 네트워크 내에서 서비스나 자원을 찾아내는 데 사용되는 통신 규약을 말하며, 특히 P2P 시스템이나 분산 환경에서 특정 서비스를 제공하는 노드가 어디에 있는지, 또는 어떤 자원이 사용 가능한지 알 수 없을 때 이 프로토콜이 핵심적인 역할을 한다.  브로드캐스트(Broadcasting) 기반서비스를 찾는 노드가 네트워크의 모든 다른 노드에게 요청을 널리 알리는(브로드캐스트) 방식과정  서비스를 찾는 노드(클라이언트 역할)는 특정 서비스 요청 메시지를 네트워크 전체에 전송  이 요청을 받은 노드 중 해당 서비스를 제공하는 노드(서버 역할)는 요청을 보낸 노드에게 직접 응답  이후 클라이언트는 응답한 서비스 제공자 노드와 직접 통신을 시작장점으로 중앙 집중식 서버가 필요 없어 진정한 의미의 분산 시스템을 구현 가능하다.단점으로 네트워크 트래픽이 많아질 수 있고, 대규모 네트워크에서는 비효율적이다.  멀티캐스트(Multicasting) 기반브로드캐스트와 유사하지만, 모든 노드가 아닌 특정 그룹의 노드에게만 요청을 전송하는 방식이다. 장점으로 브로드캐스트보다 효율적이며, 네트워크 트래픽을 줄일 수 있다.  DHT(Distributed Hash Table) 기반 (구조화된 P2P 네트워크)분산 해시 테이블은 각 노드가 특정 데이터나 서비스의 위치 정보를 분산된 방식으로 저장하고 관리하는 고급 형태의 발견 프로토콜과정  데이터나 서비스에 고유한 키를 부여하고  이 키를 해싱하여 네트워크의 특정 노드에 매핑  데이터를 찾는 노드는 DHT 프로토콜에 따라 해당 키에 해당하는 노드를 찾아간다.장점으로 대규모 네트워크에서 효율적인 검색이 가능하고, 확장성이 뛰어나다.단점으로 구현이 복잡하며, 네트워크 변화에 따른 DHT 구조 유지에 오버헤드가 발생할 수 있다.  예시제로콘프(Zeroconf) / 봉쥬르(Bonjour) / UPnP(Universal Plug and Play): 네트워크 프린터, 스마트 TV, 미디어 서버 등 홈 네트워크 장치들이 서로를 자동으로 찾아 연결하는 데 사용BitTorrent: 파일 조각을 가진 피어들을 찾아 연결하는 데 사용블록체인 네트워크 (예: 비트코인, 이더리움): 새로운 노드가 네트워크에 참여할 때 다른 노드들을 발견하고 블록체인 데이터를 동기화하는 데 사용IoT(사물 인터넷) 장치: 스마트 홈 기기들이 허브나 다른 기기들을 찾아 연결하는 데 발견 프로토콜이 활용Strictly Time Constraints엄격한 시간 제약 조건이란, 시스템의 특정 연산이나 태스크가 미리 정의된 마감 시간(deadline) 내에 반드시 완료되어야 하며, 이를 지키지 못할 경우 시스템의 기능적 오류나 재앙적인 결과가 발생하는 조건을 의미한다."
    },
  
    {
      "title": "1.9 Kernel Data Structures",
      "url": "/seonghun120614/computerscience/os/2025/07/04/1.9-kernel-data-structures.html",
      "date": "2025-07-04",
      "content": "📚 본문1.9 자료구조에 대한 것이므로 다른 분야에서 다루기 때문에 넘어간다."
    },
  
    {
      "title": "1.8 Distributed Systems",
      "url": "/seonghun120614/computerscience/os/2025/07/04/1.8-distributed-systems.html",
      "date": "2025-07-04",
      "content": "📂 목차  Distributed System 과 Network          네트워크 유형      프로토콜과 매체      네트워크 운영 체제와 분산 운영 체제      📚 본문분산 시스템은 네트워크로 연결된 물리적으로 분리된 컴퓨터들이 자원을 공유하여 계산 속도, 기능성, 데이터 가용성, 신뢰성을  향상시키는 시스템이 있다면 특화된 처리를 하도록 할 수 있게 된다.Distributed System 과 Network물리적으로 분리된 컴퓨터들이 네트워크를 통해 자원들을 공유하는 시스템을 분산시스템이라고 한다.이때 자원 공유로 계산 속도, 기능성, 데이터 가용성, 신뢰성이 향상되게 된다. 공유는 네트워크로 하게 되며 네트워크 접근에서 일부 운영체제는 파일 접근처럼 네트워크 처리(NFS) 다른 경우 명시적 네트워크 함수 호출(FTP)을 하게 된다.네트워크 유형네트워크 규모에 대해 다음과 같이 정리할 수 있다:  PAN(개인 영역 네트워크): BlueTooth, 802.11  LAN(로컬 영역 네트워크): 방, 건물, 캠퍼스 내 연결  MAN(도시 영역 네트워크): 도시 내 건물끼리 연결  WAN(광역 네트워크 연결): 도시 간, 국가 간 연결프로토콜과 매체  TCP/IP: 인터넷의 기본 프로토콜, 대부분 운영체제 지원  매체: 구리선, 광섬유, 무선(위성, 라디오, 적외선 등)  네트워크 성능과 신뢰성은 프로토콜, 거리, 매체에 따라 다양각각은 네트워크 분야에서 더 자세히 볼 수 있다.네트워크 운영 체제와 분산 운영 체제  네트워크 운영 체제          네트워크를 통해 파일 공유      프로세스 간 메시지 교환      각 컴퓨터는 독립적으로 작동      네트워크 인식 및 통신이 가능        분산 운영 체제          네트워크 컴퓨터들이 단일 운영 체제처럼 작동하도록 긴밀히 통신      덜 자율적이며, 통합된 시스템 환경 제공      1.9 자료구조에 대한 것이므로 다른 분야에서 다루기 때문에 넘어간다."
    },
  
    {
      "title": "1.7 Virtualization",
      "url": "/seonghun120614/computerscience/os/2025/07/04/1.7-virtualization.html",
      "date": "2025-07-04",
      "content": "📂 목차  Virtualization  Emulation📚 본문Virtualization가상화는 단일 컴퓨터의 하드웨어를 여러 실행 환경으로 추상화하여 독립된 컴퓨터처럼 동작하게 하는 기술이다. 보통 CPU, 메모리, 디스크 등 하드웨어를 여러 실행 환경으로 분리시키며, 각 환경이 독립된 컴퓨터처럼 작동하게 된다.  여러 운영체제를 동시에 실행하고 상호작용  사용자 간의 환경 전환은 단일 운영체제의 프로세스 전환과 유사  예시IBM 메인프레임: 다중 사용자가 단일 시스템에서 작업을 수행VMware: Windows에서 게스트 OS 와 어플리케이션 실행Emulation소프트웨어로 하드웨어를 시뮬레이션만 하는 것이고 다른 CPU 아키텍쳐에서 실행하는 착각을 준다.  소스 CPU 명령어를 타겟 CPU 명령어(다른 운영체제의 CPU 아키텍쳐 명령어)로의 변환 -&gt; 전체 운영체제를 다른 플랫폼에서 실행이 가능  예시Apple의 Rosetta: IBM Power CPU 어플리케이션을 Intel x86에서 실행가능이는 성능 저하와 네이티브 코드보다 느린 단점이 뒤따른다."
    },
  
    {
      "title": "1.6 Security and Protection",
      "url": "/seonghun120614/computerscience/os/2025/07/04/1.6-security-and-protection.html",
      "date": "2025-07-04",
      "content": "🪛 한계점다중 사용자 컴퓨터 시스템에서는 여러 사용자가, 여러 프로세스가 동시에 실행될 수 있다. 이때 데이터 접근이 서로 다른 데이터를 보고 있다면 특정 데이터에 대한 상황이 2가지의 상태가 될 수 있다. 이는 혼란을 야기할 수 있기 때문에 규제되어야 한다.📂 목차  Protection  Security  User Identifier  Security ID📚 본문운영체제로부터 적절한 권한을 획득한 프로세스만이 해당 자원을 조작할 수 있도록 보장하는 메커니즘이 필요하다.예시  메모리 주소 지정 하드웨어: 자신의 주소 공간 내에서만 실행되도록 보장  타이머: 어떤 프로세스도 CPU를 영구적으로 점유하지 않고 제어를 양보하도록 함.  장치 제어 레지스터: 사용자에게 직접 접근이 허용되지 않으므로 다양한 주변 장치의 무결성을 보호Protection이처럼 Protection은 컴퓨터 시스템이 정의한 자원에 대해 프로세스나 인가되지 않은 사용자의 접근을 막는 것을 의미한다.  인터페이스 오류 조기 탐지  시스템 신뢰성 향상  부적절한 자원 사용 방지등을 맡게 된다.Security시스템이 적절한 보호 메커니즘을 갖추고 있어도 여전히 실패하거나 부적절한 접근을 허용할 가능성이 있다. 예를 들어 시스템을 바이러스, 웜, 서비스 거부 공격, 신원/서비스 도용 등이 있고 공격으로부터 방어해야 하며, 이런 방어 메커니즘이 필요하다.User IDs위의 메커니즘을 구현하려면 보통 컴퓨터를 사용하는 사용자를 구분해야 한다. 이를 통해 프로세스/스레드에 대한 권한을 제어하여 실행시킬 수 있는 명령을 제한하거나 허가 할 수 있게 되고, 볼 수 있는 파일 또한 제어할 수 있다.유저는 보통 User Identifier를 통해 구분할 수 있고 또한 User ID 를 통해 Group 으로 만들어 그룹 별로 파일 접근 권한을 설정할 수도 있다.Security ID윈도우에서는 위 개념들보다 사용자, 그룹, 기타 보안 주체(security principal)을 고유하게 식별하기 위해 사용되는 문자열 Security ID가 있다. 이를 통해 파일, 레지스트리, 네트워크 자원 등에 대한 접근 권한을 관리하고, 사용자 인증 및 권한 부여에 사용되게 된다.위 내용들은 추후에 다루게 된다."
    },
  
    {
      "title": "6. Spring Boot Validation",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/23/6.-spring-boot-validation.html",
      "date": "2025-06-23",
      "content": "📂 목차  Business Entity  Bean Validation 의존성 추가  Bean Validation 을 통한 비즈니스 룰 검증          Validator를 통해 위반 사항 출력        Hibernate Validator Annotations  Custom Bean Validation Annotation          비밀번호 검증 애너테이션 만들기      📚 본문비즈니스 엔티티 유효성 검증을 위한 밸리데이션을 사용을 생각할 수 있다.Business Entity업무에서 중요하게 다루는 대상(실체)를 의미하며, 주로 정보 시스템이나 소프트웨어 설계에서 사용된다. 현실세계의 개념을 추상화 한 데이터이다.특징  현실 세계의 명사적 개념을 추상화  대부분 데이터베이스 테이블 단위로 구현됨  시스템 전반에서 핵심 로직의 주체로 동작함관련 개념으로는 도메인 객체, DTO 등이 있으나 검색해보길 바란다.Bean Validation 의존성 추가validation 기능을 사용하기 위해 다음 의존성을 추가해주자.// Bean Validationimplementation 'org.springframework.boot:spring-boot-starter-validation'Bean Validation 을 통한 비즈니스 룰 검증쓰기 위해 비즈니스 엔티티를 선언하자.import jakarta.validation.constraints.*;public class Account implements IAccount {    private int number;    private String name;    @Min(value=0, message = \"Account should have a minimum of 0 money\")    private int money;    public Account(int number) {}    public void setMoney(int money) {        this.money = money;    }}위와 같이 @Min을 통해 최소로 가질 값을 지정할 수 있다.Validator를 통해 위반 사항 출력대충 이를 쓰기 위해 application 클래스에서 CommandLineRunner 를 구현해서 써보자.@SpringBootApplication@EnableConfigurationProperties(CustomProperties.class)public class StudyApplication\t\timplements CommandLineRunner{    ...    \t@Override\tpublic void run(String... args) throws Exception {\t\tAccount account = new Account(123);\t\taccount.setMoney(-1);\t\tValidator validator = Validation.buildDefaultValidatorFactory().getValidator();\t\tSet&lt;ConstraintViolation&lt;Account&gt;&gt; violations = validator.validate(account);\t\tviolations.forEach(accountConstraintViolation -&gt; {\t\t\tlogger.error(\"A constraint violation has occurred. Violation details: [{}].\", accountConstraintViolation);\t\t}); \t\t// [{}] 여기에 accountConstraintViolation 내용이 들어감\t}}account 로는 최소값이 0이기 때문에 0을 준다면 에러가 발생할 것이다. Validator 에서 해당 도메인 객체가 비즈니스 룰을 만족했는지 검증을 하고, 검증 로그를 ConstraintViolation 열거형으로 반환한다.  buildDefaultValidatorFactory 는 단순 테스트 목적에서 사용된다.Spring Context에서는 @Autowired 를 사용하여 가져오길 바란다.2025-06-18 21:04:38.793 [restartedMain] ERROR StudyApplication:127 - A constraint violation has occurred. Violation details: [ConstraintViolationImpl{interpolatedMessage='Account should have a minimum of 0 money', propertyPath=money, rootBeanClass=class com.example.study.entity.account.Account, messageTemplate='Account should have a minimum of 0 money'}].위와 같이 출력되는 것을 볼 수 있다.Hibernate Validator Annotations            범주      애너테이션      설명                  Null 여부      @NotNull      null이 아니어야 함                     @NotEmpty      null, 빈 문자열 모두 허용 안 함 (공백은 허용됨)                     @NotBlank      null, 빈 문자열, 공백문자 불가              문자열 관련      @Size(min, max)      길이 제한 (문자열, 배열, 리스트 등)                     @Pattern(regexp)      정규표현식 패턴 검사                     @Email      이메일 형식 검사                     @Length(min, max)      문자열 길이 제한 (hibernate-validator 고유)              숫자 관련      @Min(value)      최소값 (정수형)                     @Max(value)      최대값 (정수형)                     @DecimalMin(value)      최소값 (실수 포함)                     @DecimalMax(value)      최대값 (실수 포함)                     @Positive      양수만 허용                     @PositiveOrZero      양수 또는 0 허용                     @Negative      음수만 허용                     @NegativeOrZero      음수 또는 0 허용                     @Digits(i, f)      정수 i자리, 소수 f자리              날짜 관련      @Past      과거 날짜만 허용                     @PastOrPresent      과거 또는 오늘                     @Future      미래 날짜만 허용                     @FutureOrPresent      미래 또는 오늘              계층 객체      @Valid      중첩 객체의 유효성 검사 수행      Custom Bean Validation Annotation비즈니스 엔티티 유효성 검증을 위 애너테이션 외에 입맛대로 검증을 수행하도록 하는 커스텀 빈 밸리데이션 애너테이션을 정의 할 수도 있다.비밀번호 검증 애너테이션 만들기커스텀 애너테이션을 만들기 위해 ConstraintValidator 인터페이스를 구현해야 된다. 제네릭 변수로 첫번째는 커스텀 밸리데이터 로직을 적용하게 해주는 애너테이션(애너테이션을 따로 정의해야 함)을 넣어주고, 두 번째로는 커스텀 애너테이션을 적용해야 하는 데이터 타입을 넣어주면 된다(밸리데이션을 수행하는 대상의 타입을 적어주라는 말).import jakarta.validation.*;import java.lang.annotation.*;public class PasswordRuleValidator implements ConstraintValidator&lt;&gt; {    @Override    public void initialize(Annotation constraintAnnotation) {        ConstraintValidator.super.initialize(constraintAnnotation);    }    @Override    public boolean isValid(Object value, ConstraintValidatorContext context) {        return false;    }}구현시 isValid 와 initialize가 생성된다. initialize는 ConstraintValidator가 특정 애너테이션에 대해 초기 설정을 수행하는 로직인데, 이는 첫번째 Generic을 인자로 받아 사용하게 된다.만약 ConstraintValidator&lt;Id, String&gt; 으로 구현을 했다면, Id 에서 가져올 수 있는 변수로 멤버변수들을 선언하여 통해 나중에 isValid 에서 이 변수들을 활용해 다양한 검증을 수행할 수 있을 것이다. 하지만 여기서는 불필요하기 때문에 그냥 삭제한다.제네릭 인자에 넣을 애너테이션을 구현해주자.import jakarta.validation.*;import java.lang.annotation.*;@Target({ElementType.TYPE, ElementType.FIELD})@Retention(RetentionPolicy.RUNTIME)public @interface Password {    // 기본 메시지 정의    String message() default \"Password do not adhere to the specified rule\";    Class&lt;?&gt;[] groups() default {};    /*     검증 대상 객체에 대한 부가적인 메타데이터를 제공하는 Payload를 사용     어떤 검증 테스트가 실패했는지를 payload 객체로 받게 됨     */    Class&lt;? extends Payload&gt;[] payload() default {};}message는 위반 사항에 대한 출력, groups는 그룹별 검증 시 유용하며, 실무에서는 계층적 유효성 검증을 할 때 사용한다. 예를 들어 회원가입에서는 name, email, password 가 모두 필수지만, 로그인 시에는 email, password만 필요하게 된다. 이때 모든 필드를 한꺼번에 검증하면 불필요한 제약이 생기게 되는데, 이럴 때 groups로 유효성 검증을 분리시켜 상황에 맞게 필요한 것만 검증을 할 수 있다.// interfaces def.classpublic interface OnRegister {}public interface OnLogin {}// User.classpublic class User {    @NotBlank(groups = OnRegister.class)    private String name;    @NotBlank(groups = {OnRegister.class, OnLogin.class})    private String email;    @NotBlank(groups = {OnRegister.class, OnLogin.class})    private String password;}// validateValidator validator = Validation.buildDefaultValidatorFactory().getValidator();User user = new User();Set&lt;ConstraintViolation&lt;User&gt;&gt; violations =    validator.validate(user, OnLogin.class);  // 로그인에 필요한 것만 검증이제 다시 PasswordValidator 로 가서 isValid() 를 구현해주자.여기서 Password 에 대한 비즈니스 검증은 굉장히 많이 쓰이기 때문에 라이브러리로 따로 구현이 되어 있다. passay 라이브러리를 추가하여 이를 쓰도록 하자.implementation 'org.passay:passay:1.6.3'Bean Validation 구현import jakarta.validation.*;import org.passay.*;import java.util.*;public class PasswordRuleValidator implements ConstraintValidator&lt;Password, String&gt; {    private static final int MIN_COMPLEX_RULE = 2;    private static final int MAX_REPETITIVE_CHARS = 3;    private static final int MIN_SPECIAL_CASE_CHARS = 1;    private static final int MIN_UPPER_CASE_CHARS = 1;    private static final int MIN_LOWER_CASE_CHARS = 1;    private static final int MIN_DIGIT_CASE_CHARS = 1;    @Override    public boolean isValid(String password, ConstraintValidatorContext context) {        List&lt;Rule&gt; passwordRules = List.of(                new LengthRule(8, 30),                new CharacterCharacteristicsRule(                        MIN_COMPLEX_RULE,                        new CharacterRule(EnglishCharacterData.Special, MIN_SPECIAL_CASE_CHARS),                        new CharacterRule(EnglishCharacterData.UpperCase, MIN_UPPER_CASE_CHARS),                        new CharacterRule(EnglishCharacterData.LowerCase, MIN_LOWER_CASE_CHARS),                        new CharacterRule(EnglishCharacterData.Digit, MIN_DIGIT_CASE_CHARS)                ),                new RepeatCharacterRegexRule(MAX_REPETITIVE_CHARS));        PasswordValidator passwordValidator = new PasswordValidator(passwordRules);        PasswordData passwordData = new PasswordData(password);        RuleResult ruleResult = passwordValidator.validate(passwordData);        return ruleResult.isValid();    }}이제 이를 비즈니스 엔티티에 적용시켜주면 되지만, 하기 전에 어노테이션과 Validator 를 연결시켜줄 무언가가 필요하다. 지금은 설계만 끝난 것이지 어노테이션이 어떤 Validate 를 할지 명시를 안해주었기에 그냥 메타데이터만 넣게 된 것 뿐이다. 따라서 어노테이션에 가서 @Constraint를 사용하여 해당 어노테이션을 사용하는 target 에게 어떤 validator 를 쓸 것인지 명시를 해준다.@Target({ElementType.TYPE, ElementType.FIELD})@Retention(RetentionPolicy.RUNTIME)@Constraint(validatedBy = PasswordRuleValidator.class)public @interface Password {\t...이제 엔티티에 적용시켜주자.import com.example.study.validator.*;import lombok.*;@Getter@ToString@NoArgsConstructor@AllArgsConstructorpublic class User {    private String name;    @Password // 커스텀 애너테이션 사용    private String password;}이제 동일하게 validator 를 통해 ConstraintViolation 들을 가져와서 검증을 수행하면 된다.🔗 관련 출처  Custom Annotation"
    },
  
    {
      "title": "Custom Annotation",
      "url": "/seonghun120614/computerscience/java/2025/06/23/custom-annotation.html",
      "date": "2025-06-23",
      "content": "개발자가 정의할 수 있는 코드의 동작에 직접 영향을 줄 수 있는 메타데이터를 보자.🪛 한계점기존 자바 어노테이션은 표준적인 용도에 국한되지만, 도메인 규칙이나 프로젝트별 특수한 요구사항을 반영하려면 개발자가 직접 어노테이션을 정의해야 하는 경우가 많다.📂 목차  Annotation 정의          @Target      @Retention      @Documented      @Inherited        Reflection을 활용한 커스텀 어노테이션 처리  Reflection을 활용한 동적 프록시 설계          동적 프록시 설계 구현                  Proxy Class 설계          ⭐️Proxy Instance 생성                          ⭐️첫 번째 인자 설명              두 번째 인자 설명              세 번째 인자 설명                                            Annotation Attribute 정의📚 본문Annotation 정의java.lang.annotation 에 커스텀 어노테이션 정의에 필요한 기능들이 다 들어가 있다.커스텀 어노테이션은 @interface 키워드로 선언되며, 이는 클래스나 인터페이스에 부가적인 메타데이터를 제공하는 특수한 문법이다. 어노테이션은 소스 코드의 의미를 확장하거나, 컴파일러 또는 런타임 프로세서가 런타임에 특정 동작을 유도할 수 있도록 도와준다.@Target({ElementType.TYPE, ElementType.FIELD, ...}) // 적용 대상@Retention(RetentionPolicy.RUNTIME)                // 유지 범위@Documented                                         // javadoc 포함 여부public @interface MyAnnotation {    String value() default \"\";    int count() default 0;}@Target해당 어노테이션을 어디에 적용할지를 정한다.  ElementType.FIELD: 필드에 적용  ElementType.TYPE: 클래스, 인터페이스, enum 등에 적용  ElementType.METHOD: 메서드에 적용  ElementType.PARAMETER: 파라미터에 적용  ElementType.CONSTRUCTOR: 생성자에 적용…@Retention어노테이션의 lifecycle 을 어디까지 유지할지(RetentionPolicy) 정의한다.JVM의 GC가 알아서 자원을 회수할 수 있도록 함.  RetentionPolicy.SOURCE: 컴파일 까지만 존재하고, .class 파일에도 존재하지 않도록 함  RetentionPolicy.CLASS: 컴파일 시 클래스 파일엔 남지만, JVM 런타임 시점에서는 참조가 불가능함  RetentionPolicy.RUNTIME: 런타임에도 유지되어서 리플렉션(Reflection) 가능, Bean Validation에는 필수로 들어가야 함          Bean Validation이나 AOP, DI(의존성 주입) 프레임워크들이 런타임에 어노테이션 정보를 읽어 동작하기 때문에 RUNTIME 설정은 필수이다.      Spring 프레임워크에서는 이 동적 프록시 기법을 사용해 AOP(관점 지향 프로그래밍), 트랜잭션, Lazy loading 등을 구현한다. 예를 들어, @Transactional이 붙은 메서드는 내부적으로 프록시 객체가 DB 트랜잭션을 시작하고, 예외 발생 시 롤백 처리를 수행한다. 동적 프록시 기법은 이 밑에 다룬다.@DocumentedJavaDoc 문서 생성 시 포함되어야 함을 명시하고, 문서화가 필요한 공용 API를 만들 때 주로 사용한다.@Inherited자식 클래스에 상속시킬지 여부이다. 단, 필드/메서드에는 적용되지 않고 클래스 단위에서만 상속된다.Reflection을 활용한 커스텀 어노테이션 처리Reflection은 그냥 메타 데이터를 읽을 수 있게 도와주는 패키지이다. Reflection 에서 제공하는 대표적인 기능들은 다음과 같다.핵심 기능  클래스 로딩: Class.forName(...)  생성자 호출: getDeclaredConstructor().newInstance()  필드 접근/변경: getDeclaredField(), setAccessible(), set()  메서드 실행: getDeclaredMethod(), invoke()실제로 밑과 같이 수행할 수 있다.커스텀 어노테이션 정의@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface RequiredField {    String message() default \"This field is required.\";}엔티티 클래스 정의public class User {    @RequiredField    private String name;    private int age;}public class ValidatorUtil {    public static void validateRequiredFields(Object obj) throws IllegalAccessException {        Class&lt;?&gt; clazz = obj.getClass();        for (Field field : clazz.getDeclaredFields()) {            if (field.isAnnotationPresent(RequiredField.class)) {                field.setAccessible(true);                Object value = field.get(obj);                if (value == null) {                    RequiredField ann = field.getAnnotation(RequiredField.class);                    System.out.println(\"❌ Validation failed: \" + ann.message());                }            }        }    }}Reflection을 활용한 동적 프록시 설계리플렉션을 활용하면 동적 프록시 설계에서 유용하게 쓸 수 있다.이때 프록시라는 것은 클라이언트와 실제 객체 사이에서 상호작용을 관리하는 또 다른 객체로 보면 되겠다. 예를 들어 일상에서는 TV를 조종하기 위해서 우리는 리모컨을 사용하게 된다. 여기서 TV는 실제 객체이며, 우리는 클라이언트이다. 리모컨은 proxy 가 된다.동적 프록시 설계 구현우선 인터페이스와, 실제 객체를 보자.인터페이스 정의public interface AccountService {    void deposit(int amount);}실제 객체 정의public class AccountServiceImpl implements AccountService {    public void deposit(int amount) {        System.out.println(\"💰 \" + amount + \"원 입금 완료\");    }}위는 우리가 조작하고 싶어하는 객체이다. 조작할 객체를 프록시로 연결시키자.Proxy Class 설계InvocationHandler 는 메서드를 호출할 때마다 invoke 라는 메서드가 중간에 가로채어서 실행할 수 있게 한다. 밑의 InvocationHandler 를 구현한 LoggingHandler 클래스 정의가 있고 여기서 handler 가 호출된다면, invoke가 실행된다.public class LoggingHandler implements InvocationHandler {    private final Object target;    public LoggingHandler(Object target) {        this.target = target;    }    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {        System.out.println(\"🔍 호출 전: \" + method.getName());        Object result = method.invoke(target, args);        System.out.println(\"✅ 호출 후: \" + method.getName());        return result;    }}invoke로 오버라이딩 된 인자 proxy, method, args는 다음과 같은 의미를 가진다:  proxy: 실제로 method.invoke()가 호출된 프록시 객체 자기 자신  method: 호출된 메서드 정보(Method 클래스)  args: 전달된 인자들InvocationHandler 를 통해 실제 구현 객체와 클라이언트 사이에서 메서드를 수행하고 해당 메서드의 결과를 반환하도록 작성해주면 된다. 프록시를 만들기 위한 사전 설계가 끝난 상태이다. proxy 의 .getClass().getName() 을 하여서 이름까지 로깅에 출력해주면 더 좋다.⭐️Proxy Instance 생성밑에서 Proxy Class 의 newProxyInstance() 통해 새로운 proxy 인스턴스를 만든다.AccountService target = new AccountServiceImpl();AccountService proxy = (AccountService) Proxy.newProxyInstance(        target.getClass().getClassLoader(),        new Class[]{AccountService.class},        new LoggingHandler(target));proxy.deposit(5000);반환하게 되는 것은 Object 이기 때문에 강제 캐스팅 수행을 통해 맞는 메서드를 수행 할 수 있도록 바꾼다.⭐️첫 번째 인자 설명우선 이 프록시 설계는 런타임 도중에 JVM이 ‘직접’ 생성해야한다(RAM에 적재시켜야 한다). 이때 JVM은 프록시 클래스를 메모리에 로딩할 위치(클래스로더)를 알아야 한다. “어디서 로딩할지를 알려줘야” 하므로 우리는 첫번째 인자를 클래스 로더를 입력하게 된다.여기서 첫 번째 인자로 타겟 객체의 Class Loader를 그대로 사용하는 것이 일반적인데, 이렇게 하면 JVM은 실제 구현체가 로딩된 환경과 동일한 위치에 프록시 클래스도 함께 로딩시킬 수 있게 되고 클래스 충돌이나 접근 제한을 방지하는 데에도 유리하게 된다.정리하면 여기서는 실제 객체인 target의 Class Loader 에다가 Proxy Class 를 올리기 위해 JVM이 해당 Class Loader를 찾아서 Proxy Class를 올리게 된다.두 번째 인자 설명new Class[]에서는 생성할 프록시 객체가 어떤 인터페이스를 구현할 것인지를 명시한다.해당 인터페이스를 기반으로 프록시 클래스가 생성되기 때문에, 반드시 구현할 대상 인터페이스를 지정해주어야 한다.예를 들어, AccountService 인터페이스를 구현하도록 지정하면 프록시는 AccountService의 모든 메서드를 위임 처리할 수 있게 된다.여러 개의 인터페이스도 동시에 지정할 수 있다. 예를 들어 PaymentService 등을 함께 등록하면, 프록시 확장성 및 재사용성이 높은 설계를 할 수 있다.세 번째 인자 설명마지막 인자는 InvocationHandler를 구현한 객체를 넘겨주는 부분이다. 이 핸들러는 프록시 객체의 메서드가 호출될 때 중간에서 가로채는 역할을 수행한다.핸들러 내부에서는 호출된 메서드 정보를 확인하고, 원하는 작업(로깅, 보안 검사, 트랜잭션 처리 등)을 수행한 뒤 실제 타겟 객체의 메서드를 실행시키고 그 결과를 반환한다.이러한 구조를 통해 공통 기능을 프록시 레벨에서 일관성 있게 주입할 수 있게 된다.Annotation Attribute 정의애너테이션 안에는 멤버 변수, 메서드가 존재하지 않는다. 대신에 attribute(element) 가 존재한다.  타입 이름();타입 이름() default 값;으로 attribute를 annotation 안에 정의할 수 있다. 또한 애너테이션은 다음 타입들을 속성으로 사용할 수 있다:  primitives: int, long, float, boolean, double, char, byte, short, …  String  Class&lt;?&gt;  Enum  Annotations  위 타입들에 대한 Class&lt;?&gt;[] 배열public @interface PrimitiveAttr {    int age() default 0;    boolean enabled() default true;}public @interface StringAttr {    String name() default “guest”;}public @interface ClassAttr {    Class&lt;?&gt; targetClass();}public enum Level {    LOW, MEDIUM, HIGH}public @interface EnumAttr {    Level level() default Level.MEDIUM;}public @interface MetaInfo {    String value();}public @interface AnnotationAttr {    MetaInfo info();}public @interface ArrayAttr {    String[] tags() default {};    int[] numbers() default {1, 2, 3};    Class&lt;?&gt;[] classes() default {};}✒️ 용어Reflectionjava.lang.reflect에서 런타임 시점에 클래스, 메서드, 필드, 생성자 등에 접근하고 조작할 수 있는 기능을 말하며, 일반적으로 코드 작성 시에 컴파일 타임에 어떤 클래스나 메서드를 호출할 지 결정하지만, 리플렉션은 실행 중에 동적으로 객체의 구조를 분석하여 수정할 수 있다.Class&lt;?&gt; clazz = Class.forName(\"com.example.User\");Object obj = clazz.getDeclaredConstructor().newInstance();Field field = clazz.getDeclaredField(\"name\");field.setAccessible(true); // 접근 제어자 무시field.set(obj, \"홍길동\");Method method = clazz.getDeclaredMethod(\"getName\");Object result = method.invoke(obj);System.out.println(result);  // \"홍길동\"  setAccessible  isAnnotationPresent  getAnnotation  Proxy.newProxyInstance등등을 사용할 수 있다."
    },
  
    {
      "title": "1.5 Resource Management",
      "url": "/seonghun120614/computerscience/os/2025/06/16/1.5-resource-management.html",
      "date": "2025-06-16",
      "content": "운영체제는 자원관리가 철저히 되어야 한다. 시스템의 CPU, 메모리 공간, 파일 저장 공간, 입출력 장치 등 다양한 자원들을 어떻게 관리하는지 대략적으로 본다.📂 목차  1.5.1 자원 관리          단일 스레드 프로세스와 멀티 스레드 프로세스      운영체제의 프로세스 관리 기능        1.5.2 Memory Management          프로그램 실행을 위한 메모리 역할      여러 프로그램 동시 실행을 위한 메모리 관리      운영체제의 메모리 관리 역할        1.5.3 File-System Management          운영체제 파일 관리 역할        1.5.4 Mass-Storage Management          Secondary Storage                  운영체제 보조기억장치 관리 역할                    Tertiary Storage                  운영체제 3차 저장장치 관리 역할                    저장장치 계층별 특징        1.5.5 Cache Management          레지스터와 캐시의 차이      하드웨어 수준 캐시      캐시 크기와 교체 정책      계층적 저장 구조와 데이터 동기화      환경별 고려 사항        1.5.6 I/O System Management          운영체제 I/O 시스템 관리 역할      📚 본문1.5.1 Process Management  프로세스는 작업 수행을 위해 CPU 시간, 메모리, 파일, I/O 장치 등의 자원을 필요  자원은 프로세스 실행 중 운영체제가 할당 및 회수여기서 프로그램과 프로세스는 서로 다른 개념이다.  프로그램: 정적인 코드(파일)  프로세스: 동적인 실행중인 단위  프로세스 = 프로그램의 인스턴스이 부단원에서 집중적으로 보는 것은 Process 이다.단일 스레드 프로세스와 멀티 스레드 프로세스프로세스는 시스템 내에서의 작업 단위이고 하나의 시스템은 다수의 프로세스들로 구성되게 된다. 컴퓨터에 실행되는 모든 프로세스들 중 일부는 운영체제 프로세스이고 나머지는 사용자 프로세스이다.또 위와 같이 안나누고, 다음과 같이 두 가지 부류로 나눌 수도 있다.  단일 스레드 프로세스, 시분할 방식: 하나의 프로그램 카운터를 가지고 순차적으로 명령어를 실행  멀티 스레드 프로세스, 병렬 프로그래밍 방식: 스레드 마다 프로그램 카운터를 따로 보유해서 병렬적으로 실행운영체제의 프로세스 관리 기능  프로세스 생명주기 관리(생성/삭제 운영체제는 재사용 가능한 자원을 회수해야 함)  프로세스 및 스레드의 CPU 스케줄링  프로세스 Suspend(중단) 및 Resume(재게) 지원  프로세스 Synchronization 메커니즘 제공  프로세스 간 통신 IPC 메커니즘 제공메모리 관리를 보자.1.5.2 Memory Management기본적으로 다음 상식이 필요하다.Main Memory는 CPU와 I/O 장치가 공유하는 빠르게 접근 가능한 저장 공간이며, 이중 CPU 가 주로 Main Memory에 접근을 하여 직접 주소를 지정하고 계산을 위한 데이터를 읽거나 쓰게 된다.  CPU는 Instruction-fetch Cycle 중에 명령어를 Main Memory에서 읽어옴  CPU는 Data-fetch Cycle 중에는 Main Memory로부터 데이터를 읽거나 씀프로그램 실행을 위한 메모리 역할프로그램을 실행하기 위해서 CPU는  Absolute Address 로 매핑을 시키고  Main Memory 에 적재하고  실행 중인 명령어/데이터를 메모리에서 접근  실행이 끝난 후에는 메모리 공간을 해제시킨다.여러 프로그램 동시 실행을 위한 메모리 관리CPU 사용률 향상과 사용자 응답 속도 개선을 위해서 이전에 CPU를 여러 개 쓰는 것을 보았고, 여러 개의 코어를 쓰도록 하기 위해 여러 프로그램을 동시에 메모리에 유지해야 함을 알 수 있었다.여러 개의 프로그램을 동시에 메모리에 유지시키기 위해서 다양한 알고리즘, 하드웨어가 존재하기 때문에 운영체제는 때에 맞는 관리법을 사용해야 한다.운영체제의 메모리 관리 역할따라서 운영체제는 다음 책임이 따른다.  어떤 메모리 영역이 사용 중인지  어떤 프로세스가 사용 중인지  실행해야 할 프로세스 메모리 공간 할당  실행이 끝난 프로세스 메모리 공간 해제  어떤 프로세스와 데이터를 메모리로 가져오거나 내보낼지 결정1.5.3 File-System Management운영체제는 저장장치의 물리적 특성을 추상화하여 사용자에게 논리적이고 일관된 저장 단위인 File 개념을 제공한다. 이들은 전부 2차, 3차 저장장치에 저장되어 있다.  File: 관련된 정보를 담은 추상적 단위          자유 형식 또는 고정 형식 등 가능하다.        파일은 Directory 구조(트리 형태)로 구성되어 관리됨          접근 권한 제어 필요      운영체제 파일 관리 역할  파일 생성 및 삭제  디렉터리 생성 및 삭제  파일/디렉터리 조작 기능 제공  파일을 물리 저장 장치에 매핑  파일을 비휘발성 저장매체에 백업1.5.4 Mass-Storage Management위는 저장장치와 운영체제 간의 의사소통 단위로써의 파일과 디렉토리를 통해 사용자에게 편의성을 제공하는 기능을 보았다면, 지금은 대용량 저장장치 자체의 관리를 본다.Secondary Storage흔히 우리가 사는 HDD, SSD(NVM) 등은 프로그램과 데이터의 주 저장 매체가 여기서 다루어지며, 대부분의 프로그램은 메모리에 올라가기 전 여기에 저장된다. 실행 중에도 저장장치를 통해 입출력 수행하고, 용도로는 자주 쓰이는 어플리케이션이나 파일 등을 저장하게 된다.운영체제 보조기억장치 관리 역할  장치 마운트/언마운트  빈 공간 관리  저장공간 할당  디스크 스케줄링  디스크 파티션 관리  자원 보호(접근 제한)Tertiary Storage속도는 느리지만 비용이 저렴하고 용량이 큰 저장장치이다. 가장 적합한 용도는 백업, 아카이브, 잘 안쓰는 데이터를 저장할 때 쓰인다.운영체제 3차 저장장치 관리 역할  장치 마운트/언마운트  장치 독점 사용 권한 관리  2차 -&gt; 3차 저장소로 데이터 마이그레이션저장장치 계층별 특징1.5.5 Cache Management자주 쓰이는 정보를 느린 저장소에서 빠른 저장소로 복사해두고 사용하는 기술을 Caching 이라고 한다.  정보가 필요하면 일단 그 정보를 먼저 캐시에서 찾고  없으면 원래 저장소에서 읽고 캐시에 복사레지스터와 캐시의 차이CPU 내부에는 명령어 처리를 위한 레지스터(Register Set) 와, 메모리 접근 속도를 높이기 위한 캐시(Cache) 가 함께 존재한다.      레지스터(Register): CPU 연산에 직접 사용되는 가장 빠르고 가장 작은 저장소이며, 명령어 실행 시 즉각 참조된다.컴파일러는 어떤 데이터를 레지스터에 보관할지 결정하기 위해 레지스터 할당 알고리즘을 사용한다.        캐시(Cache): 메인 메모리보다 빠른 저장소로, 자주 사용하는 데이터를 하드웨어가 자동으로 복사/관리한다.L1, L2, L3 등의 계층 구조를 가지며, CPU와 메인 메모리 간 병목을 줄이기 위해 존재한다.    두 장치는 모두 속도를 위한 고속 저장장치이지만,레지스터는 명령어 실행 단위의 직접 연산용,캐시는 메모리 접근 지연 최소화를 위한 자동 관리 구조라는 점에서 차이가 있다.하드웨어 수준 캐시일부 캐시는 완전히 하드웨어에 의해 구현된다. 위에서 캐시 설명에 포함되는 개념이다.  L1 Cache 예시:Instruction Cache(L1I): 다음에 실행될 명령어를 저장Data Cache(L1D): 자주 접근하는 데이터를 저장이런 캐시가 없으면 CPU는 메인 메모리에서 명령어/데이터를 가져오느라 여러 클럭 사이클 동안 대기해야 한다.캐시 크기와 교체 정책캐시는 용량이 제한적이기 때문에  크기 결정  교체 알고리즘이 두 가지로 성능이 크게 좌우된다. 이를 운영체제가 하게 된다.계층적 저장 구조와 데이터 동기화보통 저장장치는 계층적으로 구성됨을 보았다.여기서 동일한 데이터가 여러 계층에 동시에 존재함을 알 수 있는데, 이에 대한 동기화를 어떻게 하는지 간단히 보자.  예: 정수 A가 파일 B에 있고, B는 2차 저장장치에 있음      2차 저장장치에서 메인 메모리로 블록 복사    메모리 -&gt; 캐시 -&gt; 레지스터 순으로 A를 이동    레지스터에서 A를 증가시키고    수정된 값을 모든 계층에 동기화여기서 캐시 계층에 값을 최신화 시키는 것을 캐시 일관성이라고 함  환경별 고려 사항멀티태스킹 환경에서는 여러 프로세스가 동일 데이터 A에 접근할 경우에 가장 최신의 값을 보장해야 한다. 여기서 발생하는 문제를 캐시 일관성(Cache Coherency)이라하고 보통 하드웨어에서 처리하게 된다.멀티태스킹 뿐만 아니라 분산 시스템도 여러 컴퓨터에 파일 복사본(replica)이 존재 가능해서 수정 시 다른 복사본에도 동기화가 필요하게 된다.1.5.6 I/O System Management운영체제는 특정 하드웨어 장치의 복잡한 특성을 사용자로부터 숨겨서 사용자가 사용하기 편리하게 한다.대부분의 구성요소는 I/O 장치의 특성을 몰라도 되도록 I/O 하위 시스템이 이를 감추어주는데,  메모리 관리 구성요소          버퍼링: I/O 속도 차이를 완화하기 위한 임시 메모리      캐싱      스풀링: 출력 장치처럼 순차적 처리 필요한 경우 데이터를 큐에 저장        일반적인 장치 드라이버 인터페이스  특정 하드웨어 장치에 대한 드라이버  …이러한 계층화된 구성 덕분에 운영체제는 새로운 장치에 대한 특수한 세부사항을 알지 않아도 통일된 방식으로 I/O를 처리할 수 있다.효율적인 I/O 하위 시스템을 구성하기 위해 인터럽트 핸들러와 장치 드라이버가 사용된다.운영체제 I/O 시스템 관리 역할  I/O 하위 시스템이 다른 시스템 구성요소와 어떻게 인터페이스하는지  장치를 어떻게 관리하는지  데이터를 어떻게 전송하는지  I/O 완료를 어떻게 감지하는지1.6 ~ 1.11 은 간단히 넘어간다. 나중에 더 해도 됨.🔗 출처  도서: Operating System Concepts 10th Edition"
    },
  
    {
      "title": "1.4 Operating System Operations",
      "url": "/seonghun120614/computerscience/os/2025/06/15/1.4-operating-system-operations.html",
      "date": "2025-06-15",
      "content": "모든 컴퓨터 시스템의 구조를 보았기 때문에, 아래의 운영체제에 대해 상세히 살펴본다.📂 목차  Bootstrap Program          부팅 단계 요약        1.4.1 Multiprogramming and Multitasking          다중프로그래밍의 원리      다중 작업(Multitasking)      가상 메모리와 응답 시간 보장      파일 시스템        1.4.2 Dual-Mode and Multimode Operation          Dual Mode      Kernel Mode에서 실행되는 Privileged Instruction      Additional Modes      Mode 관점에서의 Virtualization      System Call 을 통한 Kernel Mode 로의 전환        1.4.3 Timer          Linux Timer      📚 본문운영체제는 프로그램이 실행되는 환경을 제공하는 소프트웨어 + 일부 하드웨어 이다.내부적으로는 다양한 방식으로 조작될 수 있어서 운영체제 마다 다를 수 있겠지만, 전체적인 틀에서 공통된 컴포넌트들을 볼 것이다.우선 운영체제가 어떻게 컴퓨터 내에서 생성이 되는지 보자.Bootstrap Program컴퓨터가 전원이 켜지거나 재시작될 때, 가장 먼저 실행되어야 할 초기 프로그램이 필요하며, 이를 부트스트랩 프로그램(Bootstrap Program)이라고 한다.부트스트랩 프로그램은  Firmware 형태로 하드웨어에 내장됨  컴퓨터 시스템의 모든 구성 요소(CPU 레지스터 집합, 디바이스 컨트롤러, 메모리 내용 등)를 초기화  운영체제 커널을 어디서 찾을지, 어떻게 적재할지, 실행을 시작할지 담당한다.부팅 단계 요약  부트스트랩 프로그램이 실행됨  부트스트랩은 모든 구성요소 초기화를 함  초기화 후 운영체제 커널을 찾아서 메모리에 적재함  적재되면 운영체제의 Daemon들이 시작됨  모든 서비스가 시작된 후 외부 이벤트(I/O 인터럽트, 하드웨어 인터럽트, Trap 인터럽트(Exception 인터럽트), system call 등)가 발생하길 기다리는 운영 상태가 됨여기서 일부 서비스는 커널 외부에서 제공되고 이는 부팅 시 메모리에 로드되어 백그라운드에서 항상 실행되는 Daemon(시스템 프로그램) 형태로 동작한다.Linux 시스템에서는 이러한 시스템 프로그램 중 첫 번째가 [systemd](#systemd) 이며, 이 프로그램이 여러 다른 daemon들을 시작하게 한다.이제 운영체제가 하는 일을 보자.1.4.1 Multiprogramming and Multitasking운영체제의 특징 중 하나는 여러 프로그램을 동시에 실행할 수 있는 능력이며, 이를 Multiprogramming 이라고 한다.다음 장점을 얻을 수 있다:  프로그램들을 조직화하여 CPU의 사용률을 높임  사용자 만족도를 향상시킴실행 중인 프로그램을 Process 라고 부른다다중프로그래밍의 원리운영체제가 여러 개의 프로세스를 동시에 메모리에 유지한다.  운영체제는 이 중 하나를 선택하여 실행을 시작함  해당 프로세스가 I/O 작업 등으로 대기 상태로 진입  이때 운영체제는 즉시 다른 프로세스로 전환하여 실행다중 작업(Multitasking)Multitasking 은 다중 프로그래밍의 논리적 확장이다.다중 작업 시스템에서는 운영체제가 짧은 시간에 여러 프로세스를 매우 빠르게 전환함으로써 사용자가 여러 작업을 동시에 하는 것처럼 느끼게 하는걸 Multitasking 이라고 한다.다중 프로세스를 위한 추가 고려 사항메모리에 여러 프로세스를 동시에 유지하려면 어떤 형태의 메모리 관리(Memory Management)가 필요하며 이는 추후에 다룬다.운영체제가 일단 메모리에 관해 하는 일로는 다음과 같다:  CPU Scheduling: 여러 프로세스가 동시에 실행 ready 상태에 있다면, 운영체제는 어떤 프로세스를 먼저 실행할지 결정한다.  동시에 여러 프로세스를 실행하려면 프로세스 간 상호 간섭을 방지해야 한다. 이는 프로세스 스케줄링, 디스크 저장소, 메모리 관리 전반에 걸쳐 필요하다.이는 추후에 다룬다.가상 메모리와 응답 시간 보장다중 작업 시스템에서는 운영체제가 적절한 응답 시간을 보장해야 한다. 이를 위한 방법 중 하나가 Virtual Memory 이다.가상 메모리는:  메모리에 완전히 올라오지 않은 프로세스도 실행 가능하게 해줌  Physical Memory보다 더 큰 프로그램도 실행 가능  Logical Memory와 Physical Memory를 분리하여, 메모리를 하나의 큰 연속 공간처럼 추상화이 방식은 프로그래머가 메모리 제약을 고려하지 않아도 되는 장점을 가진다.파일 시스템파일 시스템은 Secondary Storage 에 위치하며, Storage Management 가 제공되어야 한다.또한, 부적절한 자원의 사용을 방지하기 위한 보호 기능이 여기에 들어가야 한다.1.4.2 Dual-Mode and Multimode Operation운영체제와 사용자들은 컴퓨터 시스템의 하드웨어 및 소프트웨어 자원을 공유하기 때문에 잘 설계된 운영체제는 오류가 있거나 악의적인 프로그램이 다른 프로그램이나 운영체제 자체가 잘못 실행되도록 방해하면 안된다.Dual Mode따라서 위 문제의 해결책으로 둘을 완전히 분리시키면 서로 영향을 주지 못하게 되기 때문에 이를 위해 나온 개념이:  User Mode(사용자 모드)  Kernel Mode(커널 모드) = Supervisor Mode = System Mode = Privileged Mode이다.하드웨어에 Mode Bit를 추가하여 현재 모드를 나타낼 수 있다.  0: Kernel Mode  1: User Mode따라서 컴퓨터가 어플리케이션을 실행 중일 때는 사용자 모드이며, 운영체제의 서비스를 요청할 때(system call)는 커널 모드로 전환한다.  커널 모드(0): 시스템부팅, Trap, Interrupt 발생 시유저 모드(1): 운영체제가 적재된 후이런 모드 방식을 Dual Mode 라고 부르고 다음 기능을 하게 된다:  잘못된 사용자로 부터 보호  동시에 사용자들 간에도 상호 보호 할 수 있는 수단을 제공Kernel Mode에서 실행되는 Privileged Instruction여기서 시스템에 해를 끼치는 명령어들을 Kernel Mode 로만 실행해야하기 때문에 이런 명령어들을 Privileged Instruction 라고 한다.만약 이런 명령어를 User Mode에서 실행한다면 Trap을 발생시켜 즉시 제어를 운영체제로 넘긴다.커널 모드로 전환하는 명령어는 특권 명령어 뿐만 아니라, 입출력 제어, 타이머 관리, 인터럽트 관리 등이 있다.Additional Modes모드의 개념을 통해 사용자마다 실행할 수 있는 명령어들을 제한시킬 수 있도록 할 수 있다. 즉, 모드를 여러 개로 가져가는 것이다.운영체제 마다 기본적으로 제공하는 모드들이 다르고 개수도 다르다.  Intel: 4 protection rings(0, 1, 2, 3), 0은 커널, 3이 유저 이다ARMv8: 7 개의 모드를 제공한다Mode 관점에서의 Virtualization가상화를 지원하는 CPU는 Virtual Machine Manager(VMM) 가 시스템을 제어하고 있다는 것을 나타내기 위한 별도의 모드를 제공하기도 한다.이 모드는 일반 사용자보다는 더 많은 권한을 가지기는 하지만, 커널보다는 적은 권한을 가진다(4 protection ring에서 2, 3 정도라고 보면 된다).VMM은 이러한 권한 수준을 통해 가상 머신을 생성, 관리, CPU 상태 변경을 한다.System Call 을 통한 Kernel Mode 로의 전환사용자 프로그램이 운영체제에게 특정 작업을 요청하는 공식적인 방법이라고 할 수 있다. 보통 파일 접근, 메모리 할당, 프로세스 제어 등 운영체제만 수행할 수 있는 작업이며, 이는 사용자 모드에서는 못하는 명령어 수준이다.System Call의 과정  사용자 프로그램이 System Call  Trap 명령을 통해 Kernel Mode 로 전환  커널이 어떤 요청인지 확인 후 파라미터 검사  요청 처리 후 다시 사용자 모드로 전환Exception 과정  잘못된 명령어 실행 및 접근 불가 메모리 사용 시 Trap 발생  커널이 이를 감지하고 운영체제가 비정상 종료 처리를 함  종료 시 오류 메시지 + Memory Dump를 생성함1.4.3 Timer운영체제는 사용자 프로그램이 무한 루프에 빠지거나 운영체제에 제어를 반환하지 않는 것을 방지해야 한다.이를 위해 Timer 를 도입하고, 다음과 같이 동작한다:  운영체제가 타이머를 설정  일정 시간이 지나면 인터럽트 발생  운영체제가 제어권을 다시 획득즉, 빌리는 것이다.이를 구현하는 방식으로는:  고정 속도 클럭(Clock)과 카운터(Counter)가 필요  운영체제가 타이머의 Counter 를 설정  Clock 이 1 tick 할 때마다 Counter 를 -1  Counter가 0이 되면 Interrupt 발생  10 비트 카운터 + 1ms 클럭-&gt; 1~1024(2^10)ms 범위로 인터럽트 설정 가능운영체제는 사용자 프로그램에 제어를 넘기기 전에 반드시 타이머를 설정한다. 만약 타이머 인터럽트가 발생하면 제어는 자동으로 운영체제로 전환된다. 이때 운영체제는 이 인터럽트를 치명적인 오류(fatal error)로 간주하거나 프로그램 실행 시간을 연장해 줄 수도 있다.여기서 타이머의 내용을 수정하는 명령어는 특권 명령이며, 일반 사용자 프로그램이 직접 변경할 수 없다.Linux Timer리눅스에는 커널 설정 파라미터인 HZ 가 타이머 인터럽트의 빈도를 지정한다.  HZ = 250-&gt; 타이머는 초당 250번의 인터럽트를 발생시킴-&gt; 4밀리초마다 한번의 인터럽트가 발생따라서 리눅스에서 또 파생되어 나오는 우분투, 레드햇 등등이 이런 HZ 값이 달라질 수도 있다.이와 관련된 커널 변수로는 jiffies 가 있고, 시스템이 부팅된 이후 발생한 타이머 인터럽트의 총 횟수를 나타낸다.✒️ 용어Virtual Memory실제 메모리(RAM)의 용량을 넘는 프로그램 실행을 가능하게 해주는 메모리 관리 기법이다. 운영체제가 Secondary Storage의 일부 공간을 마치 주기억장치처럼 사용하도록 하여, 프로세스는 연속적이고 큰 메모리 공간이 있는 것처럼 동작할 수 있게 한다.주요 특징  프로그램은 전체를 한 번에 메모리에 올리지 않고, 필요한 부분만 메모리에 적재  나머지는 디스크에 저장되어 있다가 필요할 때 메모리로 불러온다 (Page 교체)  메모리 주소는 가상 주소(Virtual Address)로 관리되며, 하드웨어의 MMU(Memory Management Unit)가 이를 실제 물리 주소로 변환한다장점  실행 중인 프로그램 수 증가 가능  메모리 사용의 효율 증가  프로그램 간 메모리 보호(격리) 가능단점  디스크 접근은 느리기 때문에 과도한 페이지 교체가 발생하면 속도 저하 발생 (→ 스래싱 현상)  요약: 실제 메모리보다 더 많은 메모리를 쓰는 것처럼 “속임수”를 써서 실행시키는 운영체제의 중요한 기능Daemon백그라운드에서 지속적으로 실행되며, 특정 작업이나 요청을 대기 및 처리하는 프로그램 또는 프로세스.사용자와 직접 상호작용하지 않으며, 시스템의 서비스나 자원을 자동으로 관리함.주요 특징  시스템 부팅 시 자동 시작되며 종료될 때까지 계속 실행됨  사용자 입력 없이 작동하며, 요청이 올 때까지 대기 상태(idle) 유지  프로세스 이름 끝에 보통 d가 붙음 (예: httpd, sshd, crond)  sshd: SSH 접속 요청을 대기 및 처리httpd: 웹 서버 요청을 처리crond: 예약 작업을 일정에 따라 자동 실행…TrapTrap은 운영체제가 개입해야 할 상황에서 CPU가 발생시키는 소프트웨어 인터럽트이다. 사용자 프로그램에서 의도적으로 커널 기능(운영체제 기능)을 호출하거나, 예외 상황(예: 0으로 나누기, 메모리 접근 오류)이 발생했을 때 운영체제가 개입할 수 있도록 한다.System Call사용자 프로그램이 운영체제의 기능(서비스)을 요청할 때 사용하는 인터페이스.일반 프로그램은 직접 하드웨어를 제어할 수 없기 때문에, 운영체제를 통해 간접적으로 하드웨어나 자원에 접근해야 한다. 이때 사용하는 것이 시스템 콜이다.  예: 파일 열기, 읽기, 쓰기 (open(), read(), write())프로세스 생성 (fork())메모리 할당 (mmap())네트워크 통신 (socket())과정  사용자 프로그램이 시스템 콜 호출  Trap 명령어를 통해 커널 모드(Kernel Mode)로 전환  커널의 System Call Handler가 요청 처리  처리 결과를 사용자 프로그램에 반환하고 사용자 모드(User Mode)로 복귀특징  운영체제와 사용자 프로그램 사이의 경계(보안과 안정성) 유지  커널 모드로 진입하는 유일한 공식 통로Memory Dump프로세스가 비정상 종료가 되었을 시에 저장되는 메모리 상태이며, 디버깅에 활용된다.SystemdLinux 초기화 시스템이자 주요 Daemon 관리 도구이다.⭐️MMU(Memory Management Unit)Virtual Address -&gt; Physical Address 변환을 담당하는 하드웨어Physical memory실제 컴퓨터에 장착된 메모리(RAM)를 의미한다. CPU가 직접 접근 가능한 주소 공간으로, 운영체제가 메모리 관리를 위해 사용한다.특징  하드웨어적으로 존재하는 메모리 칩의 용량과 구조  주소는 0번부터 메모리 크기만큼 연속적인 물리 주소(Physical Address)로 구성  운영체제는 이 공간을 효율적으로 나누어 사용자 프로그램에 할당  예: 16GB RAM이 있다면, 그게 곧 물리적 메모리Logical Memory사용자 프로세스 입장에서 보이는 메모리 공간을 말한다. 즉, 프로세스가 인식하는 주소 공간이며, 실제 물리 메모리와는 다를 수 있다.  보통 0번 주소부터 시작하는 가상의 연속 메모리 공간  운영체제는 논리 주소(Logical Address)를 물리 주소로 변환(정확히는 MMU가 변환, 운영체제는 명령을 시킴)  이 추상화를 통해 각 프로세스가 독립된 주소 공간을 갖고 있는 것처럼 보이게 함  예: 두 개의 서로 다른 프로그램이 둘 다 0x00000000 주소를 사용할 수 있음실제론 서로 다른 물리 주소로 매핑됨 (운영체제가 관리)🔗 출처  도서: Operating System Concepts 10th Edition"
    },
  
    {
      "title": "1. TDD Definition",
      "url": "/seonghun120614/softwareengineering/softwaredevelopment/2025/06/14/1.-tdd-definition.html",
      "date": "2025-06-14",
      "content": "실무에 근거하여 Test-Driven Development 의 탄생과 개념을 본다.📂 목차  고전 소프트웨어 개발 방식  고전 소프트웨어 개발 방식의 문제점  TDD의 정의  TDD의 목표  개발에서 TDD의 위치  TDD의 진행 방식  JUnit5 실습          테스트 환경 구성      질문 Red      응답 Green      정제 Refactoring      반복 Repeat      📚 본문고전 소프트웨어 개발 방식  문제 영역 설정  요구사항 발생  기능 구현  검증 및 테스팅고전 소프트웨어 개발 방식의 문제점작성된 코드의 문제 유무 판단을 개발자 자신의 두뇌에 상당히 의존하게 된다.하지만 이런 개발자 한 명의 환경에 맞추다 보면 여러 다른 상황들이 무시되며,이는 작성자의 판단에 근거한 개발이며 여러 환경에 대해서 테스트 한 경우는 아니다.가벼운 개발의 경우는 위의 방식으로 전부 퉁칠 수 있다. 하지만 대게로코드의 크기가 커지기 때문에 커질수록 버그 수정에 필요한 부분을 찾아내기 어려워진다.코드의 크기가 커질수록 다음 상황을 야기한다:  틀정 모듈의 개발 기간이 길어질수록 개발자의 목표의식이 흐려진다.  작업 분량이 늘어날수록 확인이 어려워진다.  개발자의 집중력이 필요해진다.  논리적인 오류를 찾기 어렵다.  코드의 사용법과 변경 이력을 개발자의 기억력에 의존하게 되는 경우가 많다.  테스트 케이스가 적혀 있는 엑셀 파일을 보며 매번 테스트를 실행하는 게 점차 귀찮아져 점차 간소화하는 항목들이 늘어난다.  코드 수정 시에 기존 코드의 정상 동작에 대한 보장이 어렵다.  테스트를 해보려면 소스코드에 변경을 가하거나 번거로운 선행 작업이 필요하다.  소스코드를 변경할때 해야하는 회귀 테스트는 곧잘 희귀 테스트가 되기 쉽다.  테스트는 개발자의 귀중한 노동력을 많이 소모한다.이를 해결하기 위해 XP 프로그래밍 기법에서 TDD 라는 개념이 나온다.TDD의 정의TDD 정의  프로그램을 작성하기 전에 테스트 먼저 작성하라.Test the program before you write it. - Kent BeckTDD 는 메소드나 함수 같은 프로그램 모듈을 작성할 때 ‘작성 종료조건을 미리 정해놓고 코딩을 시작하라’는 의미다. 작성 종료조건을 만족했을때 비로소 코딩이 끝나게 된다.            메서드 이름      sum                  argument      int a, int b              return      int              종료 조건      a와 b를 더한 값을 결과로 돌려줌      간단한 테스트 문서이다. 하지만 TDD와 설계문서의 차이점은 “문서로 만들어 머리로 생각하고 눈으로 확인할 것인지”, “예상 결과를 코드로 표현해놓고 해당 코드가 자동으로 판단하게 할 것인지”가 차이다.TDD의 목표  잘 동작하는 깔끔한 코드Clean code that works - Ron Jeffries제대로 동작(works)하며, 명백함(clean, 작성한 코드가 명확한 의미를 전달하냐)이 함유되어 있어야 한다.개발에서 TDD의 위치TDD에서 말하는 단위 테스트는 일반적인 메소드 단위의 테스트를 뜻하며,전통적인 테스트 방법론에서 이야기하는 단위 테스트는 사용자 측면에서 제품의 기능을 테스트하는 쪽에 가깝다.따라서 여기서 나오는 단위 테스트는 전부 메소드 단위의 테스트 임을 기억하자.TDD의 진행 방식ARRR  Ask(Red): 테스트 결과가 실패하거나 코드가 멈추는 코드를 작성한다  Respond(Green): 테스트를 통과하는 코드를 작성해서 질문에 대답한다(테스트 결과는 성공)  Refine(Refactor): 아이디어를 통합하고, 불필요한 것은 제거하고, 모모한 것은 명확히 해서 대답을 정제한다(Refactoring)  Repeat: 다음 질문을 통해 대화를 계속한다.질문-응답-정제가 계속 반복되어야 한다.JUnit5 실습테스트 환경 구성Spring 에서 사용할 테스트 라이브러리인 JUnit을 불러오고 간단한 은행 계좌를 만드는 것을 테스트 해보자.dependencies {\ttestImplementation('org.springframework.boot:spring-boot-starter-test') {\t\texclude group: 'junit', module: 'junit' // JUnit 4 제외\t\texclude group: 'org.mockito', module: 'mockito-core' // 필요 시\t\texclude group: 'org.junit.vintage', module: 'junit-vintage-engine' // JUnit 3/4 호환 제거\t}\ttestImplementation 'org.junit.jupiter:junit-jupiter-api'\ttestRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine'}질문다음 비어있는 계좌 인터페이스(설계도) 를 생성하자.  src/main/entity/account/AbstractAccount.class  src/main/entity/account/Account.classpublic interface IAccount {}public class Account implements IAccount {}구현된 Account 클래스에서 &lt;command + shift + t&gt; 를 통해 test class 를 자동 생성시킨다. 이때 Junit5 로 설정후 생성한다.import org.junit.jupiter.api.*;import static org.junit.jupiter.api.Assertions.*;class AccountTest {}이제 생성하는 Unit Test를 작성한다. 여기서 @Test 애너테이션을 붙여야 테스트 수행중에 해당 메서드를 테스트로 인식하여 수행한다.import org.junit.jupiter.api.*;import static org.junit.jupiter.api.Assertions.*;class AccountTest {    @Test    void createAccount() {        IAccount account = new Account(1234);    }}이처럼 계좌를 생성시킬 수 있다. 지금은 실패한다.응답성공하는 테스트케이스를 작성한다.class Account implements IAccount {    public Account(int number) {    }}import org.junit.jupiter.api.*;import static org.junit.jupiter.api.Assertions.*;class AccountTest {    @Test    void createAccount() {        IAccount account = new Account(1234);        assertInstanceOf(Account.class, account);        assertNotNull(account);    }}정제  리팩토링을 적용할 부분이 있는지 살핀다.  To-do 목록에서 완료된 부분을 지운다.사람이 좀 더 이해하기 쉽고, 변경용이한 구조로 바꾸는 것이다.가독성이 적절한지, 중복된 코드가 없는지, 이름이 명확하지 않거나, 오버 구현을 하지 않았는지, 구조의 개선이 필요한 부분이 있는지 본다.살펴보면 계좌번호는 인자로 따로 빼낼 수 있는 부분이고, 여기서 테스트 케이스가 갈라지게 된다. 따라서 다음과 같이 고쳐주며, 테스트 케이스를 여러개 넣을 수 있도록 @ParameterizedTest와 @ValueSource를 넣어준다.import org.junit.jupiter.params.ParameterizedTest;import org.junit.jupiter.params.provider.ValueSource;import static org.junit.jupiter.api.Assertions.*;class AccountTest {    @ParameterizedTest    @ValueSource(ints = {1, 1234, 9999})    void createAccount(            int number    ) {        IAccount account = new Account(number);        assertInstanceOf(Account.class, account);        assertNotNull(account);    }}반복다음 단위 테스트 작성으로 넘어간다.이후에는 계좌번호 검증, 계좌번호 조회, 계좌 유일성 검증 등의 추가적인 기능에 대한 테스팅 할 수 있을 것이다.다음은 필자가 최종적으로 작성한 테스트 코드이다.import org.junit.jupiter.api.*;import org.junit.jupiter.params.ParameterizedTest;import org.junit.jupiter.params.provider.ValueSource;import static org.junit.jupiter.api.Assertions.*;class AccountTest {    @ParameterizedTest    @ValueSource(ints = {            Integer.MIN_VALUE, -1, 0,            1, 1234, 9999,            Integer.MAX_VALUE    })    void createAccount1(            int number    ) {        IAccount account = new Account(number);        assertInstanceOf(Account.class, account, \"계좌 종속정 테스트\");        assertNotNull(account, \"계좌 존재성 테스트\");    }    @ParameterizedTest    @ValueSource(ints = {            Integer.MIN_VALUE, -1, 0,            Integer.MAX_VALUE    })    void createAccount2(            int number    ) {        assertThrows(IllegalArgumentException.class,                () -&gt; new Account(number),                \"계좌 번호 유효성 검증\");    }    @Test    void createAccount3() {        IAccount account1 = new Account(1234);        assertThrows(IllegalArgumentException.class,                () -&gt; new Account(1234),                \"계좌 번호 유일성 검증\");    }}아직 위 테스트 작성은 부족한게 많다. 메서드 명이 명확하지 않고, TDD의 기본적인 것인 Red-Green-Refactor 에서 Red 만 정상적으로 작성한 코드이다. 여기서는 TDD 이기에 Test만을 잘 작성하는 쪽으로 구현했다. 이를 토대로 이제 개발을 해나가면 된다.⭐️ 처음 Red 를 잘 작성해놓으면 Repeat이 거의 필요없게 되는 수준에 이를 수 있다."
    },
  
    {
      "title": "5. Spring Boot Application Logging Customizing with Log4j2",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/13/5.-spring-boot-application-logging-customizing.html",
      "date": "2025-06-13",
      "content": "🪛 한계점스프링 어플리케이션이 띄우는 서버 정보에 대해 가독성이 부족하며, 추적 가능한 로그 기능이 필요하다.📂 목차  Log4j2          log4j2.properties 설정                  로깅 레벨 계층 와 이름 설정          Filter 기능을 사용한 로그 이벤트 상세 제어          Appenders 구성하기          루트 로거 설정 (기본 레벨 및 Appender 연결)                    Logger 객체를 가져와 출력해보기      📚 본문Log4j2우선 Log4j2 는 Asynchronous Logger + LMAX Disruptor 기반으로 1800만 건/s 로깅이 가능하며,  XML/JSON/YAML 설정 등을 지원  Lambda 기반 지연 로깅  MDC, Marker, 사용자 정의 Message API등의 고급 기능들을 지원한다. 사용하려면 다음 의존성을 추가해준다.dependencies {    ...    // log4j2    implementation 'org.springframework.boot:spring-boot-starter-log4j2'    ...}기존에 있는 starter 팩에 Logback과의 충돌을 막기 위해 다음을 추가한다.configurations.all {\texclude group: 'org.springframework.boot', module: 'spring-boot-starter-logging'}log4j2.propertieslog4j2 는 기본적으로 resources에 log4j2.properties 를 참조하여 로깅 구성 설정을 할 수 있다. 기본적으로 Logging을 할 때의 기능들을 수행하는 컴포넌트 Appender, Logger 가 있다.아래의 용어들을 보고 오길 바란다.로깅 레벨 계층 와 이름 설정로그를 띄울 때도 특정 정보들만 띄울 수 있도록 할 수 있다.로그 레벨 계층은 다음과 같다ALL → TRACE → DEBUG → INFO → WARN → ERROR → FATAL → OFF  ALL: 모든 로그 레벨 허용  TRACE: 가장 세밀한 단계(디테일 메서드 호출, 루프 등)  DEBUG: 개발 및 디버깅 시 유용한 정보-변수 상태, 흐름 등  INFO: 운영 중 기본적으로 남기는 일반 정보-시작/종료, 상태 전환 등  WARN: 문제는 아니지만 주의가 필요한 상황-성능 저하, 비추천 API 사용 등  ERROR: 기능 일부 실패 등 처리 중에 장애 발생  FATAL: 치명적인 오류로 어플리케이션 종료 수준  OFF: 모든 로그를 비활성화status 의 프로퍼티를 주면 해당 status 보다 하위의 로그 메시지들을 출력하게 된다.## log4j2.properties# ▼ 내부 로깅 레벨status = warnname = PropertiesConfigname으로는 로깅 설정 전체의 이름을 지정하는 식별자이다.Filter 기능을 사용한 로그 이벤트 상세 제어Log4j2는 필터를 사용하여 어떻게 처리해야 할지 제어할 수 있다.우선 이벤트를 평가하는 것부터 보자면 기본적인 필터 로직은 로그 이벤트를 평가하고, ACCEPT, DENY, NEUTRAL 중 하나의 결과를 반환하게 된다.  ACCEPT: 해당 로그를 즉시 수용하고 다음 필터는 검사하지 않음(바로 출력)  DENY: 해당 로그를 즉시 버리고 이후 단계로 전달하지 않음(버림)  NEUTRAL: 판단을 보류하고 다음 필터로 넘김(다음 필터한테 인계)위 3가지를 결정내리는 단계는 크게 4단계로 나뉘고, 각 필터 단계에서 위의 결과 중 하나를 가지게 된다.  Context-wide: 전체 설정에 대한 초기 필터  Logger-level: 특정 로거에 설정된 필터  AppenderReference: 어떤 Appender에 보낼지 결정  Appender-level: 실제 Appender 내부 필터아래 코드는 threshold 라는 필터를 통해 전역 필터를 설정하고 있다.# ▼ 전역 필터 설정: 디버그 이상 로그만 출력filters = threshold     # 전역필터 이름은 threshold# filters 뒤에 나열된 필터 이름은 이후 설정에서# filter.&lt;name&gt;.type, filter.&lt;name&gt;.level 같이 참조 가능# 전역 필터 threshold 의 타입으로 ThresholdFilter 라는 레벨 기반 필터를 사용한다.filter.threshold.type = ThresholdFilter# 메시지의 레벨이 설정한 기준 이상인지 비교하여 처리한다.# 해당 ThresholdFilter 가 적용할 기준 레벨을 정의한다.filter.threshold.level = debug# 기본적으로 onMatch=NEUTRAL, onMismatch=DENY 이므로# DEBUG 이상이면 NEUTRAL로 넘어가 다음 레벨 검사 후 출력 가능# TRACE 이하는 DENY로 바로 차단됨대표적인 필터 종류로는  ThresholdFilter: 특정 기준 이상인지 아닌지 필터링  BurstFilter  CompositeFilter  DynamicThresholdFilter  RegexFilter: 정규표현식을 사용한 필터링  MapFilter, MarkerFilter, TimeFilter 등등등이 있다.Appenders 구성하기# ▼ 콘솔 Appender 구성# 사용할 Appender 나열appenders = console, rolling# Appender 의 타입 지정, 여기서는 Console로, System.out, System.err 같은 출력 형식으로 내보냄appender.console.type = Console# Appender 에 식별자를 붙임appender.console.name = STDOUT# Appender 에 로그 메시지를 어떤 형식으로 변환할지 정함appender.console.layout.type = PatternLayout# Appender 의 로그 출력 포맷을 지정함appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5p %c{1}:%L - %m%n로그 출력 포맷  %d{…}: 날짜/시간의 포맷 지정  %t: 스레드 이름(main 등)  %-5p: 고정 폭 5자리의 로그 레벨(INFO, DEBUG 등)  %c{1}: 로거 이름의 마지막 컴포넌트, 일반적으로 클래스 명  %L: 로그 발생 코드 라인 번호  %m: 실제 메시지  %n: 줄바꿈# ▼ 롤링 파일 Appender 구성# 로그 파일 내용을 어디 저장할지 지정appender.rolling.fileName = logs/app.log# 파일명을 어떻게 쓸건지 설정appender.rolling.filePattern = logs/app-%d{yyyy-MM-dd}-%i.log.gz# Policies 라는 롤오버 조건 그룹(wrapper)를 지정appender.rolling.policies.type = Policies# 시간 기반 트리거 정책 사용, 특정 주기마다 로그 파일이 자동으로 Rolloverappender.rolling.policies.time.type = TimeBasedTriggeringPolicy# Rollover 간격을 1단위로 지정appender.rolling.policies.time.interval = 1# 파일 크기 기반 트리거 정책 지정appender.rolling.policies.size.type = SizeBasedTriggeringPolicy# 파일이 10MB를 초과 시 Rollover 실행appender.rolling.policies.size.size = 10 MB# Rollover 전 후의 처리 전략을 지정appender.rolling.strategy.type = DefaultRolloverStrategy# Rollover 파일의 최대 개수를 7개로 설정appender.rolling.strategy.max = 7루트 로거 설정 (기본 레벨 및 Appender 연결)# ▼ 루트 로그 레벨 및 Appender 참조# 로그 레벨 설정rootLogger.level = info# 기본 로그 레벨과 appender 매핑 설정rootLogger.appenderRefs = stdout, rollingrootLogger.appenderRef.stdout.ref = STDOUTrootLogger.appenderRef.rolling.ref = ROLLINGLogger 객체를 가져와 출력해보기Logging 메시지를 출력할 클래스 컨텍스트에 다음을 입력한다:import org.slf4j.*;...    private static final Logger logger =            LoggerFactory.getLogger(StudyApplication.class);출력할 메시지가 살아있는 function 의 context 에서 다음을 입력한다.ConfigurableApplicationContext applicationContext =        springApplication.run(args);logger.info(\"The application is completely running\");다음이 출력됨을 볼 수 있다.[restartedMain] INFO  StudyApplication:73 - The application is completely running✒️ 용어Logger한 개 이상의 Appender 를 사용하여 로그 메시지 표시를 담당하는 로깅 프레임워크의 컴포넌트Appender어펜더를 사용하여 로그가 출력되는 대상과 로깅 포맷을 지정할 수 있다. 로그 메시지가 출력되는 매체에 따라 다양한 어펜더가 있고, 콘솔 어펜더는 어플리케이션의 콘솔에 로그를 출력하고, 파일 어펜더는 로그 메시지를 파일에 출력한다.  RollingFileAppender: 시간과 날짜 기반으로 별도의 파일에 로그를 출력하게 된다.  SMTP Appender: 정해진 이메일 주소로 로그를 출력한다."
    },
  
    {
      "title": "1.3 Computer System Architecture",
      "url": "/seonghun120614/computerscience/os/2025/06/13/1.3-computer-system-architecture.html",
      "date": "2025-06-13",
      "content": "컴퓨터 시스템은 프로세서의 수와 배치 구조에 따라 다양한 아키텍처로 구분된다. 본 글에서는 단일 프로세서 시스템부터 멀티프로세서, 클러스터 시스템까지 주요 구조를 체계적으로 살펴본다.📂 목차  1.3.1 Single-Processor Systems          Single Core      Special-purpose Processor        1.3.2 Multiprocessor Systems          Symmetric MultiProcessing, SMP      Multi-Core System      확장성의 한계와 NUMA      Blade Server        1.3.3 Cluster System          High Availability Service      Cluster Structures      Parallel Cluster &amp; HPC      WAN Clustering &amp; Shared Disk      📚 본문일반적인 컴퓨터 시스템은 사용되는 범용 프로세서의 수에 따라 대략적으로 분류 가능하다.1.3.1 Single-Processor Systems컴퓨터 시스템은 사용되는 프로세서 수와 구조에 따라 다음과 같이 구분된다.Single Core  하나의 CPU + 하나의 Core를 가지는 시스템이다.  CPU는 General-purpose Instruction Set 및 사용자 프로세스를 실행 가능하다.Special-purpose Processor  디스크, 키보드, 그래픽 컨트롤러등에 전용 마이크로프로세서가 탑재된 걸 특수 목적 프로세서라고 한다.  Special-purpose Instruction Set만을 실행하고, 일반적인 프로세스를 실행하지 않는다.  운영체제가 이들을 직접 제어하거나 상태를 모니터링 한다.  예시디스크 컨트롤러 마이크로프로세서: 메인 CPU로 부터 요청을 받아서 자체 Disk Queue 및 Scheduling Algorithm을 실행키보드 내부 마이크로 프로세서: 키 입력을 감지하고 코드로 변환하여 CPU로 전송하는 마이크로 프로세서가 내장다른 시스템이나 상황에서는 이러한 특수 목적 프로세서가 하드웨어에 저수준 컴포넌트로 내장되어 있다. 운영체제는 이들과 직접 통신은 못하고 프로세서가 독립적으로 작업을 수행하게 된다.특수 목적 마이크로 프로세서가 여러개 있다고 시스템이 멀티 프로세서 시스템이 되는 것은 아니다.1.3.2 Multiprocessor Systems단일 처리는 느릴 수 있고 CPU가 연산 처리하는데 있어 다수의 Device의 요청을 받게 되면 지연될 수 있다.이러한 시스템은 컴퓨터 하나에 두 개 이상의 Processor를 가지는 형태로 구성하여 Throughput(처리량)과 속도를 늘릴 수 있다. 프로세서들은 Computer Bus를 공유하며 Clock Signal, 메모리, 주변 장치를 공유한다. 하지만 N개의 프로세서를 사용한다고 해서 성능이 N배 빨라지는 것은 아니다.이는 각 구성 요소들이 제대로 작동하도록 유지하는 데 드는 오버헤드가 발생하기 때문이며, 공유 자원에 대한 Contention(경합) 도 추가로 발생하기 때문에 기대에 못미치는 성능 향상을 얻을 수 있다.멀티프로세서 시스템에서도 두 가지로 크게 나눌 수 있다.Symmetric MultiProcessing, SMP각 CPU 프로세서가 동등한 입장에서 운영체제의 기능과 사용자 프로세스를 모두 처리할 수 있는 시스템을 Symmetric MultiProcessing System 이라고 한다.각 CPU는 자신만의 Register Set과 Local Cache를 가지고 있지만, 모든 프로세서는 System Bus를 통해 물리적 메모리를 공유한다.장점으로는:  N개의 CPU가 있다면 N개의 프로세스가 동시에 실행이 가능하다.  전체 시스템의 성능이 크게 저하되지 않는다.단점으로는 어떤 CPU 는 Idle 인 반면, 다른 CPU 는 Overrloaded 상태가 되는 비효율이 발생할 수 있다.이런 비효율성은 프로세서 간에 특정 데이터 구조나 자원을 공유함으로써 이를 완화할 수 있다. 시스템은 프로세스나 자원을 동적으로 여러 프로세서 사이에서 공유할 수 있어서 프로세서 간 작업량의 편차를 줄이는데 도움이 많이 된다.하지만 공유에 있어서 자원의 제어권을 명백히 구분해야하기 때문에 매우 신중하게 설계되어야 한다.Multi-Core System멀티프로세서 시스템에서 하나의 칩에 여러 연산 코어가 존재하는 멀티 코어 시스템도 포함된다.  칩 내부의 코어 간 통신(on-chip communication) 이 칩 간 통신(between-chip communication)보다 훨씬 빠르기 때문에 단일 코어를 여러 칩에 나눠 배치하는 구조보다 더 효율적  전력을 훨씬 더 적게 소비  각 코어는 Register Set + L1 Cache 보유, 각 프로세스는 L2 Cache를 통해 칩끼리 메모리 공유운영체제 입장에서는 N개의 일반적인 CPU 처럼 보이게 된다.따라서 운영체제 설계자와 어플리케이션 프로그래머에게 이러한 처리 코어들을 효율적으로 활용해야 할 부담을 가지게 되는데 이는 추후에 다룬다.연산 처리 계층적 구조 정리  Processor (물리적 칩)          Core (실제 연산 단위)                  Register Set (가장 빠르고 가장 작은 기억장소)          L1 Cache (코어별 고속 캐시)          L2 Cache (대부분 코어 간 공유되는 캐시)                    확장성의 한계와 NUMA멀티 프로세서 시스템에 CPU를 추가하면 계산 성능은 증가하지만, 무한히 확장되지는 않는다. 또한 CPU를 너무 많이 추가하면 시스템 버스에 대한 경쟁이 병목되어서 성능이 오히려 저하가 된다.이를 해결하기 위해  각 CPU에 전용 로컬 메모리를 제공  CPU 간에는 System Interconnect 로 연결 -&gt; 모든 CPU가 하나의 물리적 주소 공간 보유Blade Server여러 개의 Processor Board, I/O Board, Network Board 등이 하나의 Chassis 안에 포함된 시스템이다.각 블레이드 Processor Board가 독립적으로 부팅되고, 자체 운영체제를 실행하는 구조이며, 여러 개의 독립적인 멀티프로세서 시스템으로 구성된다.멀티프로세서 시스템이 한 시스템 내의 CPU 확장을 다룬다면, 클러스터 시스템은 여러 독립적인 시스템(= Node)을 확장하여 하나의 논리적 시스템처럼 작동하게 한다.1.3.3 Cluster Systems여러 독립적인 노드(멀티코어 컴퓨터 시스템)를 네트워크로 느슨하게 연결하여 구성한 시스템이며, 공유 저장소를 사용하여 각 노드끼리 LAN / InfiniBand 등으로 상호 통신을 한다.High Availability ServiceCluster System 은 기본적으로 High Availability 를 제공한다. High Availability 는 일부 노드가 장애가 발생하여도 서비스는 계속 지속될 때 얻을 수 있다.고가용성은 다음 두 개념을 만족하는 개념이다:  Graceful Degradation: 일부 하드웨어가 고장나도 남은 자원으로 서비스 유지  Fault Tolerance: 단일 구성 요소(노드)가 고장나도 시스템이 끊김 없이 계속 동작이렇게 봤을 때 Clustering System 은 다음 두 가지로 분류될 수 있다.Cluster Structures  Asymmetric: 한 노드는 Hot-stanby Mode, 나머지 노드가 작업을 수행  Symmetric: 여러 호스트가 동시에 다수의 실행 가능한 어플리케이션을 실행하며 상호 모니터링 수행Parallel Cluster &amp; HPC클러스터를 병렬 처리 환경으로 사용하여 연산 성능을 극대화 가능  여러 노드가 동일한 저장소에 접근 가능  프로그램을 여러 작업 단위로 나눠 여러 노드에서 병렬 실행  모든 노드의 계산 결과를 통합하여 최종 결과물 생성WAN Clustering &amp; Shared Disk  WAN 환경에서도 클러스터 가능  Parallel Cluster는 여러 노드가 동일한 저장소(공유 디스크)에 동시에 접근하지만 일반 OS는 동시 접근 미지원  이때 동시에 데이터를 접근해야하는 경우는 락 관리 및 접근 제어가 필요하게 된다 -&gt; Distributed Lock Manager(DLM) 소프트웨어 사용✒️ 용어CPU명령어들을 수행하는 하드웨어이다.Core명령어를 실행하고 데이터를 저장하기 위한 Register 집합을 포함하는 구성요소이며 CPU의 가장 기본적 연산 단위이다.Processor하나 이상의 코어를 포함할 수 있는 연산 장치로, 일반적으로는 하나의 물리적인 CPU 칩을 말한다.Multicore다수의 Core들을 동일 CPU 에 배치한 형태이다.Multiprocessor다수의 프로세서를 포함하는 형태이다.SMP (Symmetric Multiprocessing)각 CPU가 동등한 권한으로 OS와 사용자 작업을 수행하는 구조로, 물리 메모리를 공유함L1 Cache각 코어에 직접 연결된 매우 작은 용량의 고속 캐시 메모리L2 Cache같은 칩 내부의 여러 코어가 공유하는 중간 속도의 캐시 메모리NUMA (Non-Uniform Memory Access)각 CPU에 전용 메모리를 두고, 전체적으로는 공유 주소 공간을 유지하는 구조On-Chip Communication동일한 칩 내부에서 발생하는 통신으로, 매우 빠르고 전력 효율이 높음Blade Server여러 개의 독립적인 시스템 보드(CPU, I/O, 네트워크 등)를 하나의 섀시에 탑재한 서버 형태Processor BoardCPU와 메모리 등이 탑재된 블레이드 서버의 핵심 연산 유닛. 각 블레이드 서버는 각각의 독립적인 Processor Board를 가지고 있어 자체적으로 연산과 처리가 가능하다.I/O Board입출력 장치와의 연결을 담당하는 보드. 디스크, 키보드, 마우스, USB 등 다양한 장치와의 인터페이스를 제공한다. 입출력 흐름을 제어하고 데이터 전송을 중재하는 역할을 한다.Network Board네트워크 통신을 위한 전용 보드이며, 이더넷, 파이버 채널 등 다양한 네트워크 형태를 지원한다.  서버 간 통신이나 외부와의 연결을 담당  서버의 데이터 흐름과 트래픽 처리에 중요한 역할을 함  고속 전송을 위해 전용 네트워크 컨트롤러가 탑재General-purpose Instruction Set운영체제와 사용자 애플리케이션에서 사용하는 일반적인 계산, 논리, 제어, 데이터 이동 등의 명령들을 포함한 CPU의 명령어 집합이다.  ADD, MOV, JMP, LOAD, STORE, AND, OR 등이 있음  범용 CPU는 이 명령어들을 기반으로 모든 종류의 소프트웨어를 실행할 수 있음  이는 특정 작업만 수행하는 전용 명령어 집합(special-purpose instruction set) 과 대비됨Special-purpose Instruction Set특정 하드웨어 장치를 제어하기 위한 제한된 기능의 명령어 집합으로, 범용 명령어와 달리 일반적인 계산이나 논리 연산은 수행하지 않는다.  주로 디스크 컨트롤러, 키보드, 그래픽 카드 등에 내장된 마이크로프로세서에서 사용됨  일반 사용자 프로그램은 직접 사용할 수 없으며, 운영체제가 장치 드라이버를 통해 간접적으로 제어함  예: START_IO, RESET_DEVICE, SCAN_KEY 등의 간단한 명령 포함Disk Queue디스크 큐(Disk Queue)는 디스크 I/O 요청들이 저장되는 대기열(queue)로, 운영체제가 처리해야 할 디스크 접근 요청들을 일정한 순서에 따라 관리하기 위해 사용된다.  디스크에 대한 읽기/쓰기 요청이 발생하면, 해당 요청은 큐에 추가된다.  디스크는 한 번에 하나의 요청만 처리할 수 있기 때문에, 요청들을 순차적으로 관리해야 한다.  운영체제는 특정 디스크 스케줄링 알고리즘을 통해 큐에 있는 요청들의 처리 순서를 결정한다.  요청의 처리 순서에 따라 디스크의 처리 시간, 평균 대기 시간, 응답 시간 등이 달라질 수 있다.  디스크 큐는 특히 하드디스크(HDD)에서 성능에 큰 영향을 미친다 (헤드 이동 시간 존재).  SSD에서는 물리적 움직임이 없지만, 여전히 I/O 요청 관리를 위해 디스크 큐 개념은 유지된다.디스크 큐는 운영체제가 디스크 접근 요청을 최적화하고, 전체 시스템의 I/O 성능을 향상시키는 핵심 메커니즘이다.Scheduling Algorithm스케줄링 알고리즘은 어떤 객체을 우선적으로 핸들링할지 결정하는 방법이다. 여기 운영체제에서의 스케줄링 알고리즘은 다음 기능을 수행한다:  다중 프로그래밍 시스템에서 동시에 실행 대기 중인 여러 프로세스 중 하나를 선택해야 한다.  선택 기준과 방식에 따라 시스템의 공정성, 응답 시간, 처리량, 자원 활용률 등이 달라진다.  CPU 스케줄링 외에도 디스크 스케줄링, 네트워크 패킷 스케줄링 등 다양한 분야에 활용된다.Throughput단위 시간 당 시스템이 처리한 작업의 양이며, 작업의 기준은 프로세스 수, 페이지 수, 전송된 비트 수 등등 다양하다.Contention여러 프로세스나 장치가 동시에 하나의 자원을 사용하려고 할 때 발생하는 충돌 현상을 경합이라고 한다.  두 개의 프로세스가 동시에 프린터를 사용하려 하면 한쪽은 기다려야 한다.이러한 경합이 많아지면 전체 시스템 성능이 저하될 수 있다.사용자 프로세스일반 사용자가 실행하는 응용 프로그램이나 작업을 의미하며, 운영체제가 생성하고 관리하는 프로세스 중 하나이다.  예: 웹 브라우저, 텍스트 편집기, 게임 등전용 로컬 메모리NUMA 구조에서 각 CPU가 독립적으로 접근 가능한 메모리 공간을 의미하며, 해당 CPU가 직접 연결되어 빠르게 접근할 수 있는 메모리이다.  다른 CPU가 접근할 경우 지연(latency)이 발생할 수 있음Clock Signal컴퓨터의 모든 부품이 동기화된 속도로 작동하도록 주기적으로 발생하는 신호로, CPU를 비롯한 각 하드웨어 장치가 일정한 타이밍에 동작하게 만든다.  예: 3.0GHz의 Clock Signal는 1초에 30억 번 신호가 발생함을 의미함System Interconnect여러 CPU의 전용 로컬 메모리를 서로 연결하는 고속 데이터 통신 경로이다.연결은 고속 버스, 크로스바, HyperTransport, Intel QPI 등 다양하다.이때 Interconnect 를 통한 원격 메모리 접근은 지연(latency)이 크므로 운영체제가 CPU 스케줄링 시 최대한 로컬 메모리를 사용하도록 조정해야 한다.Chassis서버나 컴퓨터 시스템에서 여러 개의 보드(Processor, I/O, Network 등) 를 물리적으로 탑재하고 고정하는 외형적 하드웨어 프레임 또는 케이스를 의미한다.LANLAN(Local Area Network)은 좁은 지역 내(예: 집, 학교, 회사 등)에서 컴퓨터나 장치들을 연결하는 네트워크이며 짧은 거리에서 빠른 속도로 데이터 전송이 가능하다.보통 이더넷(Ethernet)방식으로 구성되고, 하나의 공유된 자원(프린터, 파일 서버 등)을 여러 장치가 사용할 수 있도록 해준다. 라우터, 스위치, 허브 등의 네트워크 장비가 사용된다.봐도 모르면 네트워크를 공부하고 오자Register SetCPU 코어(칩) 내부에 내장된 고속의 작은 저장장치 집합으로, 연산에 직접 사용되는 데이터를 일시적으로 저장한다. 명령어 실행 중에 자주 접근해야 하는 데이터(피연산자, 주소, 결과 등)를 빠르게 처리할 수 있도록 하고 RAM보다 훨씬 빠르지만 용량은 매우 작다.CPU마다 여러 종류의 레지스터를 가짐(이는 위에서 이미 다뤘다):  General-purposed Registers: 연산 대상 데이터를 임시로 저장  Special-purposed Registers: 프로그램 카운터(PC), 명령어 레지스터(IR), 스택 포인터(SP) 등  ⭐️Flag Register: 연산 결과 상태(오버플로우, 0인지 등)를 저장Register Set은 CPU 칩에 직접 포함되어 있어 처리 속도를 극대화하는 데 핵심적인 역할을 한다.InfiniBand고속 데이터 전송을 위한 서버 간 통신 인터페이스(고속 네트워크 아키텍처).주로 슈퍼컴퓨터나 데이터센터에서 사용되며, 낮은 지연 시간과 높은 대역폭(수십~수백 Gbps)을 제공한다. 메모리 간 직접 접근(RDMA)을 지원해 CPU 부담을 줄이고 효율을 높인다. 이더넷보다 빠르고 안정적이지만, 비용과 설정 난이도가 상대적으로 높다.High Availability시스템을 가능한 한 멈추지 않도록 설계하는 개념이며, 서버나 네트워크 장애 발생 시에도 서비스가 계속 작동하도록 중복 구성을 통해 대비한다.  예: 이중화된 서버, 자동 장애 전환(failover), 클러스터링 등.목표는 서비스 다운타임 최소화와 신뢰성 극대화주로 금융, 병원, 통신 등 서비스 중단이 치명적인 분야에서 중요하게 사용됨Hot-standby Mode예비 시스템이 항상 작동 준비 상태로 대기하는 방식이다.주 시스템(Main System, Main Node)이 장애를 일으키면, 즉시 예비 시스템(Standby System)으로 자동 전환(failover)되어 서비스가 중단되지 않도록 한다.Hot-standby는 주 시스템과 데이터를 실시간으로 동기화하거나 거의 실시간에 가깝게 유지한다.  예비 시스템이 항상 켜져 있고, 자원을 소비함  전환 속도가 매우 빠름 → 서비스 중단 시간 거의 없음  비용이 높지만 High Availability가 요구되는 환경에 적합함  예: 금융 서버, 통신 장비, 항공 관제 시스템 등.WAN (Wide Area Network)광범위한 지역(도시, 국가, 대륙 간)을 연결하는 네트워크이다. 인터넷도 WAN의 일종이며, LAN이나 MAN을 서로 연결해주는 구조이고 속도는 LAN보다 느릴 수 있지만, 넓은 거리의 통신이 가능하게 한다.통신 사업자의 인프라(광케이블, 위성 등)를 사용하며, 라우팅, 보안, 대역폭 제어가 중요함.Distributed Lock Manager (DLM)분산 시스템에서 자원 접근 충돌을 방지하기 위한 잠금 관리 시스템이다.여러 노드(서버)가 동시에 공유 자원(파일, 데이터베이스 등)에 접근할 때 상호 배타성(Mutual Exclusion)을 보장한다. DLM은 자원의 소유권(lock ownership)을 추적하고, 잠금 요청 간 충돌을 조정하여 데이터 일관성을 유지한다.🔗 출처  도서: Operating System Concepts 10th Edition"
    },
  
    {
      "title": "1.2.3 I/O Structure",
      "url": "/seonghun120614/computerscience/os/2025/06/11/1.2.3-io-structure.html",
      "date": "2025-06-11",
      "content": "📂 목차  공통버스를 통한 데이터 전송의 한계점  DMA를 통한 한계점 해결          Switch 구조를 통한 DMA 효율 상승      📚 본문운영체제의 상당 부분이 I/O 관리를 위해 있다. I/O 는 시스템의 신뢰성과 성능에 매우 민감하고, 장치들의 형태와 특성이 다양하기 때문에 이 기능에 초점을 맞춘다.공통버스를 통한 데이터 전송의 한계점이전의 인터럽트 I/O 방식을 통해 명령을 수행하는 과정을 보자.  CPU 가 Control Bus 와 Address Bus 를 통해 Device Controller 에게 명령 전달  수신 받은 Device Controller 는 I/O Device 와 직접 통신하여 해당 작업을 수행          여기서 Device Controller 는 자체 Local Buffer로 데이터를 준비하고 있는 상태임        I/O 작업이 완료되고, Device Controller 는 인터럽트 신호를 Control Bus를 통해 CPU에게 보냄  CPU 가 인터럽트를 감지하여 Context Switching 을 한 후, Interrupt Handler 를 호출          이 과정에서 인터럽트 벡터 테이블의 핸들러 주소를 조회        CPU가 Interrupt Handler Code 에서 Device Controller 로 부터 처리된 데이터를 요청  CPU가 Interrupt 처리 완료 후 실행중인 Context로 복귀모든 장치가 단일 System Bus를 공유하므로, 다중 장치가 동시에 데이터를 전송하거나 수신하려고 할 경우 버스 충돌 및 지연(latency) 이 발생한다.DMA를 통한 한계점 해결DMA(직접 메모리 접근, Direct Memory Access) 의 데이터 전송 방식은 장치 버퍼, 포인터, 카운터 등을 설정하여서 장치 컨트롤러가 CPU 개입이 없이 장치와 주기억 장치 사이에서 전체 데이터 블록(Block)을 직접 전송하는 기술이다.이때 데이터 블록 단위로 한 번의 인터럽트만 발생하여서, 작업 완료를 Device Driver 에 알리게 된다. 하지만 여기에도 단점이 있는데 시스템 버스는 단일 버스를 공유하기 때문에 사용중인 버스를 다른 장치 디바이스에서 전송은 불가하다(동시 전송 불가).그래서 버스를 사용하려면 권한을 순서대로 조율해야 한다(Bus Arbitration). 이는 따라서 대량의 데이터 이동(NVS I/O 등) 에는 과도한 오버헤드를 유발한다.Switch 구조를 통한 DMA 효율 상승일부 고성능 시스템에서는 시스템 버스 구조가 아닌 스위치 구조를 사용하여 여러 컴포넌트 간에 동시에 서로 통신 할 수 있게 하여 공유된 버스에서 사이클을 경쟁하지 않아도 되는 DMA의 효율이 더욱 높아지게 된다.바이트마다 인터럽트를 발생시키는 방식에 비해 훨씬 효율적이며, Device Controller 가 전송 작업을 수행하는 동안, CPU는 다른 작업을 수행할 수 있기 때문에 전체 시스템 효율이 높아진다.            방식      CPU 개입      인터럽트 발생      효율성                  Programmed I/O(옛날 방식)      높음      없음      낮음              Interrupt I/O      중간      매 I/O 이벤트      중간              DMA      낮음      전송 완료 시      높음      🔗 출처  도서: Operating System Concepts 10th Edition"
    },
  
    {
      "title": "1.2.2 Storage Structure",
      "url": "/seonghun120614/computerscience/os/2025/06/11/1.2.2-storage-structure.html",
      "date": "2025-06-11",
      "content": "컴퓨터의 데이터 저장이 어떻게 되는지 전반적인 구조를 본다.📂 목차  Overview  저장 장치 구조 von Neumann Architecture          von Neumann Architecture 의 메인메모리 한계점      보조 저장장치(Secondary Storage)        계층적 저장장치 구조  저장 시스템 설계 시 고려사항📚 본문Overview프로그램 실행의 전제 조건은 메모리(RAM)에서만 명령어를 불러올 수 있기 때문에, 모든 프로그램은 먼저 메모리에 적재되어야 실행할 수 있다. 대부분 DRAM(Dynamic Random Access Memory) 기반의 RAM에서 실행된다. RAM은 휘발성이므로 전원이 꺼지면 데이터가 사라진다.  예시: 문서를 메모장에서 작성 중일 때 저장하지 않고 컴퓨터를 꺼버리면 내용이 사라지는 것과 같다.반면, 부팅 시 사용하는 EEPROM(Electrically Erasable Programmable Read Only Memory) 및 Firmware(펌웨어)와 같은 비휘발성 저장소는 전원이 꺼져도 데이터가 유지되어, Bootstrap(부트스트랩) 프로그램 등을 저장한다. 이러한 저장소는 수정 속도가 느려 잦은 변경에는 적합하지 않으며, 정적인 프로그램이나 자주 변경되지 않는 데이터를 저장하는 데 사용된다.모든 형태의 메모리에는 바이트 배열의 형태로 제공되며, 각각의 바이트는 고유한 주소를 가지고 있고, 이 주소를 통해 상호작용한다. CPU는 load, store 명령어 등을 사용하여 특정 메모리 주소와 데이터를 주고받는다.  load: RAM -&gt; CPU 레지스터 로의 워드, 바이트 데이터를 옮김(이 의미보다는 그냥 메모리에 기록한다의 의미로 보는게 좋다)Main Memory -&gt; CPU    1. CPU가 Address Bus에 주소를 보냄    2. CPU가 Control Bus에 ‘읽기’ 신호 전송    3. 메모리가 해당 주소에서 데이터를 찾아 Data Bus를 통해 데이터 전송  store: CPU -&gt; RAM 의 데이터 저장CPU -&gt; Main Memory    1. CPU가 Address Bus 에 주소를 보냄    2. CPU가 Data Bus에 데이터를 전송    3. CPU가 Control Bus에 ‘쓰기’ 신호 전송CPU는 PC에 저장된 위치에서 메인 메모리로부터 명령어를 자동으로 로드하여 실행한다. 이 명령어 실행을 어떻게 수행하는지 더 자세히 보자.⭐️저장 장치 구조 von Neumann Architecture우선 전통적인 컴퓨터 시스템의 명령어 실행 사이클(Instruction Execution Cycle)을 살펴보자.명령어를 메모리에서 가져와(Instruction Fetch)-&gt; 명령어 레지스터(Instruction Register)에 저장-&gt; 명령어를 디코딩(Decoding)-&gt; 필요한 피 연산자도 메모리에서 가져와 레지스터에 저장-&gt; 연산 수행 후 결과를 다시 메모리에 저장위와 같이 메모리는 단순히 Address Stream(주소 스트림)만 인식하고 주소가 어떻게 생성되었는지, 명령어인지 데이터인지는 관심이 없다.von Neumann Architecture 의 메인메모리 한계점이렇게 된다면 프로그램과 데이터가 RAM에 항상 상주하는 것이 이상적이겠지만, Main Memory 만으로는 충분하지 않다:  메인 메모리는 모든 프로그램과 데이터를 담기에 용량이 부족하다.  램은 휘발성이기 때문에 전원이 꺼지면 내용이 사라진다. 전원이 꺼진 뒤 다시 켜면 모든 데이터를 다시 메모리에 로드해야 한다.따라서 보조 저장장치가 필요하다.보조 저장장치(Secondary Storage)  RAM 을 보완하여 대용량 데이터를 영구 저장한다  HDD, SSD, NVM 등이 있다  프로그램과 데이터를 보관하고 실행 시 RAM으로 로드된다운영체제 및 대부분의 프로그램은 보조 저장장치에 저장되며, 실행 시 RAM으로 로드된다.하지만 보조 저장장치는 메인 메모리에 비해 느리기 때문에 데이터 저장과 접근 관리가 중요한 주제가 된다.이 두 가지 메모리와는 달리 다른 Tertiary Storage(3차 저장소)도 있다.⭐️계층적 저장장치 구조저장 장치는 capacity(용량)과 access time(접근 속도)에 따라 계층적 구조를 가진다.전형적인 구조는 레지스터 &lt; 캐시 &lt; 메인 메모리 &lt; 보조 저장장치 &lt; 3차 저장장치이며, 작고 빠른 메모리는 CPU 가까이에, 크고 느린 저장장치는 멀리 배치된다. 작을수록 더 빠르고 반응성이 높다.  예시: 계산기에 바로 붙어 있는 메모장이 레지스터이고, 그보다 좀 떨어진 노트가 캐시, 책상 서랍이 메인 메모리, 서재가 하드디스크라고 비유할 수 있다.저장 시스템 설계 시 고려사항  고속이지만 비싼 메모리는 최소한만 사용하고  느리지만 저렴하고 영구적인 저장소는 최대한 활용한다  예시: 자주 쓰는 물건은 책상 위에 두고, 가끔 쓰는 물건은 창고에 보관하는 것과 같다. 창고는 크지만 접근 시간이 오래 걸린다.두 저장 장치 간 속도 차이가 클 경우에는 Cache(캐시)를 사용하여 속도 차이를 줄여 전반적인 성능을 향상시킨다.✒️ 용어DRAM우리가 쓰는 DDR5 RAM이 DRAM 의 일종이다.DRAM 모듈은 우리가 데이터를 접근할 때 비트 단위가 아닌 Byte 또는 Word 단위로 접근하므로 이에 따른 병렬성을 활용하기 위해 여러 개의 bank로 구성되어 있으며,각 bank는 데이터를 읽을 row를 지정하는 row decoder,메모리 값을 증폭해 0 또는 1로 만드는 sense amp,데이터가 저장되어 있는 array를 포함한다.SRAM에 비해 속도가 느리지만 트랜지스터 하나와 캐패시터 하나로 만들어져 있기에 고집적화가 가능하여 고용량을 만들 수 있다.EEPROM비휘발성 메모리의 한 유형으로, 전원을 꺼도 데이터가 유지된다. 전기적으로 데이터를 지우고 다시 쓸 수 있으며, 부트로더나 BIOS 저장에 주로 사용된다.Firmware하드웨어를 제어하기 위해 장치에 탑재된 영구 소프트웨어. 주로 비휘발성 메모리 ROM에 저장되며, BIOS(Basic Input Output System)나 임베디드 시스템에 널리 쓰인다.⭐️Bootstrap컴퓨터가 전원을 켰을 때 운영체제를 실행하기 위해 수행하는 일련의 초기화 과정이다. 이 과정을 Bootstrap(부트스트랩) 또는 줄여서 Booting(부팅)이라 부른다.일반적인 부트스트랩 과정은 다음과 같은 단계로 이루어진다:  전원 공급 및 하드웨어 초기화: 전원이 들어오면 CPU는 하드웨어 리셋 상태로 진입하며, 지정된 위치에서 BIOS 또는 UEFI 펌웨어 실행을 시작한다.  BIOS/UEFI 실행: 하드웨어 구성 요소(RAM, 키보드, 디스크 등)를 검사하고 초기화한다. 이를 POST(Power-On Self Test)라고 한다.  부트 디바이스 탐색: 설정된 순서에 따라 부팅 가능한 저장 장치(HDD, SSD, USB 등)를 찾는다.  ⭐️ 부트로더 실행: 부팅 가능한 장치의 MBR(또는 UEFI 환경의 ESP - 여기서 ESP는 레지스터가 아닌 파티션을 말함)에서 부트로더(예: GRUB, Windows Boot Manager 등)를 메모리로 로드하고 실행한다.  운영체제 로딩: 부트로더는 커널 이미지를 메모리에 적재하고, 운영체제 실행을 시작한다.이 과정을 통해 저장 장치에 있는 운영체제를 CPU가 실행 가능한 상태로 만들 수 있다.BIOS메인보드에 내장된 펌웨어로, 컴퓨터가 켜졌을 때 가장 먼저 실행되는 프로그램이며,  하드웨어 초기화(RAM, CPU, 키보드 등)  부트 장치 탐색 및 부트스트랩 로더 실행  간단한 I/O 인터페이스 제공의 역할을 수행한다.GRUBGNU GRUB(Grand Unified Bootloader)은 리눅스 및 기타 운영체제를 부팅할 수 있게 해주는 대표적인 부트로더이다. BIOS 또는 UEFI가 부트로더를 메모리에 로드하면, GRUB은 사용자에게 운영체제 선택 메뉴를 제공하거나 자동으로 설정된 운영체제를 로드한다. GRUB은 멀티 부트 환경, 커널 파라미터 설정, 복구 모드 진입 등의 기능도 제공하며, 리눅스 배포판에서 널리 사용된다.FetchCPU가 메모리에 저장된 명령어를 가져오는 과정을 말하며, 코드 조각이다.  프로그램 카운터(PC, Program Counter) 가 다음에 실행할 명령어의 메모리 주소를 가리킨다.  CPU 는 해당 주소 기반으로 메모리에서 명령어를 가져와 Instruction Register(IR) 에 저장한다.Program CounterCPU 내부에 있는 특수한 레지스터로, 다음에 실행할 명령어의 메모리 주소를 저장한다. Fetch 단계에서 이 값을 참조하여 메모리에서 명령어를 가져오고, 명령어가 실행된 후에는 자동으로 다음 명령어 주소로 증가하거나, 분기(branch) 명령에 따라 새로운 주소로 갱신된다. 명령어 실행 흐름을 제어하는 핵심 요소이다.Instruction RegisterCPU 내부에 있는 레지스터로, 현재 실행 중인 명령어를 저장한다. Fetch 단계에서 메모리로부터 가져온 명령어는 이 레지스터에 임시로 저장되며, 이후 Decode 및 Execute 단계에서 참조된다. 프로그램 카운터(PC)가 다음 명령어를 가리키는 반면, Instruction Register는 현재 실행될 명령어의 내용을 담고 있다는 차이가 있다.Address StreamCPU가 메모리에 접근할 때 발생하는 연속적인 주소의 흐름이다. 즉, 메모리 주소를 순서대로 참조, 점프하여 다음 메모리 주소를 참조의 여러과정을 통해 주소들이 시간의 흐름에 따라 나열된 형태를 주소 스트림이라고 한다.Tertiary Storage3차 저장장치는 주로 백업 및 아카이빙 목적으로 사용되는 저장 장치이다. 접근 속도는 매우 느리지만, 저장 용량이 크고 비용이 저렴하다. 예로는 자기 테이프(magnetic tape), 광디스크(optical disc) 등이 있으며, 데이터를 장기간 보관하거나 자주 접근하지 않는 정보의 저장에 적합하다. 필요할 때만 로드되기 때문에 자동화된 장치(예: 테이프 라이브러리)를 사용하는 경우도 많다.Cache자주 접근되는 데이터를 빠른 메모리에 미리 저장하여, 느린 메모리 접근을 줄이고 전체 시스템 응답 속도를 개선한다.🔗 출처  DRAM 나무위키  EEPROM 위키백과  도서: Operating System Concepts 10th Edition"
    },
  
    {
      "title": "보조. Component",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/09/subsidiary-component.html",
      "date": "2025-06-09",
      "content": "📂 목차  @Service  @Repository  @Controller  @Component 와 @Bean 과의 차이📚 본문@Component 는 클래스 위에 붙는 애너테이션이며, Spring 이 해당 클래스를 @ComponentScan 시 자동으로 빈으로 등록하도록 만든다.@Component 만이 아니라 이를 구현하는 다른 interface 또한 있다.@Service@Component의 특수한 형태로  비즈니스 로직을 수행하는 클래스에 사용  @Component 의 기능을 포함하고 서비스 클래스 임을 명시  AOP(예: 트랜잭션 처리)와 같은 부가 기능을 적용할 수 있는 힌트로 활용@Servicepublic class OrderService {    public void processOrder() { ... }}@Repository@Component의 특수한 형태로  데이터베이스에 접근하는 DAO(Data Access Object) 클래스에 사용  데이터 접근 계층에 대한 예외를 Spring DataAccessException으로 통일  JPA나 MyBatis와 같이 ORM 또는 SQL 매퍼 라이브러리와 함께 사용@Controller@Component의 특수한 형태로  웹 요청을 처리하는 프레젠테이션 계층(Controller Layer) 클래스에 사용  Spring MVC에서 요청을 받아 처리하고 뷰에 결과를 반환하는 역할  @RequestMapping 등의 애너테이션과 함께 사용(나중에 나옴)@Component 와 @Bean 과의 차이@Bean은 수동 등록이며 @Configuration 클래스 내의 메서드에 붙여서 해당 메서드의 리턴값을 Bean 으로 등록한다.@Configurationpublic class AppConfig {    @Bean    public MyService myService() {        return new MyService();    }}이는 외부 라이브러리 클래스의 수정이 불가할 때, 즉 @Component 를 직접 사용할 수 없을 때 해당 외부 클래스를 Bean으로 등록하는 경우 유용하다. 복잡한 초기화 로직이 필요한 객체를 생성하는 경우에도 사용한다.📁 관련 글  4. Spring Boot Application Initialization✒️ 용어AOP관점 지향 프로그래밍(Aspect-Oriented Programming)의 줄임말로, 로깅, 트랜잭션, 보안 등 부가 기능을 핵심 로직과 분리하여 모듈화할 수 있게 해주는 프로그래밍 패러다임JPA자바 진영의 ORM(Object-Relational Mapping) 표준 인터페이스이며 개발자가 직접 SQL을 작성하지 않고도 Java 객체와 데이터베이스 테이블을 매핑하여 다룰 수 있게 해준다.DAOData Access Object의 약자로, 데이터베이스에 접근하는 로직을 담당하는 객체이고 비즈니스 로직과 데이터 접근 로직을 분리하여 코드의 책임을 명확히 할 수 있다.MyBatisSQL 기반의 데이터 매퍼 프레임워크로, XML 또는 애너테이션을 사용하여 SQL 문을 작성하고 Java 객체와 매핑한다. 복잡한 SQL 작성이 필요한 경우 유용하다.MVCModel-View-Controller의 약자로, 사용자 인터페이스와 로직을 분리하기 위한 소프트웨어 아키텍처 패턴이다. 전공 공부에서도 나오고, 정처기에서도 나온다.ORMObject-Relational Mapping의 약자로, 객체 지향 프로그래밍 언어를 사용하여 관계형 데이터베이스의 데이터를 객체처럼 다룰 수 있게 해주는 기술"
    },
  
    {
      "title": "4. Spring Boot Application Initialization",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/09/4.-spring-boot-application-initialization.html",
      "date": "2025-06-09",
      "content": "🪛 한계점스프링 부트 어플리케이션을 시작하기 전에 특정 코드를 실행시켜야 함.  데이터베이스 초기화  무거운 클래스 사전 로딩  외부 REST API 연결 테스트  외부 API 데이터 사전 로드위를 해결하기 위해 스프링 부트에서는 CommandLineRunner 인터페이스를 제공한다.📂 목차  @CommandLineRunner 로 스프링 부트 어플리케이션 시작 시 특정 코드 실행📚 본문@CommandLineRunner 로 스프링 부트 어플리케이션 시작 시 특정 코드 실행클래스가 CommandLineRunner 인터페이스를 구현하기만 한다면 클래스를 따로 둬서 사용할 수 있다.import org.springframework.boot.*;import org.springframework.core.annotation.*;import org.springframework.stereotype.*;@Component@Order(1)public class CustomCommandLineRunner implements CommandLineRunner {    @Override    public void run(String... args) throws Exception {        System.out.println(\"\\n\\n\\n\\n\\n This is Executed ! \\n\\n\\n\\n\");    }}여기서 @Order 는 서로 같이 실행될때 누가 먼저 실행될지 우선순위를 부여하는 애너테이션이다.CommandLineRunner 구현체가 언제 실행되는지 궁금할 수 있는데, SpringApplication 이 빈 등록, 초기화 과정 등을 전부 끝마친 뒤에 수행하도록 되어 있기에 어떤 Bean 이든 주입 받아서 CommandLineRunner 컨텍스트에서 사용할 수 있다.🔗 출처  도서 Spring Boot in Practice📁 관련 글  보조. Component"
    },
  
    {
      "title": "Lombok",
      "url": "/seonghun120614/computerscience/java/2025/06/09/lombok.html",
      "date": "2025-06-09",
      "content": "🪛 한계점Java 의 구조가 유사한 Constructor, Getter, Setter, toString, equalsTo 등등의 보일러플레이트 코드가 매우 빈번히 발생한다. 이를 위해 Lombok 에서 애너테이션을 추가하는 것만으로 클래스 자체에 보일러플레이트 코드들을 획기적으로 줄일 수 있다.📂 목차  @RequiredArgsConsturctor  @Builder  @Data📚 본문Lombok 은 Java 에서 반복적으로 작성해야 하는 보일러플레이트 코드를 줄이기 위한 라이브러리이다.읽기전에 밑의 기본적인 애너테이션은 숙지하고 간다.            애너테이션      기능 설명                  @Getter, @Setter      각 필드에 대해 getter, setter 자동 생성              @ToString      객체의 toString() 메서드 자동 생성              @EqualsAndHashCode      equals()와 hashCode() 메서드 자동 생성              @NoArgsConstructor      파라미터가 없는 기본 생성자 자동 생성              @AllArgsConstructor      모든 필드를 포함하는 생성자 자동 생성      @RequiredArgsConstructor생성자가 전부 필요한 것, 전부 필요없는 것 뿐 아니라 필요한 필드만 생성자로 추가하도록 할 수도 있다.final, @NonNull 이 붙으면 무조건 Lombok 은 RequiredArgsConstructor의 생성자의 인자로 등록해준다.@RequiredArgsConstructorpublic class UserService {    private final UserRepository userRepository;    @NonNull    private String name    private int age; // 이건 포함 안됨}@NotEmpty, @NotNull 은 다른 패키지의 validation 애너테이션이다. 주의하자.@Builder빌더 패턴 메서드를 자동 생성한다.// User.classimport lombok.Builder;import lombok.ToString;@Builder@ToStringpublic class User {    private String name;    private int age;    private String email;}// Main.classpublic class Main {    public static void main(String[] args) {        User user = User.builder()                        .name(\"홍길동\")                        .age(25)                        .email(\"hong@example.com\")                        .build();        System.out.println(user);    }}@Data@Data = @Getter + @Setter + @ToString + @EqualsAndHashCode + @RequiredArgsConstructor다른 설명은 하지 않겠다.📁 관련 글  3. Spring Boot Custom Property"
    },
  
    {
      "title": "Nested Class",
      "url": "/seonghun120614/computerscience/java/2025/06/09/nested-class.html",
      "date": "2025-06-09",
      "content": "🪛 한계점Java 의 특정 클래스에는 다른 클래스가 없다면 아무 쓸모가 없는 클래스가 있을 수 있다.가령 다음 Entry 라는 클래스를 보자.// Map.classpublic class Map { ... }// Entry.classpublic class Entry&lt;K, V&gt; { ... }Map 안의 구성요소로 자리잡은 Entry 는 다른 클래스에선 전혀 쓸모가 없는 클래스가 된다.이렇게 된다면 파일 구조 자체를 Entry 를 따로 만들 필요 없고, 이는 응집도(Cohesion)가 떨어지는 구조가 된다.따라서 Java 에서는 이를 위해 Nested Class 를 지원한다📂 목차  Nested Class 의 사용으로 인한 Logical Grouping  Encapsulation 와 노출 최소화  static 을 통한 상태를 공유할지 말지 명시적 선택 가능  Nested Class 의 용도📚 본문Nested Class 의 사용으로 인한 Logical Grouping위 클래스를 아래와 같이 바꾸자:// Map.classpublic class Map {     ...    public static class Entry&lt;K, V&gt; { ... }}결과적으로 응집도가 높아지며, 읽는 사람의 눈에도 한눈에 파악할 수 있게 된다.Encapsulation 와 노출 최소화외부적으로 이를 쓰는 클래스는 굳이 절대 쓸 일 없는 보조 클래스인 Entry 가 어떻게 흘러가는지 알 필요가 없다. 따라서 다음과 같이 바꿀 수도 있다.// Map.classpublic class Map {     ...    private static class Entry&lt;K, V&gt; { ... }}이를 통해 API 인터페이스 surface 를 줄이고, 유지보수성을 가져가게 된다.static 을 통한 상태를 공유할지 말지 명시적 선택 가능static 이면 독립적인 클래스로(상위 클래스에 종속되지 않음), 바깥 인스턴스 없이도 동작한다. non-static 이면 outer class 의 인스턴스 상태에 의존한다.// Map.classpublic class Map {     ...    private class Entry&lt;K, V&gt; { ... }}Entry 는 굳이 독립적으로 존재하면 안되기에 static 을 빼준다.Nested Class 의 용도  외부 클래스의 인스턴스 없이도 의미가 있을 때  Builder, DTO 구조화, Enum 안의 상태 표현 등에 쓰이게 된다.public class Person {    public static class Builder {        private String name;        public Builder name(String name) {            this.name = name;            return this;        }        public Person build() {            return new Person(name);        }    }}📁 관련 글  3. Spring Boot Custom Property"
    },
  
    {
      "title": "3. Spring Boot Custom Property",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/09/3.-spring-boot-custom-property.html",
      "date": "2025-06-09",
      "content": "어플리케이션 정보를 properties 에서 key-value 로 지정할 수 있는 property 는 두 종류로 나눌 수 있다:  built-in property: Spring Boot 에서 자동으로 제공하는 property  custom property: 사용자가 임의로 정하는 property, 필요한 만큼 사용이 가능이전까지는 built-in property 들을 보았지만, 이제부터는 custom property 들을 본다.📂 목차  @ConfigurationProperties 를 사용하여 커스텀 프로퍼티 정의  @EnableConfigurationProperties 로 Bean 등록하기📚 본문앞서서 Environment 인스턴스에 바인딩 되는 프로퍼티들을 출력해보았는데 Environment 인스턴스를 자동주입(@Autowired)하고 프로퍼티 값들을 읽고 사용할 수 있기 때문에 어디서든 Environment 를 주입 받아서 프로퍼티를 읽어올 수 있다.여기서 Environment 는 런타임에 한해서만 존재되는 인스턴스, 빈이다. 이렇듯 properties 를 파일로 선언하여 Env 로 가져오면 편리하지만 몇 가지 단점이 있다:  프로퍼티 값의 타입 안전성(type-safety)이 보장되지 않음(URL인지 아닌지, 이메일 주소 인지 아닌지) -&gt; 런타임 에러가 발생 우려  프로퍼티 값을 일정 단위로 묶어서 읽을 수 없고, @Value 애너테이션이나 스프링의 Environment 인스턴스를 사용해서 하나하나 개별적으로만 읽을 수 있음이를 방지하기 위해 커스텀 프로퍼티를 사용해 type-safety 와 valiation, 그리고 여러 개를 한꺼번에 가져올 수 있게 해야 한다.이에 대한 방법은 여러가지 이다.@ConfigurationProperties 를 사용하여 커스텀 프로퍼티 정의@ConfigurationProperties 애너테이션을 사용하면 특정 prefix 에 대한 프로퍼티 정보를 담는 클래스를 만들 수 있고, 이를 통해 값을 보장하고 유효성을 검증한다. @Value 애너테이션을 사용하거나 Environment 빈을 자동 주입 받지 않아도 되는 방법이다.우선 custom property 로 쓸 것들을 application.properties 에 넣어주자app.sbip.ct.name=StudyApplicationapp.sbip.ct.ip=127.0.0.1app.sbip.ct.port=9090app.sbip.ct.security.enabled=trueapp.sbip.ct.security.token=abc123app.sbip.ct.security.roles=USER,ADMIN위 property 는 전부 app.sbip.ct 의 prefix를 가진다. CustomProperties.class 하나를 생성하여 다음을 입력하자. 여기서는 Getter, Setter 등등의 보일러플레이트 코드(boilerplate code)의 불편성을 위해 Lombok 을 사용했다.import lombok.*;import org.springframework.boot.context.properties.*;import java.util.*;@AllArgsConstructor@Getter@ToString@ConfigurationProperties(prefix=\"app.sbip.ct\")public class CustomProperties {    private final String name;    private final String ip;    private final String port;    private final Security security;    @AllArgsConstructor    @Getter    @ToString    public static class Security {        private final boolean enabled;        private final String token;        private final List&lt;String&gt; roles;    }}위처럼 app.sbip.ct 인 프로퍼티만 읽을 수 있고, 더 세부적으로 .으로 나뉘었다면, 그 안에 public static class를 선언하여 할 수도 있다(public static 으로 nested class 를 선언하는 이유)지금은 Lombok 을 써서 인자들을 가져오지만 원한다면 생성자에서 검증하는 코드를 넣을 수도 있다.@EnableConfigurationProperties 로 Bean 등록하기기본적으로 ConfigurationProperties 에는 Bean 으로 등록하는 메커니즘이 없다.다음 CustomService 클래스를 만들어 Bean이 자동 주입되는지 살펴보자.import com.example.study.properties.*;import lombok.*;import org.springframework.beans.factory.annotation.*;import org.springframework.stereotype.*;@Service@Getterpublicclass CustomService {    private final CustomProperties customProperties;    @Autowired    public CustomService(CustomProperties customProperties) {        this.customProperties = customProperties;    }}이제 아래와 같이 작성한다.@EnableConfigurationProperties(CustomProperties.class)public class DemoApplication {    ...    public static void main(String[] args)  {        ...        CustomService customService = applicationContext.getBean(CustomService.class);\t\tSystem.out.println(customService.getCustomProperties().toString());    }}SpringApplication 을 밑과 같이 작성하여 실행해보고 실행하면public class DemoApplication {    ...    public static void main(String[] args)  {        SpringApplication springApplication = new SpringApplication(DemoApplication.class);        ConfigurableApplicationContext applicationContext = springApplication.run(args);        CustomService customService = applicationContext.getBean(CustomService.class);\t\tSystem.out.println(customService.getCustomProperties().toString());    }}Consider defining a bean of type 'com.example.study.properties.CustomProperties' in your configuration.와 같은 메시지를 볼 수 있다.@ConfigurationProperties 자체에 아래와 같이 interface 가 구현되고 있다.@Target({ ElementType.TYPE, ElementType.METHOD })@Retention(RetentionPolicy.RUNTIME)@Documented@Indexedpublic @interface ConfigurationProperties {이는 그냥 프로퍼티를 만들고 어플리케이션에 적용을 안한 것과 같다. 선언한 CustomProperties를 적용하고 싶은 Application의 클래스에 @EnableConfigurationProperties 애너테이션을 사용하여 Bean 으로 등록할 수 있다.@EnableConfigurationProperties(CustomProperties.class)public class DemoApplication {    ...    public static void main(String[] args)  {        ...        CustomService customService = applicationContext.getBean(CustomService.class);\t\tSystem.out.println(\"\\n\\n\\ngetCustomProperties\");\t\tSystem.out.println(customService.getCustomProperties().toString());\t\tSystem.out.println(\"\\n\\n\\n\");    }}이제 Bean 이 제대로 불러와짐을 알 수 있고, 출력 또한 잘 되는 것을 볼 수 있다.🔗 출처  도서 Spring Boot in Practice📁 관련 글  Lombok  Nested Class✒️ 용어보일러플레이트 코드항상 비슷한 형태로 여기저기 반복적으로 작성해야 하는 코드이며 기능 구현과는 큰 관련이 없지만, 기능이나 구현에 있어서 자주 사용하여 필수적으로 작성해야하는 코드를 말한다. 예시로는 생성자, Getter, Setter 등이 있다.Lombok보일러플레이트 코드를 줄일 수 있도록 애너테이션을 지원해주는 패키지이다. 의존성 추가를 통해 사용가능하다.dependencies {    compileOnly 'org.projectlombok:lombok:(최신 버전)'    annotationProcessor 'org.projectlombok:lombok(최신 버전)'}따로 Lombok 을 정리한 글이다."
    },
  
    {
      "title": "1.2.1 Interrupts",
      "url": "/seonghun120614/computerscience/os/2025/06/07/1.2.1-interrupts.html",
      "date": "2025-06-07",
      "content": "컴퓨터 시스템의 구조 전반이 어떻게 생겨 먹었는지, 그리고 어떻게 돌아가는지 살펴본다.📂 목차  1.2.1.1 Interrupts          I/O 작업 완료 알림      ⭐️ Interrupt Handler      Interrupt Vector Table(Interrupt Vector) 을 사용한 방식        1.2.1.2 Implementation          Interrupt Controller      Interrupt Chaining      Interrupt Priority Level      📚 본문현대 컴퓨터 시스템은 하나 이상의 CPU와 여러 개의 장치 컨트롤러(Device Controller)로 구성되어 있고, 공통 버스(Common Bus, System Bus) 를 통해 연결되어 있다.Common Bus는 각 구성 요소들과 공유 메모리(Shared Memory) 간의 접근 경로를 제공한다(공유 메모리가 있다면 각 장치들마다 해당 메모리를 읽어서 데이터를 공유할 수 있다). 일반적으로 운영체제는 각 Device Controller 마다 하나의 장치 드라이버(Device Driver) 를 가지게 된다. CPU 와 장치 컨트롤러는 병렬로 동작이 가능하기에 메모리 접근 주기(Memory Cycle) 도중 경쟁하게 된다.이런 공유 메모리에 대한 접근을 질서있게 하기 위해서 메모리 컨트롤러(Memory Controller)가 존재하고 컨트롤러는 메모리 접근을 동기화(Synchronize) 한다.위의 흐름을 가지고 다음을 읽자.1.2.1.1 InterruptsInterrupt는 CPU의 주의를 끌기 위해 사용되는 제어 신호로,Common Bus의 Control Bus를 통해 전달된다. 주된 종류는 다음과 같다:  I/O 작업 완료 알림: 디스크 읽기, 프린터 출력 등 작업 완료 시  입력 이벤트 알림: 키보드 입력, 마우스 클릭 등 사용자 인터랙션 발생 시  타이머 인터럽트 (Timer Interrupt): 일정 주기로 발생하여 OS가 CPU 제어권을 회수할 수 있게 함  소프트웨어 인터럽트 (System Call): 사용자 프로그램이 운영체제 기능을 요청할 때 발생  하드웨어 오류/예외 (Exception): 0으로 나누기, 잘못된 메모리 접근 등 오류 발생 시 자동으로 발생I/O 작업 완료 알림I/O 작업 완료 알림을 예로 들어보자.  CPU가 I/O 장치 A에 작업을 요청  운영체제의 Device Driver가 CPU 명령을 해당 장치가 이해할 수 있도록 해석 및 변환  변환된 명령이 Device Controller 하드웨어로 전달됨  Device Controller가 실제 장치에 명령을 내려 작업 수행  작업 완료 시, Device Controller가 Control Bus를 통해 CPU에 Interrupt를 전송  CPU는 Interrupt를 수신하고, 적절한 Interrupt Handler (Interrupt Service Routine, ISR)를 호출하여 후속 작업을 처리Interrupt Handler 를 보자.⭐️ Interrupt Handler운영체제 내부에서 Interrupt 가 발생했을 때, 실행되는 특수한 함수/코드 블록이다.CPU가 Control Bus 에서 Interrupt 를 받았을 때, 현재 실행 중이던 작업을 잠시 멈추고,즉시 고정된 위치(fixed location) 로 제어를 전환(Context Switching)한다.고정된 위치는 일반적으로 해당 인터럽트를 처리하기 위한 서비스 루틴(Interrupt Service Routine, ISR) 의 시작 주소를 포함한다. ISR이 실행되고, 그 작업이 완료되면 CPU는 중단된 게산을 다시 이어서 수행하게 된다. 인터럽트를 처리하는데 있어서 책에서 제공하는 방법은 두 가지 이다.      인터럽트 정보를 확인하는 일반 루틴(Generic Routine)을 호출한 뒤,해당 루틴이 인터럽트에 특화된 핸들러를 호출하는 방식이 일반적이고 단순한 방법이다.    인터럽트는 매우 자주 발생하기 때문에 빠르게 처리되어야 하므로 위 방법은 맞지 않고,속도를 높이기 위해 인터럽트 루틴들의 주소를 저장한 포인터 테이블(Interrupt Vector Table)을 사용한다면Generic Routine 을 거치지 않고도 테이블을 통해 직접 해당 ISR 으로 점프할 수 있다.  Interrupt Vector Table 을 이용한 방법을 보자.Interrupt Vector Table(Interrupt Vector)을 사용한 방식Interrupt Vector Table은 보통 메모리의 낮은 영역(처음 100여 개 위치)에 저장되며,각 위치에는 인터럽트 요청 번호(인터럽트 벡터)에 해당하는 서비스 루틴(ISR)의 주소가 저장된다.CPU는 인터럽트가 발생하면, 전달받은 고유 번호(벡터 번호)를 기반으로Interrupt Vector Table을 인덱싱하여 해당 ISR로 직접 점프한다.이 방식은 Windows, UNIX 등 대부분의 운영체제에서 사용된다.이때, 인터럽트 처리를 위해서는 CPU의 상태 정보(예: 레지스터 값)를 반드시 저장해야 한다.인터럽트 처리가 끝난 후에는 이 상태를 복원하여 중단된 작업을 재개할 수 있어야 한다.  ✅ 따라서 인터럽트 처리를 위해 필요한 조건은 다음과 같다.      ISR들의 주소가 저장된 Interrupt Vector Table이 필요    인터럽트 발생 시, CPU 상태 정보(Context)를 저장해야 함    ISR 실행 완료 후, CPU는 인터럽트 복귀 명령(Return from Interrupt)을 실행하여 원래 작업으로 복귀  그럼 이러한 이론들을 기반으로 실제 구현 단계에서는 어떤 구조가 필요할지 살펴보자.1.2.1.2 Implementation구현에 있어서 크게 다음 기능들을 구현해야 한다.  Interrupt Controller  Interrupt Chaining  Interrupt Priority LevelInterrupt Controller앞에서 인터럽트의 전체적인 처리 과정을 이해했으니, 이제 CPU가 인터럽트 신호를 어떻게 해석하고 처리하는지를 살펴보자.현대 컴퓨터에서는 여러 장치들이 서로 다른 방식으로 인터럽트를 발생시키기 때문에,CPU가 직접 해석하기엔 일관성이 부족하다. 이를 해결하기 위해 Interrupt Controller라는 하드웨어가 사용된다.Interrupt Controller는 장치들로부터 들어오는 Interrupt Request Line의 신호를 감지하고,해당 신호들의 우선순위를 판별하여, 가장 먼저 처리해야 할 인터럽트 번호(Interrupt Vector Number)를 CPU에 전달한다.CPU는 이 번호를 사용하여 Interrupt Vector Table을 인덱싱하고,해당 위치에 등록된 ISR(Interrupt Service Routine)을 실행한다.이를 위 요구사항과 더불어 추가하면:      Interrupt Controller는 Interrupt Request Line을 통해 인터럽트 신호를 감지    신호에 따라 판별된 인터럽트 번호를 CPU에 전달    CPU는 해당 번호로 Interrupt Vector Table을 인덱싱    ISR들의 주소가 저장된 Interrupt Vector Table이 필요    인터럽트 발생 시, CPU 상태 정보(Context)를 저장해야 함    ISR 실행 완료 후, CPU는 인터럽트 복귀 명령(Return from Interrupt)을 실행하여 원래 작업으로 복귀  이 과정을 통해 컴퓨터 시스템은 Interrupt Controller라는 하드웨어 자원을 활용하여 ISR을 안정적으로 실행할 수 있으며,운영체제 입장에서는 이를 Interrupt Controller라는 추상적인 객체로 간주하여 관리하게 된다.Interrupt ChainingInterrupt Vector Table은 말 그대로 인터럽트 번호를 통해 ISR 주소를 빠르게 찾아갈 수 있도록 설계된 테이블이다.그러나 장치 수가 많아질수록 각 장치에 대해 개별적인 각 장치마다 독립된 인터럽트 벡터 항목이 필요해지므로,공간 복잡도가 급격히 증가하게 된다.  예시      32번(키보드): 0x1000    33번(키보드): 0x1100    34번(키보드): 0x1200    35번(마우스): 0x1300    36번(디스크): 0x1400    37번(디스크): 0x1500…  장치가 추가될 때마다 번호를 계속 할당하면 테이블은 비대해져 공간 복잡도가 증가하고, 관리도 어렵다.또 다른 문제는, 예를 들어 USB와 같은 포트 기반 장치는여러 장치(USB 마우스, USB 키보드 등)가 공통된 인터럽트 번호(예: 64번)를 공유해야 하는 상황이 자주 발생한다.  예시      64번(USB): 0x8500…  이 경우 하나의 ISR이 모든 요청을 처리하게 되므로 요청이 많을수록 조건문이 복잡해지고, 시간 복잡도가 증가하게 된다.이러한 비효율을 줄이기 위해 Interrupt Chaining이라는 기법이 사용된다.이 방식에서는 Interrupt Vector Table의 각 항목이 ISR 하나의 주소가 아니라, ISR들을 연결한 연결 리스트의 시작점을 가리킨다.즉, 인터럽트 번호 40번에 대응되는 테이블 항목이 다음과 같은 구조를 갖는다:Index 40 → [ ISR1 ] → [ ISR2 ] → [ ISR3 ] → null이 구조는,  모든 장치에 대해 거대한 인터럽트 벡터 테이블을 만드는 공간 오버헤드와  하나의 ISR에서 모든 요청을 처리하는 시간 오버헤드 사이에서 절충된 설계를 하는 것이라고 볼 수 있다(널리 사용됨).Interrupt Priority Levels우선순위는 들어오는 Interrupt 에 대해 낮은 순위를 가지는 Interrupt 처리를 지연(defer)하게 하고모든 인터럽트를 완전히 차단하지 않아도 되게 해준다.따라서 더 높은 우선순위의 인터럽트가 실행 중인 낮은 우선순위의 인터럽트를 중단하고(preempt) 먼저 처리될 수 있도록 한다.  (예: 타이머 인터럽트가 키보드 입력보다 높은 우선순위로 처리됨)이는 인터럽트가 운영체제 전반에서 비동기 이벤트 처리를 위해 또는 다양한 목적을 위해 사용될 수 있으며시간에 대해 민감한 처리(time-sensitive processing)에 광범위하게 사용할 수 있으며,인터럽트를 효율적으로 처리하는 것이 시스템 성능을 좌우하게 하는 매우 중요한 요소이다.✒️ 용어Device Controller특정 유형의 장치를 제어하는 역할을 담당하는 하드웨어  Device Controller 1:n Devices 로 매핑 가능  로컬 버퍼 (Local Buffer) 와 특수 목적 레지스터 (Special-purpose Registers) 를 내장  주변 장치와 이 로컬 버퍼 간에 데이터를 전송하는 역할을 수행Common Bus(System Bus)컴퓨터 시스템 내의 모든 주요 구성 요소들을 연결시키는 하나의 공통된 통신선을 Common Bus 라고 하며,이를 통해 데이터를 주고 받는데, 이 통신선은 세 가지 유형의 신호선을 포함한다:  데이터 버스 (Data Bus): 데이터 전송  주소 버스 (Address Bus): 데이터의 위치 지정  제어 버스 (Control Bus): 동작 제어 및 동기화Shared Memory컴퓨터 시스템 내의 여러 구성 요소들이 공동으로 접근할 수 있는 메모리 공간(RAM의 일부)을 의미한다.Device Driver  Device Driver 1:1 Device Controller 로 매핑  컨트롤러의 세부 동작을 이해  일관된 인터페이스를 다른 장치들에게 뿌림Memory CycleCPU 또는 장치 컨트롤러와 같은 구성 요소가 메모리에 데이터를 읽거나 쓰기 위해 소요되는 단일 동작 주기를 의미하나의 메모리 사이클은  주소 지정 (Addressing) → CPU 또는 컨트롤러가 접근하고자 하는 메모리 주소를 지정  읽기 또는 쓰기 (R/W) → 지정된 주소로부터 데이터를 읽거나 데이터를 해당 위치에 기록  응답 대기 (Wait/Response) → 메모리가 요청을 처리하고 응답하는 데 걸리는 시간 포함의 과정을 행하는 시간이다.Memory Controller여러 구성요소의 메모리 동시 접근에 대해 충돌을 방지하고 접근을 동기화 하는 역할을 수행하는 하드웨어  공유 메모리에 대한 읽기/쓰기 요청 순서를 조정  구성 요소 간의 병렬 접근 충돌 방지  현대 시스템에서는 메모리 계층 구조에 따라 다양한 컨트롤러가 분산되어 존재추후에 나옴Synchronize여러 구성 요소가 동시에 자원에 접근하려고 할 때, 그 순서를 조정하여 충돌이나 오류가 없도록 처리를 제어하는 것을 의미Interrupt Request Line(IRQ Line)Interrupt Controller 와 직접적으로 연결되어 있는 2개의 하드웨어 선이며,하나는 Non-Maskable Interrupt(NMI), 다른 하나는 Maskable Interrupt 이다.  Non-Maskable Interrupt: 절대 무시할 수 없는 신호를 담당(반드시 처리), 메모리 오류, 하드웨어 고장, CPU 팬 멈춤, …  Maskable Interrupt: 일반적인 인터럽트(보편적으로 인터럽트는 이걸 말함), 중요한 계산중이라면 이 Interrupt 로 들어온건 무시 가능Context Switching하나의 프로세스가 CPU를 사용 중인 상태에서 다른 프로세스가 CPU를 사용하도록 하기 위해, 이전의 프로세스의 상태(context)를 저장하고 새로운 프로세스의 상태를 적재(load)하는 작업🔗 출처  도서: Operating System Concepts 10th Edition"
    },
  
    {
      "title": "1.1 What Operating Systems Do",
      "url": "/seonghun120614/computerscience/os/2025/06/06/1.1-what-operating-systems-do.html",
      "date": "2025-06-06",
      "content": "Operating System 이 컴퓨터에서 어떤 역할을 하는지 본다. 이 글이 우리 학과 학생들에게 도움이 됐으면 한다.📂 목차  1.1.1 User View  1.1.2 System View  1.1.3 Defining Operating Systems          본질적인 정의      운영체제의 구성 범주      Modern OS      📚 본문어려운 내용인 만큼 영어가 많이 등장한다. 내가 대학 커리큘럼의 정리했던 내용을 다시 읊는다. 외우는게 아니라 몸으로 받아들인다.컴퓨터 시스템을 살펴보자. 크게 4가지로 나뉠 수 있다.  Hardware: CPU, I/O Devices, Volatile Memory, Non-volatile Memory, System Bus, Motherboard, PSU, Interface(Socket)  Operating System: 하드웨어를 제어 및 하드웨어 자원의 사용을 관리(최근에는 Hardware 까지의 영역도 일부 포함된다 - 교수님께서 그러셨다)  Application: 운영체제(OS) 위에서 동작하며, 특정 목적을 달성하기 위해 실행 가능한(executable) 독립적인 소프트웨어.  User: 우리들, end point 에서 계산 가능한 기기들을 다루는 행위자1.1.1 User View사용자가 컴퓨터를 바라보는 관점으로 가보자. 사용자가 컴퓨터를 볼 때는 사용 중인 인터페이스에 따라 달라진다.일반적인 개인용 컴퓨터 환경은 단일 사용자가 시스템 자원을 전부 독점적으로 사용하는 것을 전제로 설계되어 있다. 부수적으로는 성능(performance)과 보안(security)에도 일정 부분 신경을 쓰지만, 자원 활용률(resource utilization)—즉, 시스템 자원을 여러 사용자나 프로세스 간에 어떻게 효율적으로 배분할지—는 고려 대상이 아니다.따라서 사용자는 OS에 대해 다음과 같이 인식한다:  단일 사용자 환경  사용자 편의성(ease of use) 최우선 ⭐️  성능/보안은 부가적 고려  자원 공유 최적화 중요하지 않음사용자들은 위 사항들을 기준 삼아서 다음 OS 를 맞게 사용하게 된다:  Mobile Devices: UI 를 통한 직접적이고 시각적인 피드백 제공  Desktop/Laptop: I/O Device 를 통한 상호작용  Embedded Computers: 사용자 개입이 거의 없는 자동화된 장치따라서 사용자들은 편의성에 맞는 인터페이스를 선택하여 목적과 사용자 행동 방식에 따라 OS의 인식이 완전히 달라지고, 정리하면 다음과 같다.  운영체제 = 인터페이스(행동 방식과 목적)에 따른 인식 → Mobild Devices, Desktop/Laptop, Embedded Systems1.1.2 System View첫번째로 컴퓨터 시스템 입장에서 OS는 하드웨어와 가장 밀접하게 연결된 프로그램이며 OS는 자원할당자(Resource Allocator)의 기능을 수행한다고 이해할 수 있다. 컴퓨터 시스템은 문제를 해결하기 위해 다양한 자원이 필요한데 다음과 같다:  CPU Time  Memory Space  Storage Space  I/O Devices운영체제는 이 자원들을 관리하고, 수많은 동시적 요청들을 알맞게 처리할 수 있는 능력을 가져야 한다. 운영체제는 어떤 자원을 어떤 프로그램과 사용자에게 어떻게 배분할 것인지 결정하는 일을 담당하게 되고, 그 목적은 효율성, 공정성을 가져야 한다.두번째로 컴퓨터 시스템은 OS를 입출력 장치와 사용자 프로그램을 제어하는 제어 프로그램(Control Program)으로도 볼 수 있다. 운영체제는 사용자 프로그램의 실행을 관리하고 에러 발생이나 시스템의 오용을 방지하는 역할을 수행하며 특히 입출력 장치의 제어와 동작에 큰 비중을 둔다.System View 에서는 다음과 같이 정리 할 수 있다.  운영체제 = 자원 관리자 (Resource Allocator) → CPU, 메모리, I/O 등의 자원을 효율적이고 공정하게 할당  운영체제 = 제어 프로그램 (Control Program) → 사용자 프로그램 실행을 관리하고 오류와 오용을 방지 → I/O 장치 제어에 특히 집중1.1.3 Defining Operating Systems운영체제는 하나로 단정할 수 없는 포괄적 개념이며, 시대와 용도에 따라 진화해 왔다.  초기: 하드웨어 제어를 단순화하는 수단으로 등장  발전: 문제 해결을 지원하는 응용 프로그램과의 연결 고리 역할 수행  오늘날: 모바일/임베디드 환경 등 다양한 분야에 적용되며 구조 복잡도 증가본질적인 정의  컴퓨터를 사용 가능하게 만드는 공통 기능 집합  입출력 제어, 자원 관리, 응용 프로그램 실행 환경을 제공운영체제의 구성 범주위를 총합하여 볼때, 운영체제는 다음과 같이 경계를 나눌 수 있다:  Kernel: 항상 실행 중이며, 자원과 프로세스를 직접 관리하는 핵심 소프트웨어  System Programs: 운영체제 기능을 보조하는 도구 (예: 셸, 파일 유틸리티)  Application Programs: 사용자 목적의 소프트웨어, OS와는 직접 관련 없음  운영체제 = 보통 커널을 중심으로 정의되며, 시스템 프로그램은 포함될 수도 있고, 애플리케이션은 별개로 취급됨Modern OS오늘날 모바일 기기를 위한 운영체제를 살펴보자면,  모바일 OS (예: iOS, Android)는 커널 + 미들웨어 + 일부 시스템 프로그램까지 포함  미들웨어(Middleware)는 DB, 멀티미디어, 그래픽 등 고급 기능을 프레임워크 형태로 제공하여 개발자 편의성을 높임운영체제를 구성하는 기능 수가 점점 증가하고 있으며 코어 커널(Core Kernel) 뿐 아니라 미들웨어(Middleware) 까지도 포함된다. 따라서 새로운 용어까지 포함된 형태가 현대적인 시각에서 OS 를 바라보는 가장 가까운 정의가 될 것이다.📌 현대적 정의:  운영체제 = Kernel + Middleware Frameworks + Partial System Programs✒️ 용어Middleware미들웨어는 커널과 애플리케이션 사이에서 개발자를 위한 공통 기능을 제공하는 중간 계층 소프트웨어이다.🔗 출처  도서: Operating System Concepts 10th Edition"
    },
  
    {
      "title": "보조. Bean 이란",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/06/subsidiary-bean-definition.html",
      "date": "2025-06-06",
      "content": "Bean 개념 설명 및 사용법🪛 한계점Spring 을 사용함에 있어 효율적인 Java 의 인스턴스 관리가 필요하다.📂 목차  Bean Lifecycle Scope  Bean 수동 등록하기  Bean Component Scan 방식으로 자동 등록하기  @Autowired 로 등록된 Bean 가져오기📚 본문Bean 이라는 것은 순수 자바에서 new 로 생성하는 인스턴스들을 가르키고 만약 Spring 이 이를 관리하게 된다면 이를 Bean 이라고 부르게 된다.Bean 은 RAM -&gt; JVM -&gt; IoC 안에 있으며 한 번 등록이 되면 이를 어떤 클래스에서든 쉽게 쉽게 가져올 수 있고 객체의 생명주기를 자동으로 쉽게 관리할 수 있다. 이런 이점 때문에 Bean 을 쓰고 Bean 으로 등록하려면 @Configuration 클래스 안에 @Bean 을 메서드에 넣어주면 된다.Bean Lifecycle ScopeBean 의 관리 범위는 다음과 같다.  singleton(기본값): 컨테이너 당 하나만 생성  prototype: 요청 시마다 새로 생성  request: HTTP 요청마다 하나(웹에서만 적용되는 인자)  session: HTTP 세션마다 하나  application: servlet context마다 하나Bean 수동 등록하기import org.springframework.context.annotation.*;@Configurationpublic class MyConfig {    @Bean    public OrderService orderService() {        return new OrderService();    }    public static class OrderService {        public String process() {            return \"Order processed\";        }    }}위와 같이 작성하면 OrderService 클래스는 Bean으로 등록될 때 기본 스코프가 singleton이기 때문에 하나만 생성되며, 이 OrderService를 의존하는 다른 Bean들에게 자동으로 주입된다. 이러한 과정을 DI (Dependency Injection)이라고 한다.Bean Component Scan 방식으로 자동 등록하기@ComponentScan 은 Spring이 자동으로 Component 를 찾아 Bean 으로 등록하도록 범위를 지정하는 애너테이션이다. Spring Boot에서는 보통 자동으로 포함되지만, 커스터마이징이 필요할 땐 직접 사용해야 한다.basePackages 로 String[]의 인자를 받고 해당 String 의 패키지에 있는 모든 @Component 들을 Bean에 등록하게 된다.import org.springframework.context.annotation.*;@Configuration@ComponentScan(basePackages = {        \"com.example.study.config\",        \"com.example.study.service\"})public class MyConfig { }config, service 패키지들의 Component 들을 전부 가져와 Bean 으로 등록한다.등록된 Bean 가져오기스프링부트 IoC 컨테이너에는 Bean 들이 등록되어 있는 테이블이 있다. 이 테이블에서 Bean을 가져오려면 @Autowired 애너테이션을 변수 선언이나 메서드, 인자에 사용하여 들고 올 수 있다. 만약 UserRepository 라는 클래스를 Bean에 등록했다고 해보자. 다른 클래스에서 다음과 같이 써주면 된다.....public class AppService {    ...    @Autowired    public AppService(AppProperties appProperties) {        this.appProperties = appProperties;    }    ...}appProperties 는 자동적으로 @Autowired를 통해 Bean 에 등록된 객체를 가져오게 된다.🔗 출처  도서 Spring Boot in Practice📁 관련 글  2. Spring Boot Custom Property✒️ 용어@ComponentScan@ComponentScan 애너테이션은 Spring이 자동으로 @Component 의 Bean을 찾아 등록하도록 범위를 지정하는 애너테이션이다. Spring Boot에서는 보통 자동으로 포함되지만, 커스터마이징이 필요할 땐 직접 사용해야 한다."
    },
  
    {
      "title": "2. Spring Boot Configuration",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/06/2.-spring-boot-configuration.html",
      "date": "2025-06-06",
      "content": "Spring Application 구성 정보 설정 및 properties 파일 세팅🪛 한계점Application 의 설정값만 바꿔 기능을 서비스와 환경에 맞게 조절하는게 필요하다.📂 목차  Spring Application 의 setDefaultProperties() 메서드로 구성 정보 설정하기  Spring Application 의 properties 파일로 구성 정보 설정하기          properties 파일을 @PropertySource 로 매핑시켜 코드 단에서 다루기      CLI 수준에서 구성 정보를 설정하기        구성 정보 집합 Configuration 의 정보를 출력해보기          @EnvironmentCapable 인터페이스      @PropertyResolver 인터페이스        application.properties 를 읽는 위치  내부적 설정 파일 우선순위  총체적 설정 파일 우선순위📚 본문개발, 테스트, 스테이징, 상용 환경 등의 여러 환경에서 어플리케이션의 설정 정보를 다르게 가져갈 수 있게 해야한다. 이는 어플리케이션이 비대해지면서 더 관리하기 어려워진다. 해야 할 것은 환경이 달라지면 어플리케이션 소스코드는 거의 달라지지 않아야 하며, 보안 설정, DB 초기화, DB 설정 정보 등이 관리되어야 한다.Spring Application 의 setDefaultProperties() 메서드로 구성 정보 설정하기Spring Boot 는 SpringApplication 클래스를 사용하여 어플리케이션 설정 정보를 저장한다. 클래스 자체가 setDefaultProperties() 메서드로 Properties 혹은 Map&lt;String, Object&gt; 의 인자를 받고 메서드 호출 시 설정 정보가 어플리케이션에 적용된다. 아래는 설정 정보를 코드 단에서 정의하는 과정이다.import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import java.util.*;@SpringBootApplicationpublic class ExampleApplication {    public static void main(String[] args) {        SpringApplication springApplication = new SpringApplication(ExampleApplication.class);        Properties properties = new Properties();        properties.setProperty(\"spring.config.import\", \"additional-application.properties\");        properties.setProperty(\"spring.config.test\", \"hi\");        springApplication.setDefaultProperties(properties);        springApplication.run();    }}소스코드로 적용하면 한 번 정의 시 나중에 바뀌지 않기 때문에 나중에 변경안해도 되는 설정 정보만 넣는게 좋다.Spring Application 의 properties 파일로 구성 정보 설정하기application.properties 를 통해 설정 정보를 key/value 형식으로 정의 가능하다.            key      value      description                  server.shutdown      graceful, immediate      immediate가 기본값이며, 실행 중인 요청에 대해 즉시 끊을지, 아니면 요청을 완료하고 끊을지 여부              spring.lifecycle.timeout-per-shutdown-phase      ISO-8601 duration-like 표기법      graceful shutdown 에 대해 요청 완료를 기다리는 시간을 설정한다.              server.port      [open port number]      어떤 열려 있는 포트 번호로 request 를 받을지 설정, 기본 8080              spring.config.import      classpath:(파일명).properties      해당 파일의 설정 정보를 읽어 반영한다.              spring.config.on-not-found      ignore, warn, fail      설정 파일의 부재에 대한 피드백, 기본값은 ignore              …      …      …      # application.propertiesspring.application.name=studyserver.port=8080server.shutdown=gracefulspring.lifecycle.timeout-per-shutdown-phase=1mspring.config.import=classpath:additional-application.propertiesspring.config.on-not-found=ignore# Logger 에서 나중에 다룸logging.level.root=INFOlogging.level.com.example=DEBUGlogging.file.name=app.log# DB / JPA Configure 나중에 다룸spring.datasource.url=jdbc:h2:mem:studyspring.datasource.username=rootspring.datasource.password=spring.datasource.driverClassName=org.h2.Driverspring.jpa.hibernate.ddl-auto=updatespring.jpa.show-sql=truespring.jpa.properties.hibernate.format_sql=true# 웹 서버 설정server.servlet.contextPath=/apiserver.error.includeMessage=alwaysserver.compression.enabled=true# Cache 설정spring.cache.type=simplespring.cache.cache-names=users,productsspring.cache.caffeine.spec=maximumSize=500,expireAfterWrite=60s# Securityspring.security.user.name=adminspring.security.user.password=1234spring.security.user.roles=USER,ADMIN# Actuatormanagement.endpoints.web.exposure.include=*management.endpoint.shutdown.enabled=truemanagement.server.port=9091# Filespring.servlet.multipart.max-file-size=10MBspring.servlet.multipart.max-request-size=20MB# Messagespring.messages.basename=messagesspring.messages.encoding=UTF-8...추후에 다룬다.properties 파일을 @PropertySource 로 매핑시켜 코드 단에서 다루기위처럼 정적으로 properties 파일을 생성해서 key-value 를 입력 할 수도 있는데, 코드 단에서 이 설정 정보들을 가져오고 싶으면 class 로의 매핑을 시키게 할 수 있다.# custom-application.propertiesusername=sapassword=1234위와 같이 세팅해주자.import org.springframework.context.annotation.*;@Configuration@PropertySource(\"classpath:custom-application.properties\")public class CustomConfiguration { }이제 실행 시 Spring 은 @Configuration 가 붙은 클래스들을 환경 설정으로 받아들이고, @PropertySource 애너테이션을 통해 클래스패스의 custom-application.properties 를 가져와 구성 정보를 읽어 등록시키게 된다.CLI 수준에서 구성 정보를 설정하기./gradle build 작업을 수행 시 빌드된 파일 .jar 이 생성됨을 볼 수 있는데, 해당 .jar은 executable 하며 이를 실행하기 위해서는 java -jar (경로).jar 을 터미널에 입력해주면 된다.실행 시 root 의 /build/libs/ 에 .jar 파일 2개가 생성됨을 볼 수 있다. -plain이 붙은 것은 Spring Boot 실행에 필요한 의존성을 포함하지 않은 순수 클래스 파일만 들어있는 JAR 이다. 따라서 실행이 불가하고,다른 .jar 파일이 executable 하다. 해당 build를 할때 파일명을 지정해주고 싶다면,// build.gradletasks.named('bootJar') {\tarchiveFileName = 'myapp.jar'}를 입력해준다.이제 java -jar /build/libs/myapp.jar 을 통해 실행시키면 정상적으로 서버가 올라감을 볼 수 있다.여기서 test 없이 build를 하고 싶을 수도 있는데, 이때는 ./gradle build -x test로 옵션을 준다.CLI에서 서버를 구동시킬 때에도 인자를 주어서 args에 전달을 해 직접적으로 구성 정보를 수정 할 수도 있다.java -jar /build/libs/myapp.jar --spring.config.name=thisisconfig구성 정보 집합 Configuration 의 정보를 출력해보기실행 후에 서버에서는 어떤 형태로 properties 가 존재하는지 추적이 되어야 한다. 실제로 적용이 완료가 되었는지 보고 싶다면 run() 의 반환값을 Context 로 받아서 Context 가 가지는 Environment Bean 을 들고와서 key 에 대한 값이 잘 있는지 봐야 한다.@EnvironmentCapable 인터페이스import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.context.*;import org.springframework.core.env.*;@SpringBootApplicationpublic class MyApplication {    public static void main(String[] args) {        SpringApplication springApplication = new SpringApplication(MyApplication.class);        ConfigurableApplicationContext context = springApplication.run(args);    }}위를 통해 확인이 가능하다. 여기서 ConfigurableApplicationContext 인터페이스는 ApplicationContext 인터페이스를 상속받는다.ApplicationContext 인터페이스는 다시 EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver 인터페이스들을 상속받게 된다.  ConfigurableApplicationContext          ApplicationContext                  EnvironmentCapable,  ListableBeanFactory,  HierarchicalBeanFactory,  MessageSource,  ApplicationEventPublisher,  ResourcePatternResolver                    각 의미는 다음과 같다.  @EnvironmentCapable: Environment 객체를 반환할 수 있는 기능을 제공, getEnvironment()  @ListenableBeanFactory: 이름 기반 혹은 타입 기반으로 여러 개의 Bean 을 조회 할 수 있는 기능을 제공, getBeansOfType(Class&lt;T&gt; type), getBeanDefinitionNames()  @HierarchicalBeanFactory: 부모-자식 구조로 된 컨테이너 체계 지원, getParentBeanFactory(), containsLocalBean(String name)  @MessageSource: 다국어 메시지(i18n)을 관리하는 인터페이스, getMessage(String code, Object[] args, Locale locale)  @ApplicationEventPublisher: Spring 의 이벤트 발행기 인터페이스, publishEvent(ApplicationEvent event)  @ResourcePatternResolver: 리소스 패턴을 통해 파일 등을 조회하는 기능을 제공, getResource(String locationPattern), 용도는 file:, classpath: 등을 url에 쓸 수 있도록 하여 간편한 path 기능 제공우선은 @EnvironmentCapable 만 보자. 이를 통해 다음 메서드를 실행시킨다.@PropertyResolver 인터페이스import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.context.*;import org.springframework.core.env.*;@SpringBootApplicationpublic class MyApplication {    public static void main(String[] args) {        SpringApplication springApplication = new SpringApplication(MyApplication.class);        ConfigurableApplicationContext context = springApplication.run(args);        Environment env = context.getBean(Environment.class);        System.out.println(\"\\n\\n\\n\");        System.out.println(env.getProperty(\"username\"));        System.out.println(env.getProperty(\"password\"));        System.out.println(\"\\n\\n\\n\");    }}@Environment 인터페이스는 @PropertyResolver 인터페이스를 상속받는다. PropertyResolver 는 말 그대로 String 으로 된 Property 정보를 key/value 로 잘 해석하여 객체로 변환하는 역할을 한다.  @PropertyResolver: 어플리케이션 설정 값들을 다양한 소스에서 읽고, 가공하고, 변환하는 기능을 제공, containsProperty(String key), getProperty(), getRequiredProperty(), resolvePlaceholders() 등의 메서드를 지원한다.실행시 제대로 출력됨을 볼 수 있다.application.properties 를 읽는 위치  classpath: 루트  classpath:config 패키지  (현재 디렉터리)  (현재 디렉터리)/config 디렉터리  /config 디렉터리의 바로 하위 디렉터리의 범위이며, 이 위치 말고도 spring.config.location 프로퍼티를 사용하여 다른 설정 파일을 읽을 수 있다.이는 CLI 로 타 구성정보를 불러오고 싶을때 유용하다. 상대경로(src/main/resource/로 시작), 절대경로가 가능하다.그리고 만약 location 을 지정했는데 해당 파일이 부재 시에는 exception 이 발생하기 때문에 이런 예외를 발생시키고싶지 않다면 --spring.config.location=optional:(경로)로 CLI에 넣어주면 되겠다.내부적 설정 파일 우선 순위  application JAR 파일 안의 application.properties 파일  application JAR 파일 안의 application-{profile}.properties 파일  application JAR 파일 밖의 application.properties 파일  application JAR 파일 밖의 application-{profile}.properties 파일여기서 {profile} 은 --spring.profiles.active={profile}로 지정할 수 있다. 늦게 로딩되는 파일이 정보를 덮어쓰기 때문에 4번인 application JAR 파일 밖의 application-{profile}.properties 가 위의 파일들 보다 우선이다.총체적 설정 파일 우선 순위보통 스프링 부트하면 properties 에 설정된 정보를 읽어 사용하는게 관례이다.하지만 만약 컴퓨터 자체의 환경 변수에 properties 에 정의된 변수 A가 정의되어 있다면,properties 에서 A를 어떤 값으로 정의한들, 환경 변수의 값을 우선으로 하여 값이 설정된다.또한 환경 변수만 있는게 아니라 CLI 자체에서 args 로 넘겨주는 인자에서도 이를 설정할 수 있을 것이다.따라서 정리하면 다음과 같다:  SpringApplication  @PropertySource  설정 정보 파일(application.properties)  운영 체제 환경 변수(ENV)  명령행 인자(CLI)🔗 출처  도서 Spring Boot in Practice✒️ 용어classpathJVM 이 리소스를 찾기 위해 검색하는 디렉토리, JAR 파일들의 경로 목록이며, Spring Boot 은 다음 폴더들을 포함한다.  src/main/java  src/main/resources  dependencies: JAR 로 포함된 외부 라이브러리  build/classes/java/main: Gradle@SpringBootApplicationSpringBootApplication 의 entry point 에 사용하는 애너테이션이며, 다음 애너테이션들을 포함한다.  @Configuration: 이 클래스가 설정 클래스임을 명시  @EnableAutoConfiguration: 자동 설정 활성화하여 classpath 에 있는 라이브러리 기반으로 자동 Bean 등록  @ComponentScan(basePackage=\"\"): 같은 패키지 및 하위 패키지를 스캔하여 Bean 으로 등록@BeanSpring 은 IoC 라는 컨테이너가 있는데, 이 컨테이너가 관리하는 대상 객체가 Bean 이다. 글을 참고하자."
    },
  
    {
      "title": "1. Spring Boot 처음 시작하기",
      "url": "/seonghun120614/computerscience/java/spring/2025/06/05/1.-spring-boot-start.html",
      "date": "2025-06-05",
      "content": "Spring Boot 기본 설명🪛 한계점Java EE 의 복잡성과 비효율성을 극복하기 위해 나온 단순하면서 테스트 가능한 POJO 기반 개발Java EE 의 한계  많은 XML 설정 및 복잡한 라이프사이클 관리  비즈니스 로직 작성 시도에도 무거운 클래스 계층 요구  테스트 어려움 (EJB 중심 구조)이로 인해 나온게 Spring Framework 인데, 여기서도 단점은  설정이 너무 많다  프로젝트 초기 셋업 시간이 길다  톰캣 따로 설치 &amp; 배포가 필요하다이로 인해 나온게 Spring Boot 이다.📂 목차  Spring Boot          spring-boot      spring-boot-autoconfigure      spring-boot-starter      spring-boot-CLI      spring-boot-actuator      spring-boot-actuator-autoconfigure      spring-boot-test      spring-boot-loader      spring-boot-devtools      📚 본문Spring 을 쉽게 시작하고, 실무 중심으로 접할 수 있도록 ‘거시적인’ 개념을 본다.Spring BootSpring Boot 는 Spring Framework 의 확장판으로 설정 없이도 어플리케이션을 빠르게 실행할 수 있게 도와준다.자주 사용하는 Spring 컴포넌트를 보자.spring-boot스프링 부트의 기본 컴포넌트로 다른 컴포넌트를 사용할 수 있도록 지원한다.spring-boot 의 SpringApplication 클래스는 spring-boot 에 내장된 웹 서버 기능 지원, 어플리케이션 설정 정보 외부화 기능 지원 등의 다양한 서로 다른 컴포넌트들을 연결한다.            항목      Spring Boot Application      Spring Application                  설정 방식      자동 설정 (@SpringBootApplication)      수동 설정 (XML 또는 Java Config)              서버 실행      내장 Tomcat/Jetty 등 사용, JAR로 실행 가능      외부 WAS 필요, WAR로 배포              실행 진입점      main()에서 SpringApplication.run() 호출      외부 서버의 web.xml에서 초기화              의존성 관리      spring-boot-starter-*, BOM으로 버전 관리      개별 라이브러리 수동 설정              개발 생산성      빠름 – 설정 없이 바로 시작 가능      느림 – 많은 설정 필요              파일 구조      application.yml, Java Config 중심      applicationContext.xml 등 XML 설정 사용              테스트 및 도구      DevTools, Actuator 등 내장 도구 제공      별도 설정 필요      spring-boot-autoconfigureSpring Application 을 자동 구성 할 수 있게 하는 Component이다.테스트 환경, 개발 환경, 배포 환경은 서로 다르다. 또한 DB 연결도 어떤 Database 를 쓰는지에 따라 다르다. 그에 맞는 Spring Application 의 설정 값들을 자동으로 바꾸도록 한다.spring-boot-starter개발자 편의를 위해 제공되는 패키지들의 모음이다.여러 기술을 개발자에게 제공하여 이 스타터가 없다면 쓸 패키지들을 일일히 다 써서 설정해줘야 한다.spring-boot-CLIGroovy 코드를 컴파일하고 실행할 수 있는 개발자 친화적 명령행 도구이다.파일 내용을 감지하는 기능이 있어 어플리케이션 수정 시 직접 재부팅을 할 필요가 없다.spring-boot-actuator스프링 부트 어플리케이션을 모니터링한다.액추에이터 엔드포인트를 제공하고, 어플리케이션의 여러 상태를 감지할 수 있고 미리 정의된 여러 가지 액추에이터 엔드포인트를 사용하거나 커스텀 액추에이터 엔드포인트를 사용하여 새로운 엔드포인트를 만들 수도 있다.spring-boot-actuator-autoconfigure클래스를 기반으로 액추에이터 엔드포인트를 자동으로 구성해주는 컴포넌트이다.만약 Micrometer 의 의존관계가 있다면, 스프링부트가 자동으로 MetricsEndpoint 를 액추에이터 엔드포인트로 추가해준다.spring-boot-test스프링 부트 어플리케이션 테스트 케이스 작성에 필요한 Annotation 과 메서드가 포함되어 있다.spring-boot-loader스프링 부트 어플리케이션을 실행가능한 하나의 JAR 파일로 패키징 하는데 필요한 모든 라이브러리들과 독립 실행형으로 실행되는 내장 웹 서버를 포함하고 있다. 이 컴포넌트는 독립적으로 사용하지 않고, Maven, Gradle 플러그인과 함께 사용된다.spring-boot-devtools스프링 부트 어플리케이션 개발을 도와주는 여러 가지 개발자 도구를 지원한다.코드 변경 자동 감지, HTML 변경 시 자동 새로고침 LiveReload 기능이 있다.🔗 출처  도서 Spring Boot in Practice✒️ 용어POJOPain Old Java Object 의 약자로,  지향적인 원리에 충실하면서 환경과 기술에 종속되지 않고, 필요에 따라 재활용될 수 있는 방식으로 설계된 오브젝트이다.  Java 나 Java 에서 정의한 규정만 따른다.  환경에 독립적이어야 한다.Component정의된 기능을 수행하고, 재사용이 가능한 소프트웨어 모듈이다.외부와의 인터페이스가 명확하기 때문에 독립적으로 배포, 수정, 교체, 조립이 가능한 단위다.Spring 에서는 중요한 개념으로 클래스에 애너테이션으로 붙여 정의 할 수 있다.GroovyJava 를 확장한 동적 객체 지향 프로그래밍 언어이다. 여기서 동적이라는 말은 변수 타입을 컴파일이 아니라 런타임때 정한다. 자바 코드를 그대로 쓸 수도 있고, 스크립팅 언어이다.Annotation클래스, 메서드, 필드, 파라미터 등에 부착하여 프레임워크나 컴파일러가 특정 작업을 하도록 만드는 기능이다.책임 분리가 가능하도록 하며, 이 덕분에 Single Responsibility 를 챙겨갈 수 있다.또한 사용자 정의 애너테이션을 정의할 수도 있다.MavenJava 기반의 프로젝트 빌드 자동화 도구이다.의존성 관리, 빌드 테스트, 패키징, 배포 등을 스크립트화하여 자동화한다.GradleJava 기반의 프로젝트 빌드 자동화 도구이다.의존성 관리, 빌드 테스트, 패키징, 배포 등을 스크립트화하여 자동화한다."
    }
  
]